[
  {
    "id": "arxiv-2510.11717v1",
    "arxivId": "2510.11717v1",
    "title": "Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams",
    "abstract": "Event cameras offer various advantages for novel view rendering compared to synchronously operating RGB cameras, and efficient event-based techniques supporting rigid scenes have been recently demonstrated in the literature. In the case of non-rigid objects, however, existing approaches additionally require sparse RGB inputs, which can be a substantial practical limitation; it remains unknown if similar models could be learned from event streams only. This paper sheds light on this challenging open question and introduces Ev4DGS, i.e., the first approach for novel view rendering of non-rigidly deforming objects in the explicit observation space (i.e., as RGB or greyscale images) from monocular event streams. Our method regresses a deformable 3D Gaussian Splatting representation through 1) a loss relating the outputs of the estimated model with the 2D event observation space, and 2) a coarse 3D deformation model trained from binary masks generated from events. We perform experimental comparisons on existing synthetic and newly recorded real datasets with non-rigid objects. The results demonstrate the validity of Ev4DGS and its superior performance compared to multiple naive baselines that can be applied in our setting. We will release our models and the datasets used in the evaluation for research purposes; see the project webpage: https://4dqv.mpi-inf.mpg.de/Ev4DGS/.",
    "authors": [
      "Takuya Nakabayashi",
      "Navami Kairanda",
      "Hideo Saito",
      "Vladislav Golyanik"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:59:55.000Z",
    "updatedAt": "2025-10-13T17:59:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11717v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11717v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11718v1",
    "arxivId": "2510.11718v1",
    "title": "CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images",
    "abstract": "Recent advances in Large Language Models (LLMs) and Vision Language Models (VLMs) have shown significant progress in mathematical reasoning, yet they still face a critical bottleneck with problems requiring visual assistance, such as drawing auxiliary lines or plotting functions to solve the problems. Most LLMs and VLMs are constrained to text-only reasoning chains, while multimodal unified models that can generate interleaved text and images lack the necessary precision and controllability for such tasks. To address this, we propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for \"thinking with images\" in mathematics. Our approach leverages the VLM to generate text reasoning as well as executable plotting code, which is then rendered into images as \"visual thought\", to solve mathematical problems. To achieve this, we first construct Math-VR, the first large-scale, bilingual dataset and benchmark for Mathematics problems with Visual Reasoning, comprising 178K samples. Second, to create high-quality training data, we develop a state-of-the-art image-to-code converter specialized for parsing complex mathematical figures into codes. Finally, using these training data, we train the CodePlot-CoT model for solving mathematical problems. Experimental results show that our model achieves up to 21% increase over base model on our new benchmark, fully validating the efficacy of our proposed code-driven reasoning paradigm. Our work opens a new direction for multimodal mathematical reasoning and provides the community with the first large-scale dataset, comprehensive benchmark, and strong approach for such problems. To facilitate future research, we make our datasets, code, and pretrained models publicly available at https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT.",
    "authors": [
      "Chengqi Duan",
      "Kaiyue Sun",
      "Rongyao Fang",
      "Manyuan Zhang",
      "Yan Feng",
      "Ying Luo",
      "Yufang Liu",
      "Ke Wang",
      "Peng Pei",
      "Xunliang Cai",
      "Hongsheng Li",
      "Yi Ma",
      "Xihui Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:59:55.000Z",
    "updatedAt": "2025-10-13T17:59:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11718v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11718v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11715v1",
    "arxivId": "2510.11715v1",
    "title": "Point Prompting: Counterfactual Tracking with Video Diffusion Models",
    "abstract": "Trackers and video generators solve closely related problems: the former analyze motion, while the latter synthesize it. We show that this connection enables pretrained video diffusion models to perform zero-shot point tracking by simply prompting them to visually mark points as they move over time. We place a distinctively colored marker at the query point, then regenerate the rest of the video from an intermediate noise level. This propagates the marker across frames, tracing the point's trajectory. To ensure that the marker remains visible in this counterfactual generation, despite such markers being unlikely in natural videos, we use the unedited initial frame as a negative prompt. Through experiments with multiple image-conditioned video diffusion models, we find that these \"emergent\" tracks outperform those of prior zero-shot methods and persist through occlusions, often obtaining performance that is competitive with specialized self-supervised models.",
    "authors": [
      "Ayush Shrivastava",
      "Sanyam Mehta",
      "Daniel Geng",
      "Andrew Owens"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:59:46.000Z",
    "updatedAt": "2025-10-13T17:59:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11715v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11715v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11713v1",
    "arxivId": "2510.11713v1",
    "title": "Are Large Reasoning Models Interruptible?",
    "abstract": "Large Reasoning Models (LRMs) excel at complex reasoning but are traditionally evaluated in static, \"frozen world\" settings: model responses are assumed to be instantaneous, and the context of a request is presumed to be immutable over the duration of the response. While generally true for short-term tasks, the \"frozen world\" assumption breaks down in modern reasoning tasks such as assistive programming, where models may take hours to think through problems and code may change dramatically from the time the model starts thinking to the model's final output. In this work, we challenge the frozen world assumption and evaluate LRM robustness under two realistic dynamic scenarios: interruptions, which test the quality of the model's partial outputs on a limited budget, and dynamic context, which tests model adaptation to in-flight changes. Across mathematics and programming benchmarks that require long-form reasoning, static evaluations consistently overestimate robustness: even state-of-the-art LRMs, which achieve high accuracy in static settings, can fail unpredictably when interrupted or exposed to changing context, with performance dropping by up to 60% when updates are introduced late in the reasoning process. Our analysis further reveals several novel failure modes, including reasoning leakage, where models fold the reasoning into their final answer when interrupted; panic, where under time pressure models abandon reasoning entirely and return incorrect answers; and self-doubt, where performance degrades while incorporating updated information.",
    "authors": [
      "Tsung-Han Wu",
      "Mihran Miroyan",
      "David M. Chan",
      "Trevor Darrell",
      "Narges Norouzi",
      "Joseph E. Gonzalez"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T17:59:35.000Z",
    "updatedAt": "2025-10-13T17:59:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11713v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11713v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11712v1",
    "arxivId": "2510.11712v1",
    "title": "DiT360: High-Fidelity Panoramic Image Generation via Hybrid Training",
    "abstract": "In this work, we propose DiT360, a DiT-based framework that performs hybrid training on perspective and panoramic data for panoramic image generation. For the issues of maintaining geometric fidelity and photorealism in generation quality, we attribute the main reason to the lack of large-scale, high-quality, real-world panoramic data, where such a data-centric view differs from prior methods that focus on model design. Basically, DiT360 has several key modules for inter-domain transformation and intra-domain augmentation, applied at both the pre-VAE image level and the post-VAE token level. At the image level, we incorporate cross-domain knowledge through perspective image guidance and panoramic refinement, which enhance perceptual quality while regularizing diversity and photorealism. At the token level, hybrid supervision is applied across multiple modules, which include circular padding for boundary continuity, yaw loss for rotational robustness, and cube loss for distortion awareness. Extensive experiments on text-to-panorama, inpainting, and outpainting tasks demonstrate that our method achieves better boundary consistency and image fidelity across eleven quantitative metrics. Our code is available at https://github.com/Insta360-Research-Team/DiT360.",
    "authors": [
      "Haoran Feng",
      "Dizhe Zhang",
      "Xiangtai Li",
      "Bo Du",
      "Lu Qi"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:59:15.000Z",
    "updatedAt": "2025-10-13T17:59:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11712v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11712v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11711v1",
    "arxivId": "2510.11711v1",
    "title": "Reinforced sequential Monte Carlo for amortised sampling",
    "abstract": "This paper proposes a synergy of amortised and particle-based methods for sampling from distributions defined by unnormalised density functions. We state a connection between sequential Monte Carlo (SMC) and neural sequential samplers trained by maximum-entropy reinforcement learning (MaxEnt RL), wherein learnt sampling policies and value functions define proposal kernels and twist functions. Exploiting this connection, we introduce an off-policy RL training procedure for the sampler that uses samples from SMC -- using the learnt sampler as a proposal -- as a behaviour policy that better explores the target distribution. We describe techniques for stable joint training of proposals and twist functions and an adaptive weight tempering scheme to reduce training signal variance. Furthermore, building upon past attempts to use experience replay to guide the training of neural samplers, we derive a way to combine historical samples with annealed importance sampling weights within a replay buffer. On synthetic multi-modal targets (in both continuous and discrete spaces) and the Boltzmann distribution of alanine dipeptide conformations, we demonstrate improvements in approximating the true distribution as well as training stability compared to both amortised and Monte Carlo methods.",
    "authors": [
      "Sanghyeok Choi",
      "Sarthak Mittal",
      "Víctor Elvira",
      "Jinkyoo Park",
      "Nikolay Malkin"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T17:59:11.000Z",
    "updatedAt": "2025-10-13T17:59:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11711v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11711v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11709v1",
    "arxivId": "2510.11709v1",
    "title": "Adversarial Attacks Leverage Interference Between Features in Superposition",
    "abstract": "Fundamental questions remain about when and why adversarial examples arise in neural networks, with competing views characterising them either as artifacts of the irregularities in the decision landscape or as products of sensitivity to non-robust input features. In this paper, we instead argue that adversarial vulnerability can stem from efficient information encoding in neural networks. Specifically, we show how superposition - where networks represent more features than they have dimensions - creates arrangements of latent representations that adversaries can exploit. We demonstrate that adversarial perturbations leverage interference between superposed features, making attack patterns predictable from feature arrangements. Our framework provides a mechanistic explanation for two known phenomena: adversarial attack transferability between models with similar training regimes and class-specific vulnerability patterns. In synthetic settings with precisely controlled superposition, we establish that superposition suffices to create adversarial vulnerability. We then demonstrate that these findings persist in a ViT trained on CIFAR-10. These findings reveal adversarial vulnerability can be a byproduct of networks' representational compression, rather than flaws in the learning process or non-robust inputs.",
    "authors": [
      "Edward Stevinson",
      "Lucas Prieto",
      "Melih Barsbey",
      "Tolga Birdal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:59:02.000Z",
    "updatedAt": "2025-10-13T17:59:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11709v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11709v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11704v1",
    "arxivId": "2510.11704v1",
    "title": "Bayesian Topological Convolutional Neural Nets",
    "abstract": "Convolutional neural networks (CNNs) have been established as the main workhorse in image data processing; nonetheless, they require large amounts of data to train, often produce overconfident predictions, and frequently lack the ability to quantify the uncertainty of their predictions. To address these concerns, we propose a new Bayesian topological CNN that promotes a novel interplay between topology-aware learning and Bayesian sampling. Specifically, it utilizes information from important manifolds to accelerate training while reducing calibration error by placing prior distributions on network parameters and properly learning appropriate posteriors. One important contribution of our work is the inclusion of a consistency condition in the learning cost, which can effectively modify the prior distributions to improve the performance of our novel network architecture. We evaluate the model on benchmark image classification datasets and demonstrate its superiority over conventional CNNs, Bayesian neural networks (BNNs), and topological CNNs. In particular, we supply evidence that our method provides an advantage in situations where training data is limited or corrupted. Furthermore, we show that the new model allows for better uncertainty quantification than standard BNNs since it can more readily identify examples of out-of-distribution data on which it has not been trained. Our results highlight the potential of our novel hybrid approach for more efficient and robust image classification.",
    "authors": [
      "Sarah Harkins Dayton",
      "Hayden Everett",
      "Ioannis Schizas",
      "David L. Boothe Jr.",
      "Vasileios Maroulas"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:57:43.000Z",
    "updatedAt": "2025-10-13T17:57:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11704v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11704v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11701v1",
    "arxivId": "2510.11701v1",
    "title": "Demystifying Reinforcement Learning in Agentic Reasoning",
    "abstract": "Recently, the emergence of agentic RL has showcased that RL could also effectively improve the agentic reasoning ability of LLMs, yet the key design principles and optimal practices remain unclear. In this work, we conduct a comprehensive and systematic investigation to demystify reinforcement learning in agentic reasoning from three key perspectives: data, algorithm, and reasoning mode. We highlight our key insights: (i) Replacing stitched synthetic trajectories with real end-to-end tool-use trajectories yields a far stronger SFT initialization; high-diversity, model-aware datasets sustain exploration and markedly improve RL performance. (ii) Exploration-friendly techniques are crucial for agentic RL, such as clip higher, overlong reward shaping, and maintaining adequate policy entropy could improve the training efficiency. (iii) A deliberative strategy with fewer tool calls outperforms frequent tool calls or verbose self-reasoning, improving tool efficiency and final accuracy. Together, these simple practices consistently enhance agentic reasoning and training efficiency, achieving strong results on challenging benchmarks with smaller models, and establishing a practical baseline for future agentic RL research. Beyond these empirical insights, we further contribute a high-quality, real end-to-end agentic SFT dataset along with a high-quality RL dataset, and demonstrate the effectiveness of our insights in boosting the agentic reasoning ability of LLMs across four challenging benchmarks, including AIME2024/AIME2025, GPQA-Diamond, and LiveCodeBench-v6. With our recipes, 4B-sized models could also achieve superior agentic reasoning performance compared to 32B-sized models. Code and models: https://github.com/Gen-Verse/Open-AgentRL",
    "authors": [
      "Zhaochen Yu",
      "Ling Yang",
      "Jiaru Zou",
      "Shuicheng Yan",
      "Mengdi Wang"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T17:57:15.000Z",
    "updatedAt": "2025-10-13T17:57:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11701v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11701v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11697v1",
    "arxivId": "2510.11697v1",
    "title": "A Fast-Converging Decentralized Approach to the Weighted Minimum Vertex Cover Problem",
    "abstract": "We address the problem of computing a Minimum Weighted Vertex Cover (MWVC) in a decentralized network. MWVC, a classical NP-hard problem, is foundational in applications such as network monitoring and resource placement. We propose a fully decentralized protocol where each node makes decisions using only local knowledge and communicates with its neighbors. The method is adaptive, communication-efficient, and avoids centralized coordination. We evaluate the protocol on real-world and synthetic graphs, comparing it to both centralized and decentralized baselines. Our results demonstrate competitive solution quality with reduced communication overhead, highlighting the feasibility of MWVC computation in decentralized environments.",
    "authors": [
      "Matteo Mordacchini",
      "Emanuele Carlini",
      "Patrizio Dazzi"
    ],
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-13T17:55:17.000Z",
    "updatedAt": "2025-10-13T17:55:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11697v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11697v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11696v1",
    "arxivId": "2510.11696v1",
    "title": "QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning for LLMs",
    "abstract": "We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for large language models (LLMs). While RL is essential for LLMs' reasoning capabilities, it is resource-intensive, requiring substantial GPU memory and long rollout durations. QeRL addresses these issues by combining NVFP4 quantization with Low-Rank Adaptation (LoRA), accelerating rollout phase of RL while reducing memory overhead. Beyond efficiency, our findings show that quantization noise increases policy entropy, enhancing exploration, and enabling the discovery of better strategies during RL. To further optimize exploration, QeRL introduces an Adaptive Quantization Noise (AQN) mechanism, which dynamically adjusts noise during training. Experiments demonstrate that QeRL delivers over 1.5 times speedup in the rollout phase. Moreover, this is the first framework to enable RL training of a 32B LLM on a single H100 80GB GPU, while delivering overall speedups for RL training. It also achieves faster reward growth and higher final accuracy than 16-bit LoRA and QLoRA, while matching the performance of full-parameter fine-tuning on mathematical benchmarks such as GSM8K (90.8%) and MATH 500 (77.4%) in the 7B model. These results establish QeRL as an efficient and effective framework for RL training in LLMs.",
    "authors": [
      "Wei Huang",
      "Yi Ge",
      "Shuai Yang",
      "Yicheng Xiao",
      "Huizi Mao",
      "Yujun Lin",
      "Hanrong Ye",
      "Sifei Liu",
      "Ka Chun Cheung",
      "Hongxu Yin",
      "Yao Lu",
      "Xiaojuan Qi",
      "Song Han",
      "Yukang Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:55:09.000Z",
    "updatedAt": "2025-10-13T17:55:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11696v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11696v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11695v1",
    "arxivId": "2510.11695v1",
    "title": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents",
    "abstract": "Although Large Language Model (LLM)-based agents are increasingly used in financial trading, it remains unclear whether they can reason and adapt in live markets, as most studies test models instead of agents, cover limited periods and assets, and rely on unverified data. To address these gaps, we introduce Agent Market Arena (AMA), the first lifelong, real-time benchmark for evaluating LLM-based trading agents across multiple markets. AMA integrates verified trading data, expert-checked news, and diverse agent architectures within a unified trading framework, enabling fair and continuous comparison under real conditions. It implements four agents, including InvestorAgent as a single-agent baseline, TradeAgent and HedgeFundAgent with different risk styles, and DeepFundAgent with memory-based reasoning, and evaluates them across GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, and Gemini-2.0-flash. Live experiments on both cryptocurrency and stock markets demonstrate that agent frameworks display markedly distinct behavioral patterns, spanning from aggressive risk-taking to conservative decision-making, whereas model backbones contribute less to outcome variation. AMA thus establishes a foundation for rigorous, reproducible, and continuously evolving evaluation of financial reasoning and trading intelligence in LLM-based agents.",
    "authors": [
      "Lingfei Qian",
      "Xueqing Peng",
      "Yan Wang",
      "Vincent Jim Zhang",
      "Huan He",
      "Hanley Smith",
      "Yi Han",
      "Yueru He",
      "Haohang Li",
      "Yupeng Cao",
      "Yangyang Yu",
      "Alejandro Lopez-Lira",
      "Peng Lu",
      "Jian-Yun Nie",
      "Guojun Xiong",
      "Jimin Huang",
      "Sophia Ananiadou"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T17:54:09.000Z",
    "updatedAt": "2025-10-13T17:54:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11695v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11695v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11694v1",
    "arxivId": "2510.11694v1",
    "title": "Operand Quant: A Single-Agent Architecture for Autonomous Machine Learning Engineering",
    "abstract": "We present Operand Quant, a single-agent, IDE-based architecture for autonomous machine learning engineering (MLE). Operand Quant departs from conventional multi-agent orchestration frameworks by consolidating all MLE lifecycle stages -- exploration, modeling, experimentation, and deployment -- within a single, context-aware agent. On the MLE-Benchmark (2025), Operand Quant achieved a new state-of-the-art (SOTA) result, with an overall medal rate of 0.3956 +/- 0.0565 across 75 problems -- the highest recorded performance among all evaluated systems to date. The architecture demonstrates that a linear, non-blocking agent, operating autonomously within a controlled IDE environment, can outperform multi-agent and orchestrated systems under identical constraints.",
    "authors": [
      "Arjun Sahney",
      "Ram Gorthi",
      "Cezary Łastowski",
      "Javier Vega"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:54:02.000Z",
    "updatedAt": "2025-10-13T17:54:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11694v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11694v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11693v1",
    "arxivId": "2510.11693v1",
    "title": "Scaling Language-Centric Omnimodal Representation Learning",
    "abstract": "Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approaches stems from implicit cross-modal alignment achieved during generative pretraining, where the language decoder learns to exploit multimodal signals within a shared representation space for generating unimodal outputs. Through analysis of anisotropy and kernel similarity structure, we empirically confirm that latent alignment emerges within MLLM representations, allowing CL to serve as a lightweight refinement stage. Leveraging this insight, we propose a Language-Centric Omnimodal Embedding framework, termed LCO-Emb. Extensive experiments across diverse backbones and benchmarks demonstrate its effectiveness, achieving state-of-the-art performance across modalities. Furthermore, we identify a Generation-Representation Scaling Law (GRSL), showing that the representational capabilities gained through contrastive refinement scales positively with the MLLM's generative capabilities. This suggests that improving generative abilities evolves as an effective paradigm for enhancing representation quality. We provide a theoretical explanation of GRSL, which formally links the MLLM's generative quality to the upper bound on its representation performance, and validate it on a challenging, low-resource visual-document retrieval task, showing that continual generative pretraining before CL can further enhance the potential of a model's embedding capabilities. Codes, models, and resources are available at https://github.com/LCO-Embedding/LCO-Embedding.",
    "authors": [
      "Chenghao Xiao",
      "Hou Pong Chan",
      "Hao Zhang",
      "Weiwen Xu",
      "Mahani Aljunied",
      "Yu Rong"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:53:52.000Z",
    "updatedAt": "2025-10-13T17:53:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11693v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11693v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11692v1",
    "arxivId": "2510.11692v1",
    "title": "Analysis of the Geometric Heat Flow Equation: Computing Geodesics in Real-Time with Convergence Guarantees",
    "abstract": "We present an analysis on the convergence properties of the so-called geometric heat flow equation for computing geodesics (shortest-path~curves) on Riemannian manifolds. Computing geodesics numerically in real-time has become an important capability in several fields, including control and motion planning. The geometric heat flow equation involves solving a parabolic partial differential equation whose solution is a geodesic. In practice, solving this PDE numerically can be done efficiently, and tends to be more numerically stable and exhibit a better rate of convergence compared to numerical optimization. We prove that the geometric heat flow equation is globally exponentially stable in $L_2$ if the curvature of the Riemannian manifold is not too positive, and that asymptotic convergence in $L_2$ is always guaranteed. We also present a pseudospectral method that leverages Chebyshev polynomials to accurately compute geodesics in only a few milliseconds for non-contrived manifolds. Our analysis was verified with our custom pseudospectral method by computing geodesics on common non-Euclidean surfaces, and in feedback for a contraction-based controller with a non-flat metric for a nonlinear system.",
    "authors": [
      "Samuel G. Gessow",
      "Brett T. Lopez"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T17:52:52.000Z",
    "updatedAt": "2025-10-13T17:52:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11692v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11692v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11691v1",
    "arxivId": "2510.11691v1",
    "title": "Tight Regret Upper and Lower Bounds for Optimistic Hedge in Two-Player Zero-Sum Games",
    "abstract": "In two-player zero-sum games, the learning dynamic based on optimistic Hedge achieves one of the best-known regret upper bounds among strongly-uncoupled learning dynamics. With an appropriately chosen learning rate, the social and individual regrets can be bounded by $O(\\log(mn))$ in terms of the numbers of actions $m$ and $n$ of the two players. This study investigates the optimality of the dependence on $m$ and $n$ in the regret of optimistic Hedge. To this end, we begin by refining existing regret analysis and show that, in the strongly-uncoupled setting where the opponent's number of actions is known, both the social and individual regret bounds can be improved to $O(\\sqrt{\\log m \\log n})$. In this analysis, we express the regret upper bound as an optimization problem with respect to the learning rates and the coefficients of certain negative terms, enabling refined analysis of the leading constants. We then show that the existing social regret bound as well as these new social and individual regret upper bounds cannot be further improved for optimistic Hedge by providing algorithm-dependent individual regret lower bounds. Importantly, these social regret upper and lower bounds match exactly including the constant factor in the leading term. Finally, building on these results, we improve the last-iterate convergence rate and the dynamic regret of a learning dynamic based on optimistic Hedge, and complement these bounds with algorithm-dependent dynamic regret lower bounds that match the improved bounds.",
    "authors": [
      "Taira Tsuchiya"
    ],
    "categories": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T17:52:01.000Z",
    "updatedAt": "2025-10-13T17:52:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11691v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11691v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11690v1",
    "arxivId": "2510.11690v1",
    "title": "Diffusion Transformers with Representation Autoencoders",
    "abstract": "Latent generative modeling, where a pretrained autoencoder maps pixels into a latent space for the diffusion process, has become the standard strategy for Diffusion Transformers (DiT); however, the autoencoder component has barely evolved. Most DiTs continue to rely on the original VAE encoder, which introduces several limitations: outdated backbones that compromise architectural simplicity, low-dimensional latent spaces that restrict information capacity, and weak representations that result from purely reconstruction-based training and ultimately limit generative quality. In this work, we explore replacing the VAE with pretrained representation encoders (e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term Representation Autoencoders (RAEs). These models provide both high-quality reconstructions and semantically rich latent spaces, while allowing for a scalable transformer-based architecture. Since these latent spaces are typically high-dimensional, a key challenge is enabling diffusion transformers to operate effectively within them. We analyze the sources of this difficulty, propose theoretically motivated solutions, and validate them empirically. Our approach achieves faster convergence without auxiliary representation alignment losses. Using a DiT variant equipped with a lightweight, wide DDT head, we achieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no guidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers clear advantages and should be the new default for diffusion transformer training.",
    "authors": [
      "Boyang Zheng",
      "Nanye Ma",
      "Shengbang Tong",
      "Saining Xie"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T17:51:39.000Z",
    "updatedAt": "2025-10-13T17:51:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11690v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11690v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11689v1",
    "arxivId": "2510.11689v1",
    "title": "Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation",
    "abstract": "Learning robotic manipulation policies directly in the real world can be expensive and time-consuming. While reinforcement learning (RL) policies trained in simulation present a scalable alternative, effective sim-to-real transfer remains challenging, particularly for tasks that require precise dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL pipeline that combines vision-language model (VLM)-inferred physical parameter estimates with interactive adaptation through uncertainty-aware fusion. Our approach consists of three core components: (1) high-fidelity geometric reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions over physical parameters, and (3) online physical parameter estimation from interaction data. Phys2Real conditions policies on interpretable physical parameters, refining VLM predictions with online estimates via ensemble-based uncertainty quantification. On planar pushing tasks of a T-block with varying center of mass (CoM) and a hammer with an off-center mass distribution, Phys2Real achieves substantial improvements over a domain randomization baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23% in the challenging top-weighted T-block, and 15% faster average task completion for hammer pushing. Ablation studies indicate that the combination of VLM and interaction information is essential for success. Project website: https://phys2real.github.io/ .",
    "authors": [
      "Maggie Wang",
      "Stephen Tian",
      "Aiden Swann",
      "Ola Shorinwa",
      "Jiajun Wu",
      "Mac Schwager"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:51:23.000Z",
    "updatedAt": "2025-10-13T17:51:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11689v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11689v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11688v1",
    "arxivId": "2510.11688v1",
    "title": "PACEbench: A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities",
    "abstract": "The increasing autonomy of Large Language Models (LLMs) necessitates a rigorous evaluation of their potential to aid in cyber offense. Existing benchmarks often lack real-world complexity and are thus unable to accurately assess LLMs' cybersecurity capabilities. To address this gap, we introduce PACEbench, a practical AI cyber-exploitation benchmark built on the principles of realistic vulnerability difficulty, environmental complexity, and cyber defenses. Specifically, PACEbench comprises four scenarios spanning single, blended, chained, and defense vulnerability exploitations. To handle these complex challenges, we propose PACEagent, a novel agent that emulates human penetration testers by supporting multi-phase reconnaissance, analysis, and exploitation. Extensive experiments with seven frontier LLMs demonstrate that current models struggle with complex cyber scenarios, and none can bypass defenses. These findings suggest that current models do not yet pose a generalized cyber offense threat. Nonetheless, our work provides a robust benchmark to guide the trustworthy development of future models.",
    "authors": [
      "Zicheng Liu",
      "Lige Huang",
      "Jie Zhang",
      "Dongrui Liu",
      "Yuan Tian",
      "Jing Shao"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:50:25.000Z",
    "updatedAt": "2025-10-13T17:50:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11688v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11688v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11687v1",
    "arxivId": "2510.11687v1",
    "title": "Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View",
    "abstract": "Estimating an object's 6D pose, size, and shape from visual input is a fundamental problem in computer vision, with critical applications in robotic grasping and manipulation. Existing methods either rely on object-specific priors such as CAD models or templates, or suffer from limited generalization across categories due to pose-shape entanglement and multi-stage pipelines. In this work, we propose a unified, category-agnostic framework that simultaneously predicts 6D pose, size, and dense shape from a single RGB-D image, without requiring templates, CAD models, or category labels at test time. Our model fuses dense 2D features from vision foundation models with partial 3D point clouds using a Transformer encoder enhanced by a Mixture-of-Experts, and employs parallel decoders for pose-size estimation and shape reconstruction, achieving real-time inference at 28 FPS. Trained solely on synthetic data from 149 categories in the SOPE dataset, our framework is evaluated on four diverse benchmarks SOPE, ROPE, ObjaversePose, and HANDAL, spanning over 300 categories. It achieves state-of-the-art accuracy on seen categories while demonstrating remarkably strong zero-shot generalization to unseen real-world objects, establishing a new standard for open-set 6D understanding in robotics and embodied AI.",
    "authors": [
      "Jinyu Zhang",
      "Haitao Lin",
      "Jiashu Hou",
      "Xiangyang Xue",
      "Yanwei Fu"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:49:15.000Z",
    "updatedAt": "2025-10-13T17:49:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11687v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11687v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11686v1",
    "arxivId": "2510.11686v1",
    "title": "Representation-Based Exploration for Language Models: From Test-Time to Post-Training",
    "abstract": "Reinforcement learning (RL) promises to expand the capabilities of language models, but it is unclear if current RL techniques promote the discovery of novel behaviors, or simply sharpen those already present in the base model. In this paper, we investigate the value of deliberate exploration -- explicitly incentivizing the model to discover novel and diverse behaviors -- and aim to understand how the knowledge in pre-trained models can guide this search. Our main finding is that exploration with a simple, principled, representation-based bonus derived from the pre-trained language model's hidden states significantly improves diversity and pass@k rates -- both for post-training, and in a novel inference-time scaling setting we introduce. For inference-time, exploration with representation-based diversity improves efficiency, consistently improving pass@k rates across a variety of models and reasoning tasks. For example, for Qwen-2.5-14b-Instruct we obtain over 50% improvement in verifier efficiency on almost all tasks. For post-training, we show that integrating this exploration strategy into an RL pipeline improves reasoning performance over that of the initial model and over standard RL post-training. For example, on AIME 2024, our post-trained Qwen-2.5-7b-Instruct's pass@80 matches the pass@256 of GRPO on the same model, demonstrating a 3x improvement in test-time sample efficiency. Overall, our findings suggest that deliberate exploration -- with the right notion of diversity -- is a practical path toward discovery of new behaviors beyond sharpening.",
    "authors": [
      "Jens Tuyls",
      "Dylan J. Foster",
      "Akshay Krishnamurthy",
      "Jordan T. Ash"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:49:05.000Z",
    "updatedAt": "2025-10-13T17:49:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11686v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11686v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11683v1",
    "arxivId": "2510.11683v1",
    "title": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models",
    "abstract": "A key challenge in applying reinforcement learning (RL) to diffusion large language models (dLLMs) lies in the intractability of their likelihood functions, which are essential for the RL objective, necessitating corresponding approximation in each training step. While existing methods approximate the log-likelihoods by their evidence lower bounds (ELBOs) via customized Monte Carlo (MC) sampling, the forward computational graphs of all MC samples need to be retained for the gradient computation of non-linear terms in the RL objective, resulting in significant memory overhead. This constraint restricts feasible sample sizes, leading to imprecise likelihood approximations and ultimately distorting the RL objective. To overcome this limitation, we propose \\emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient RL algorithm that maximizes a specially constructed lower bound of the ELBO-based objective. This lower bound is carefully designed to satisfy two key properties: (1) Linearity: it is formulated in a linear sum where each term depends only on a single MC sample, thereby enabling gradient accumulation across samples and ensuring constant memory usage; (2) Equivalence: Both the value and gradient of this lower bound are equal to those of the ELBO-based objective in on-policy training, making it also an effective approximation for the original RL objective. These properties allow BGPO to adopt a large MC sample size, resulting in more accurate likelihood approximations and improved RL objective estimation, which in turn leads to enhanced performance. Experiments show that BGPO significantly outperforms previous RL algorithms for dLLMs in math problem solving, code generation, and planning tasks.",
    "authors": [
      "Nianyi Lin",
      "Jiajie Zhang",
      "Lei Hou",
      "Juanzi Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T17:47:50.000Z",
    "updatedAt": "2025-10-13T17:47:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11683v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11683v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11682v1",
    "arxivId": "2510.11682v1",
    "title": "Ego-Vision World Model for Humanoid Contact Planning",
    "abstract": "Enabling humanoid robots to exploit physical contact, rather than simply avoid collisions, is crucial for autonomy in unstructured environments. Traditional optimization-based planners struggle with contact complexity, while on-policy reinforcement learning (RL) is sample-inefficient and has limited multi-task ability. We propose a framework combining a learned world model with sampling-based Model Predictive Control (MPC), trained on a demonstration-free offline dataset to predict future outcomes in a compressed latent space. To address sparse contact rewards and sensor noise, the MPC uses a learned surrogate value function for dense, robust planning. Our single, scalable model supports contact-aware tasks, including wall support after perturbation, blocking incoming objects, and traversing height-limited arches, with improved data efficiency and multi-task capability over on-policy RL. Deployed on a physical humanoid, our system achieves robust, real-time contact planning from proprioception and ego-centric depth images. Website: https://ego-vcp.github.io/",
    "authors": [
      "Hang Liu",
      "Yuman Gao",
      "Sangli Teng",
      "Yufeng Chi",
      "Yakun Sophia Shao",
      "Zhongyu Li",
      "Maani Ghaffari",
      "Koushil Sreenath"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-13T17:47:39.000Z",
    "updatedAt": "2025-10-13T17:47:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11682v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11682v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11677v1",
    "arxivId": "2510.11677v1",
    "title": "Chronologically Consistent Generative AI",
    "abstract": "We introduce a family of chronologically consistent, instruction-following large language models to eliminate lookahead bias. Each model is trained only on data available before a clearly defined knowledge-cutoff date, ensuring strict temporal separation from any post-cutoff data. The resulting framework offers (i) a simple, conversational chat interface, (ii) fully open, fixed model weights that guarantee replicability, and (iii) a conservative lower bound on forecast accuracy, isolating the share of predictability that survives once training leakage is removed. Together, these features provide researchers with an easy-to-use generative AI tool useful for a wide range of prediction tasks that is free of lookahead bias.",
    "authors": [
      "Songrun He",
      "Linying Lv",
      "Asaf Manela",
      "Jimmy Wu"
    ],
    "categories": [
      "cs.LG",
      "q-fin.GN"
    ],
    "publishedAt": "2025-10-13T17:45:24.000Z",
    "updatedAt": "2025-10-13T17:45:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11677v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11677v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11676v1",
    "arxivId": "2510.11676v1",
    "title": "Accelerated stochastic first-order method for convex optimization under heavy-tailed noise",
    "abstract": "We study convex composite optimization problems, where the objective function is given by the sum of a prox-friendly function and a convex function whose subgradients are estimated under heavy-tailed noise. Existing work often employs gradient clipping or normalization techniques in stochastic first-order methods to address heavy-tailed noise. In this paper, we demonstrate that a vanilla stochastic algorithm -- without additional modifications such as clipping or normalization -- can achieve optimal complexity for these problems. In particular, we establish that an accelerated stochastic proximal subgradient method achieves a first-order oracle complexity that is universally optimal for smooth, weakly smooth, and nonsmooth convex optimization, as well as for stochastic convex optimization under heavy-tailed noise. Numerical experiments are further provided to validate our theoretical results.",
    "authors": [
      "Chuan He",
      "Zhaosong Lu"
    ],
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "49M05, 49M37, 90C25, 90C30"
    ],
    "publishedAt": "2025-10-13T17:45:05.000Z",
    "updatedAt": "2025-10-13T17:45:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11676v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11676v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11675v1",
    "arxivId": "2510.11675v1",
    "title": "FACE: Faithful Automatic Concept Extraction",
    "abstract": "Interpreting deep neural networks through concept-based explanations offers a bridge between low-level features and high-level human-understandable semantics. However, existing automatic concept discovery methods often fail to align these extracted concepts with the model's true decision-making process, thereby compromising explanation faithfulness. In this work, we propose FACE (Faithful Automatic Concept Extraction), a novel framework that augments Non-negative Matrix Factorization (NMF) with a Kullback-Leibler (KL) divergence regularization term to ensure alignment between the model's original and concept-based predictions. Unlike prior methods that operate solely on encoder activations, FACE incorporates classifier supervision during concept learning, enforcing predictive consistency and enabling faithful explanations. We provide theoretical guarantees showing that minimizing the KL divergence bounds the deviation in predictive distributions, thereby promoting faithful local linearity in the learned concept space. Systematic evaluations on ImageNet, COCO, and CelebA datasets demonstrate that FACE outperforms existing methods across faithfulness and sparsity metrics.",
    "authors": [
      "Dipkamal Bhusal",
      "Michael Clifford",
      "Sara Rampazzi",
      "Nidhi Rastogi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:44:45.000Z",
    "updatedAt": "2025-10-13T17:44:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11675v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11675v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11673v1",
    "arxivId": "2510.11673v1",
    "title": "Integral Matrices of Fixed Rank over Number Fields",
    "abstract": "We prove an asymptotic formula for the number of fixed rank matrices with integer coefficients over a number field K/Q and bounded norm. As an application, we derive an approximate Rogers integral formula for discrete sets of module lattices obtained from lifts of algebraic codes. This in turn implies that the moment estimates of random lattices with a number field structure also carry through for large enough discrete sets of module lattices.",
    "authors": [
      "Nihar Gargava",
      "Vlad Serban",
      "Maryna Viazovska",
      "Ilaria Viglino"
    ],
    "categories": [
      "math.NT",
      "cs.IT",
      "math.IT",
      "11H06, 11H50, 68R01, 94B75"
    ],
    "publishedAt": "2025-10-13T17:43:58.000Z",
    "updatedAt": "2025-10-13T17:43:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11673v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11673v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11670v1",
    "arxivId": "2510.11670v1",
    "title": "Understanding the interplay of collagen and myocyte adaptation in cardiac volume overload: a multi-constituent growth and remodeling framework",
    "abstract": "Hearts subjected to volume overload (VO) are prone to detrimental anatomical and functional changes in response to elevated mechanical stretches, ultimately leading to heart failure. Experimental findings increasingly emphasize that organ-scale changes following VO cannot be explained by myocyte growth alone, as traditionally proposed in the literature. Collagen degradation, in particular, has been associated with left ventricular adaptation in both acute and chronic stages of VO. These hypotheses remain to be substantiated by comprehensive mechanistic evidence, and the contribution of each constituent to myocardial growth and remodeling (G&R) processes is yet to be quantified. In this work, we establish a hybrid G&R framework in which we integrate a mixture-based constitutive model with the kinematic growth formulation. This multi-constituent model enables us to mechanistically assess the relative contributions of collagen and myocyte changes to alterations in tissue properties, ventricular dimensions, and growth phenotype. Our numerical results confirm that collagen dynamics control the passive mechanical response of the myocardium, whereas myocytes predominantly impact the extent and the phenotype of eccentric hypertrophy. Importantly, collagen degradation exacerbates myocyte hypertrophy, demonstrating a synergistic interplay that accelerates left ventricular progression toward diastolic dysfunction. This work constitutes an important step towards an integrated characterization of the early compensatory stages of VO-induced cardiac G&R.",
    "authors": [
      "Ludovica Maga",
      "Mathias Peirlinck",
      "Lise Noël"
    ],
    "categories": [
      "physics.med-ph",
      "cs.NA",
      "math.NA",
      "q-bio.TO"
    ],
    "publishedAt": "2025-10-13T17:43:08.000Z",
    "updatedAt": "2025-10-13T17:43:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11670v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11670v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11661v1",
    "arxivId": "2510.11661v1",
    "title": "SR-Scientist: Scientific Equation Discovery With Agentic AI",
    "abstract": "Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities.",
    "authors": [
      "Shijie Xia",
      "Yuhan Sun",
      "Pengfei Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:35:23.000Z",
    "updatedAt": "2025-10-13T17:35:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11661v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11661v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11660v1",
    "arxivId": "2510.11660v1",
    "title": "ManiAgent: An Agentic Framework for General Robotic Manipulation",
    "abstract": "While Vision-Language-Action (VLA) models have demonstrated impressive capabilities in robotic manipulation, their performance in complex reasoning and long-horizon task planning is limited by data scarcity and model capacity. To address this, we introduce ManiAgent, an agentic architecture for general manipulation tasks that achieves end-to-end output from task descriptions and environmental inputs to robotic manipulation actions. In this framework, multiple agents involve inter-agent communication to perform environmental perception, sub-task decomposition and action generation, enabling efficient handling of complex manipulation scenarios. Evaluations show ManiAgent achieves an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world pick-and-place tasks, enabling efficient data collection that yields VLA models with performance comparable to those trained on human-annotated datasets.The project webpage is available at https://yi-yang929.github.io/ManiAgent/.",
    "authors": [
      "Yi Yang",
      "Kefan Gu",
      "Yuqing Wen",
      "Hebei Li",
      "Yucheng Zhao",
      "Tiancai Wang",
      "Xudong Liu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:34:48.000Z",
    "updatedAt": "2025-10-13T17:34:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11660v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11660v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11658v1",
    "arxivId": "2510.11658v1",
    "title": "Automatically Generating Questions About Scratch Programs",
    "abstract": "When learning to program, students are usually assessed based on the code they wrote. However, the mere completion of a programming task does not guarantee actual comprehension of the underlying concepts. Asking learners questions about the code they wrote has therefore been proposed as a means to assess program comprehension. As creating targeted questions for individual student programs can be tedious and challenging, prior work has proposed to generate such questions automatically. In this paper we generalize this idea to the block-based programming language Scratch. We propose a set of 30 different questions for Scratch code covering an established program comprehension model, and extend the LitterBox static analysis tool to automatically generate corresponding questions for a given Scratch program. On a dataset of 600,913 projects we generated 54,118,694 questions automatically. Our initial experiments with 34 ninth graders demonstrate that this approach can indeed generate meaningful questions for Scratch programs, and we find that the ability of students to answer these questions on their programs relates to their overall performance.",
    "authors": [
      "Florian Obermüller",
      "Gordon Fraser"
    ],
    "categories": [
      "cs.SE",
      "97P50",
      "D.2.5; K.3.2"
    ],
    "publishedAt": "2025-10-13T17:34:12.000Z",
    "updatedAt": "2025-10-13T17:34:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11658v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11658v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11657v1",
    "arxivId": "2510.11657v1",
    "title": "An Eulerian Perspective on Straight-Line Sampling",
    "abstract": "We study dynamic measure transport for generative modeling: specifically, flows induced by stochastic processes that bridge a specified source and target distribution. The conditional expectation of the process' velocity defines an ODE whose flow map achieves the desired transport. We ask \\emph{which processes produce straight-line flows} -- i.e., flows whose pointwise acceleration vanishes and thus are exactly integrable with a first-order method? We provide a concise PDE characterization of straightness as a balance between conditional acceleration and the divergence of a weighted covariance (Reynolds) tensor. Using this lens, we fully characterize affine-in-time interpolants and show that straightness occurs exactly under deterministic endpoint couplings. We also derive necessary conditions that constrain flow geometry for general processes, offering broad guidance for designing transports that are easier to integrate.",
    "authors": [
      "Panos Tsimpos",
      "Youssef Marzouk"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T17:33:58.000Z",
    "updatedAt": "2025-10-13T17:33:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11657v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11657v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11654v1",
    "arxivId": "2510.11654v1",
    "title": "FinVet: A Collaborative Framework of RAG and External Fact-Checking Agents for Financial Misinformation Detection",
    "abstract": "Financial markets face growing threats from misinformation that can trigger billions in losses in minutes. Most existing approaches lack transparency in their decision-making and provide limited attribution to credible sources. We introduce FinVet, a novel multi-agent framework that integrates two Retrieval-Augmented Generation (RAG) pipelines with external fact-checking through a confidence-weighted voting mechanism. FinVet employs adaptive three-tier processing that dynamically adjusts verification strategies based on retrieval confidence, from direct metadata extraction to hybrid reasoning to full model-based analysis. Unlike existing methods, FinVet provides evidence-backed verdicts, source attribution, confidence scores, and explicit uncertainty flags when evidence is insufficient. Experimental evaluation on the FinFact dataset shows that FinVet achieves an F1 score of 0.85, which is a 10.4% improvement over the best individual pipeline (fact-check pipeline) and 37% improvement over standalone RAG approaches.",
    "authors": [
      "Daniel Berhane Araya",
      "Duoduo Liao"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T17:31:49.000Z",
    "updatedAt": "2025-10-13T17:31:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11654v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11654v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11653v1",
    "arxivId": "2510.11653v1",
    "title": "MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model",
    "abstract": "With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL) methods has emerged that seem to unlock stronger mathematical reasoning. However, a closer look at the open-source ecosystem reveals a critical limitation: with sufficiently many draws (e.g., $\\texttt{pass@1024}$), many existing base models already solve nearly all questions on widely used math benchmarks such as MATH-500 and AIME 2024. This suggests that the RL fine-tuning methods prevalent in the LLM reasoning literature largely sharpen existing solution modes rather than discovering entirely new ones. Such sharpening stands in contrast to the broader promise of RL: to foster exploration and to acquire new skills. To move beyond this plateau, we introduce MATH-Beyond (MATH-B), a benchmark deliberately constructed to defeat common open-source models of up to 8B parameters even under large sampling budgets. Improving performance on our benchmark via RL requires methods that learn to reason in ways that go beyond base model capabilities in repeated sampling. Since the problems are drawn from subsets of DAPO-Math-17K and DeepScaleR datasets, they remain topically equivalent to standard high-school math. Validating our premise, RL fine-tuned models such as Nemotron-Research-Reasoning-Qwen-1.5B and DeepScaleR-1.5B-Preview perform poorly on MATH-B at $\\texttt{pass@1024}$, showing how existing approaches fall short on tackling harder instances. We hope MATH-B will catalyze exploration-driven RL approaches that elicit deeper reasoning capabilities. We release MATH-B at https://huggingface.co/datasets/brendel-group/MATH-Beyond.",
    "authors": [
      "Prasanna Mayilvahanan",
      "Ricardo Dominguez-Olmedo",
      "Thaddäus Wiedemer",
      "Wieland Brendel"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T17:30:54.000Z",
    "updatedAt": "2025-10-13T17:30:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11653v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11653v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11652v1",
    "arxivId": "2510.11652v1",
    "title": "ACADREASON: Exploring the Limits of Reasoning Models with Academic Research Problems",
    "abstract": "In recent years, the research focus of large language models (LLMs) and agents has shifted increasingly from demonstrating novel capabilities to complex reasoning and tackling challenging tasks. However, existing evaluations focus mainly on math/code contests or general tasks, while existing multi-domain academic benchmarks lack sufficient reasoning depth, leaving the field without a rigorous benchmark for high-level reasoning. To fill this gap, we introduce the Acadreason benchmark, designed to evaluate the ability of LLMs and agents to acquire and reason over academic knowledge. It consists of 50 expert-annotated academic problems across five high-reasoning domains, including computer science, economics, law, mathematics, and philosophy. All questions are sourced from top-tier publications in recent years and undergo rigorous annotation and quality control to ensure they are both challenging and answerable. We conduct systematic evaluations of over 10 mainstream LLMs and agents. The results show that most LLMs scored below 20 points, with even the cutting-edge GPT-5 achieving only 16 points. While agents achieved higher scores, none exceeded 40 points. This demonstrates the current capability gap between LLMs and agents in super-intelligent academic research tasks and highlights the challenges of Acadreason.",
    "authors": [
      "Xin Gui",
      "King Zhu",
      "JinCheng Ren",
      "Qianben Chen",
      "Zekun Moore Wang",
      "Yizhi LI",
      "Xinpeng Liu",
      "Xiaowan Li",
      "Wenli Ren",
      "Linyu Miao",
      "Tianrui Qin",
      "Ziqi Shu",
      "He Zhu",
      "Xiangru Tang",
      "Dingfeng Shi",
      "Jiaheng Liu",
      "Yuchen Eleanor Jiang",
      "Minghao Liu",
      "Ge Zhang",
      "Wangchunshu Zhou"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T17:30:36.000Z",
    "updatedAt": "2025-10-13T17:30:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11652v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11652v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11650v1",
    "arxivId": "2510.11650v1",
    "title": "InfiniHuman: Infinite 3D Human Creation with Precise Control",
    "abstract": "Generating realistic and controllable 3D human avatars is a long-standing challenge, particularly when covering broad attribute ranges such as ethnicity, age, clothing styles, and detailed body shapes. Capturing and annotating large-scale human datasets for training generative models is prohibitively expensive and limited in scale and diversity. The central question we address in this paper is: Can existing foundation models be distilled to generate theoretically unbounded, richly annotated 3D human data? We introduce InfiniHuman, a framework that synergistically distills these models to produce richly annotated human data at minimal cost and with theoretically unlimited scalability. We propose InfiniHumanData, a fully automatic pipeline that leverages vision-language and image generation models to create a large-scale multi-modal dataset. User study shows our automatically generated identities are undistinguishable from scan renderings. InfiniHumanData contains 111K identities spanning unprecedented diversity. Each identity is annotated with multi-granularity text descriptions, multi-view RGB images, detailed clothing images, and SMPL body-shape parameters. Building on this dataset, we propose InfiniHumanGen, a diffusion-based generative pipeline conditioned on text, body shape, and clothing assets. InfiniHumanGen enables fast, realistic, and precisely controllable avatar generation. Extensive experiments demonstrate significant improvements over state-of-the-art methods in visual quality, generation speed, and controllability. Our approach enables high-quality avatar generation with fine-grained control at effectively unbounded scale through a practical and affordable solution. We will publicly release the automatic data generation pipeline, the comprehensive InfiniHumanData dataset, and the InfiniHumanGen models at https://yuxuan-xue.com/infini-human.",
    "authors": [
      "Yuxuan Xue",
      "Xianghui Xie",
      "Margaret Kostyrko",
      "Gerard Pons-Moll"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:29:55.000Z",
    "updatedAt": "2025-10-13T17:29:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11650v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11650v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11649v1",
    "arxivId": "2510.11649v1",
    "title": "PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image",
    "abstract": "Reconstructing metrically accurate humans and their surrounding scenes from a single image is crucial for virtual reality, robotics, and comprehensive 3D scene understanding. However, existing methods struggle with depth ambiguity, occlusions, and physically inconsistent contacts. To address these challenges, we introduce PhySIC, a framework for physically plausible Human-Scene Interaction and Contact reconstruction. PhySIC recovers metrically consistent SMPL-X human meshes, dense scene surfaces, and vertex-level contact maps within a shared coordinate frame from a single RGB image. Starting from coarse monocular depth and body estimates, PhySIC performs occlusion-aware inpainting, fuses visible depth with unscaled geometry for a robust metric scaffold, and synthesizes missing support surfaces like floors. A confidence-weighted optimization refines body pose, camera parameters, and global scale by jointly enforcing depth alignment, contact priors, interpenetration avoidance, and 2D reprojection consistency. Explicit occlusion masking safeguards invisible regions against implausible configurations. PhySIC is efficient, requiring only 9 seconds for joint human-scene optimization and under 27 seconds end-to-end. It naturally handles multiple humans, enabling reconstruction of diverse interactions. Empirically, PhySIC outperforms single-image baselines, reducing mean per-vertex scene error from 641 mm to 227 mm, halving PA-MPJPE to 42 mm, and improving contact F1 from 0.09 to 0.51. Qualitative results show realistic foot-floor interactions, natural seating, and plausible reconstructions of heavily occluded furniture. By converting a single image into a physically plausible 3D human-scene pair, PhySIC advances scalable 3D scene understanding. Our implementation is publicly available at https://yuxuan-xue.com/physic.",
    "authors": [
      "Pradyumna Yalandur Muralidhar",
      "Yuxuan Xue",
      "Xianghui Xie",
      "Margaret Kostyrko",
      "Gerard Pons-Moll"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:29:51.000Z",
    "updatedAt": "2025-10-13T17:29:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11649v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11649v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11647v1",
    "arxivId": "2510.11647v1",
    "title": "IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment",
    "abstract": "Instruction-guided video editing has emerged as a rapidly advancing research direction, offering new opportunities for intuitive content transformation while also posing significant challenges for systematic evaluation. Existing video editing benchmarks fail to support the evaluation of instruction-guided video editing adequately and further suffer from limited source diversity, narrow task coverage and incomplete evaluation metrics. To address the above limitations, we introduce IVEBench, a modern benchmark suite specifically designed for instruction-guided video editing assessment. IVEBench comprises a diverse database of 600 high-quality source videos, spanning seven semantic dimensions, and covering video lengths ranging from 32 to 1,024 frames. It further includes 8 categories of editing tasks with 35 subcategories, whose prompts are generated and refined through large language models and expert review. Crucially, IVEBench establishes a three-dimensional evaluation protocol encompassing video quality, instruction compliance and video fidelity, integrating both traditional metrics and multimodal large language model-based assessments. Extensive experiments demonstrate the effectiveness of IVEBench in benchmarking state-of-the-art instruction-guided video editing methods, showing its ability to provide comprehensive and human-aligned evaluation outcomes.",
    "authors": [
      "Yinan Chen",
      "Jiangning Zhang",
      "Teng Hu",
      "Yuxiang Zeng",
      "Zhucun Xue",
      "Qingdong He",
      "Chengjie Wang",
      "Yong Liu",
      "Xiaobin Hu",
      "Shuicheng Yan"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T17:27:08.000Z",
    "updatedAt": "2025-10-13T17:27:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11647v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11647v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11646v1",
    "arxivId": "2510.11646v1",
    "title": "BridgeCode: A Dual Speech Representation Paradigm for Autoregressive Zero-Shot Text-to-Speech Synthesis",
    "abstract": "Autoregressive (AR) frameworks have recently achieved remarkable progress in zero-shot text-to-speech (TTS) by leveraging discrete speech tokens and large language model techniques. Despite their success, existing AR-based zero-shot TTS systems face two critical limitations: (i) an inherent speed-quality trade-off, as sequential token generation either reduces frame rates at the cost of expressiveness or enriches tokens at the cost of efficiency, and (ii) a text-oriented supervision mismatch, as cross-entropy loss penalizes token errors uniformly without considering the fine-grained acoustic similarity among adjacent tokens. To address these challenges, we propose BridgeTTS, a novel AR-TTS framework built upon the dual speech representation paradigm BridgeCode. BridgeTTS reduces AR iterations by predicting sparse tokens while reconstructing rich continuous features for high-quality synthesis. Joint optimization of token-level and feature-level objectives further enhances naturalness and intelligibility. Experiments demonstrate that BridgeTTS achieves competitive quality and speaker similarity while significantly accelerating synthesis. Speech demos are available at https://test1562.github.io/demo/.",
    "authors": [
      "Jingyuan Xing",
      "Mingru Yang",
      "Zhipeng Li",
      "Xiaofen Xing",
      "Xiangmin Xu"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-13T17:27:05.000Z",
    "updatedAt": "2025-10-13T17:27:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11646v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11646v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11640v1",
    "arxivId": "2510.11640v1",
    "title": "Continual Release of Densest Subgraphs: Privacy Amplification & Sublinear Space via Subsampling",
    "abstract": "We study the sublinear space continual release model for edge-differentially private (DP) graph algorithms, with a focus on the densest subgraph problem (DSG) in the insertion-only setting. Our main result is the first continual release DSG algorithm that matches the additive error of the best static DP algorithms and the space complexity of the best non-private streaming algorithms, up to constants. The key idea is a refined use of subsampling that simultaneously achieves privacy amplification and sparsification, a connection not previously formalized in graph DP. Via a simple black-box reduction to the static setting, we obtain both pure and approximate-DP algorithms with $O(\\log n)$ additive error and $O(n\\log n)$ space, improving both accuracy and space complexity over the previous state of the art. Along the way, we introduce graph densification in the graph DP setting, adding edges to trigger earlier subsampling, which removes the extra logarithmic factors in error and space incurred by prior work [ELMZ25]. We believe this simple idea may be of independent interest.",
    "authors": [
      "Felix Zhou"
    ],
    "categories": [
      "cs.DS",
      "cs.CR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T17:20:13.000Z",
    "updatedAt": "2025-10-13T17:20:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11640v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11640v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11639v1",
    "arxivId": "2510.11639v1",
    "title": "OneRec-Think: In-Text Reasoning for Generative Recommendation",
    "abstract": "The powerful generative capacity of Large Language Models (LLMs) has instigated a paradigm shift in recommendation. However, existing generative models (e.g., OneRec) operate as implicit predictors, critically lacking the capacity for explicit and controllable reasoning-a key advantage of LLMs. To bridge this gap, we propose OneRec-Think, a unified framework that seamlessly integrates dialogue, reasoning, and personalized recommendation. OneRec-Think incorporates: (1) Itemic Alignment: cross-modal Item-Textual Alignment for semantic grounding; (2) Reasoning Activation: Reasoning Scaffolding to activate LLM reasoning within the recommendation context; and (3) Reasoning Enhancement, where we design a recommendation-specific reward function that accounts for the multi-validity nature of user preferences. Experiments across public benchmarks show state-of-the-art performance. Moreover, our proposed \"Think-Ahead\" architecture enables effective industrial deployment on Kuaishou, achieving a 0.159\\% gain in APP Stay Time and validating the practical efficacy of the model's explicit reasoning capability.",
    "authors": [
      "Zhanyu Liu",
      "Shiyao Wang",
      "Xingmei Wang",
      "Rongzhou Zhang",
      "Jiaxin Deng",
      "Honghui Bao",
      "Jinghao Zhang",
      "Wuchao Li",
      "Pengfei Zheng",
      "Xiangyu Wu",
      "Yifei Hu",
      "Qigen Hu",
      "Xinchen Luo",
      "Lejian Ren",
      "Zixing Zhang",
      "Qianqian Wang",
      "Kuo Cai",
      "Yunfan Wu",
      "Hongtao Cheng",
      "Zexuan Cheng",
      "Lu Ren",
      "Huanjie Wang",
      "Yi Su",
      "Ruiming Tang",
      "Kun Gai",
      "Guorui Zhou"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T17:20:13.000Z",
    "updatedAt": "2025-10-13T17:20:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11639v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11639v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11636v1",
    "arxivId": "2510.11636v1",
    "title": "LRQ-Solver: A Transformer-Based Neural Operator for Fast and Accurate Solving of Large-scale 3D PDEs",
    "abstract": "Solving large-scale Partial Differential Equations (PDEs) on complex three-dimensional geometries represents a central challenge in scientific and engineering computing, often impeded by expensive pre-processing stages and substantial computational overhead. We introduce Low-Rank Query-based PDE Solver (LRQ-Solver), a physics-integrated framework engineered for rapid, accurate, and highly scalable simulations of industrial-grade models. This framework is built upon two primary technical innovations. First, our Parameter Conditioned Lagrangian Modeling (PCLM) approach explicitly couples local physical states with global design parameters, enabling robust predictions across varied simulation configurations. By embedding physical consistency directly into the learning architecture, PCLM ensures that predictions remain physically meaningful even under unseen design conditions, significantly enhancing generalization and reliability. Second, the Low-Rank Query Attention (LR-QA) module leverages the second-order statistics of physical fields to construct a global coherence kernel, reducing the computational complexity of attention from O(N2) to O(NC2 + C3). By replacing point-wise clustering with covariance decomposition, LRQ-Solver achieves exceptional scalability efficiently processing up to 2 million points on a single GPU. Validated on standard benchmarks, LRQ-Solver achieves a 38.9% error reduction on the DrivAer++ dataset and 28.76% on the 3D Beam dataset, alongside a training speedup of up to 50 times. Our results establish that LRQ-Solver offers a powerful paradigm for multi-configuration physics simulations, delivering a SOTA combination of accuracy, scalability, and efficiency. Code to reproduce the experiments is available at https://github.com/LilaKen/LRQ-Solver.",
    "authors": [
      "Peijian Zeng",
      "Guan Wang",
      "Haohao Gu",
      "Xiaoguang Hu",
      "TiezhuGao",
      "Zhuowei Wang",
      "Aimin Yang",
      "Xiaoyu Song"
    ],
    "categories": [
      "cs.CE"
    ],
    "publishedAt": "2025-10-13T17:18:30.000Z",
    "updatedAt": "2025-10-13T17:18:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11636v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11636v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11632v1",
    "arxivId": "2510.11632v1",
    "title": "NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection",
    "abstract": "Recent studies in 3D object detection for autonomous vehicles aim to enrich features through the utilization of multi-modal setups or the extraction of local patterns within LiDAR point clouds. However, multi-modal methods face significant challenges in feature alignment, and gaining features locally can be oversimplified for complex 3D object detection tasks. In this paper, we propose a novel model, NV3D, which utilizes local features acquired from voxel neighbors, as normal vectors computed per voxel basis using K-nearest neighbors (KNN) and principal component analysis (PCA). This informative feature enables NV3D to determine the relationship between the surface and pertinent target entities, including cars, pedestrians, or cyclists. During the normal vector extraction process, NV3D offers two distinct sampling strategies: normal vector density-based sampling and FOV-aware bin-based sampling, allowing elimination of up to 55% of data while maintaining performance. In addition, we applied element-wise attention fusion, which accepts voxel features as the query and value and normal vector features as the key, similar to the attention mechanism. Our method is trained on the KITTI dataset and has demonstrated superior performance in car and cyclist detection owing to their spatial shapes. In the validation set, NV3D without sampling achieves 86.60% and 80.18% mean Average Precision (mAP), greater than the baseline Voxel R-CNN by 2.61% and 4.23% mAP, respectively. With both samplings, NV3D achieves 85.54% mAP in car detection, exceeding the baseline by 1.56% mAP, despite roughly 55% of voxels being filtered out.",
    "authors": [
      "Krittin Chaowakarn",
      "Paramin Sangwongngam",
      "Nang Htet Htet Aung",
      "Chalie Charoenlarpnopparut"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.9; I.2.10; I.4.8; I.4.10; I.5.1; I.5.4"
    ],
    "publishedAt": "2025-10-13T17:13:06.000Z",
    "updatedAt": "2025-10-13T17:13:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11632v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11632v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11631v1",
    "arxivId": "2510.11631v1",
    "title": "EvoCAD: Evolutionary CAD Code Generation with Vision Language Models",
    "abstract": "Combining large language models with evolutionary computation algorithms represents a promising research direction leveraging the remarkable generative and in-context learning capabilities of LLMs with the strengths of evolutionary algorithms. In this work, we present EvoCAD, a method for generating computer-aided design (CAD) objects through their symbolic representations using vision language models and evolutionary optimization. Our method samples multiple CAD objects, which are then optimized using an evolutionary approach with vision language and reasoning language models. We assess our method using GPT-4V and GPT-4o, evaluating it on the CADPrompt benchmark dataset and comparing it to prior methods. Additionally, we introduce two new metrics based on topological properties defined by the Euler characteristic, which capture a form of semantic similarity between 3D objects. Our results demonstrate that EvoCAD outperforms previous approaches on multiple metrics, particularly in generating topologically correct objects, which can be efficiently evaluated using our two novel metrics that complement existing spatial metrics.",
    "authors": [
      "Tobias Preintner",
      "Weixuan Yuan",
      "Adrian König",
      "Thomas Bäck",
      "Elena Raponi",
      "Niki van Stein"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "publishedAt": "2025-10-13T17:12:02.000Z",
    "updatedAt": "2025-10-13T17:12:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11631v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11631v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11627v1",
    "arxivId": "2510.11627v1",
    "title": "Sublinear Metric Steiner Forest via Maximal Independent Set",
    "abstract": "In this work we consider the Metric Steiner Forest problem in the sublinear time model. Given a set $V$ of $n$ points in a metric space where distances are provided by means of query access to an $n\\times n$ distance matrix, along with a set of $k$ terminal pairs $(s_1,t_1), \\dots, (s_k,t_k)\\in V\\times V$, the goal is to find a minimum-weight subset of edges that connects each terminal pair. Although sublinear time algorithms have been studied for estimating the weight of a minimum spanning tree in both general and metric settings, as well as for the metric Steiner Tree problem, no sublinear time algorithm was known for the metric Steiner Forest problem. Here, we give an $O(\\log k)$-approximation algorithm for the problem that runs in time $\\widetilde{O}(n^{3/2})$. Along the way, we provide the first sublinear-time algorithm for estimating the size of a Maximal Independent Set (MIS). Our algorithm runs in time $\\widetilde{O}(n^{3/2}/\\varepsilon^2)$ under the adjacency matrix oracle model and obtains a purely multiplicative $(1+\\varepsilon)$-approximation. Previously, sublinear-time algorithms for MIS were only known for bounded-degree graphs.",
    "authors": [
      "Sepideh Mahabadi",
      "Mohammad Roghani",
      "Jakub Tarnawski",
      "Ali Vakilian"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-13T17:10:22.000Z",
    "updatedAt": "2025-10-13T17:10:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11627v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11627v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11625v1",
    "arxivId": "2510.11625v1",
    "title": "Multiwinner Voting with Interval Preferences under Incomplete Information",
    "abstract": "In multiwinner approval elections with many candidates, voters may struggle to determine their preferences over the entire slate of candidates. It is therefore of interest to explore which (if any) fairness guarantees can be provided under reduced communication. In this paper, we consider voters with one-dimensional preferences: voters and candidates are associated with points in $\\mathbb R$, and each voter's approval set forms an interval of $\\mathbb R$. We put forward a probabilistic preference model, where the voter set consists of $\\sigma$ different groups; each group is associated with a distribution over an interval of $\\mathbb R$, so that each voter draws the endpoints of her approval interval from the distribution associated with her group. We present an algorithm for computing committees that provide Proportional Justified Representation + (PJR+), which proceeds by querying voters' preferences, and show that, in expectation, it makes $\\mathcal{O}(\\log( \\sigma\\cdot k))$ queries per voter, where $k$ is the desired committee size.",
    "authors": [
      "Drew Springham",
      "Edith Elkind",
      "Bart de Keijzer",
      "Maria Polukarov"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-13T17:07:00.000Z",
    "updatedAt": "2025-10-13T17:07:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11625v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11625v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11620v1",
    "arxivId": "2510.11620v1",
    "title": "Enhancing Long Chain-of-Thought Reasoning through Multi-Path Plan Aggregation",
    "abstract": "Inference-time scaling enhances the reasoning ability of a language model (LM) by extending its chain-of-thought (CoT). However, existing approaches typically generate the entire reasoning chain in a single forward pass, which often leads to CoT derailment, i.e., the reasoning trajectory drifting off course due to compounding errors. This problem is particularly severe for smaller LMs with long CoTs due to their limited capacity. To address this, we analyze raw long CoTs and uncover a reasoning hierarchy consisting of planning and execution steps. Our analysis reveals that most reasoning errors stem from incorrect planning. Motivated by this observation, we propose Multi-Path Plan Aggregation (MPPA), a framework that augments single-pass reasoning with plan exploration and aggregation. Following a variable interval schedule based on the token position, MPPA generates multiple candidate plans and aggregates them into a refined planning step. To maintain efficiency, we adopt a minimal design in which the base LM serves as the primary policy, while a lightweight LoRA module implements the plan aggregation policy. We further observe that outcome-reward RL is inefficient for long trajectories (e.g., exceeding 4K tokens). To overcome this, we introduce online Step-DPO, a process-level preference optimization scheme that leverages Twisted Sequential Monte Carlo (TSMC) to provide scalable stepwise supervision using small LMs. This yields more efficient training, improved stability, and higher accuracy. Extensive experiments on challenging math, science, and logical reasoning benchmarks demonstrate that, with only 10% SFT data and 5% of preference pairs, our method outperforms both the DeepSeek-R1 distillation baseline and the outcome-reward RL baseline across multiple base models and tasks.",
    "authors": [
      "Siheng Xiong",
      "Ali Payani",
      "Faramarz Fekri"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T17:02:41.000Z",
    "updatedAt": "2025-10-13T17:02:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11620v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11620v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11618v1",
    "arxivId": "2510.11618v1",
    "title": "StoryBox: Collaborative Multi-Agent Simulation for Hybrid Bottom-Up Long-Form Story Generation Using Large Language Models",
    "abstract": "Human writers often begin their stories with an overarching mental scene, where they envision the interactions between characters and their environment. Inspired by this creative process, we propose a novel approach to long-form story generation, termed hybrid bottom-up long-form story generation, using multi-agent simulations. In our method, agents interact within a dynamic sandbox environment, where their behaviors and interactions with one another and the environment generate emergent events. These events form the foundation for the story, enabling organic character development and plot progression. Unlike traditional top-down approaches that impose rigid structures, our hybrid bottom-up approach allows for the natural unfolding of events, fostering more spontaneous and engaging storytelling. The system is capable of generating stories exceeding 10,000 words while maintaining coherence and consistency, addressing some of the key challenges faced by current story generation models. We achieve state-of-the-art performance across several metrics. This approach offers a scalable and innovative solution for creating dynamic, immersive long-form stories that evolve organically from agent-driven interactions.",
    "authors": [
      "Zehao Chen",
      "Rong Pan",
      "Haoran Li"
    ],
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "publishedAt": "2025-10-13T16:57:32.000Z",
    "updatedAt": "2025-10-13T16:57:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11618v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11618v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11617v1",
    "arxivId": "2510.11617v1",
    "title": "Lecture Notes on Verifying Graph Neural Networks",
    "abstract": "In these lecture notes, we first recall the connection between graph neural networks, Weisfeiler-Lehman tests and logics such as first-order logic and graded modal logic. We then present a modal logic in which counting modalities appear in linear inequalities in order to solve verification tasks on graph neural networks. We describe an algorithm for the satisfiability problem of that logic. It is inspired from the tableau method of vanilla modal logic, extended with reasoning in quantifier-free fragment Boolean algebra with Presburger arithmetic.",
    "authors": [
      "François Schwarzentruber"
    ],
    "categories": [
      "cs.LO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T16:57:20.000Z",
    "updatedAt": "2025-10-13T16:57:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11617v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11617v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11616v1",
    "arxivId": "2510.11616v1",
    "title": "Attention Factors for Statistical Arbitrage",
    "abstract": "Statistical arbitrage exploits temporal price differences between similar assets. We develop a framework to jointly identify similar assets through factors, identify mispricing and form a trading policy that maximizes risk-adjusted performance after trading costs. Our Attention Factors are conditional latent factors that are the most useful for arbitrage trading. They are learned from firm characteristic embeddings that allow for complex interactions. We identify time-series signals from the residual portfolios of our factors with a general sequence model. Estimating factors and the arbitrage trading strategy jointly is crucial to maximize profitability after trading costs. In a comprehensive empirical study we show that our Attention Factor model achieves an out-of-sample Sharpe ratio above 4 on the largest U.S. equities over a 24-year period. Our one-step solution yields an unprecedented Sharpe ratio of 2.3 net of transaction costs. We show that weak factors are important for arbitrage trading.",
    "authors": [
      "Elliot L. Epstein",
      "Rose Wang",
      "Jaewon Choi",
      "Markus Pelger"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.CP",
      "I.2.0"
    ],
    "publishedAt": "2025-10-13T16:56:30.000Z",
    "updatedAt": "2025-10-13T16:56:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11616v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11616v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11615v1",
    "arxivId": "2510.11615v1",
    "title": "LLM-Oriented Token-Adaptive Knowledge Distillation",
    "abstract": "Knowledge distillation (KD) is a key technique for compressing large-scale language models (LLMs), yet prevailing logit-based methods typically employ static strategies that are misaligned with the dynamic learning process of student models. These methods typically treat all tokens indiscriminately and apply a single, fixed temperature, resulting in suboptimal knowledge transfer. To address these limitations, we propose LLM-Oriented Token-Adaptive Knowledge Distillation (AdaKD), a novel framework that adapts the distillation process to the real-time learning state of each token. AdaKD consists of two synergistic modules driven by a unified token difficulty metric. First, our Loss-Driven Adaptive Token Focusing (LATF) module dynamically adjusts the distillation focus by monitoring the student's learning stability, concentrating computational resources on the most valuable tokens at each training phase. Second, we introduce Inverse Difficulty Temperature Scaling (IDTS), a counterintuitive yet effective token-level temperature strategy. It employs low temperatures for difficult tokens for targeted error correction, and high temperatures for easy tokens to encourage students to learn from the teacher's complete and smooth output distribution, thereby enhancing generalization. As a plug-and-play framework, AdaKD can consistently improve the performance of various distillation methods on multiple model architectures and benchmarks.",
    "authors": [
      "Xurong Xie",
      "Zhucun Xue",
      "Jiafu Wu",
      "Jian Li",
      "Yabiao Wang",
      "Xiaobin Hu",
      "Yong Liu",
      "Jiangning Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T16:55:07.000Z",
    "updatedAt": "2025-10-13T16:55:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11615v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11615v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11613v1",
    "arxivId": "2510.11613v1",
    "title": "High-resolution Photo Enhancement in Real-time: A Laplacian Pyramid Network",
    "abstract": "Photo enhancement plays a crucial role in augmenting the visual aesthetics of a photograph. In recent years, photo enhancement methods have either focused on enhancement performance, producing powerful models that cannot be deployed on edge devices, or prioritized computational efficiency, resulting in inadequate performance for real-world applications. To this end, this paper introduces a pyramid network called LLF-LUT++, which integrates global and local operators through closed-form Laplacian pyramid decomposition and reconstruction. This approach enables fast processing of high-resolution images while also achieving excellent performance. Specifically, we utilize an image-adaptive 3D LUT that capitalizes on the global tonal characteristics of downsampled images, while incorporating two distinct weight fusion strategies to achieve coarse global image enhancement. To implement this strategy, we designed a spatial-frequency transformer weight predictor that effectively extracts the desired distinct weights by leveraging frequency features. Additionally, we apply local Laplacian filters to adaptively refine edge details in high-frequency components. After meticulously redesigning the network structure and transformer model, LLF-LUT++ not only achieves a 2.64 dB improvement in PSNR on the HDR+ dataset, but also further reduces runtime, with 4K resolution images processed in just 13 ms on a single GPU. Extensive experimental results on two benchmark datasets further show that the proposed approach performs favorably compared to state-of-the-art methods. The source code will be made publicly available at https://github.com/fengzhang427/LLF-LUT.",
    "authors": [
      "Feng Zhang",
      "Haoyou Deng",
      "Zhiqiang Li",
      "Lida Li",
      "Bin Xu",
      "Qingbo Lu",
      "Zisheng Cao",
      "Minchen Wei",
      "Changxin Gao",
      "Nong Sang",
      "Xiang Bai"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T16:52:32.000Z",
    "updatedAt": "2025-10-13T16:52:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11613v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11613v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11608v1",
    "arxivId": "2510.11608v1",
    "title": "ParaCook: On Time-Efficient Planning for Multi-Agent Systems",
    "abstract": "Large Language Models (LLMs) exhibit strong reasoning abilities for planning long-horizon, real-world tasks, yet existing agent benchmarks focus on task completion while neglecting time efficiency in parallel and asynchronous operations. To address this, we present ParaCook, a benchmark for time-efficient collaborative planning. Inspired by the Overcooked game, ParaCook provides an environment for various challenging interaction planning of multi-agent systems that are instantiated as cooking tasks, with a simplified action space to isolate the core challenge of strategic parallel planning. Through a comprehensive evaluation of state-of-the-art LLMs, we find that current approaches achieve suboptimal plans, which struggle with parallel actions or coordination. Our analysis also reveals LLMs' potential on abstract tasks where they can focus on high-level parallel optimization. ParaCook provides a scalable evaluation framework with adjustable complexity, establishing a foundation for developing and assessing time efficiency-aware multi-agent planning. The code and data are available at https://github.com/zsq259/ParaCook.",
    "authors": [
      "Shiqi Zhang",
      "Xinbei Ma",
      "Yunqing Xu",
      "Zouying Cao",
      "Pengrui Lu",
      "Haobo Yuan",
      "Tiancheng Shen",
      "Zhuosheng Zhang",
      "Hai Zhao",
      "Ming-Hsuan Yang"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T16:47:07.000Z",
    "updatedAt": "2025-10-13T16:47:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11608v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11608v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11606v1",
    "arxivId": "2510.11606v1",
    "title": "ExpVid: A Benchmark for Experiment Video Understanding & Reasoning",
    "abstract": "Multimodal Large Language Models (MLLMs) hold promise for accelerating scientific discovery by interpreting complex experimental procedures. However, their true capabilities are poorly understood, as existing benchmarks neglect the fine-grained and long-horizon nature of authentic laboratory work, especially in wet-lab settings. To bridge this gap, we introduce ExpVid, the first benchmark designed to systematically evaluate MLLMs on scientific experiment videos. Curated from peer-reviewed video publications, ExpVid features a new three-level task hierarchy that mirrors the scientific process: (1) Fine-grained Perception of tools, materials, and actions; (2) Procedural Understanding of step order and completeness; and (3) Scientific Reasoning that connects the full experiment to its published conclusions. Our vision-centric annotation pipeline, combining automated generation with multi-disciplinary expert validation, ensures that tasks require visual grounding. We evaluate 19 leading MLLMs on ExpVid and find that while they excel at coarse-grained recognition, they struggle with disambiguating fine details, tracking state changes over time, and linking experimental procedures to scientific outcomes. Our results reveal a notable performance gap between proprietary and open-source models, particularly in high-order reasoning. ExpVid not only provides a diagnostic tool but also charts a roadmap for developing MLLMs capable of becoming trustworthy partners in scientific experimentation.",
    "authors": [
      "Yicheng Xu",
      "Yue Wu",
      "Jiashuo Yu",
      "Ziang Yan",
      "Tianxiang Jiang",
      "Yinan He",
      "Qingsong Zhao",
      "Kai Chen",
      "Yu Qiao",
      "Limin Wang",
      "Manabu Okumura",
      "Yi Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T16:45:28.000Z",
    "updatedAt": "2025-10-13T16:45:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11606v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11606v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11605v1",
    "arxivId": "2510.11605v1",
    "title": "ACE-G: Improving Generalization of Scene Coordinate Regression Through Query Pre-Training",
    "abstract": "Scene coordinate regression (SCR) has established itself as a promising learning-based approach to visual relocalization. After mere minutes of scene-specific training, SCR models estimate camera poses of query images with high accuracy. Still, SCR methods fall short of the generalization capabilities of more classical feature-matching approaches. When imaging conditions of query images, such as lighting or viewpoint, are too different from the training views, SCR models fail. Failing to generalize is an inherent limitation of previous SCR frameworks, since their training objective is to encode the training views in the weights of the coordinate regressor itself. The regressor essentially overfits to the training views, by design. We propose to separate the coordinate regressor and the map representation into a generic transformer and a scene-specific map code. This separation allows us to pre-train the transformer on tens of thousands of scenes. More importantly, it allows us to train the transformer to generalize from mapping images to unseen query images during pre-training. We demonstrate on multiple challenging relocalization datasets that our method, ACE-G, leads to significantly increased robustness while keeping the computational footprint attractive.",
    "authors": [
      "Leonard Bruns",
      "Axel Barroso-Laguna",
      "Tommaso Cavallari",
      "Áron Monszpart",
      "Sowmya Munukutla",
      "Victor Adrian Prisacariu",
      "Eric Brachmann"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T16:45:17.000Z",
    "updatedAt": "2025-10-13T16:45:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11605v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11605v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11604v1",
    "arxivId": "2510.11604v1",
    "title": "Explainability, risk modeling, and segmentation based customer churn analytics for personalized retention in e-commerce",
    "abstract": "In online retail, customer acquisition typically incurs higher costs than customer retention, motivating firms to invest in churn analytics. However, many contemporary churn models operate as opaque black boxes, limiting insight into the determinants of attrition, the timing of retention opportunities, and the identification of high-risk customer segments. Accordingly, the emphasis should shift from prediction alone to the design of personalized retention strategies grounded in interpretable evidence. This study advances a three-component framework that integrates explainable AI to quantify feature contributions, survival analysis to model time-to-event churn risk, and RFM profiling to segment customers by transactional behaviour. In combination, these methods enable the attribution of churn drivers, estimation of intervention windows, and prioritization of segments for targeted actions, thereby supporting strategies that reduce attrition and strengthen customer loyalty.",
    "authors": [
      "Sanjula De Alwis",
      "Indrajith Ekanayake"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T16:44:24.000Z",
    "updatedAt": "2025-10-13T16:44:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11604v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11604v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11602v1",
    "arxivId": "2510.11602v1",
    "title": "Deconstructing Attention: Investigating Design Principles for Effective Language Modeling",
    "abstract": "The success of Transformer language models is widely credited to their dot-product attention mechanism, which interweaves a set of key design principles: mixing information across positions (enabling multi-token interactions), sequence-dependent activations (where attention weights adapt to each input), a specific mathematical form (dot-product similarities plus softmax weighting), and coupling of queries and keys to evolving hidden states (grounding attention in the current layer). However, the necessity of each of these principles remains largely untested. In this work, we systematically deconstruct attention by designing controlled variants that selectively relax these principles, applied both uniformly across all layers and in hybrid architectures where only some layers retain standard attention. Our empirical analysis reveals that mechanisms for mixing tokens are indispensable, as their absence collapses models to near-random behavior, while the exact mathematical form and sequence dependency can be substantially relaxed, especially when preserved in just a subset of layers. Surprisingly, even variants that fail in isolation can achieve robust performance when interleaved with standard attention, highlighting a cooperative effect. These findings deepen our understanding of what truly underpins attention's effectiveness and open new avenues for simplifying language models without sacrificing performance.",
    "authors": [
      "Huiyin Xue",
      "Nafise Sadat Moosavi",
      "Nikolaos Aletras"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T16:42:14.000Z",
    "updatedAt": "2025-10-13T16:42:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11602v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11602v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11599v1",
    "arxivId": "2510.11599v1",
    "title": "SemCSE-Multi: Multifaceted and Decodable Embeddings for Aspect-Specific and Interpretable Scientific Domain Mapping",
    "abstract": "We propose SemCSE-Multi, a novel unsupervised framework for generating multifaceted embeddings of scientific abstracts, evaluated in the domains of invasion biology and medicine. These embeddings capture distinct, individually specifiable aspects in isolation, thus enabling fine-grained and controllable similarity assessments as well as adaptive, user-driven visualizations of scientific domains. Our approach relies on an unsupervised procedure that produces aspect-specific summarizing sentences and trains embedding models to map semantically related summaries to nearby positions in the embedding space. We then distill these aspect-specific embedding capabilities into a unified embedding model that directly predicts multiple aspect embeddings from a scientific abstract in a single, efficient forward pass. In addition, we introduce an embedding decoding pipeline that decodes embeddings back into natural language descriptions of their associated aspects. Notably, we show that this decoding remains effective even for unoccupied regions in low-dimensional visualizations, thus offering vastly improved interpretability in user-centric settings.",
    "authors": [
      "Marc Brinner",
      "Sina Zarrieß"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T16:38:20.000Z",
    "updatedAt": "2025-10-13T16:38:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11599v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11599v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11598v1",
    "arxivId": "2510.11598v1",
    "title": "MeTA-LoRA: Data-Efficient Multi-Task Fine-Tuning for Large Language Models",
    "abstract": "Low-Rank Adaptation (LoRA) has emerged as one of the most widely used parameter-efficient fine-tuning (PEFT) methods for adapting large language models (LLMs) to downstream tasks. While highly effective in single-task settings, it struggles to efficiently leverage inter-task knowledge in complex multi-task learning scenarios, often requiring substantial task-specific data to achieve optimal performance. To address this limitation, we introduce MeTA-LoRA, a two-stage optimization framework that significantly improves data efficiency in multi-task adaptation. In the first stage, task-specific LoRA adapters are learned using only a few samples from each involved dataset, enabling rapid adaptation without large-scale supervision. In the second stage, the shared LoRA adapter is updated by aggregating gradients from multiple tasks to promote knowledge transfer across tasks, further reducing data usage by leveraging common patterns. In both multi-task learning and multilingual learning scenarios, our method matches or surpasses the performance of traditional full-data LoRA fine-tuning approaches, while using significantly less task-specific data.",
    "authors": [
      "Bo Cheng",
      "Xu Wang",
      "Jinda Liu",
      "Yi Chang",
      "Yuan Wu"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:37:40.000Z",
    "updatedAt": "2025-10-13T16:37:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11598v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11598v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11596v1",
    "arxivId": "2510.11596v1",
    "title": "GlobalizeEd: A Multimodal Translation System that Preserves Speaker Identity in Academic Lectures",
    "abstract": "A large amount of valuable academic content is only available in its original language, creating a significant access barrier for the global student community. This is a challenge for translating in several subjects, such as history, culture, and the arts, where current automated subtitle tools fail to convey the appropriate pedagogical tone and specialized meaning. In addition, reading traditional automated subtitles increases cognitive load and leads to a disconnected learning experience. Through a mixed-methods study involving 36 participants, we found that GlobalizeEds dubbed formats significantly reduce cognitive load and offer a more immersive learning experience compared to traditional subtitles. Although learning effectiveness was comparable between high-quality subtitles and dubbed formats, both groups valued GlobalizeEds ability to preserve the speakers voice, which enhanced perceived authenticity. Instructors rated translation accuracy and vocal naturalness, whereas students reported that synchronized, identity-preserving outputs fostered engagement and trust. This work contributes a novel human-centered AI framework for cross-lingual education, demonstrating how multimodal translation systems can balance linguistic fidelity, cultural adaptability, and user control to create more inclusive global learning experiences.",
    "authors": [
      "Hoang-Son Vo",
      "Karina Kolmogortseva",
      "Ngumimi Karen Iyortsuun",
      "Hong-Duyen Vo",
      "Soo-Hyung Kim"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T16:35:20.000Z",
    "updatedAt": "2025-10-13T16:35:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11596v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11596v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11595v1",
    "arxivId": "2510.11595v1",
    "title": "Reproducibility: The New Frontier in AI Governance",
    "abstract": "AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific standards, via weak reproducibility protocols, effectively erodes the power of policymakers to enact meaningful policy and governance protocols. Our paper outlines how AI research could adopt stricter reproducibility guidelines to assist governance endeavours and improve consensus on the AI risk landscape. We evaluate the forthcoming reproducibility crisis within AI research through the lens of crises in other scientific domains; providing a commentary on how adopting preregistration, increased statistical power and negative result publication reproducibility protocols can enable effective AI governance. While we maintain that AI governance must be reactive due to AI's significant societal implications we argue that policymakers and governments must consider reproducibility protocols as a core tool in the governance arsenal and demand higher standards for AI research. Code to replicate data and figures: https://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance",
    "authors": [
      "Israel Mason-Williams",
      "Gabryel Mason-Williams"
    ],
    "categories": [
      "cs.AI",
      "cs.GL"
    ],
    "publishedAt": "2025-10-13T16:34:25.000Z",
    "updatedAt": "2025-10-13T16:34:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11595v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11595v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11593v1",
    "arxivId": "2510.11593v1",
    "title": "Hierarchical Qubit-Merging Transformer for Quantum Error Correction",
    "abstract": "For reliable large-scale quantum computation, a quantum error correction (QEC) scheme must effectively resolve physical errors to protect logical information. Leveraging recent advances in deep learning, neural network-based decoders have emerged as a promising approach to enhance the reliability of QEC. We propose the Hierarchical Qubit-Merging Transformer (HQMT), a novel and general decoding framework that explicitly leverages the structural graph of stabilizer codes to learn error correlations across multiple scales. Our architecture first computes attention locally on structurally related groups of stabilizers and then systematically merges these qubit-centric representations to build a global view of the error syndrome. The proposed HQMT achieves substantially lower logical error rates for surface codes by integrating a dedicated qubit-merging layer within the transformer architecture. Across various code distances, HQMT significantly outperforms previous neural network-based QEC decoders as well as a powerful belief propagation with ordered statistics decoding (BP+OSD) baseline. This hierarchical approach provides a scalable and effective framework for surface code decoding, advancing the realization of reliable quantum computing.",
    "authors": [
      "Seong-Joon Park",
      "Hee-Youl Kwak",
      "Yongjune Kim"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T16:31:46.000Z",
    "updatedAt": "2025-10-13T16:31:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11593v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11593v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11592v1",
    "arxivId": "2510.11592v1",
    "title": "REGENT: Relevance-Guided Attention for Entity-Aware Multi-Vector Neural Re-Ranking",
    "abstract": "Current neural re-rankers often struggle with complex information needs and long, content-rich documents. The fundamental issue is not computational--it is intelligent content selection: identifying what matters in lengthy, multi-faceted texts. While humans naturally anchor their understanding around key entities and concepts, neural models process text within rigid token windows, treating all interactions as equally important and missing critical semantic signals. We introduce REGENT, a neural re-ranking model that mimics human-like understanding by using entities as a \"semantic skeleton\" to guide attention. REGENT integrates relevance guidance directly into the attention mechanism, combining fine-grained lexical matching with high-level semantic reasoning. This relevance-guided attention enables the model to focus on conceptually important content while maintaining sensitivity to precise term matches. REGENT achieves new state-of-the-art performance in three challenging datasets, providing up to 108% improvement over BM25 and consistently outperforming strong baselines including ColBERT and RankVicuna. To our knowledge, this is the first work to successfully integrate entity semantics directly into neural attention, establishing a new paradigm for entity-aware information retrieval.",
    "authors": [
      "Shubham Chatterjee"
    ],
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:31:42.000Z",
    "updatedAt": "2025-10-13T16:31:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11592v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11592v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11590v1",
    "arxivId": "2510.11590v1",
    "title": "Diffusion-DFL: Decision-focused Diffusion Models for Stochastic Optimization",
    "abstract": "Decision-focused learning (DFL) integrates predictive modeling and optimization by training predictors to optimize the downstream decision target rather than merely minimizing prediction error. To date, existing DFL methods typically rely on deterministic point predictions, which are often insufficient to capture the intrinsic stochasticity of real-world environments. To address this challenge, we propose the first diffusion-based DFL approach, which trains a diffusion model to represent the distribution of uncertain parameters and optimizes the decision by solving a stochastic optimization with samples drawn from the diffusion model. Our contributions are twofold. First, we formulate diffusion DFL using the reparameterization trick, enabling end-to-end training through diffusion. While effective, it is memory and compute-intensive due to the need to differentiate through the diffusion sampling process. Second, we propose a lightweight score function estimator that uses only several forward diffusion passes and avoids backpropagation through the sampling. This follows from our results that backpropagating through stochastic optimization can be approximated by a weighted score function formulation. We empirically show that our diffusion DFL approach consistently outperforms strong baselines in decision quality. The source code for all experiments is available at the project repository: https://github.com/GT-KOALA/Diffusion_DFL.",
    "authors": [
      "Zihao Zhao",
      "Christopher Yeh",
      "Lingkai Kong",
      "Kai Wang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T16:31:17.000Z",
    "updatedAt": "2025-10-13T16:31:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11590v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11590v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11589v1",
    "arxivId": "2510.11589v1",
    "title": "QDER: Query-Specific Document and Entity Representations for Multi-Vector Document Re-Ranking",
    "abstract": "Neural IR has advanced through two distinct paths: entity-oriented approaches leveraging knowledge graphs and multi-vector models capturing fine-grained semantics. We introduce QDER, a neural re-ranking model that unifies these approaches by integrating knowledge graph semantics into a multi-vector model. QDER's key innovation lies in its modeling of query-document relationships: rather than computing similarity scores on aggregated embeddings, we maintain individual token and entity representations throughout the ranking process, performing aggregation only at the final scoring stage - an approach we call \"late aggregation.\" We first transform these fine-grained representations through learned attention patterns, then apply carefully chosen mathematical operations for precise matches. Experiments across five standard benchmarks show that QDER achieves significant performance gains, with improvements of 36% in nDCG@20 over the strongest baseline on TREC Robust 2004 and similar improvements on other datasets. QDER particularly excels on difficult queries, achieving an nDCG@20 of 0.70 where traditional approaches fail completely (nDCG@20 = 0.0), setting a foundation for future work in entity-aware retrieval.",
    "authors": [
      "Shubham Chatterjee",
      "Jeff Dalton"
    ],
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:31:06.000Z",
    "updatedAt": "2025-10-13T16:31:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11589v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11589v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11588v1",
    "arxivId": "2510.11588v1",
    "title": "Analyzing and Internalizing Complex Policy Documents for LLM Agents",
    "abstract": "Large Language Model (LLM)-based agentic systems rely on in-context policy documents encoding diverse business rules. As requirements grow, these documents expand rapidly, causing high computational overhead. This motivates developing internalization methods that embed policy documents into model priors while preserving performance. Prior prompt compression work targets generic prompts, but agentic policy documents span multiple complexity levels and require deeper reasoning, making internalization harder. We introduce CC-Gen, an agentic benchmark generator with Controllable Complexity across four levels, enabling systematic evaluation of agents' ability to handle complexity and offering a unified framework for assessing policy internalization. Our analysis shows that complex policy specifications governing workflows pose major reasoning challenges. Supporting internalization with gold user agent interaction trajectories containing chain-of-thought (CoT) annotations via supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy complexity increases. To mitigate data and reasoning burdens, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline parses policy documents to extract key specifications, grouping them into factual, behavioral, and conditional categories, and isolating complex conditions that drive workflow complexity. This guides targeted data synthesis and enables agents to internalize policy information through an autoregressive pretraining loss. Experiments show CAP-CPT improves SFT baselines in all settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT data.",
    "authors": [
      "Jiateng Liu",
      "Zhenhailong Wang",
      "Xiaojiang Huang",
      "Yingjie Li",
      "Xing Fan",
      "Xiang Li",
      "Chenlei Guo",
      "Ruhi Sarikaya",
      "Heng Ji"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T16:30:07.000Z",
    "updatedAt": "2025-10-13T16:30:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11588v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11588v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11586v1",
    "arxivId": "2510.11586v1",
    "title": "Survey Response Generation: Generating Closed-Ended Survey Responses In-Silico with Large Language Models",
    "abstract": "Many in-silico simulations of human survey responses with large language models (LLMs) focus on generating closed-ended survey responses, whereas LLMs are typically trained to generate open-ended text instead. Previous research has used a diverse range of methods for generating closed-ended survey responses with LLMs, and a standard practice remains to be identified. In this paper, we systematically investigate the impact that various Survey Response Generation Methods have on predicted survey responses. We present the results of 32 mio. simulated survey responses across 8 Survey Response Generation Methods, 4 political attitude surveys, and 10 open-weight language models. We find significant differences between the Survey Response Generation Methods in both individual-level and subpopulation-level alignment. Our results show that Restricted Generation Methods perform best overall, and that reasoning output does not consistently improve alignment. Our work underlines the significant impact that Survey Response Generation Methods have on simulated survey responses, and we develop practical recommendations on the application of Survey Response Generation Methods.",
    "authors": [
      "Georg Ahnert",
      "Anna-Carolina Haensch",
      "Barbara Plank",
      "Markus Strohmaier"
    ],
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "publishedAt": "2025-10-13T16:29:19.000Z",
    "updatedAt": "2025-10-13T16:29:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11586v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11586v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11584v1",
    "arxivId": "2510.11584v1",
    "title": "LLMAtKGE: Large Language Models as Explainable Attackers against Knowledge Graph Embeddings",
    "abstract": "Adversarial attacks on knowledge graph embeddings (KGE) aim to disrupt the model's ability of link prediction by removing or inserting triples. A recent black-box method has attempted to incorporate textual and structural information to enhance attack performance. However, it is unable to generate human-readable explanations, and exhibits poor generalizability. In the past few years, large language models (LLMs) have demonstrated powerful capabilities in text comprehension, generation, and reasoning. In this paper, we propose LLMAtKGE, a novel LLM-based framework that selects attack targets and generates human-readable explanations. To provide the LLM with sufficient factual context under limited input constraints, we design a structured prompting scheme that explicitly formulates the attack as multiple-choice questions while incorporating KG factual evidence. To address the context-window limitation and hesitation issues, we introduce semantics-based and centrality-based filters, which compress the candidate set while preserving high recall of attack-relevant information. Furthermore, to efficiently integrate both semantic and structural information into the filter, we precompute high-order adjacency and fine-tune the LLM with a triple classification task to enhance filtering performance. Experiments on two widely used knowledge graph datasets demonstrate that our attack outperforms the strongest black-box baselines and provides explanations via reasoning, and showing competitive performance compared with white-box methods. Comprehensive ablation and case studies further validate its capability to generate explanations.",
    "authors": [
      "Ting Li",
      "Yang Yang",
      "Yipeng Yu",
      "Liang Yao",
      "Guoqing Chao",
      "Ruifeng Xu"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:29:17.000Z",
    "updatedAt": "2025-10-13T16:29:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11584v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11584v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11583v1",
    "arxivId": "2510.11583v1",
    "title": "Smooth Spatiotemporal Tube Synthesis for Prescribed-Time Reach-Avoid-Stay Control",
    "abstract": "In this work, we address the issue of controller synthesis for a control-affine nonlinear system to meet prescribed time reach-avoid-stay specifications. Our goal is to improve upon previous methods based on spatiotemporal tubes (STTs) by eliminating the need for circumvent functions, which often lead to abrupt tube modifications and high control effort. We propose an adaptive framework that constructs smooth STTs around static unsafe sets, enabling continuous avoidance while guiding the system toward the target within the prescribed time. A closed-form, approximation-free control law is derived to ensure the system trajectory remains within the tube and satisfies the RAS task. The effectiveness of the proposed approach is demonstrated through a case study, showing a significant reduction in control effort compared to prior methods.",
    "authors": [
      "Siddhartha Upadhyay",
      "Ratnangshu Das",
      "Pushpak Jagtap"
    ],
    "categories": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T16:27:11.000Z",
    "updatedAt": "2025-10-13T16:27:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11583v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11583v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11582v1",
    "arxivId": "2510.11582v1",
    "title": "Beyond the Use-and-then-Forget (UatF) Bound: Fixed Point Algorithms for Statistical Max-Min Power Control",
    "abstract": "We introduce mathematical tools and fixed point algorithms for optimal statistical max-min power control in cellular and cell-less massive MIMO systems. Unlike previous studies that rely on the use-and-then-forget (UatF) lower bound on Shannon achievable (ergodic) rates, our proposed framework can deal with alternative bounds that explicitly consider perfect or imperfect channel state information (CSI) at the decoder. In doing so, we address limitations of UatF-based algorithms, which inherit the shortcomings of the UatF bound. For example, the UatF bound can be overly conservative: in extreme cases, under fully statistical (nonadaptive) beamforming in zero-mean channels, the UatF bound produces trivial (zero) rate bounds. It also lacks scale invariance: merely scaling the beamformers can change the bound drastically, especially when simple beamforming strategies are employed. In contrast, our framework is compatible with information-theoretic bounds that do not suffer from the above drawbacks. We illustrate the framework by solving a max-min power control problem considering a standard bound that exploits instantaneous CSI at the decoder.",
    "authors": [
      "Renato Luis Garrido Cavalcante",
      "Noor Ul Ain",
      "Lorenzo Miretti",
      "Slawomir Stanczak"
    ],
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T16:26:32.000Z",
    "updatedAt": "2025-10-13T16:26:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11582v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11582v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11579v1",
    "arxivId": "2510.11579v1",
    "title": "MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis",
    "abstract": "Multimodal Sentiment Analysis (MSA) aims to identify and interpret human emotions by integrating information from heterogeneous data sources such as text, video, and audio. While deep learning models have advanced in network architecture design, they remain heavily limited by scarce multimodal annotated data. Although Mixup-based augmentation improves generalization in unimodal tasks, its direct application to MSA introduces critical challenges: random mixing often amplifies label ambiguity and semantic inconsistency due to the lack of emotion-aware mixing mechanisms. To overcome these issues, we propose MS-Mix, an adaptive, emotion-sensitive augmentation framework that automatically optimizes sample mixing in multimodal settings. The key components of MS-Mix include: (1) a Sentiment-Aware Sample Selection (SASS) strategy that effectively prevents semantic confusion caused by mixing samples with contradictory emotions. (2) a Sentiment Intensity Guided (SIG) module using multi-head self-attention to compute modality-specific mixing ratios dynamically based on their respective emotional intensities. (3) a Sentiment Alignment Loss (SAL) that aligns the prediction distributions across modalities, and incorporates the Kullback-Leibler-based loss as an additional regularization term to train the emotion intensity predictor and the backbone network jointly. Extensive experiments on three benchmark datasets with six state-of-the-art backbones confirm that MS-Mix consistently outperforms existing methods, establishing a new standard for robust multimodal sentiment augmentation. The source code is available at: https://github.com/HongyuZhu-s/MS-Mix.",
    "authors": [
      "Hongyu Zhu",
      "Lin Chen",
      "Mounim A. El-Yacoubi",
      "Mingsheng Shang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T16:23:32.000Z",
    "updatedAt": "2025-10-13T16:23:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11579v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11579v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11577v1",
    "arxivId": "2510.11577v1",
    "title": "Newton series representation of completely monotone functions",
    "abstract": "We prove that every completely monotone function defined on a right-unbounded open interval admits a Newton series expansion at every point of that interval. This result can be viewed as an analog of Bernstein's little theorem for absolutely monotone functions. As an application, we use it to study principal indefinite sums, which are constructed via a broad generalization of Bohr-Mollerup's theorem.",
    "authors": [
      "Thomas Lamby",
      "Jean-Luc Marichal",
      "Naïm Zenaïdi"
    ],
    "categories": [
      "math.CA",
      "cs.DM",
      "math.CO",
      "26A48, 26A51, 39A70, 41A58 (Primary), 33B15, 39A12, 40A30&#10;  (Secondary)"
    ],
    "publishedAt": "2025-10-13T16:22:01.000Z",
    "updatedAt": "2025-10-13T16:22:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11577v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11577v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11576v1",
    "arxivId": "2510.11576v1",
    "title": "Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping",
    "abstract": "Foundation models are transforming Earth observation, but their potential for hyperspectral crop mapping remains underexplored. This study benchmarks three foundation models for cereal crop mapping using hyperspectral imagery: HyperSigma, DOFA, and Vision Transformers pre-trained on the SpectralEarth dataset (a large multitemporal hyperspectral archive). Models were fine-tuned on manually labeled data from a training region and evaluated on an independent test region. Performance was measured with overall accuracy (OA), average accuracy (AA), and F1-score. HyperSigma achieved an OA of 34.5% (+/- 1.8%), DOFA reached 62.6% (+/- 3.5%), and the SpectralEarth model achieved an OA of 93.5% (+/- 0.8%). A compact SpectralEarth variant trained from scratch achieved 91%, highlighting the importance of model architecture for strong generalization across geographic regions and sensor platforms. These results provide a systematic evaluation of foundation models for operational hyperspectral crop mapping and outline directions for future model development.",
    "authors": [
      "Walid Elbarz",
      "Mohamed Bourriz",
      "Hicham Hajji",
      "Hamd Ait Abdelali",
      "François Bourzeix"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T16:21:59.000Z",
    "updatedAt": "2025-10-13T16:21:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11576v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11576v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11574v1",
    "arxivId": "2510.11574v1",
    "title": "Calibrated Dynamic Modeling for Force and Payload Estimation in Hydraulic Machinery",
    "abstract": "Accurate real-time estimation of end effector interaction forces in hydraulic excavators is a key enabler for advanced automation in heavy machinery. Accurate knowledge of these forces allows improved, precise grading and digging maneuvers. To address these challenges, we introduce a high-accuracy, retrofittable 2D force- and payload estimation algorithm that does not impose additional requirements on the operator regarding trajectory, acceleration or the use of the slew joint. The approach is designed for retrofittability, requires minimal calibration and no prior knowledge of machine-specific dynamic characteristics. Specifically, we propose a method for identifying a dynamic model, necessary to estimate both end effector interaction forces and bucket payload during normal operation. Our optimization-based payload estimation achieves a full-scale payload accuracy of 1%. On a standard 25 t excavator, the online force measurement from pressure and inertial measurements achieves a direction accuracy of 13 degree and a magnitude accuracy of 383 N. The method's accuracy and generalization capability are validated on two excavator platforms of different type and weight classes. We benchmark our payload estimation against a classical quasistatic method and a commercially available system. Our system outperforms both in accuracy and precision.",
    "authors": [
      "Lennart Werner",
      "Pol Eyschen",
      "Sean Costello",
      "Pierluigi Micarelli",
      "Marco Hutter"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T16:20:48.000Z",
    "updatedAt": "2025-10-13T16:20:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11574v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11574v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11573v1",
    "arxivId": "2510.11573v1",
    "title": "(Dis)Proving Spectre Security with Speculation-Passing Style",
    "abstract": "Constant-time (CT) verification tools are commonly used for detecting potential side-channel vulnerabilities in cryptographic libraries. Recently, a new class of tools, called speculative constant-time (SCT) tools, has also been used for detecting potential Spectre vulnerabilities. In many cases, these SCT tools have emerged as liftings of CT tools. However, these liftings are seldom defined precisely and are almost never analyzed formally. The goal of this paper is to address this gap, by developing formal foundations for these liftings, and to demonstrate that these foundations can yield practical benefits. Concretely, we introduce a program transformation, coined Speculation-Passing Style (SPS), for reducing SCT verification to CT verification. Essentially, the transformation instruments the program with a new input that corresponds to attacker-controlled predictions and modifies the program to follow them. This approach is sound and complete, in the sense that a program is SCT if and only if its SPS transform is CT. Thus, we can leverage existing CT verification tools to prove SCT; we illustrate this by combining SPS with three standard methodologies for CT verification, namely reducing it to non-interference, assertion safety and dynamic taint analysis. We realize these combinations with three existing tools, EasyCrypt, BINSEC, and ctgrind, and we evaluate them on Kocher's benchmarks for Spectre-v1. Our results focus on Spectre-v1 in the standard CT leakage model; however, we also discuss applications of our method to other variants of Spectre and other leakage models.",
    "authors": [
      "Santiago Arranz-Olmos",
      "Gilles Barthe",
      "Lionel Blatter",
      "Xingyu Xie",
      "Zhiyuan Zhang"
    ],
    "categories": [
      "cs.PL"
    ],
    "publishedAt": "2025-10-13T16:19:54.000Z",
    "updatedAt": "2025-10-13T16:19:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11573v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11573v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11571v1",
    "arxivId": "2510.11571v1",
    "title": "Robust Online Sampling from Possibly Moving Target Distributions",
    "abstract": "We suppose we are given a list of points $x_1, \\dots, x_n \\in \\mathbb{R}$, a target probability measure $\\mu$ and are asked to add additional points $x_{n+1}, \\dots, x_{n+m}$ so that $x_1, \\dots, x_{n+m}$ is as close as possible to the distribution of $\\mu$; additionally, we want this to be true uniformly for all $m$. We propose a simple method that achieves this goal. It selects new points in regions where the existing set is lacking points and avoids regions that are already overly crowded. If we replace $\\mu$ by another measure $\\mu_2$ in the middle of the computation, the method dynamically adjusts and allows us to keep the original sampling points. $x_{n+1}$ can be computed in $\\mathcal{O}(n)$ steps and we obtain state-of-the-art results. It appears to be an interesting dynamical system in its own right; we analyze a continuous mean-field version that reflects much of the same behavior.",
    "authors": [
      "François Clément",
      "Stefan Steinerberger"
    ],
    "categories": [
      "math.OC",
      "cs.DS",
      "math.ST",
      "stat.TH"
    ],
    "publishedAt": "2025-10-13T16:17:41.000Z",
    "updatedAt": "2025-10-13T16:17:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11571v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11571v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11570v1",
    "arxivId": "2510.11570v1",
    "title": "Bag of Tricks for Subverting Reasoning-based Safety Guardrails",
    "abstract": "Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs), such as deliberative alignment, have shown strong defense against jailbreak attacks. By leveraging LRMs' reasoning ability, these guardrails help the models to assess the safety of user inputs before generating final responses. The powerful reasoning ability can analyze the intention of the input query and will refuse to assist once it detects the harmful intent hidden by the jailbreak methods. Such guardrails have shown a significant boost in defense, such as the near-perfect refusal rates on the open-source gpt-oss series. Unfortunately, we find that these powerful reasoning-based guardrails can be extremely vulnerable to subtle manipulation of the input prompts, and once hijacked, can lead to even more harmful results. Specifically, we first uncover a surprisingly fragile aspect of these guardrails: simply adding a few template tokens to the input prompt can successfully bypass the seemingly powerful guardrails and lead to explicit and harmful responses. To explore further, we introduce a bag of jailbreak methods that subvert the reasoning-based guardrails. Our attacks span white-, gray-, and black-box settings and range from effortless template manipulations to fully automated optimization. Along with the potential for scalable implementation, these methods also achieve alarmingly high attack success rates (e.g., exceeding 90% across 5 different benchmarks on gpt-oss series on both local host models and online API services). Evaluations across various leading open-source LRMs confirm that these vulnerabilities are systemic, underscoring the urgent need for stronger alignment techniques for open-sourced LRMs to prevent malicious misuse. Code is open-sourced at https://chenxshuo.github.io/bag-of-tricks.",
    "authors": [
      "Shuo Chen",
      "Zhen Han",
      "Haokun Chen",
      "Bailan He",
      "Shengyun Si",
      "Jingpei Wu",
      "Philip Torr",
      "Volker Tresp",
      "Jindong Gu"
    ],
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:16:44.000Z",
    "updatedAt": "2025-10-13T16:16:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11570v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11570v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11567v1",
    "arxivId": "2510.11567v1",
    "title": "A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation",
    "abstract": "Synthetic datasets are widely used for training urban scene recognition models, but even highly realistic renderings show a noticeable gap to real imagery. This gap is particularly pronounced when adapting to a specific target domain, such as Cityscapes, where differences in architecture, vegetation, object appearance, and camera characteristics limit downstream performance. Closing this gap with more detailed 3D modelling would require expensive asset and scene design, defeating the purpose of low-cost labelled data. To address this, we present a new framework that adapts an off-the-shelf diffusion model to a target domain using only imperfect pseudo-labels. Once trained, it generates high-fidelity, target-aligned images from semantic maps of any synthetic dataset, including low-effort sources created in hours rather than months. The method filters suboptimal generations, rectifies image-label misalignments, and standardises semantics across datasets, transforming weak synthetic data into competitive real-domain training sets. Experiments on five synthetic datasets and two real target datasets show segmentation gains of up to +8.0%pt. mIoU over state-of-the-art translation methods, making rapidly constructed synthetic datasets as effective as high-effort, time-intensive synthetic datasets requiring extensive manual design. This work highlights a valuable collaborative paradigm where fast semantic prototyping, combined with generative models, enables scalable, high-quality training data creation for urban scene understanding.",
    "authors": [
      "Denis Zavadski",
      "Damjan Kalšan",
      "Tim Küchler",
      "Haebom Lee",
      "Stefan Roth",
      "Carsten Rother"
    ],
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T16:12:29.000Z",
    "updatedAt": "2025-10-13T16:12:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11567v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11567v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11566v1",
    "arxivId": "2510.11566v1",
    "title": "SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy",
    "abstract": "Scooping items with tools such as spoons and ladles is common in daily life, ranging from assistive feeding to retrieving items from environmental disaster sites. However, developing a general and autonomous robotic scooping policy is challenging since it requires reasoning about complex tool-object interactions. Furthermore, scooping often involves manipulating deformable objects, such as granular media or liquids, which is challenging due to their infinite-dimensional configuration spaces and complex dynamics. We propose a method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA Omniverse) to collect scooping demonstrations using algorithmic procedures that rely on privileged state information. Then, we use generative policies via diffusion to imitate demonstrations from observational input. We directly apply the learned policy in diverse real-world scenarios, testing its performance on various item quantities, item characteristics, and container types. In zero-shot deployment, our method demonstrates promising results across 465 trials in diverse scenarios, including objects of different difficulty levels that we categorize as \"Level 1\" and \"Level 2.\" SCOOP'D outperforms all baselines and ablations, suggesting that this is a promising approach to acquiring robotic scooping skills. Project page is at https://scoopdiff.github.io/.",
    "authors": [
      "Kuanning Wang",
      "Yongchong Gu",
      "Yuqian Fu",
      "Zeyu Shangguan",
      "Sicheng He",
      "Xiangyang Xue",
      "Yanwei Fu",
      "Daniel Seita"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T16:11:34.000Z",
    "updatedAt": "2025-10-13T16:11:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11566v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11566v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11565v1",
    "arxivId": "2510.11565v1",
    "title": "SNAP: Towards Segmenting Anything in Any Point Cloud",
    "abstract": "Interactive 3D point cloud segmentation enables efficient annotation of complex 3D scenes through user-guided prompts. However, current approaches are typically restricted in scope to a single domain (indoor or outdoor), and to a single form of user interaction (either spatial clicks or textual prompts). Moreover, training on multiple datasets often leads to negative transfer, resulting in domain-specific tools that lack generalizability. To address these limitations, we present \\textbf{SNAP} (\\textbf{S}egment a\\textbf{N}ything in \\textbf{A}ny \\textbf{P}oint cloud), a unified model for interactive 3D segmentation that supports both point-based and text-based prompts across diverse domains. Our approach achieves cross-domain generalizability by training on 7 datasets spanning indoor, outdoor, and aerial environments, while employing domain-adaptive normalization to prevent negative transfer. For text-prompted segmentation, we automatically generate mask proposals without human intervention and match them against CLIP embeddings of textual queries, enabling both panoptic and open-vocabulary segmentation. Extensive experiments demonstrate that SNAP consistently delivers high-quality segmentation results. We achieve state-of-the-art performance on 8 out of 9 zero-shot benchmarks for spatial-prompted segmentation and demonstrate competitive results on all 5 text-prompted benchmarks. These results show that a unified model can match or exceed specialized domain-specific approaches, providing a practical tool for scalable 3D annotation. Project page is at, https://neu-vi.github.io/SNAP/",
    "authors": [
      "Aniket Gupta",
      "Hanhui Wang",
      "Charles Saunders",
      "Aruni RoyChowdhury",
      "Hanumant Singh",
      "Huaizu Jiang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T16:07:00.000Z",
    "updatedAt": "2025-10-13T16:07:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11565v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11565v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11563v1",
    "arxivId": "2510.11563v1",
    "title": "Culturally-Aware Conversations: A Framework & Benchmark for LLMs",
    "abstract": "Existing benchmarks that measure cultural adaptation in LLMs are misaligned with the actual challenges these models face when interacting with users from diverse cultural backgrounds. In this work, we introduce the first framework and benchmark designed to evaluate LLMs in realistic, multicultural conversational settings. Grounded in sociocultural theory, our framework formalizes how linguistic style - a key element of cultural communication - is shaped by situational, relational, and cultural context. We construct a benchmark dataset based on this framework, annotated by culturally diverse raters, and propose a new set of desiderata for cross-cultural evaluation in NLP: conversational framing, stylistic sensitivity, and subjective correctness. We evaluate today's top LLMs on our benchmark and show that these models struggle with cultural adaptation in a conversational setting.",
    "authors": [
      "Shreya Havaldar",
      "Sunny Rai",
      "Young-Min Cho",
      "Lyle Ungar"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:06:14.000Z",
    "updatedAt": "2025-10-13T16:06:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11563v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11563v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11561v1",
    "arxivId": "2510.11561v1",
    "title": "Ontolearn-A Framework for Large-scale OWL Class Expression Learning in Python",
    "abstract": "In this paper, we present Ontolearn-a framework for learning OWL class expressions over large knowledge graphs. Ontolearn contains efficient implementations of recent stateof-the-art symbolic and neuro-symbolic class expression learners including EvoLearner and DRILL. A learned OWL class expression can be used to classify instances in the knowledge graph. Furthermore, Ontolearn integrates a verbalization module based on an LLM to translate complex OWL class expressions into natural language sentences. By mapping OWL class expressions into respective SPARQL queries, Ontolearn can be easily used to operate over a remote triplestore. The source code of Ontolearn is available at https://github.com/dice-group/Ontolearn.",
    "authors": [
      "Caglar Demir",
      "Alkid Baci",
      "N'Dah Jean Kouagou",
      "Leonie Nora Sieger",
      "Stefan Heindorf",
      "Simon Bin",
      "Lukas Blübaum",
      "Alexander Bigerl",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "categories": [
      "cs.LG",
      "cs.SC"
    ],
    "publishedAt": "2025-10-13T16:04:06.000Z",
    "updatedAt": "2025-10-13T16:04:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11561v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11561v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11560v1",
    "arxivId": "2510.11560v1",
    "title": "Characterizing Web Search in The Age of Generative AI",
    "abstract": "The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response. This output modality stands in stark contrast to traditional web search, where results are returned as a ranked list of independent web pages. In this paper, we ask: Along what dimensions do generative search outputs differ from traditional web search? We compare Google, a traditional web search engine, with four generative search engines from two providers (Google and OpenAI) across queries from four domains. Our analysis reveals intriguing differences. Most generative search engines cover a wider range of sources compared to web search. Generative search engines vary in the degree to which they rely on internal knowledge contained within the model parameters v.s. external knowledge retrieved from the web. Generative search engines surface varying sets of concepts, creating new opportunities for enhancing search diversity and serendipity. Our results also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.",
    "authors": [
      "Elisabeth Kirsten",
      "Jost Grosse Perdekamp",
      "Mihir Upadhyay",
      "Krishna P. Gummadi",
      "Muhammad Bilal Zafar"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T16:04:03.000Z",
    "updatedAt": "2025-10-13T16:04:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11560v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11560v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11558v1",
    "arxivId": "2510.11558v1",
    "title": "Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products",
    "abstract": "Governance of data, compliance, and business privacy matters, particularly for healthcare and finance businesses. Since the recent emergence of AI enterprise AI assistants enhancing business productivity, safeguarding private data and compliance is now a priority. With the implementation of AI assistants across the enterprise, the zero data retention can be achieved by implementing zero data retention policies by Large Language Model businesses like Open AI and Anthropic and Meta. In this work, we explore zero data retention policies for the Enterprise apps of large language models (LLMs). Our key contribution is defining the architectural, compliance, and usability trade-offs of such systems in parallel. In this research work, we examine the development of commercial AI assistants with two industry leaders and market titans in this arena - Salesforce and Microsoft. Both of these companies used distinct technical architecture to support zero data retention policies. Salesforce AgentForce and Microsoft Copilot are among the leading AI assistants providing much-needed push to business productivity in customer care. The purpose of this paper is to analyze the technical architecture and deployment of zero data retention policy by consuming applications as well as big language models service providers like Open Ai, Anthropic, and Meta.",
    "authors": [
      "Komal Gupta",
      "Aditya Shrivastava"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T16:00:34.000Z",
    "updatedAt": "2025-10-13T16:00:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11558v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11558v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11557v1",
    "arxivId": "2510.11557v1",
    "title": "Invisible Languages of the LLM Universe",
    "abstract": "Large Language Models are trained on massive multilingual corpora, yet this abundance masks a profound crisis: of the world's 7,613 living languages, approximately 2,000 languages with millions of speakers remain effectively invisible in digital ecosystems. We propose a critical framework connecting empirical measurements of language vitality (real world demographic strength) and digitality (online presence) with postcolonial theory and epistemic injustice to explain why linguistic inequality in AI systems is not incidental but structural. Analyzing data across all documented human languages, we identify four categories: Strongholds (33%, high vitality and digitality), Digital Echoes (6%, high digitality despite declining vitality), Fading Voices (36%, low on both dimensions), and critically, Invisible Giants (27%, high vitality but near-zero digitality) - languages spoken by millions yet absent from the LLM universe. We demonstrate that these patterns reflect continuities from colonial-era linguistic hierarchies to contemporary AI development, constituting what we term digital epistemic injustice. Our analysis reveals that English dominance in AI is not a technical necessity but an artifact of power structures that systematically exclude marginalized linguistic knowledge. We conclude with implications for decolonizing language technology and democratizing access to AI benefits.",
    "authors": [
      "Saurabh Khanna",
      "Xinxu Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T16:00:15.000Z",
    "updatedAt": "2025-10-13T16:00:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11557v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11557v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11556v1",
    "arxivId": "2510.11556v1",
    "title": "Personalized and Constructive Feedback for Computer Science Students Using the Large Language Model (LLM)",
    "abstract": "The evolving pedagogy paradigms are leading toward educational transformations. One fundamental aspect of effective learning is relevant, immediate, and constructive feedback to students. Providing constructive feedback to large cohorts in academia is an ongoing challenge. Therefore, academics are moving towards automated assessment to provide immediate feedback. However, current approaches are often limited in scope, offering simplistic responses that do not provide students with personalized feedback to guide them toward improvements. This paper addresses this limitation by investigating the performance of Large Language Models (LLMs) in processing students assessments with predefined rubrics and marking criteria to generate personalized feedback for in-depth learning. We aim to leverage the power of existing LLMs for Marking Assessments, Tracking, and Evaluation (LLM-MATE) with personalized feedback to enhance students learning. To evaluate the performance of LLM-MATE, we consider the Software Architecture (SA) module as a case study. The LLM-MATE approach can help module leaders overcome assessment challenges with large cohorts. Also, it helps students improve their learning by obtaining personalized feedback in a timely manner. Additionally, the proposed approach will facilitate the establishment of ground truth for automating the generation of students assessment feedback using the ChatGPT API, thereby reducing the overhead associated with large cohort assessments.",
    "authors": [
      "Javed Ali Khan",
      "Muhammad Yaqoob",
      "Mamoona Tasadduq",
      "Hafsa Shareef Dar",
      "Aitezaz Ahsan"
    ],
    "categories": [
      "cs.CY"
    ],
    "publishedAt": "2025-10-13T15:59:30.000Z",
    "updatedAt": "2025-10-13T15:59:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11556v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11556v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11553v1",
    "arxivId": "2510.11553v1",
    "title": "How many samples to label for an application given a foundation model? Chest X-ray classification study",
    "abstract": "Chest X-ray classification is vital yet resource-intensive, typically demanding extensive annotated data for accurate diagnosis. Foundation models mitigate this reliance, but how many labeled samples are required remains unclear. We systematically evaluate the use of power-law fits to predict the training size necessary for specific ROC-AUC thresholds. Testing multiple pathologies and foundation models, we find XrayCLIP and XraySigLIP achieve strong performance with significantly fewer labeled examples than a ResNet-50 baseline. Importantly, learning curve slopes from just 50 labeled cases accurately forecast final performance plateaus. Our results enable practitioners to minimize annotation costs by labeling only the essential samples for targeted performance.",
    "authors": [
      "Nikolay Nechaev",
      "Evgenia Przhezdzetskaya",
      "Viktor Gombolevskiy",
      "Dmitry Umerenkov",
      "Dmitry Dylov"
    ],
    "categories": [
      "cs.CV",
      "68T07 (Primary) 68T45, 62H30, 62P10 (Secondary)"
    ],
    "publishedAt": "2025-10-13T15:53:55.000Z",
    "updatedAt": "2025-10-13T15:53:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11553v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11553v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11552v1",
    "arxivId": "2510.11552v1",
    "title": "Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education",
    "abstract": "Recent developments of low cost off-the-shelf programmable components, their modularity, and also rapid prototyping made educational robotics flourish, as it is accessible in most schools today. They allow to illustrate and embody theoretical problems in practical and tangible applications, and gather multidisciplinary skills. They also give a rich natural context for project-oriented pedagogy. However, most current robot kits all are limited to egocentric aspect of the robots perception. This makes it difficult to access more high-level problems involving e.g. coordinates or navigation. In this paper we introduce an educational holonomous robot kit that comes with an external tracking system, which lightens the constraint on embedded systems, but allows in the same time to discover high-level aspects of robotics, otherwise unreachable.",
    "authors": [
      "Gregoire Passault",
      "Clement Gaspard",
      "Olivier Ly"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T15:53:51.000Z",
    "updatedAt": "2025-10-13T15:53:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11552v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11552v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11550v1",
    "arxivId": "2510.11550v1",
    "title": "On the Complexity of Stationary Nash Equilibria in Discounted Perfect Information Stochastic Games",
    "abstract": "We study the problem of computing stationary Nash equilibria in discounted perfect information stochastic games from the viewpoint of computational complexity. For two-player games we prove the problem to be in PPAD, which together with a previous PPAD-hardness result precisely classifies the problem as PPAD-complete. In addition to this we give an improved and simpler PPAD-hardness proof for computing a stationary epsilon-Nash equilibrium. For 3-player games we construct games showing that rational-valued stationary Nash equilibria are not guaranteed to exist, and we use these to prove SqrtSum-hardness of computing a stationary Nash equilibrium in 4-player games.",
    "authors": [
      "Kristoffer Arnsfelt Hansen",
      "Xinhao Nie"
    ],
    "categories": [
      "cs.GT",
      "cs.CC"
    ],
    "publishedAt": "2025-10-13T15:52:44.000Z",
    "updatedAt": "2025-10-13T15:52:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11550v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11550v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11549v1",
    "arxivId": "2510.11549v1",
    "title": "ODI-Bench: Can MLLMs Understand Immersive Omnidirectional Environments?",
    "abstract": "Omnidirectional images (ODIs) provide full 360x180 view which are widely adopted in VR, AR and embodied intelligence applications. While multi-modal large language models (MLLMs) have demonstrated remarkable performance on conventional 2D image and video understanding benchmarks, their ability to comprehend the immersive environments captured by ODIs remains largely unexplored. To address this gap, we first present ODI-Bench, a novel comprehensive benchmark specifically designed for omnidirectional image understanding. ODI-Bench contains 2,000 high-quality omnidirectional images and over 4,000 manually annotated question-answering (QA) pairs across 10 fine-grained tasks, covering both general-level and spatial-level ODI understanding. Extensive experiments are conducted to benchmark 20 representative MLLMs, including proprietary and open-source models, under both close-ended and open-ended settings. Experimental results reveal that current MLLMs still struggle to capture the immersive context provided by ODIs. To this end, we further introduce Omni-CoT, a training-free method which significantly enhances MLLMs' comprehension ability in the omnidirectional environment through chain-of-thought reasoning across both textual information and visual cues. Both the benchmark and the code will be released upon the publication.",
    "authors": [
      "Liu Yang",
      "Huiyu Duan",
      "Ran Tao",
      "Juntao Cheng",
      "Sijing Wu",
      "Yunhao Li",
      "Jing Liu",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T15:51:47.000Z",
    "updatedAt": "2025-10-13T15:51:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11549v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11549v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11547v1",
    "arxivId": "2510.11547v1",
    "title": "Sublinear Algorithms for Estimating Single-Linkage Clustering Costs",
    "abstract": "Single-linkage clustering is a fundamental method for data analysis. Algorithmically, one can compute a single-linkage $k$-clustering (a partition into $k$ clusters) by computing a minimum spanning tree and dropping the $k-1$ most costly edges. This clustering minimizes the sum of spanning tree weights of the clusters. This motivates us to define the cost of a single-linkage $k$-clustering as the weight of the corresponding spanning forest, denoted by $\\mathrm{cost}_k$. Besides, if we consider single-linkage clustering as computing a hierarchy of clusterings, the total cost of the hierarchy is defined as the sum of the individual clusterings, denoted by $\\mathrm{cost}(G) = \\sum_{k=1}^{n} \\mathrm{cost}_k$. In this paper, we assume that the distances between data points are given as a graph $G$ with average degree $d$ and edge weights from $\\{1,\\dots, W\\}$. Given query access to the adjacency list of $G$, we present a sampling-based algorithm that computes a succinct representation of estimates $\\widehat{\\mathrm{cost}}_k$ for all $k$. The running time is $\\tilde O(d\\sqrt{W}/\\varepsilon^3)$, and the estimates satisfy $\\sum_{k=1}^{n} |\\widehat{\\mathrm{cost}}_k - \\mathrm{cost}_k| \\le \\varepsilon\\cdot \\mathrm{cost}(G)$, for any $0<\\varepsilon <1$. Thus we can approximate the cost of every $k$-clustering upto $(1+\\varepsilon)$ factor \\emph{on average}. In particular, our result ensures that we can estimate $\\cost(G)$ upto a factor of $1\\pm \\varepsilon$ in the same running time. We also extend our results to the setting where edges represent similarities. In this case, the clusterings are defined by a maximum spanning tree, and our algorithms run in $\\tilde{O}(dW/\\varepsilon^3)$ time. We futher prove nearly matching lower bounds for estimating the total clustering cost and we extend our algorithms to metric space settings.",
    "authors": [
      "Pan Peng",
      "Christian Sohler",
      "Yi Xu"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-13T15:48:48.000Z",
    "updatedAt": "2025-10-13T15:48:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11547v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11547v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11546v1",
    "arxivId": "2510.11546v1",
    "title": "Efficient Group Lasso Regularized Rank Regression with Data-Driven Parameter Determination",
    "abstract": "High-dimensional regression often suffers from heavy-tailed noise and outliers, which can severely undermine the reliability of least-squares based methods. To improve robustness, we adopt a non-smooth Wilcoxon score based rank objective and incorporate structured group sparsity regularization, a natural generalization of the lasso, yielding a group lasso regularized rank regression method. By extending the tuning-free parameter selection scheme originally developed for the lasso, we introduce a data-driven, simulation-based tuning rule and further establish a finite-sample error bound for the resulting estimator. On the computational side, we develop a proximal augmented Lagrangian method for solving the associated optimization problem, which eliminates the singularity issues encountered in existing methods, thereby enabling efficient semismooth Newton updates for the subproblems. Extensive numerical experiments demonstrate the robustness and effectiveness of our proposed estimator against alternatives, and showcase the scalability of the algorithm across both simulated and real-data settings.",
    "authors": [
      "Meixia Lin",
      "Meijiao Shi",
      "Yunhai Xiao",
      "Qian Zhang"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "math.ST",
      "stat.TH"
    ],
    "publishedAt": "2025-10-13T15:45:58.000Z",
    "updatedAt": "2025-10-13T15:45:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11546v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11546v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11545v1",
    "arxivId": "2510.11545v1",
    "title": "Information-Preserving Reformulation of Reasoning Traces for Antidistillation",
    "abstract": "Recent advances in Large Language Models (LLMs) show that extending the length of reasoning chains significantly improves performance on complex tasks. While revealing these reasoning traces helps users better follow, verify, and learn from the model's problem-solving process, it also makes them highly vulnerable to unauthorized distillation. To mitigate this risk, proprietary model providers often adopt aggressive protection strategies, such as replacing detailed reasoning with brief summaries, which deprive users of valuable intermediate information. To address this trade-off, we propose PART, an information-preserving antidistillation reformulation of reasoning traces. Motivated by the difference between how humans understand reasoning traces and how LLMs exploit them for supervised fine-tuning, we design a simple but effective two-step reformulation: removing self-talk behaviors and reordering sub-conclusions. A small auxiliary model is trained to perform this reformulation, incurring minimal computational overhead. Extensive experiments demonstrate that PART consistently disrupts distillation across student models of different sizes and types on various reasoning benchmarks. For instance, when training on reformulated traces, even the performance of a large 32B student model decreases from 54.17 to 46.88 on AIME 2024, corresponding to a 13.5% degradation.",
    "authors": [
      "Jiayu Ding",
      "Lei Cui",
      "Li Dong",
      "Nanning Zheng",
      "Furu Wei"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T15:42:11.000Z",
    "updatedAt": "2025-10-13T15:42:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11545v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11545v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11542v1",
    "arxivId": "2510.11542v1",
    "title": "NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) has emerged as a powerful method to learn robust control policies for bipedal locomotion. Yet, it can be difficult to tune desired robot behaviors due to unintuitive and complex reward design. In comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics, offer more tuneable, interpretable, and mathematically grounded motion plans for high-dimensional legged systems. However, these methods often remain brittle to real-world disturbances like external perturbations. In this work, we present NaviGait, a hierarchical framework that combines the structure of trajectory optimization with the adaptability of RL for robust and intuitive locomotion control. NaviGait leverages a library of offline-optimized gaits and smoothly interpolates between them to produce continuous reference motions in response to high-level commands. The policy provides both joint-level and velocity command residual corrections to modulate and stabilize the reference trajectories in the gait library. One notable advantage of NaviGait is that it dramatically simplifies reward design by encoding rich motion priors from trajectory optimization, reducing the need for finely tuned shaping terms and enabling more stable and interpretable learning. Our experimental results demonstrate that NaviGait enables faster training compared to conventional and imitation-based RL, and produces motions that remain closest to the original reference. Overall, by decoupling high-level motion generation from low-level correction, NaviGait offers a more scalable and generalizable approach for achieving dynamic and robust locomotion.",
    "authors": [
      "Neil C. Janwani",
      "Varun Madabushi",
      "Maegan Tucker"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T15:41:38.000Z",
    "updatedAt": "2025-10-13T15:41:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11542v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11542v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11541v1",
    "arxivId": "2510.11541v1",
    "title": "Query-Specific GNN: A Comprehensive Graph Representation Learning Method for Retrieval Augmented Generation",
    "abstract": "Retrieval-augmented generation (RAG) has demonstrated its ability to enhance Large Language Models (LLMs) by integrating external knowledge sources. However, multi-hop questions, which require the identification of multiple knowledge targets to form a synthesized answer, raise new challenges for RAG systems. Under the multi-hop settings, existing methods often struggle to fully understand the questions with complex semantic structures and are susceptible to irrelevant noise during the retrieval of multiple information targets. To address these limitations, we propose a novel graph representation learning framework for multi-hop question retrieval. We first introduce a Multi-information Level Knowledge Graph (Multi-L KG) to model various information levels for a more comprehensive understanding of multi-hop questions. Based on this, we design a Query-Specific Graph Neural Network (QSGNN) for representation learning on the Multi-L KG. QSGNN employs intra/inter-level message passing mechanisms, and in each message passing the information aggregation is guided by the query, which not only facilitates multi-granular information aggregation but also significantly reduces the impact of noise. To enhance its ability to learn robust representations, we further propose two synthesized data generation strategies for pre-training the QSGNN. Extensive experimental results demonstrate the effectiveness of our framework in multi-hop scenarios, especially in high-hop questions the improvement can reach 33.8\\%. The code is available at: https://github.com/Jerry2398/QSGNN.",
    "authors": [
      "Yuchen Yan",
      "Zhihua Liu",
      "Hao Wang",
      "Weiming Li",
      "Xiaoshuai Hao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:41:15.000Z",
    "updatedAt": "2025-10-13T15:41:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11541v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11541v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11539v1",
    "arxivId": "2510.11539v1",
    "title": "Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization",
    "abstract": "Accurate state estimation is critical for legged and aerial robots operating in dynamic, uncertain environments. A key challenge lies in specifying process and measurement noise covariances, which are typically unknown or manually tuned. In this work, we introduce a bi-level optimization framework that jointly calibrates covariance matrices and kinematic parameters in an estimator-in-the-loop manner. The upper level treats noise covariances and model parameters as optimization variables, while the lower level executes a full-information estimator. Differentiating through the estimator allows direct optimization of trajectory-level objectives, resulting in accurate and consistent state estimates. We validate our approach on quadrupedal and humanoid robots, demonstrating significantly improved estimation accuracy and uncertainty calibration compared to hand-tuned baselines. Our method unifies state estimation, sensor, and kinematics calibration into a principled, data-driven framework applicable across diverse robotic platforms.",
    "authors": [
      "Denglin Cheng",
      "Jiarong Kang",
      "Xiaobin Xiong"
    ],
    "categories": [
      "cs.RO",
      "math.OC"
    ],
    "publishedAt": "2025-10-13T15:39:21.000Z",
    "updatedAt": "2025-10-13T15:39:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11539v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11539v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11538v1",
    "arxivId": "2510.11538v1",
    "title": "Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers",
    "abstract": "Diffusion Transformers (DiTs) have recently emerged as a powerful backbone for visual generation. Recent observations reveal \\emph{Massive Activations} (MAs) in their internal feature maps, yet their function remains poorly understood. In this work, we systematically investigate these activations to elucidate their role in visual generation. We found that these massive activations occur across all spatial tokens, and their distribution is modulated by the input timestep embeddings. Importantly, our investigations further demonstrate that these massive activations play a key role in local detail synthesis, while having minimal impact on the overall semantic content of output. Building on these insights, we propose \\textbf{D}etail \\textbf{G}uidance (\\textbf{DG}), a MAs-driven, training-free self-guidance strategy to explicitly enhance local detail fidelity for DiTs. Specifically, DG constructs a degraded ``detail-deficient'' model by disrupting MAs and leverages it to guide the original network toward higher-quality detail synthesis. Our DG can seamlessly integrate with Classifier-Free Guidance (CFG), enabling further refinements of fine-grained details. Extensive experiments demonstrate that our DG consistently improves fine-grained detail quality across various pre-trained DiTs (\\eg, SD3, SD3.5, and Flux).",
    "authors": [
      "Chaofan Gan",
      "Zicheng Zhao",
      "Yuanpeng Tu",
      "Xi Chen",
      "Ziran Qin",
      "Tieyuan Chen",
      "Mehrtash Harandi",
      "Weiyao Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T15:39:13.000Z",
    "updatedAt": "2025-10-13T15:39:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11538v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11538v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11537v1",
    "arxivId": "2510.11537v1",
    "title": "An Encoder-Integrated PhoBERT with Graph Attention for Vietnamese Token-Level Classification",
    "abstract": "We propose a novel neural architecture named TextGraphFuseGAT, which integrates a pretrained transformer encoder (PhoBERT) with Graph Attention Networks for token-level classification tasks. The proposed model constructs a fully connected graph over the token embeddings produced by PhoBERT, enabling the GAT layer to capture rich inter-token dependencies beyond those modeled by sequential context alone. To further enhance contextualization, a Transformer-style self-attention layer is applied on top of the graph-enhanced embeddings. The final token representations are passed through a classification head to perform sequence labeling. We evaluate our approach on three Vietnamese benchmark datasets: PhoNER-COVID19 for named entity recognition in the COVID-19 domain, PhoDisfluency for speech disfluency detection, and VietMed-NER for medical-domain NER. VietMed-NER is the first Vietnamese medical spoken NER dataset, featuring 18 entity types collected from real-world medical speech transcripts and annotated with the BIO tagging scheme. Its specialized vocabulary and domain-specific expressions make it a challenging benchmark for token-level classification models. Experimental results show that our method consistently outperforms strong baselines, including transformer-only and hybrid neural models such as BiLSTM + CNN + CRF, confirming the effectiveness of combining pretrained semantic features with graph-based relational modeling for improved token classification across multiple domains.",
    "authors": [
      "Ba-Quang Nguyen"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T15:39:09.000Z",
    "updatedAt": "2025-10-13T15:39:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11537v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11537v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11536v1",
    "arxivId": "2510.11536v1",
    "title": "CodeWatcher: IDE Telemetry Data Extraction Tool for Understanding Coding Interactions with LLMs",
    "abstract": "Understanding how developers interact with code generation tools (CGTs) requires detailed, real-time data on programming behavior which is often difficult to collect without disrupting workflow. We present \\textit{CodeWatcher}, a lightweight, unobtrusive client-server system designed to capture fine-grained interaction events from within the Visual Studio Code (VS Code) editor. \\textit{CodeWatcher} logs semantically meaningful events such as insertions made by CGTs, deletions, copy-paste actions, and focus shifts, enabling continuous monitoring of developer activity without modifying user workflows. The system comprises a VS Code plugin, a Python-based RESTful API, and a MongoDB backend, all containerized for scalability and ease of deployment. By structuring and timestamping each event, \\textit{CodeWatcher} enables post-hoc reconstruction of coding sessions and facilitates rich behavioral analyses, including how and when CGTs are used during development. This infrastructure is crucial for supporting research on responsible AI, developer productivity, and the human-centered evaluation of CGTs. Please find the demo, diagrams, and tool here: https://osf.io/j2kru/overview.",
    "authors": [
      "Manaal Basha",
      "Aimeê M. Ribeiro",
      "Jeena Javahar",
      "Cleidson R. B. de Souza",
      "Gema Rodríguez-Pérez"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:39:08.000Z",
    "updatedAt": "2025-10-13T15:39:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11536v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11536v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11535v1",
    "arxivId": "2510.11535v1",
    "title": "A Flexible Multi-Agent Deep Reinforcement Learning Framework for Dynamic Routing and Scheduling of Latency-Critical Services",
    "abstract": "Timely delivery of delay-sensitive information over dynamic, heterogeneous networks is increasingly essential for a range of interactive applications, such as industrial automation, self-driving vehicles, and augmented reality. However, most existing network control solutions target only average delay performance, falling short of providing strict End-to-End (E2E) peak latency guarantees. This paper addresses the challenge of reliably delivering packets within application-imposed deadlines by leveraging recent advancements in Multi-Agent Deep Reinforcement Learning (MA-DRL). After introducing the Delay-Constrained Maximum-Throughput (DCMT) dynamic network control problem, and highlighting the limitations of current solutions, we present a novel MA-DRL network control framework that leverages a centralized routing and distributed scheduling architecture. The proposed framework leverages critical networking domain knowledge for the design of effective MA-DRL strategies based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) technique, where centralized routing and distributed scheduling agents dynamically assign paths and schedule packet transmissions according to packet lifetimes, thereby maximizing on-time packet delivery. The generality of the proposed framework allows integrating both data-driven \\blue{Deep Reinforcement Learning (DRL)} agents and traditional rule-based policies in order to strike the right balance between performance and learning complexity. Our results confirm the superiority of the proposed framework with respect to traditional stochastic optimization-based approaches and provide key insights into the role and interplay between data-driven DRL agents and new rule-based policies for both efficient and high-performance control of latency-critical services.",
    "authors": [
      "Vincenzo Norman Vitale",
      "Antonia Maria Tulino",
      "Andreas F. Molisch",
      "Jaime Llorca"
    ],
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:38:10.000Z",
    "updatedAt": "2025-10-13T15:38:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11535v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11535v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11534v1",
    "arxivId": "2510.11534v1",
    "title": "IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy",
    "abstract": "Realistic traffic simulation is critical for ensuring the safety and reliability of autonomous vehicles (AVs), especially in complex and diverse urban traffic environments. However, existing data-driven simulators face two key challenges: a limited focus on modeling dense, heterogeneous interactions at urban intersections - which are prevalent, crucial, and practically significant in countries like China, featuring diverse agents including motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and the inherent difficulty in robustly learning high-dimensional joint distributions for such high-density scenes, often leading to mode collapse and long-term simulation instability. We introduce City Crossings Dataset (CiCross), a large-scale dataset collected from a real-world urban intersection, uniquely capturing dense, heterogeneous multi-agent interactions, particularly with a substantial proportion of MVs, NMVs and pedestrians. Based on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving Environment), a data-driven simulator tailored for complex urban intersection scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a training paradigm that learns compositional dynamics from agent subsets, enabling the marginal-to-joint simulation. Integrated into a scene-aware Transformer network with specialized training techniques, IDS significantly enhances simulation robustness and long-term stability for modeling heterogeneous interactions. Experiments on CiCross show that IntersectioNDE outperforms baseline methods in simulation fidelity, stability, and its ability to replicate complex, distribution-level urban traffic dynamics.",
    "authors": [
      "Enli Lin",
      "Ziyuan Yang",
      "Qiujing Lu",
      "Jianming Hu",
      "Shuo Feng"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-13T15:38:05.000Z",
    "updatedAt": "2025-10-13T15:38:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11534v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11534v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11530v1",
    "arxivId": "2510.11530v1",
    "title": "Exploring Artificial Intelligence and Culture: Methodology for a comparative study of AI's impact on norms, trust, and problem-solving across academic and business environments",
    "abstract": "This paper proposes a rigorous framework to examine the two-way relationship between artificial intelligence (AI), human cognition, problem-solving, and cultural adaptation across academic and business settings. It addresses a key gap by asking how AI reshapes cognitive processes and organizational norms, and how cultural values and institutional contexts shape AI adoption, trust, and use over time. We employ a three-wave longitudinal design that tracks AI knowledge, perceived competence, trust trajectories, and cultural responses. Participants span academic institutions and diverse firms, enabling contextual comparison. A dynamic sample continuous, intermittent, and wave-specific respondents mirrors real organizational variability and strengthens ecological validity. Methodologically, the study integrates quantitative longitudinal modeling with qualitative thematic analysis to capture temporal, structural, and cultural patterns in AI uptake. We trace AI acculturation through phases of initial resistance, exploratory adoption, and cultural embedding, revealing distinctive trust curves and problem-solving strategies by context: academic environments tend to collaborative, deliberative integration; business environments prioritize performance, speed, and measurable outcomes. Framing adoption as bidirectional challenges deterministic views: AI both reflects and reconfigures norms, decision-making, and cognitive engagement. As the first comparative longitudinal study of its kind, this work advances methodological rigor and offers actionable foundations for human-centred, culturally responsive AI strategies-supporting evidence-based policies, training, and governance that align cognitive performance, organizational goals, and ethical commitments.",
    "authors": [
      "Matthias Huemmer",
      "Theophile Shyiramunda",
      "Michelle J. Cummings-Koether"
    ],
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "publishedAt": "2025-10-13T15:31:31.000Z",
    "updatedAt": "2025-10-13T15:31:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11530v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11530v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11529v1",
    "arxivId": "2510.11529v1",
    "title": "Hallucination Detection via Internal States and Structured Reasoning Consistency in Large Language Models",
    "abstract": "The detection of sophisticated hallucinations in Large Language Models (LLMs) is hampered by a ``Detection Dilemma'': methods probing internal states (Internal State Probing) excel at identifying factual inconsistencies but fail on logical fallacies, while those verifying externalized reasoning (Chain-of-Thought Verification) show the opposite behavior. This schism creates a task-dependent blind spot: Chain-of-Thought Verification fails on fact-intensive tasks like open-domain QA where reasoning is ungrounded, while Internal State Probing is ineffective on logic-intensive tasks like mathematical reasoning where models are confidently wrong. We resolve this with a unified framework that bridges this critical gap. However, unification is hindered by two fundamental challenges: the Signal Scarcity Barrier, as coarse symbolic reasoning chains lack signals directly comparable to fine-grained internal states, and the Representational Alignment Barrier, a deep-seated mismatch between their underlying semantic spaces. To overcome these, we introduce a multi-path reasoning mechanism to obtain more comparable, fine-grained signals, and a segment-aware temporalized cross-attention module to adaptively fuse these now-aligned representations, pinpointing subtle dissonances. Extensive experiments on three diverse benchmarks and two leading LLMs demonstrate that our framework consistently and significantly outperforms strong baselines. Our code is available: https://github.com/peach918/HalluDet.",
    "authors": [
      "Yusheng Song",
      "Lirong Qiu",
      "Xi Zhang",
      "Zhihao Tang"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T15:31:21.000Z",
    "updatedAt": "2025-10-13T15:31:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11529v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11529v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11527v1",
    "arxivId": "2510.11527v1",
    "title": "A fourth-order active flux method for parabolic problems with application to porous medium equation",
    "abstract": "The active flux (AF) method is a compact high-order finite volume method originally proposed for solving hyperbolic conservation laws, in which cell averages and point values at cell interfaces are evolved simultaneously. This paper develops a fourth-order AF method for one- and two-dimensional parabolic problems, employing the explicit strong-stability-preserving Runge-Kutta (SSP-RK) method for time integration. The proposed method is built on a degenerate first-order system with auxiliary variables representing the derivatives of the primal variable, similar to local discontinuous Galerkin (LDG) methods, which avoids introducing pseudo-time or performing iterations within a physical time step in the existing hyperbolic formulations. The evolution of cell averages follows the standard finite volume method, ensuring conservation, while the point values of both the primal and auxiliary variables are updated using fourth-order central finite difference operators. A discrete Fourier analysis confirms the fourth-order accuracy in 1D. With the third-order SSP-RK method, the maximum CFL number for stability is $0.27$ in 1D, as obtained by von Neumann analysis, larger than that of LDG methods. The proposed method is further applied to the porous medium equation, and positivity-preserving limitings are incorporated to guarantee the non-negativity of the numerical solutions. Several numerical experiments validate the theoretical results and efficacy of the method.",
    "authors": [
      "Junming Duan"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T15:30:50.000Z",
    "updatedAt": "2025-10-13T15:30:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11527v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11527v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11525v1",
    "arxivId": "2510.11525v1",
    "title": "DQ-NMPC: Dual-Quaternion NMPC for Quadrotor Flight",
    "abstract": "MAVs have great potential to assist humans in complex tasks, with applications ranging from logistics to emergency response. Their agility makes them ideal for operations in complex and dynamic environments. However, achieving precise control in agile flights remains a significant challenge, particularly due to the underactuated nature of quadrotors and the strong coupling between their translational and rotational dynamics. In this work, we propose a novel NMPC framework based on dual-quaternions (DQ-NMPC) for quadrotor flight. By representing both quadrotor dynamics and the pose error directly on the dual-quaternion manifold, our approach enables a compact and globally non-singular formulation that captures the quadrotor coupled dynamics. We validate our approach through simulations and real-world experiments, demonstrating better numerical conditioning and significantly improved tracking performance, with reductions in position and orientation errors of up to 56.11% and 56.77%, compared to a conventional baseline NMPC method. Furthermore, our controller successfully handles aggressive trajectories, reaching maximum speeds up to 13.66 m/s and accelerations reaching 4.2 g within confined space conditions of dimensions 11m x 4.5m x 3.65m under which the baseline controller fails.",
    "authors": [
      "Luis F. Recalde",
      "Dhruv Agrawal",
      "Jon Arrizabalaga",
      "Guanrui Li"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T15:30:34.000Z",
    "updatedAt": "2025-10-13T15:30:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11525v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11525v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11524v1",
    "arxivId": "2510.11524v1",
    "title": "Networks Multiscale Entropy Analysis",
    "abstract": "Understanding the structural complexity and predictability of complex networks is a central challenge in network science. Although recent studies have revealed a relationship between compression-based entropy and link prediction performance, existing methods focus on single-scale representations. This approach often overlooks the rich hierarchical patterns that can exist in real-world networks. In this study, we introduce a multiscale entropy framework that extends previous entropy-based approaches by applying spectral graph reduction. This allows us to quantify how structural entropy evolves as the network is gradually coarsened, capturing complexity across multiple scales. We apply our framework to real-world networks across biological, economic, social, technological, and transportation domains. The results uncover consistent entropy profiles across network families, revealing three structural regimes$\\unicode{x2013}$stable, increasing, and hybrid$\\unicode{x2013}$that align with domain-specific behaviors. Compared to single-scale models, multiscale entropy significantly improves our ability to determine network predictability. This shows that considering structural information across scales provides a more complete characterization of network complexity. Together, these results position multiscale entropy as a powerful and scalable tool for characterizing, classifying, and assessing the structure of complex networks.",
    "authors": [
      "Sebastián Brzovic",
      "Cristóbal Rojas",
      "Andrés Abeliuk"
    ],
    "categories": [
      "cs.SI",
      "math-ph",
      "math.MP"
    ],
    "publishedAt": "2025-10-13T15:30:25.000Z",
    "updatedAt": "2025-10-13T15:30:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11524v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11524v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11520v1",
    "arxivId": "2510.11520v1",
    "title": "mmWalk: Towards Multi-modal Multi-view Walking Assistance",
    "abstract": "Walking assistance in extreme or complex environments remains a significant challenge for people with blindness or low vision (BLV), largely due to the lack of a holistic scene understanding. Motivated by the real-world needs of the BLV community, we build mmWalk, a simulated multi-modal dataset that integrates multi-view sensor and accessibility-oriented features for outdoor safe navigation. Our dataset comprises 120 manually controlled, scenario-categorized walking trajectories with 62k synchronized frames. It contains over 559k panoramic images across RGB, depth, and semantic modalities. Furthermore, to emphasize real-world relevance, each trajectory involves outdoor corner cases and accessibility-specific landmarks for BLV users. Additionally, we generate mmWalkVQA, a VQA benchmark with over 69k visual question-answer triplets across 9 categories tailored for safe and informed walking assistance. We evaluate state-of-the-art Vision-Language Models (VLMs) using zero- and few-shot settings and found they struggle with our risk assessment and navigational tasks. We validate our mmWalk-finetuned model on real-world datasets and show the effectiveness of our dataset for advancing multi-modal walking assistance.",
    "authors": [
      "Kedi Ying",
      "Ruiping Liu",
      "Chongyan Chen",
      "Mingzhe Tao",
      "Hao Shi",
      "Kailun Yang",
      "Jiaming Zhang",
      "Rainer Stiefelhagen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T15:25:52.000Z",
    "updatedAt": "2025-10-13T15:25:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11520v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11520v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11516v1",
    "arxivId": "2510.11516v1",
    "title": "Cracking CodeWhisperer: Analyzing Developers' Interactions and Patterns During Programming Tasks",
    "abstract": "The use of AI code-generation tools is becoming increasingly common, making it important to understand how software developers are adopting these tools. In this study, we investigate how developers engage with Amazon's CodeWhisperer, an LLM-based code-generation tool. We conducted two user studies with two groups of 10 participants each, interacting with CodeWhisperer - the first to understand which interactions were critical to capture and the second to collect low-level interaction data using a custom telemetry plugin. Our mixed-methods analysis identified four behavioral patterns: 1) incremental code refinement, 2) explicit instruction using natural language comments, 3) baseline structuring with model suggestions, and 4) integrative use with external sources. We provide a comprehensive analysis of these patterns .",
    "authors": [
      "Jeena Javahar",
      "Tanya Budhrani",
      "Manaal Basha",
      "Cleidson R. B. de Souza",
      "Ivan Beschastnikh",
      "Gema Rodriguez-Perez"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:22:12.000Z",
    "updatedAt": "2025-10-13T15:22:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11516v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11516v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11515v1",
    "arxivId": "2510.11515v1",
    "title": "A Physics-Informed Reinforcement Learning Approach for Degradation-Aware Long-Term Charging Optimization in Batteries",
    "abstract": "Batteries degrade with usage and continuous cycling. This aging is typically reflected through the resistance growth and the capacity fade of battery cells. Over the years, various charging methods have been presented in the literature that proposed current profiles in order to enable optimal, fast, and/or health-conscious charging. However, very few works have attempted to make the ubiquitous Constant Current Constant Voltage (CCCV) charging protocol adaptive to the changing battery health as it cycles. This work aims to address this gap and proposes a framework that optimizes the constant current part of the CCCV protocol adapting to long-term battery degradation. Specifically, a physics-informed Reinforcement Learning (RL) approach has been used that not only estimates a key battery degradation mechanism, namely, Loss of Active Material (LAM), but also adjusts the current magnitude of CCCV as a result of this particular degradation. The proposed framework has been implemented by combining PyBamm, an open-source battery modeling tool, and Stable-baselines where the RL agent was trained using a Proximal Policy Optimization (PPO) network. Simulation results show the potential of the proposed framework for enhancing the widely used CCCV protocol by embedding physics information in RL algorithm. A comparative study of this proposed agent has also been discussed with 2 other charging protocols generated by a non-physics-based RL agent and a constant CCCV for all the cycles.",
    "authors": [
      "Shanthan Kumar Padisala",
      "Bharatkumar Hegde",
      "Ibrahim Haskara",
      "Satadru Dey"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T15:21:57.000Z",
    "updatedAt": "2025-10-13T15:21:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11515v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11515v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11514v1",
    "arxivId": "2510.11514v1",
    "title": "Toward Efficient and Privacy-Aware eHealth Systems: An Integrated Sensing, Computing, and Semantic Communication Approach",
    "abstract": "Real-time and contactless monitoring of vital signs, such as respiration and heartbeat, alongside reliable communication, is essential for modern healthcare systems, especially in remote and privacy-sensitive environments. Traditional wireless communication and sensing networks fall short in meeting all the stringent demands of eHealth, including accurate sensing, high data efficiency, and privacy preservation. To overcome the challenges, we propose a novel integrated sensing, computing, and semantic communication (ISCSC) framework. In the proposed system, a service robot utilises radar to detect patient positions and monitor their vital signs, while sending updates to the medical devices. Instead of transmitting raw physiological information, the robot computes and communicates semantically extracted health features to medical devices. This semantic processing improves data throughput and preserves the clinical relevance of the messages, while enhancing data privacy by avoiding the transmission of sensitive data. Leveraging the estimated patient locations, the robot employs an interacting multiple model (IMM) filter to actively track patient motion, thereby enabling robust beam steering for continuous and reliable monitoring. We then propose a joint optimisation of the beamforming matrices and the semantic extraction ratio, subject to computing capability and power budget constraints, with the objective of maximising both the semantic secrecy rate and sensing accuracy. Simulation results validate that the ISCSC framework achieves superior sensing accuracy, improved semantic transmission efficiency, and enhanced privacy preservation compared to conventional joint sensing and communication methods.",
    "authors": [
      "Yinchao Yang",
      "Yahao Ding",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Zhaoyang Zhang",
      "Dusit Niyato",
      "Mohammad Shikh-Bahaei"
    ],
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T15:21:32.000Z",
    "updatedAt": "2025-10-13T15:21:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11514v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11514v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11513v1",
    "arxivId": "2510.11513v1",
    "title": "An Asynchronous Many-Task Algorithm for Unstructured $S_{N}$ Transport on Shared Memory Systems",
    "abstract": "Discrete ordinates $S_N$ transport solvers on unstructured meshes pose a challenge to scale due to complex data dependencies, memory access patterns and a high-dimensional domain. In this paper, we review the performance bottlenecks within the shared memory parallelization scheme of an existing transport solver on modern many-core architectures with high core counts. With this analysis, we then survey the performance of this solver across a variety of compute hardware. We then present a new Asynchronous Many-Task (AMT) algorithm for shared memory parallelism, present results showing an increase in computational performance over the existing method, and evaluate why performance is improved.",
    "authors": [
      "Alex Elwood",
      "Tom Deakin",
      "Justin Lovegrove",
      "Chris Nelson"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-13T15:21:12.000Z",
    "updatedAt": "2025-10-13T15:21:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11513v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11513v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11512v1",
    "arxivId": "2510.11512v1",
    "title": "LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference",
    "abstract": "Intuitive physics understanding in video diffusion models plays an essential role in building general-purpose physically plausible world simulators, yet accurately evaluating such capacity remains a challenging task due to the difficulty in disentangling physics correctness from visual appearance in generation. To the end, we introduce LikePhys, a training-free method that evaluates intuitive physics in video diffusion models by distinguishing physically valid and impossible videos using the denoising objective as an ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By testing on our constructed benchmark of twelve scenarios spanning over four physics domains, we show that our evaluation metric, Plausibility Preference Error (PPE), demonstrates strong alignment with human preference, outperforming state-of-the-art evaluator baselines. We then systematically benchmark intuitive physics understanding in current video diffusion models. Our study further analyses how model design and inference settings affect intuitive physics understanding and highlights domain-specific capacity variations across physical laws. Empirical results show that, despite current models struggling with complex and chaotic dynamics, there is a clear trend of improvement in physics understanding as model capacity and inference settings scale.",
    "authors": [
      "Jianhao Yuan",
      "Fabio Pizzati",
      "Francesco Pinto",
      "Lars Kunze",
      "Ivan Laptev",
      "Paul Newman",
      "Philip Torr",
      "Daniele De Martini"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:19:07.000Z",
    "updatedAt": "2025-10-13T15:19:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11512v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11512v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11509v1",
    "arxivId": "2510.11509v1",
    "title": "Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model",
    "abstract": "Physical environments and circumstances are fundamentally dynamic, yet current 3D datasets and evaluation benchmarks tend to concentrate on either dynamic scenarios or dynamic situations in isolation, resulting in incomplete comprehension. To overcome these constraints, we introduce Situat3DChange, an extensive dataset supporting three situation-aware change understanding tasks following the perception-action model: 121K question-answer pairs, 36K change descriptions for perception tasks, and 17K rearrangement instructions for the action task. To construct this large-scale dataset, Situat3DChange leverages 11K human observations of environmental changes to establish shared mental models and shared situational awareness for human-AI collaboration. These observations, enriched with egocentric and allocentric perspectives as well as categorical and coordinate spatial relations, are integrated using an LLM to support understanding of situated changes. To address the challenge of comparing pairs of point clouds from the same scene with minor changes, we propose SCReasoner, an efficient 3D MLLM approach that enables effective point cloud comparison with minimal parameter overhead and no additional tokens required for the language decoder. Comprehensive evaluation on Situat3DChange tasks highlights both the progress and limitations of MLLMs in dynamic scene and situation understanding. Additional experiments on data scaling and cross-domain transfer demonstrate the task-agnostic effectiveness of using Situat3DChange as a training dataset for MLLMs.",
    "authors": [
      "Ruiping Liu",
      "Junwei Zheng",
      "Yufan Chen",
      "Zirui Wang",
      "Kunyu Peng",
      "Kailun Yang",
      "Jiaming Zhang",
      "Marc Pollefeys",
      "Rainer Stiefelhagen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T15:17:18.000Z",
    "updatedAt": "2025-10-13T15:17:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11509v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11509v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11508v1",
    "arxivId": "2510.11508v1",
    "title": "Towards Fast and Scalable Normal Integration using Continuous Components",
    "abstract": "Surface normal integration is a fundamental problem in computer vision, dealing with the objective of reconstructing a surface from its corresponding normal map. Existing approaches require an iterative global optimization to jointly estimate the depth of each pixel, which scales poorly to larger normal maps. In this paper, we address this problem by recasting normal integration as the estimation of relative scales of continuous components. By constraining pixels belonging to the same component to jointly vary their scale, we drastically reduce the number of optimization variables. Our framework includes a heuristic to accurately estimate continuous components from the start, a strategy to rebalance optimization terms, and a technique to iteratively merge components to further reduce the size of the problem. Our method achieves state-of-the-art results on the standard normal integration benchmark in as little as a few seconds and achieves one-order-of-magnitude speedup over pixel-level approaches on large-resolution normal maps.",
    "authors": [
      "Francesco Milano",
      "Jen Jen Chung",
      "Lionel Ott",
      "Roland Siegwart"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T15:17:16.000Z",
    "updatedAt": "2025-10-13T15:17:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11508v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11508v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11507v1",
    "arxivId": "2510.11507v1",
    "title": "Automatic Music Sample Identification with Multi-Track Contrastive Learning",
    "abstract": "Sampling, the technique of reusing pieces of existing audio tracks to create new music content, is a very common practice in modern music production. In this paper, we tackle the challenging task of automatic sample identification, that is, detecting such sampled content and retrieving the material from which it originates. To do so, we adopt a self-supervised learning approach that leverages a multi-track dataset to create positive pairs of artificial mixes, and design a novel contrastive learning objective. We show that such method significantly outperforms previous state-of-the-art baselines, that is robust to various genres, and that scales well when increasing the number of noise songs in the reference database. In addition, we extensively analyze the contribution of the different components of our training pipeline and highlight, in particular, the need for high-quality separated stems for this task.",
    "authors": [
      "Alain Riou",
      "Joan Serrà",
      "Yuki Mitsufuji"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "publishedAt": "2025-10-13T15:17:08.000Z",
    "updatedAt": "2025-10-13T15:17:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11507v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11507v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11505v1",
    "arxivId": "2510.11505v1",
    "title": "Knowledge-Guided Machine Learning Models to Upscale Evapotranspiration in the U.S. Midwest",
    "abstract": "Evapotranspiration (ET) plays a critical role in the land-atmosphere interactions, yet its accurate quantification across various spatiotemporal scales remains a challenge. In situ measurement approaches, like eddy covariance (EC) or weather station-based ET estimation, allow for measuring ET at a single location. Agricultural uses of ET require estimates for each field over broad areas, making it infeasible to deploy sensing systems at each location. This study integrates tree-based and knowledge-guided machine learning (ML) techniques with multispectral remote sensing data, griddled meteorology and EC data to upscale ET across the Midwest United States. We compare four tree-based models - Random Forest, CatBoost, XGBoost, LightGBM - and a simple feed-forward artificial neural network in combination with features engineered using knowledge-guided ML principles. Models were trained and tested on EC towers located in the Midwest of the United States using k-fold cross validation with k=5 and site-year, biome stratified train-test split to avoid data leakage. Results show that LightGBM with knowledge-guided features outperformed other methods with an R2=0.86, MSE=14.99 W m^-2 and MAE = 8.82 W m^-2 according to grouped k-fold validation (k=5). Feature importance analysis shows that knowledge-guided features were most important for predicting evapotranspiration. Using the best performing model, we provide a data product at 500 m spatial and one-day temporal resolution for gridded ET for the period of 2019-2024. Intercomparison between the new gridded product and state-level weather station-based ET estimates show best-in-class correspondence.",
    "authors": [
      "Aleksei Rozanov",
      "Samikshya Subedi",
      "Vasudha Sharma",
      "Bryan C. Runck"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T15:15:40.000Z",
    "updatedAt": "2025-10-13T15:15:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11505v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11505v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11503v1",
    "arxivId": "2510.11503v1",
    "title": "People use fast, flat goal-directed simulation to reason about novel problems",
    "abstract": "Games have long been a microcosm for studying planning and reasoning in both natural and artificial intelligence, especially with a focus on expert-level or even super-human play. But real life also pushes human intelligence along a different frontier, requiring people to flexibly navigate decision-making problems that they have never thought about before. Here, we use novice gameplay to study how people make decisions and form judgments in new problem settings. We show that people are systematic and adaptively rational in how they play a game for the first time, or evaluate a game (e.g., how fair or how fun it is likely to be) before they have played it even once. We explain these capacities via a computational cognitive model that we call the \"Intuitive Gamer\". The model is based on mechanisms of fast and flat (depth-limited) goal-directed probabilistic simulation--analogous to those used in Monte Carlo tree-search models of expert game-play, but scaled down to use very few stochastic samples, simple goal heuristics for evaluating actions, and no deep search. In a series of large-scale behavioral studies with over 1000 participants and 121 two-player strategic board games (almost all novel to our participants), our model quantitatively captures human judgments and decisions varying the amount and kind of experience people have with a game--from no experience at all (\"just thinking\"), to a single round of play, to indirect experience watching another person and predicting how they should play--and does so significantly better than much more compute-intensive expert-level models. More broadly, our work offers new insights into how people rapidly evaluate, act, and make suggestions when encountering novel problems, and could inform the design of more flexible and human-like AI systems that can determine not just how to solve new tasks, but whether a task is worth thinking about at all.",
    "authors": [
      "Katherine M. Collins",
      "Cedegao E. Zhang",
      "Lionel Wong",
      "Mauricio Barba da Costa",
      "Graham Todd",
      "Adrian Weller",
      "Samuel J. Cheyette",
      "Thomas L. Griffiths",
      "Joshua B. Tenenbaum"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.GT"
    ],
    "publishedAt": "2025-10-13T15:12:08.000Z",
    "updatedAt": "2025-10-13T15:12:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11503v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11503v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11502v1",
    "arxivId": "2510.11502v1",
    "title": "Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors",
    "abstract": "Research on reasoning in language models (LMs) predominantly focuses on improving the correctness of their outputs. But some important applications require modeling reasoning patterns that are incorrect. For example, automated systems that can reason about and simulate student errors are useful for providing real-time feedback in the classroom or offline practice for educators-in-training. This paper presents a new method, MISTAKE, that (1) constructs high-quality synthetic examples of reasoning errors by leveraging cycle consistency between incorrect answers and latent misconceptions; and (2) uses the generated data to learn models for student simulation, misconception classification, and answer generation. We evaluate MISTAKE on three educational tasks and find that it results in (1) higher accuracy when simulating incorrect student answers based on specific misconceptions, (2) increased performance inferring latent misconceptions from observed incorrect answers, and (3) higher alignment with expert-written distractor answers when generating incorrect answers (e.g., for multiple-choice tests).",
    "authors": [
      "Alexis Ross",
      "Jacob Andreas"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T15:10:38.000Z",
    "updatedAt": "2025-10-13T15:10:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11502v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11502v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11501v1",
    "arxivId": "2510.11501v1",
    "title": "Context-Aware Model-Based Reinforcement Learning for Autonomous Racing",
    "abstract": "Autonomous vehicles have shown promising potential to be a groundbreaking technology for improving the safety of road users. For these vehicles, as well as many other safety-critical robotic technologies, to be deployed in real-world applications, we require algorithms that can generalize well to unseen scenarios and data. Model-based reinforcement learning algorithms (MBRL) have demonstrated state-of-the-art performance and data efficiency across a diverse set of domains. However, these algorithms have also shown susceptibility to changes in the environment and its transition dynamics. In this work, we explore the performance and generalization capabilities of MBRL algorithms for autonomous driving, specifically in the simulated autonomous racing environment, Roboracer (formerly F1Tenth). We frame the head-to-head racing task as a learning problem using contextual Markov decision processes and parameterize the driving behavior of the adversaries using the context of the episode, thereby also parameterizing the transition and reward dynamics. We benchmark the behavior of MBRL algorithms in this environment and propose a novel context-aware extension of the existing literature, cMask. We demonstrate that context-aware MBRL algorithms generalize better to out-of-distribution adversary behaviors relative to context-free approaches. We also demonstrate that cMask displays strong generalization capabilities, as well as further performance improvement relative to other context-aware MBRL approaches when racing against adversaries with in-distribution behaviors.",
    "authors": [
      "Emran Yasser Moustafa",
      "Ivana Dusparic"
    ],
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T15:09:09.000Z",
    "updatedAt": "2025-10-13T15:09:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11501v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11501v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11500v1",
    "arxivId": "2510.11500v1",
    "title": "Structure-preserving finite element approximations of a hybrid relativistic cold fluid-particle model",
    "abstract": "We derive mixed finite element discretizations of a cold relativistics fluid model from approximations of the Poisson bracket that preserve mass, energy and the divergence constraints. For time-discretization we derive an implicit energy-conserving average-vector field method or apply an explicit strong-stability preserving Runge-Kutta scheme. We also consider a coupling of the fluid model to relativistic particles. We perform a numerical study of the scheme which shows convergence and conservation properties of the proposed methods and apply the new scheme to a plasma wake field simulation.",
    "authors": [
      "Tileuzhan Mukhamet",
      "Katharina Kormann"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.comp-ph"
    ],
    "publishedAt": "2025-10-13T15:06:52.000Z",
    "updatedAt": "2025-10-13T15:06:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11500v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11500v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11499v1",
    "arxivId": "2510.11499v1",
    "title": "Offline Reinforcement Learning with Generative Trajectory Policies",
    "abstract": "Generative models have emerged as a powerful class of policies for offline reinforcement learning (RL) due to their ability to capture complex, multi-modal behaviors. However, existing methods face a stark trade-off: slow, iterative models like diffusion policies are computationally expensive, while fast, single-step models like consistency policies often suffer from degraded performance. In this paper, we demonstrate that it is possible to bridge this gap. The key to moving beyond the limitations of individual methods, we argue, lies in a unifying perspective that views modern generative models, including diffusion, flow matching, and consistency models, as specific instances of learning a continuous-time generative trajectory governed by an Ordinary Differential Equation (ODE). This principled foundation provides a clearer design space for generative policies in RL and allows us to propose Generative Trajectory Policies (GTPs), a new and more general policy paradigm that learns the entire solution map of the underlying ODE. To make this paradigm practical for offline RL, we further introduce two key theoretically principled adaptations. Empirical results demonstrate that GTP achieves state-of-the-art performance on D4RL benchmarks - it significantly outperforms prior generative policies, achieving perfect scores on several notoriously hard AntMaze tasks.",
    "authors": [
      "Xinsong Feng",
      "Leshu Tang",
      "Chenan Wang",
      "Haipeng Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:06:28.000Z",
    "updatedAt": "2025-10-13T15:06:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11499v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11499v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11498v1",
    "arxivId": "2510.11498v1",
    "title": "ReLook: Vision-Grounded RL with a Multimodal LLM Critic for Agentic Web Coding",
    "abstract": "While Large Language Models (LLMs) excel at algorithmic code generation, they struggle with front-end development, where correctness is judged on rendered pixels and interaction. We present ReLook, an agentic, vision-grounded reinforcement learning framework that empowers an agent to close a robust generate--diagnose--refine loop by invoking a multimodal LLM (MLLM) as a tool. During training, the agent uses the MLLM-in-the-loop both as a visual critic--scoring code with screenshots--and as a source of actionable, vision-grounded feedback; a strict zero-reward rule for invalid renders anchors renderability and prevents reward hacking. To prevent behavioral collapse, we introduce Forced Optimization, a strict acceptance rule that admits only improving revisions, yielding monotonically better trajectories. At inference, we decouple the critic and run a lightweight, critic-free self-edit cycle, keeping latency comparable to base decoding while retaining most of the gains. Across three widely used benchmarks, ReLook consistently outperforms strong baselines in vision-grounded front-end code generation, highlighting the benefits of agentic perception, visual rewards, and training-inference decoupling.",
    "authors": [
      "Yuhang Li",
      "Chenchen Zhang",
      "Ruilin Lv",
      "Ao Liu",
      "Ken Deng",
      "Yuanxing Zhang",
      "Jiaheng Liu",
      "Wiggin Zhou",
      "Bo Zhou"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T15:05:50.000Z",
    "updatedAt": "2025-10-13T15:05:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11498v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11498v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11496v1",
    "arxivId": "2510.11496v1",
    "title": "AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model",
    "abstract": "In recent years, while cloud-based MLLMs such as QwenVL, InternVL, GPT-4o, Gemini, and Claude Sonnet have demonstrated outstanding performance with enormous model sizes reaching hundreds of billions of parameters, they significantly surpass the limitations in memory, power consumption, and computing capacity of edge devices such as mobile phones. This paper introduces AndesVL, a suite of mobile-side MLLMs with 0.6B to 4B parameters based on Qwen3's LLM and various visual encoders. We comprehensively outline the model architectures, training pipeline, and training data of AndesVL, which achieves first-tier performance across a wide range of open-source benchmarks, including fields such as text-rich image understanding, reasoning and math, multi-image comprehension, general VQA, hallucination mitigation, multilingual understanding, and GUI-related tasks when compared with state-of-the-art models of a similar scale. Furthermore, we introduce a 1+N LoR",
    "authors": [
      "Zhiwei Jin",
      "Xiaohui Song",
      "Nan Wang",
      "Yafei Liu",
      "Chao Li",
      "Xin Li",
      "Ruichen Wang",
      "Zhihao Li",
      "Qi Qi",
      "Long Cheng",
      "Dongze Hao",
      "Quanlong Zheng",
      "Yanhao Zhang",
      "Haobo Ji",
      "Jian Ma",
      "Zhitong Zheng",
      "Zhenyi Lin",
      "Haolin Deng",
      "Xin Zou",
      "Xiaojie Yin",
      "Ruilin Wang",
      "Liankai Cai",
      "Haijing Liu",
      "Yuqing Qiu",
      "Ke Chen",
      "Zixian Li",
      "Chi Xie",
      "Huafei Li",
      "Chenxing Li",
      "Chuangchuang Wang",
      "Kai Tang",
      "Zhiguang Zhu",
      "Kai Tang",
      "Wenmei Gao",
      "Rui Wang",
      "Jun Wu",
      "Chao Liu",
      "Qin Xie",
      "Chen Chen",
      "Haonan Lu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T15:04:38.000Z",
    "updatedAt": "2025-10-13T15:04:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11496v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11496v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11495v1",
    "arxivId": "2510.11495v1",
    "title": "How Reinforcement Learning After Next-Token Prediction Facilitates Learning",
    "abstract": "Recent advances in reasoning domains with neural networks have primarily been enabled by a training recipe that optimizes Large Language Models, previously trained to predict the next-token in a sequence, with reinforcement learning algorithms. We introduce a framework to study the success of this paradigm, and we theoretically expose the optimization mechanisms by which reinforcement learning improves over next-token prediction in this setting. We study learning from mixture distributions of short and long ``chain-of-thought'' sequences encoding a single task. In particular, when the task consists of predicting the parity of $d$ bits and long sequences are rare, we show how reinforcement learning after next-token prediction enables autoregressive transformers to generalize, whereas mere next-token prediction requires extreme statistical or computational resources to do so. We further explain how reinforcement learning leverages increased test-time computation, manifested in longer responses, to facilitate this learning process. In a simplified setting, we theoretically prove that autoregressive linear models following this training recipe can efficiently learn to predict the parity of $d$ bits as long as the proportion of long demonstrations in the data mix is not exponentially small in the input dimension $d$. Finally, we demonstrate these same phenomena in other settings, including the post-training of Llama-series models on mixture variations of common mathematical reasoning benchmarks.",
    "authors": [
      "Nikolaos Tsilivis",
      "Eran Malach",
      "Karen Ullrich",
      "Julia Kempe"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T15:04:00.000Z",
    "updatedAt": "2025-10-13T15:04:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11495v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11495v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11491v1",
    "arxivId": "2510.11491v1",
    "title": "Constraint-Aware Reinforcement Learning via Adaptive Action Scaling",
    "abstract": "Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that arise from exploration during training by reducing constraint violations while maintaining task performance. Existing approaches typically rely on a single policy to jointly optimize reward and safety, which can cause instability due to conflicting objectives, or they use external safety filters that override actions and require prior system knowledge. In this paper, we propose a modular cost-aware regulator that scales the agent's actions based on predicted constraint violations, preserving exploration through smooth action modulation rather than overriding the policy. The regulator is trained to minimize constraint violations while avoiding degenerate suppression of actions. Our approach integrates seamlessly with off-policy RL methods such as SAC and TD3, and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion tasks with sparse costs, reducing constraint violations by up to 126 times while increasing returns by over an order of magnitude compared to prior methods.",
    "authors": [
      "Murad Dawood",
      "Usama Ahmed Siddiquie",
      "Shahram Khorshidi",
      "Maren Bennewitz"
    ],
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-13T14:59:28.000Z",
    "updatedAt": "2025-10-13T14:59:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11491v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11491v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11484v1",
    "arxivId": "2510.11484v1",
    "title": "Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware",
    "abstract": "Integer AI inference significantly reduces computational complexity in embedded systems. Quantization-aware training (QAT) helps mitigate accuracy degradation associated with post-training quantization but still overlooks the impact of integer rescaling during inference, which is a hardware costly operation in integer-only AI inference. This work shows that rescaling cost can be dramatically reduced post-training, by applying a stronger quantization to the rescale multiplicands at no model-quality loss. Furthermore, we introduce Rescale-Aware Training, a fine tuning method for ultra-low bit-width rescaling multiplicands. Experiments show that even with 8x reduced rescaler widths, the full accuracy is preserved through minimal incremental retraining. This enables more energy-efficient and cost-efficient AI inference for resource-constrained embedded systems.",
    "authors": [
      "Lion Mueller",
      "Alberto Garcia-Ortiz",
      "Ardalan Najafi",
      "Adam Fuks",
      "Lennart Bamberg"
    ],
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "publishedAt": "2025-10-13T14:55:34.000Z",
    "updatedAt": "2025-10-13T14:55:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11484v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11484v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11483v1",
    "arxivId": "2510.11483v1",
    "title": "Uncertainty Quantification for Retrieval-Augmented Reasoning",
    "abstract": "Retrieval-augmented reasoning (RAR) is a recent evolution of retrieval-augmented generation (RAG) that employs multiple reasoning steps for retrieval and generation. While effective for some complex queries, RAR remains vulnerable to errors and misleading outputs. Uncertainty quantification (UQ) offers methods to estimate the confidence of systems' outputs. These methods, however, often handle simple queries with no retrieval or single-step retrieval, without properly handling RAR setup. Accurate estimation of UQ for RAR requires accounting for all sources of uncertainty, including those arising from retrieval and generation. In this paper, we account for all these sources and introduce Retrieval-Augmented Reasoning Consistency (R2C)--a novel UQ method for RAR. The core idea of R2C is to perturb the multi-step reasoning process by applying various actions to reasoning steps. These perturbations alter the retriever's input, which shifts its output and consequently modifies the generator's input at the next step. Through this iterative feedback loop, the retriever and generator continuously reshape one another's inputs, enabling us to capture uncertainty arising from both components. Experiments on five popular RAR systems across diverse QA datasets show that R2C improves AUROC by over 5% on average compared to the state-of-the-art UQ baselines. Extrinsic evaluations using R2C as an external signal further confirm its effectiveness for two downstream tasks: in Abstention, it achieves ~5% gains in both F1Abstain and AccAbstain; in Model Selection, it improves the exact match by ~7% over single models and ~3% over selection methods.",
    "authors": [
      "Heydar Soudani",
      "Hamed Zamani",
      "Faegheh Hasibi"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T14:55:28.000Z",
    "updatedAt": "2025-10-13T14:55:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11483v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11483v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11482v1",
    "arxivId": "2510.11482v1",
    "title": "Investigating Large Language Models' Linguistic Abilities for Text Preprocessing",
    "abstract": "Text preprocessing is a fundamental component of Natural Language Processing, involving techniques such as stopword removal, stemming, and lemmatization to prepare text as input for further processing and analysis. Despite the context-dependent nature of the above techniques, traditional methods usually ignore contextual information. In this paper, we investigate the idea of using Large Language Models (LLMs) to perform various preprocessing tasks, due to their ability to take context into account without requiring extensive language-specific annotated resources. Through a comprehensive evaluation on web-sourced data, we compare LLM-based preprocessing (specifically stopword removal, lemmatization and stemming) to traditional algorithms across multiple text classification tasks in six European languages. Our analysis indicates that LLMs are capable of replicating traditional stopword removal, lemmatization, and stemming methods with accuracies reaching 97%, 82%, and 74%, respectively. Additionally, we show that ML algorithms trained on texts preprocessed by LLMs achieve an improvement of up to 6% with respect to the $F_1$ measure compared to traditional techniques. Our code, prompts, and results are publicly available at https://github.com/GianCarloMilanese/llm_pipeline_wi-iat.",
    "authors": [
      "Marco Braga",
      "Gian Carlo Milanese",
      "Gabriella Pasi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T14:53:44.000Z",
    "updatedAt": "2025-10-13T14:53:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11482v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11482v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11478v1",
    "arxivId": "2510.11478v1",
    "title": "Numerical Methods for Kernel Slicing",
    "abstract": "Kernels are key in machine learning for modeling interactions. Unfortunately, brute-force computation of the related kernel sums scales quadratically with the number of samples. Recent Fourier-slicing methods lead to an improved linear complexity, provided that the kernel can be sliced and its Fourier coefficients are known. To obtain these coefficients, we view the slicing relation as an inverse problem and present two algorithms for their recovery. Extensive numerical experiments demonstrate the speed and accuracy of our methods.",
    "authors": [
      "Nicolaj Rux",
      "Johannes Hertrich",
      "Sebastian Neumayer"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "65R32, 45Q05"
    ],
    "publishedAt": "2025-10-13T14:46:50.000Z",
    "updatedAt": "2025-10-13T14:46:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11478v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11478v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11476v1",
    "arxivId": "2510.11476v1",
    "title": "The Role of Flexible Connection in Accelerating Load Interconnection in Distribution Networks",
    "abstract": "This paper investigates the role of flexible connection in accelerating the interconnection of large loads amid rising electricity demand from data centers and electrification. Flexible connection allows new loads to defer or curtail consumption during rare, grid-constrained periods, enabling faster access without major infrastructure upgrades. To quantify how flexible connection unlocks load hosting capacity, we formulate a flexibility-aware hosting capacity analysis problem that explicitly limits the number of utility-controlled interventions per year, ensuring infrequent disruption. Efficient solution methods are developed for this nonconvex problem and applied to real load data and test feeders. Empirical results reveal that modest flexibility, i.e., few interventions with small curtailments or delays, can unlock substantial hosting capacity. Theoretical analysis further explains and generalizes these findings, highlighting the broad potential of flexible connection.",
    "authors": [
      "Nan Gu",
      "Ge Chen",
      "Junjie Qin"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T14:46:26.000Z",
    "updatedAt": "2025-10-13T14:46:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11476v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11476v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11475v1",
    "arxivId": "2510.11475v1",
    "title": "An adaptive time-stepping strategy for the modified phase field crystal model with a strong nonlinear vacancy potential",
    "abstract": "This paper develops three linear and energy-stable schemes for a modified phase field crystal model with a strong nonlinear vacancy potential (VMPFC model). This sixth-order phase-field model enables realistic crystal growth simulation. Starting from a Crank-Nicolson scheme based on the stabilized-SAV (S-SAV) method, we optimize it via the generalized positive auxiliary variable (GPAV) and modified exponential scalar auxiliary variable (ESAV) methods, thereby reducing computational complexity or eliminating the requirement for the nonlinear free energy potential to be bounded from below. The newly developed Energy-Variation Moving Average (EV-MA) adaptive time-stepping strategy resolves numerical instabilities and mitigates the high parameter sensitivity of the conventional adaptive time algorithm during rapid energy decay in the strongly nonlinear system. Unlike conventional instantaneous energy-derivative monitors, the EV-MA technique incorporates a moving average of the energy variation. Additionally, the rate of change between adjacent time steps is constrained by a maximum change factor. This design effectively dampens spurious oscillations and enhances the robustness of time step selection. Extensive numerical experiments are conducted to validate the accuracy and energy stability of the proposed schemes. The EV-MA strategy is also demonstrated to perform robustly across a wide range of parameters.",
    "authors": [
      "Wanrong Hao",
      "Yunqing Huang"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "math-ph",
      "math.MP"
    ],
    "publishedAt": "2025-10-13T14:45:55.000Z",
    "updatedAt": "2025-10-13T14:45:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11475v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11475v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11474v1",
    "arxivId": "2510.11474v1",
    "title": "Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning",
    "abstract": "Achieving mission objectives in a realistic simulation of aerial combat is highly challenging due to imperfect situational awareness and nonlinear flight dynamics. In this work, we introduce a novel 3D multi-agent air combat environment and a Hierarchical Multi-Agent Reinforcement Learning framework to tackle these challenges. Our approach combines heterogeneous agent dynamics, curriculum learning, league-play, and a newly adapted training algorithm. To this end, the decision-making process is organized into two abstraction levels: low-level policies learn precise control maneuvers, while high-level policies issue tactical commands based on mission objectives. Empirical results show that our hierarchical approach improves both learning efficiency and combat performance in complex dogfight scenarios.",
    "authors": [
      "Ardian Selmonaj",
      "Giacomo Del Rio",
      "Adrian Schneider",
      "Alessandro Antonucci"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "publishedAt": "2025-10-13T14:44:51.000Z",
    "updatedAt": "2025-10-13T14:44:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11474v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11474v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11473v1",
    "arxivId": "2510.11473v1",
    "title": "VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment",
    "abstract": "3D Gaussian Splatting has recently emerged as an efficient solution for high-quality and real-time novel view synthesis. However, its capability for accurate surface reconstruction remains underexplored. Due to the discrete and unstructured nature of Gaussians, supervision based solely on image rendering loss often leads to inaccurate geometry and inconsistent multi-view alignment. In this work, we propose a novel method that enhances the geometric representation of 3D Gaussians through view alignment (VA). Specifically, we incorporate edge-aware image cues into the rendering loss to improve surface boundary delineation. To enforce geometric consistency across views, we introduce a visibility-aware photometric alignment loss that models occlusions and encourages accurate spatial relationships among Gaussians. To further mitigate ambiguities caused by lighting variations, we incorporate normal-based constraints to refine the spatial orientation of Gaussians and improve local surface estimation. Additionally, we leverage deep image feature embeddings to enforce cross-view consistency, enhancing the robustness of the learned geometry under varying viewpoints and illumination. Extensive experiments on standard benchmarks demonstrate that our method achieves state-of-the-art performance in both surface reconstruction and novel view synthesis. The source code is available at https://github.com/LeoQLi/VA-GS.",
    "authors": [
      "Qing Li",
      "Huifang Feng",
      "Xun Gong",
      "Yu-Shen Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T14:44:50.000Z",
    "updatedAt": "2025-10-13T14:44:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11473v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11473v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11472v1",
    "arxivId": "2510.11472v1",
    "title": "Differentiable Fast Top-K Selection for Large-Scale Recommendation",
    "abstract": "Cascade ranking is a widely adopted paradigm in large-scale information retrieval systems for Top-K item selection. However, the Top-K operator is non-differentiable, hindering end-to-end training. Existing methods include Learning-to-Rank approaches (e.g., LambdaLoss), which optimize ranking metrics like NDCG and suffer from objective misalignment, and differentiable sorting-based methods (e.g., ARF, LCRON), which relax permutation matrices for direct Top-K optimization but introduce gradient conflicts through matrix aggregation. A promising alternative is to directly construct a differentiable approximation of the Top-K selection operator, bypassing the use of soft permutation matrices. However, even state-of-the-art differentiable Top-K operator (e.g., LapSum) require $O(n \\log n)$ complexity due to their dependence on sorting for solving the threshold. Thus, we propose DFTopK, a novel differentiable Top-K operator achieving optimal $O(n)$ time complexity. By relaxing normalization constraints, DFTopK admits a closed-form solution and avoids sorting. DFTopK also avoids the gradient conflicts inherent in differentiable sorting-based methods. We evaluate DFTopK on both the public benchmark RecFLow and an industrial system. Experimental results show that DFTopK significantly improves training efficiency while achieving superior performance, which enables us to scale up training samples more efficiently. In the online A/B test, DFTopK yielded a +1.77\\% revenue lift with the same computational budget compared to the baseline. To the best of our knowledge, this work is the first to introduce differentiable Top-K operators into recommendation systems and the first to achieve theoretically optimal linear-time complexity for Top-K selection. We have open-sourced our implementation to facilitate future research in both academia and industry.",
    "authors": [
      "Yanjie Zhu",
      "Zhen Zhang",
      "Yunli Wang",
      "Zhiqiang Wang",
      "Yu Li",
      "Rufan Zhou",
      "Shiyang Wen",
      "Peng Jiang",
      "Chenhao Lin",
      "Jian Yang"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T14:40:49.000Z",
    "updatedAt": "2025-10-13T14:40:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11472v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11472v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11471v1",
    "arxivId": "2510.11471v1",
    "title": "Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers",
    "abstract": "Modern learning systems increasingly rely on amortized learning - the idea of reusing computation or inductive biases shared across tasks to enable rapid generalization to novel problems. This principle spans a range of approaches, including meta-learning, in-context learning, prompt tuning, learned optimizers and more. While motivated by similar goals, these approaches differ in how they encode and leverage task-specific information, often provided as in-context examples. In this work, we propose a unified framework which describes how such methods differ primarily in the aspects of learning they amortize - such as initializations, learned updates, or predictive mappings - and how they incorporate task data at inference. We introduce a taxonomy that categorizes amortized models into parametric, implicit, and explicit regimes, based on whether task adaptation is externalized, internalized, or jointly modeled. Building on this view, we identify a key limitation in current approaches: most methods struggle to scale to large datasets because their capacity to process task data at inference (e.g., context length) is often limited. To address this, we propose iterative amortized inference, a class of models that refine solutions step-by-step over mini-batches, drawing inspiration from stochastic optimization. Our formulation bridges optimization-based meta-learning with forward-pass amortization in models like LLMs, offering a scalable and extensible foundation for general-purpose task adaptation.",
    "authors": [
      "Sarthak Mittal",
      "Divyat Mahajan",
      "Guillaume Lajoie",
      "Mohammad Pezeshki"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T14:40:47.000Z",
    "updatedAt": "2025-10-13T14:40:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11471v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11471v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11462v1",
    "arxivId": "2510.11462v1",
    "title": "Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model",
    "abstract": "Deductive and abductive reasoning are two critical paradigms for analyzing knowledge graphs, enabling applications from financial query answering to scientific discovery. Deductive reasoning on knowledge graphs usually involves retrieving entities that satisfy a complex logical query, while abductive reasoning generates plausible logical hypotheses from observations. Despite their clear synergistic potential, where deduction can validate hypotheses and abduction can uncover deeper logical patterns, existing methods address them in isolation. To bridge this gap, we propose DARK, a unified framework for Deductive and Abductive Reasoning in Knowledge graphs. As a masked diffusion model capable of capturing the bidirectional relationship between queries and conclusions, DARK has two key innovations. First, to better leverage deduction for hypothesis refinement during abductive reasoning, we introduce a self-reflective denoising process that iteratively generates and validates candidate hypotheses against the observed conclusion. Second, to discover richer logical associations, we propose a logic-exploration reinforcement learning approach that simultaneously masks queries and conclusions, enabling the model to explore novel reasoning compositions. Extensive experiments on multiple benchmark knowledge graphs show that DARK achieves state-of-the-art performance on both deductive and abductive reasoning tasks, demonstrating the significant benefits of our unified approach.",
    "authors": [
      "Yisen Gao",
      "Jiaxin Bai",
      "Yi Huang",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Yangqiu Song"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T14:34:57.000Z",
    "updatedAt": "2025-10-13T14:34:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11462v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11462v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11457v1",
    "arxivId": "2510.11457v1",
    "title": "From <Answer> to <Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization",
    "abstract": "Improving the multi-step reasoning ability of Large Language Models (LLMs) is a critical yet challenging task. The dominant paradigm, outcome-supervised reinforcement learning (RLVR), rewards only correct final answers, often propagating flawed reasoning and suffering from sparse reward signals. While process-level reward models (PRMs) provide denser, step-by-step feedback, they lack generalizability and interpretability, requiring task-specific segmentation of the reasoning process. To this end, we propose the Dimension-level Reward Model (DRM), a new supervision framework that bridges the gap between these two approaches. DRM evaluates the quality of a reasoning process along three fundamental, complementary, and interpretable dimensions: Confidence for uncertainty calibration, Relevance for semantic alignment, and Coherence for logical consistency. Together, these dimensions capture aspects beyond final answer correctness and enable interpretable assessment without requiring ground truth answers. Experimental results show that DRM provides effective supervision signals, guides the optimization of LLMs and enhances their reasoning ability. In particular, DRM-supervised training achieves consistent gains on both in-distribution and out-of-distribution open-domain tasks, including mathematics, question answering, code execution, and puzzles. Our findings demonstrate that multidimensional supervision of the reasoning process can improve the generalized reasoning ability of LLMs beyond the training distribution.",
    "authors": [
      "Beining Wang",
      "Weihang Su",
      "Hongtao Tian",
      "Tao Yang",
      "Yujia Zhou",
      "Ting Yao",
      "Qingyao Ai",
      "Yiqun Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T14:29:15.000Z",
    "updatedAt": "2025-10-13T14:29:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11457v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11457v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11456v1",
    "arxivId": "2510.11456v1",
    "title": "Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion",
    "abstract": "Existing Infrared and Visible Image Fusion (IVIF) methods typically assume high-quality inputs. However, when handing degraded images, these methods heavily rely on manually switching between different pre-processing techniques. This decoupling of degradation handling and image fusion leads to significant performance degradation. In this paper, we propose a novel VLM-Guided Degradation-Coupled Fusion network (VGDCFusion), which tightly couples degradation modeling with the fusion process and leverages vision-language models (VLMs) for degradation-aware perception and guided suppression. Specifically, the proposed Specific-Prompt Degradation-Coupled Extractor (SPDCE) enables modality-specific degradation awareness and establishes a joint modeling of degradation suppression and intra-modal feature extraction. In parallel, the Joint-Prompt Degradation-Coupled Fusion (JPDCF) facilitates cross-modal degradation perception and couples residual degradation filtering with complementary cross-modal feature fusion. Extensive experiments demonstrate that our VGDCFusion significantly outperforms existing state-of-the-art fusion approaches under various degraded image scenarios. Our code is available at https://github.com/Lmmh058/VGDCFusion.",
    "authors": [
      "Tianpei Zhang",
      "Jufeng Zhao",
      "Yiming Zhu",
      "Guangmang Cui"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T14:26:33.000Z",
    "updatedAt": "2025-10-13T14:26:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11456v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11456v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11454v1",
    "arxivId": "2510.11454v1",
    "title": "Audio-Maestro: Enhancing Large Audio-Language Models with Tool-Augmented Reasoning",
    "abstract": "Recent advancements in large multimodal models (LMMs) have shown strong capabilities in audio understanding. However, most systems rely solely on end-to-end reasoning, limiting interpretability and accuracy for tasks that require structured knowledge or specialized signal analysis. In this work, we present Audio-Maestro -- a tool-augmented audio reasoning framework that enables audio-language models to autonomously call external tools and integrate their timestamped outputs into the reasoning process. This design allows the model to analyze, transform, and interpret audio signals through specialized tools rather than relying solely on end-to-end inference. Experiments show that Audio-Maestro consistently improves general audio reasoning performance: Gemini-2.5-flash's average accuracy on MMAU-Test rises from 67.4% to 72.1%, DeSTA-2.5 from 58.3% to 62.8%, and GPT-4o from 60.8% to 63.9%. To our knowledge, Audio-Maestro is the first framework to integrate structured tool output into the large audio language model reasoning process.",
    "authors": [
      "Kuan-Yi Lee",
      "Tsung-En Lin",
      "Hung-Yi Lee"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T14:25:34.000Z",
    "updatedAt": "2025-10-13T14:25:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11454v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11454v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11453v1",
    "arxivId": "2510.11453v1",
    "title": "List Decoding Reed--Solomon Codes in the Lee, Euclidean, and Other Metrics",
    "abstract": "Reed--Solomon error-correcting codes are ubiquitous across computer science and information theory, with applications in cryptography, computational complexity, communication and storage systems, and more. Most works on efficient error correction for these codes, like the celebrated Berlekamp--Welch unique decoder and the (Guruswami--)Sudan list decoders, are focused on measuring error in the Hamming metric, which simply counts the number of corrupted codeword symbols. However, for some applications, other metrics that depend on the specific values of the errors may be more appropriate. This work gives a polynomial-time algorithm that list decodes (generalized) Reed--Solomon codes over prime fields in $\\ell_p$ (semi)metrics, for any $0 < p \\leq 2$. Compared to prior algorithms for the Lee ($\\ell_1$) and Euclidean ($\\ell_2$) metrics, ours decodes to arbitrarily large distances (for correspondingly small rates), and has better distance-rate tradeoffs for all decoding distances above some moderate thresholds. We also prove lower bounds on the $\\ell_{1}$ and $\\ell_{2}$ minimum distances of a certain natural subclass of GRS codes, which establishes that our list decoder is actually a unique decoder for many parameters of interest. Finally, we analyze our algorithm's performance under random Laplacian and Gaussian errors, and show that it supports even larger rates than for corresponding amounts of worst-case error in $\\ell_{1}$ and $\\ell_{2}$ (respectively).",
    "authors": [
      "Chris Peikert",
      "Alexandra Veliche Hostetler"
    ],
    "categories": [
      "cs.IT",
      "cs.DS",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T14:25:33.000Z",
    "updatedAt": "2025-10-13T14:25:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11453v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11453v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11449v1",
    "arxivId": "2510.11449v1",
    "title": "Enhancing Maritime Domain Awareness on Inland Waterways: A YOLO-Based Fusion of Satellite and AIS for Vessel Characterization",
    "abstract": "Maritime Domain Awareness (MDA) for inland waterways remains challenged by cooperative system vulnerabilities. This paper presents a novel framework that fuses high-resolution satellite imagery with vessel trajectory data from the Automatic Identification System (AIS). This work addresses the limitations of AIS-based monitoring by leveraging non-cooperative satellite imagery and implementing a fusion approach that links visual detections with AIS data to identify dark vessels, validate cooperative traffic, and support advanced MDA. The You Only Look Once (YOLO) v11 object detection model is used to detect and characterize vessels and barges by vessel type, barge cover, operational status, barge count, and direction of travel. An annotated data set of 4,550 instances was developed from $5{,}973~\\mathrm{mi}^2$ of Lower Mississippi River imagery. Evaluation on a held-out test set demonstrated vessel classification (tugboat, crane barge, bulk carrier, cargo ship, and hopper barge) with an F1 score of 95.8\\%; barge cover (covered or uncovered) detection yielded an F1 score of 91.6\\%; operational status (staged or in motion) classification reached an F1 score of 99.4\\%. Directionality (upstream, downstream) yielded 93.8\\% accuracy. The barge count estimation resulted in a mean absolute error (MAE) of 2.4 barges. Spatial transferability analysis across geographically disjoint river segments showed accuracy was maintained as high as 98\\%. These results underscore the viability of integrating non-cooperative satellite sensing with AIS fusion. This approach enables near-real-time fleet inventories, supports anomaly detection, and generates high-quality data for inland waterway surveillance. Future work will expand annotated datasets, incorporate temporal tracking, and explore multi-modal deep learning to further enhance operational scalability.",
    "authors": [
      "Geoffery Agorku",
      "Sarah Hernandez",
      "Hayley Hames",
      "Cade Wagner"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T14:19:58.000Z",
    "updatedAt": "2025-10-13T14:19:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11449v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11449v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11448v1",
    "arxivId": "2510.11448v1",
    "title": "A Faster and More Reliable Middleware for Autonomous Driving Systems",
    "abstract": "Ensuring safety in high-speed autonomous vehicles requires rapid control loops and tightly bounded delays from perception to actuation. Many open-source autonomy systems rely on ROS 2 middleware; when multiple sensor and control nodes share one compute unit, ROS 2 and its DDS transports add significant (de)serialization, copying, and discovery overheads, shrinking the available time budget. We present Sensor-in-Memory (SIM), a shared-memory transport designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double buffers that overwrite old data to prioritize freshness, and integrates into ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM operates beside ROS 2 and is optimized for applications where data freshness and minimal latency outweigh guaranteed completeness. SIM provides sequence numbers, a writer heartbeat, and optional checksums to ensure ordering, liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces data-transport latency by up to 98% compared to ROS 2 zero-copy transports such as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows 95th/99th-percentile tail latencies by around 96%. In tests on a production-ready Level 4 vehicle running Autoware.Universe, SIM increased localization frequency from 7.5 Hz to 9.5 Hz. Applied across all latency-critical modules, SIM cut average perception-to-decision latency from 521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h) on dry concrete by 13.6 ft (4.14 m).",
    "authors": [
      "Yuankai He",
      "Hanlin Chen",
      "Weisong Shi"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "C.3; D.4.1; D.4.4; D.4.8; I.2.9"
    ],
    "publishedAt": "2025-10-13T14:17:14.000Z",
    "updatedAt": "2025-10-13T14:17:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11448v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11448v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11447v1",
    "arxivId": "2510.11447v1",
    "title": "Building and Evaluating a Realistic Virtual World for Large Scale Urban Exploration from 360° Videos",
    "abstract": "We propose to build realistic virtual worlds, called 360RVW, for large urban environments directly from 360{\\deg} videos. We provide an interface for interactive exploration, where users can freely navigate via their own avatars. 360{\\deg} videos record the entire environment of the shooting location simultaneously leading to highly realistic and immersive representations. Our system uses 360{\\deg} videos recorded along streets and builds a 360RVW through four main operations: video segmentation by intersection detection, video completion to remove the videographer, semantic segmentation for virtual collision detection with the avatar, and projection onto a distorted sphere that moves along the camera trajectory following the avatar's movements. Our interface allows users to explore large urban environments by changing their walking direction at intersections or choosing a new location by clicking on a map. Even without a 3D model, the users can experience collision with buildings using metadata produced by semantic segmentation. Furthermore, we stream the 360{\\deg} videos so users can directly access 360RVW via their web browser. We fully evaluate our system, including a perceptual experiment comparing our approach to previous exploratory interfaces. The results confirm the quality of our system, especially regarding the presence of users and the interactive exploration, making it most suitable for a virtual tour of urban environments.",
    "authors": [
      "Mizuki Takenawa",
      "Naoki Sugimoto",
      "Leslie Wöhler",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "categories": [
      "cs.MM"
    ],
    "publishedAt": "2025-10-13T14:17:06.000Z",
    "updatedAt": "2025-10-13T14:17:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11447v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11447v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11445v1",
    "arxivId": "2510.11445v1",
    "title": "Repeated-and-Offset QPSK for DFT-s-OFDM in Satellite Access",
    "abstract": "Motivated by the convergence of terrestrial cellular networks with satellite networks, we consider an adaptation of offset quadrature phase shift keying (OQPSK), used with single-carrier waveform in traditional satellite systems, to discrete Fourier transform spread (DFT-s-) orthogonal frequency-division multiplexed (OFDM) waveform employed in the uplink of terrestrial systems. We introduce a new order-one constellation modulation, termed repeated-and-offset QPSK (RO-QPSK), derive its basic properties, and compare it with pi/2-BPSK with frequency-domain spectral shaping (FDSS), as supported in 5G. RO-QPSK naturally produces a Hann-window-shaped spectrum, resulting in a very low maximum peak-to-average power ratio (PAPR) on the order of 2 dB. Moreover, with single-tap equalization and symbol combining at the receiver, RO-QSPK can improve the signal-to-interference-plus-noise (SINR) compared to pi/2-BPSK with FDSS, in narrowband and/or moderately frequency-selective channels, as encountered in satellite communications. A moderate FDSS can also be combined with RO-QSPK to further reduce the PAPR while providing similar performance. Of independent interest, general SINR expressions for DFT-s-OFDM are also provided.",
    "authors": [
      "Renaud-Alexandre Pitaval"
    ],
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T14:15:58.000Z",
    "updatedAt": "2025-10-13T14:15:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11445v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11445v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11444v1",
    "arxivId": "2510.11444v1",
    "title": "GenCNER: A Generative Framework for Continual Named Entity Recognition",
    "abstract": "Traditional named entity recognition (NER) aims to identify text mentions into pre-defined entity types. Continual Named Entity Recognition (CNER) is introduced since entity categories are continuously increasing in various real-world scenarios. However, existing continual learning (CL) methods for NER face challenges of catastrophic forgetting and semantic shift of non-entity type. In this paper, we propose GenCNER, a simple but effective Generative framework for CNER to mitigate the above drawbacks. Specifically, we skillfully convert the CNER task into sustained entity triplet sequence generation problem and utilize a powerful pre-trained seq2seq model to solve it. Additionally, we design a type-specific confidence-based pseudo labeling strategy along with knowledge distillation (KD) to preserve learned knowledge and alleviate the impact of label noise at the triplet level. Experimental results on two benchmark datasets show that our framework outperforms previous state-of-the-art methods in multiple CNER settings, and achieves the smallest gap compared with non-CL results.",
    "authors": [
      "Yawen Yang",
      "Fukun Ma",
      "Shiao Meng",
      "Aiwei Liu",
      "Lijie Wen"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T14:15:31.000Z",
    "updatedAt": "2025-10-13T14:15:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11444v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11444v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11442v1",
    "arxivId": "2510.11442v1",
    "title": "Reconstructing 12-Lead ECG from 3-Lead ECG using Variational Autoencoder to Improve Cardiac Disease Detection of Wearable ECG Devices",
    "abstract": "Twelve-lead electrocardiograms (ECGs) are the clinical gold standard for cardiac diagnosis, providing comprehensive spatial coverage of the heart necessary to detect conditions such as myocardial infarction (MI). However, their lack of portability limits continuous and large-scale use. Three-lead ECG systems are widely used in wearable devices due to their simplicity and mobility, but they often fail to capture pathologies in unmeasured regions. To address this, we propose WearECG, a Variational Autoencoder (VAE) method that reconstructs twelve-lead ECGs from three leads: II, V1, and V5. Our model includes architectural improvements to better capture temporal and spatial dependencies in ECG signals. We evaluate generation quality using MSE, MAE, and Frechet Inception Distance (FID), and assess clinical validity via a Turing test with expert cardiologists. To further validate diagnostic utility, we fine-tune ECGFounder, a large-scale pretrained ECG model, on a multi-label classification task involving over 40 cardiac conditions, including six different myocardial infarction locations, using both real and generated signals. Experiments on the MIMIC dataset show that our method produces physiologically realistic and diagnostically informative signals, with robust performance in downstream tasks. This work demonstrates the potential of generative modeling for ECG reconstruction and its implications for scalable, low-cost cardiac screening.",
    "authors": [
      "Xinyan Guan",
      "Yongfan Lai",
      "Jiarui Jin",
      "Jun Li",
      "Haoyu Wang",
      "Qinghao Zhao",
      "Deyun Zhang",
      "Shijia Geng",
      "Shenda Hong"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05",
      "I.2.6; I.2.7"
    ],
    "publishedAt": "2025-10-13T14:14:37.000Z",
    "updatedAt": "2025-10-13T14:14:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11442v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11442v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11439v1",
    "arxivId": "2510.11439v1",
    "title": "On the boundedness of dilation operators in the context of Triebel-Lizorkin-Morrey spaces",
    "abstract": "In this paper we study the behavior of dilation operators $ D_\\lambda \\colon f \\mapsto f(\\lambda\\,\\cdot) $ with $ \\lambda > 1 $ in the context of Triebel-Lizorkin-Morrey spaces $\\mathcal{E}^{s}_{u,p,q}(\\mathbb{R}^d)$. For that purpose we prove upper and lower bounds for the operator (quasi-)norm $\\| D_\\lambda \\,|\\, \\mathcal{L}\\big(\\mathcal{E}^s_{u,p,q}(\\mathbb{R}^d)\\big) \\| $. We show that for $s>\\sigma_p $ the operator (quasi-)norm $\\| D_\\lambda \\,|\\, \\mathcal{L}\\big(\\mathcal{E}^s_{u,p,q}(\\mathbb{R}^d)\\big) \\| $ up to constants behaves as $\\lambda^{s - \\frac{d}{u}} $. For the borderline case $ s = \\sigma_{p} $ we observe a behavior of the form $\\lambda^{\\sigma_p- \\frac{d}{u}}$, multiplied with logarithmic terms of $\\lambda$ that also depend on the fine index $q$. For $s < \\sigma_{p}$ and $p \\geq 1$ we find the relation $\\| D_\\lambda \\,|\\, \\mathcal{L}\\big(\\mathcal{E}^s_{u,p,q}(\\mathbb{R}^d)\\big) \\| \\sim \\lambda^{ - \\frac{d}{u}}$. The case $s < \\sigma_{p}$ and $p < 1$ is investigated as well. Our proofs are mainly based on the Fourier analytic approach to Triebel-Lizorkin-Morrey spaces. As byproducts we show an advanced Fourier multiplier theorem for band-limited functions in the context of Morrey spaces and derive some new equivalent (quasi-)norms and characterizations of $\\mathcal{E}^{s}_{u,p,q}(\\mathbb{R}^d)$. Keywords: Dilation Operator, Morrey space, Triebel-Lizorkin-Morrey space, Fourier multiplier",
    "authors": [
      "Marc Hovemann",
      "Markus Weimar"
    ],
    "categories": [
      "math.FA",
      "cs.NA",
      "math.AP",
      "math.NA",
      "46E35, 46E30"
    ],
    "publishedAt": "2025-10-13T14:10:41.000Z",
    "updatedAt": "2025-10-13T14:10:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11439v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11439v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11438v1",
    "arxivId": "2510.11438v1",
    "title": "What Generative Search Engines Like and How to Optimize Web Content Cooperatively",
    "abstract": "By employing large language models (LLMs) to retrieve documents and generate natural language responses, Generative Engines, such as Google AI overview and ChatGPT, provide significantly enhanced user experiences and have rapidly become the new form of search. Their rapid adoption also drives the needs of Generative Engine Optimization (GEO), as content providers are eager to gain more traction from them. In this paper, we introduce AutoGEO, a framework to automatically learn generative engine preferences when using retrieved contents for response generation, and rewrite web contents for more such traction. AutoGEO first prompts frontier LLMs to explain generative engine preferences and extract meaningful preference rules from these explanations. Then it uses preference rules as context engineering for AutoGEO$_\\text{API}$, a prompt-based GEO system, and as rule-based rewards to train AutoGEO$_\\text{Mini}$, a cost-effective GEO model. Experiments on the standard GEO-Bench and two newly constructed benchmarks using real user queries demonstrate the effectiveness of AutoGEO in enhancing content traction while preserving search utility. Analyses confirm the learned rules' robustness and abilities to capture unique preferences in variant domains, and AutoGEO systems' ability to embed them in content optimization. The code is released at https://github.com/cxcscmu/AutoGEO.",
    "authors": [
      "Yujiang Wu",
      "Shanshan Zhong",
      "Yubin Kim",
      "Chenyan Xiong"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T14:10:26.000Z",
    "updatedAt": "2025-10-13T14:10:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11438v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11438v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11434v1",
    "arxivId": "2510.11434v1",
    "title": "Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated Content",
    "abstract": "Generative large language models (LLMs) have become central to everyday life, producing human-like text across diverse domains. A growing body of research investigates whether these models also exhibit personality- and demographic-like characteristics in their language. In this work, we introduce a novel, data-driven methodology for assessing LLM personality without relying on self-report questionnaires, applying instead automatic personality and gender classifiers to model replies on open-ended questions collected from Reddit. Comparing six widely used models to human-authored responses, we find that LLMs systematically express higher Agreeableness and lower Neuroticism, reflecting cooperative and stable conversational tendencies. Gendered language patterns in model text broadly resemble those of human writers, though with reduced variation, echoing prior findings on automated agents. We contribute a new dataset of human and model responses, along with large-scale comparative analyses, shedding new light on the topic of personality and demographic patterns of generative AI.",
    "authors": [
      "Dana Sotto Porat",
      "Ella Rabinovich"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T14:06:17.000Z",
    "updatedAt": "2025-10-13T14:06:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11434v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11434v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11423v1",
    "arxivId": "2510.11423v1",
    "title": "Beyond the Crowd: LLM-Augmented Community Notes for Governing Health Misinformation",
    "abstract": "Community Notes, the crowd-sourced misinformation governance system on X (formerly Twitter), enables users to flag misleading posts, attach contextual notes, and vote on their helpfulness. However, our analysis of 30.8K health-related notes reveals significant latency, with a median delay of 17.6 hours before the first note receives a helpfulness status. To improve responsiveness during real-world misinformation surges, we propose CrowdNotes+, a unified framework that leverages large language models (LLMs) to augment Community Notes for faster and more reliable health misinformation governance. CrowdNotes+ integrates two complementary modes: (1) evidence-grounded note augmentation and (2) utility-guided note automation, along with a hierarchical three-step evaluation that progressively assesses relevance, correctness, and helpfulness. We instantiate the framework through HealthNotes, a benchmark of 1.2K helpfulness-annotated health notes paired with a fine-tuned helpfulness judge. Experiments on fifteen LLMs reveal an overlooked loophole in current helpfulness evaluation, where stylistic fluency is mistaken for factual accuracy, and demonstrate that our hierarchical evaluation and LLM-augmented generation jointly enhance factual precision and evidence utility. These results point toward a hybrid human-AI governance model that improves both the rigor and timeliness of crowd-sourced fact-checking.",
    "authors": [
      "Jiaying Wu",
      "Zihang Fu",
      "Haonan Wang",
      "Fanxiao Li",
      "Min-Yen Kan"
    ],
    "categories": [
      "cs.SI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T13:57:23.000Z",
    "updatedAt": "2025-10-13T13:57:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11423v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11423v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11421v1",
    "arxivId": "2510.11421v1",
    "title": "A Modular AIoT Framework for Low-Latency Real-Time Robotic Teleoperation in Smart Cities",
    "abstract": "This paper presents an AI-driven IoT robotic teleoperation system designed for real-time remote manipulation and intelligent visual monitoring, tailored for smart city applications. The architecture integrates a Flutter-based cross-platform mobile interface with MQTT-based control signaling and WebRTC video streaming via the LiveKit framework. A YOLOv11-nano model is deployed for lightweight object detection, enabling real-time perception with annotated visual overlays delivered to the user interface. Control commands are transmitted via MQTT to an ESP8266-based actuator node, which coordinates multi-axis robotic arm motion through an Arduino Mega2560 controller. The backend infrastructure is hosted on DigitalOcean, ensuring scalable cloud orchestration and stable global communication. Latency evaluations conducted under both local and international VPN scenarios (including Hong Kong, Japan, and Belgium) demonstrate actuator response times as low as 0.2 seconds and total video latency under 1.2 seconds, even across high-latency networks. This low-latency dual-protocol design ensures responsive closed-loop interaction and robust performance in distributed environments. Unlike conventional teleoperation platforms, the proposed system emphasizes modular deployment, real-time AI sensing, and adaptable communication strategies, making it well-suited for smart city scenarios such as remote infrastructure inspection, public equipment servicing, and urban automation. Future enhancements will focus on edge-device deployment, adaptive routing, and integration with city-scale IoT networks to enhance resilience and scalability.",
    "authors": [
      "Shih-Chieh Sun",
      "Yun-Cheng Tsai"
    ],
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T13:56:15.000Z",
    "updatedAt": "2025-10-13T13:56:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11421v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11421v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11420v1",
    "arxivId": "2510.11420v1",
    "title": "HUGR: A Quantum-Classical Intermediate Representation",
    "abstract": "We introduce the Hierarchical Unified Graph Representation (HUGR): a novel graph based intermediate representation for mixed quantum-classical programs. HUGR's design features high expressivity and extensibility to capture the capabilities of near-term and forthcoming quantum computing devices, as well as new and evolving abstractions from novel quantum programming paradigms. The graph based structure is machine-friendly and supports powerful pattern matching based compilation techniques. Inspired by MLIR, HUGR's extensibility further allows compilation tooling to reason about programs at multiple levels of abstraction, lowering smoothly between them. Safety guarantees in the structure including strict, static typing and linear quantum types allow rapid development of compilation tooling without fear of program invalidation. A full specification of HUGR and reference implementation are open-source and available online.",
    "authors": [
      "Mark Koch",
      "Agustín Borgna",
      "Seyon Sivarajah",
      "Alan Lawrence",
      "Alec Edgington",
      "Douglas Wilson",
      "Craig Roy",
      "Luca Mondada",
      "Lukas Heidemann",
      "Ross Duncan"
    ],
    "categories": [
      "cs.PL",
      "quant-ph"
    ],
    "publishedAt": "2025-10-13T13:55:54.000Z",
    "updatedAt": "2025-10-13T13:55:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11420v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11420v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11419v1",
    "arxivId": "2510.11419v1",
    "title": "Representations",
    "abstract": "The formal analysis of automated systems is an important and growing industry. This activity routinely requires new verification frameworks to be developed to tackle new programming features, or new considerations (bugs of interest). Often, one particular property can prove frustrating to establish: completeness of the logic with respect to the semantics. In this paper, we try and make such developments easier, with a particular attention on completeness. Towards that aim, we propose a formal (meta-)model of software analysis systems (SAS), the eponymous Representations. This model requires few assumptions on the SAS being modeled, and as such is able to capture a large class of such systems. We then show how our approach can be fruitful, both to understand how existing completeness proofs can be structured, and to leverage this structure to build new systems and prove their completeness.",
    "authors": [
      "Paul Brunet"
    ],
    "categories": [
      "cs.LO"
    ],
    "publishedAt": "2025-10-13T13:55:19.000Z",
    "updatedAt": "2025-10-13T13:55:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11419v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11419v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11418v1",
    "arxivId": "2510.11418v1",
    "title": "Forward-Forward Autoencoder Architectures for Energy-Efficient Wireless Communications",
    "abstract": "The application of deep learning to the area of communications systems has been a growing field of interest in recent years. Forward-forward (FF) learning is an efficient alternative to the backpropagation (BP) algorithm, which is the typically used training procedure for neural networks. Among its several advantages, FF learning does not require the communication channel to be differentiable and does not rely on the global availability of partial derivatives, allowing for an energy-efficient implementation. In this work, we design end-to-end learned autoencoders using the FF algorithm and numerically evaluate their performance for the additive white Gaussian noise and Rayleigh block fading channels. We demonstrate their competitiveness with BP-trained systems in the case of joint coding and modulation, and in a scenario where a fixed, non-differentiable modulation stage is applied. Moreover, we provide further insights into the design principles of the FF network, its training convergence behavior, and significant memory and processing time savings compared to BP-based approaches.",
    "authors": [
      "Daniel Seifert",
      "Onur Günlü",
      "Rafael F. Schaefer"
    ],
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T13:54:50.000Z",
    "updatedAt": "2025-10-13T13:54:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11418v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11418v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11417v1",
    "arxivId": "2510.11417v1",
    "title": "Robust Ego-Exo Correspondence with Long-Term Memory",
    "abstract": "Establishing object-level correspondence between egocentric and exocentric views is essential for intelligent assistants to deliver precise and intuitive visual guidance. However, this task faces numerous challenges, including extreme viewpoint variations, occlusions, and the presence of small objects. Existing approaches usually borrow solutions from video object segmentation models, but still suffer from the aforementioned challenges. Recently, the Segment Anything Model 2 (SAM 2) has shown strong generalization capabilities and excellent performance in video object segmentation. Yet, when simply applied to the ego-exo correspondence (EEC) task, SAM 2 encounters severe difficulties due to ineffective ego-exo feature fusion and limited long-term memory capacity, especially for long videos. Addressing these problems, we propose a novel EEC framework based on SAM 2 with long-term memories by presenting a dual-memory architecture and an adaptive feature routing module inspired by Mixture-of-Experts (MoE). Compared to SAM 2, our approach features (i) a Memory-View MoE module which consists of a dual-branch routing mechanism to adaptively assign contribution weights to each expert feature along both channel and spatial dimensions, and (ii) a dual-memory bank system with a simple yet effective compression strategy to retain critical long-term information while eliminating redundancy. In the extensive experiments on the challenging EgoExo4D benchmark, our method, dubbed LM-EEC, achieves new state-of-the-art results and significantly outperforms existing methods and the SAM 2 baseline, showcasing its strong generalization across diverse scenarios. Our code and model are available at https://github.com/juneyeeHu/LM-EEC.",
    "authors": [
      "Yijun Hu",
      "Bing Fan",
      "Xin Gu",
      "Haiqing Ren",
      "Dongfang Liu",
      "Heng Fan",
      "Libo Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T13:54:12.000Z",
    "updatedAt": "2025-10-13T13:54:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11417v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11417v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11416v1",
    "arxivId": "2510.11416v1",
    "title": "Convergence Analysis of Galerkin Approximations for the Lindblad Master Equation",
    "abstract": "This paper analyzes the numerical approximation of the Lindblad master equation on infinite-dimensional Hilbert spaces. We employ a classical Galerkin approach for spatial discretization and investigate the convergence of the discretized solution to the exact solution. Using \\textit{a priori} estimates, we derive explicit convergence rates and demonstrate the effectiveness of our method through examples motivated by autonomous quantum error correction.",
    "authors": [
      "Rémi Robin",
      "Pierre Rouchon"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "quant-ph",
      "81Q05, 65J10, 47N50, 65M60"
    ],
    "publishedAt": "2025-10-13T13:53:56.000Z",
    "updatedAt": "2025-10-13T13:53:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11416v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11416v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11414v1",
    "arxivId": "2510.11414v1",
    "title": "Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model",
    "abstract": "The proliferation of autonomous AI agents within enterprise environments introduces a critical security challenge: managing access control for emergent, novel tasks for which no predefined policies exist. This paper introduces an advanced security framework that extends the Task-Based Access Control (TBAC) model by using a Large Language Model (LLM) as an autonomous, risk-aware judge. This model makes access control decisions not only based on an agent's intent but also by explicitly considering the inherent \\textbf{risk associated with target resources} and the LLM's own \\textbf{model uncertainty} in its decision-making process. When an agent proposes a novel task, the LLM judge synthesizes a just-in-time policy while also computing a composite risk score for the task and an uncertainty estimate for its own reasoning. High-risk or high-uncertainty requests trigger more stringent controls, such as requiring human approval. This dual consideration of external risk and internal confidence allows the model to enforce a more robust and adaptive version of the principle of least privilege, paving the way for safer and more trustworthy autonomous systems.",
    "authors": [
      "Charles Fleming",
      "Ashish Kundu",
      "Ramana Kompella"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T13:52:33.000Z",
    "updatedAt": "2025-10-13T13:52:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11414v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11414v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11413v1",
    "arxivId": "2510.11413v1",
    "title": "Trajectory control of a suspended load with non-stopping flying carriers",
    "abstract": "This paper presents the first closed-loop control framework for cooperative payload transportation with non-stopping flying carriers. Building upon grasp-matrix formulations and internal force redundancy, we propose a feedback wrench controller that actively regulates the payload's pose while an optimization layer dynamically shapes internal-force oscillations to guarantee persistent carrier motion. Preliminary experimental results on multirotor UAVs validate the model assumptions, and numerical simulations demonstrate that the method successfully prevents carrier stagnation, achieves accurate load tracking, and generates physically feasible trajectories with smooth velocity profiles. The proposed framework not only advances the state of the art but also offers a reliable, versatile solution for future real-world applications requiring load transportation by coordinated non-stopping flying carriers.",
    "authors": [
      "Sofia Girardello",
      "Giulia Michieletto",
      "Angelo Cenedese",
      "Antonio Franchi",
      "Chiara Gabellieri"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T13:52:16.000Z",
    "updatedAt": "2025-10-13T13:52:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11413v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11413v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11411v1",
    "arxivId": "2510.11411v1",
    "title": "DE-Sinc approximation for unilateral rapidly decreasing functions and its computational error bound",
    "abstract": "The Sinc approximation is known to be a highly efficient approximation formula for rapidly decreasing functions. For unilateral rapidly decreasing functions, which rapidly decrease as $x\\to\\infty$ but does not as $x\\to-\\infty$, an appropriate variable transformation makes the functions rapidly decreasing. As such a variable transformation, Stenger proposed $t = \\sinh(\\log(\\operatorname{arsinh}(\\exp x)))$, which enables the Sinc approximation to achieve root-exponential convergence. Recently, another variable transformation $t = 2\\sinh(\\log(\\log(1+\\exp x)))$ was proposed, which improved the convergence rate. Furthermore, its computational error bound was provided. However, the improvement is not significant because the convergence rate is still root-exponential order. To improve the convergence rate drastically, this study proposes a new transformation $t = 2\\sinh(\\log(\\log(1+\\exp(\\pi\\sinh x))))$, which is categorized as the double-exponential (DE) transformation. Furthermore, this study provides its computational error bound, which shows that the proposed approximation formula may achieve almost exponential convergence. Numerical experiments that confirm the theoretical result are also provided.",
    "authors": [
      "Tomoaki Okayama"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "65D05, 65D15"
    ],
    "publishedAt": "2025-10-13T13:49:21.000Z",
    "updatedAt": "2025-10-13T13:49:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11411v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11411v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11410v1",
    "arxivId": "2510.11410v1",
    "title": "Autonomous vehicles need social awareness to find optima in multi-agent reinforcement learning routing games",
    "abstract": "Previous work has shown that when multiple selfish Autonomous Vehicles (AVs) are introduced to future cities and start learning optimal routing strategies using Multi-Agent Reinforcement Learning (MARL), they may destabilize traffic systems, as they would require a significant amount of time to converge to the optimal solution, equivalent to years of real-world commuting. We demonstrate that moving beyond the selfish component in the reward significantly relieves this issue. If each AV, apart from minimizing its own travel time, aims to reduce its impact on the system, this will be beneficial not only for the system-wide performance but also for each individual player in this routing game. By introducing an intrinsic reward signal based on the marginal cost matrix, we significantly reduce training time and achieve convergence more reliably. Marginal cost quantifies the impact of each individual action (route-choice) on the system (total travel time). Including it as one of the components of the reward can reduce the degree of non-stationarity by aligning agents' objectives. Notably, the proposed counterfactual formulation preserves the system's equilibria and avoids oscillations. Our experiments show that training MARL algorithms with our novel reward formulation enables the agents to converge to the optimal solution, whereas the baseline algorithms fail to do so. We show these effects in both a toy network and the real-world network of Saint-Arnoult. Our results optimistically indicate that social awareness (i.e., including marginal costs in routing decisions) improves both the system-wide and individual performance of future urban systems with AVs.",
    "authors": [
      "Anastasia Psarou",
      "Łukasz Gorczyca",
      "Dominik Gaweł",
      "Rafał Kucharski"
    ],
    "categories": [
      "cs.MA"
    ],
    "publishedAt": "2025-10-13T13:48:38.000Z",
    "updatedAt": "2025-10-13T13:48:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11410v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11410v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11409v1",
    "arxivId": "2510.11409v1",
    "title": "Leveraging LLMs for Semi-Automatic Corpus Filtration in Systematic Literature Reviews",
    "abstract": "The creation of systematic literature reviews (SLR) is critical for analyzing the landscape of a research field and guiding future research directions. However, retrieving and filtering the literature corpus for an SLR is highly time-consuming and requires extensive manual effort, as keyword-based searches in digital libraries often return numerous irrelevant publications. In this work, we propose a pipeline leveraging multiple large language models (LLMs), classifying papers based on descriptive prompts and deciding jointly using a consensus scheme. The entire process is human-supervised and interactively controlled via our open-source visual analytics web interface, LLMSurver, which enables real-time inspection and modification of model outputs. We evaluate our approach using ground-truth data from a recent SLR comprising over 8,000 candidate papers, benchmarking both open and commercial state-of-the-art LLMs from mid-2024 and fall 2025. Results demonstrate that our pipeline significantly reduces manual effort while achieving lower error rates than single human annotators. Furthermore, modern open-source models prove sufficient for this task, making the method accessible and cost-effective. Overall, our work demonstrates how responsible human-AI collaboration can accelerate and enhance systematic literature reviews within academic workflows.",
    "authors": [
      "Lucas Joos",
      "Daniel A. Keim",
      "Maximilian T. Fischer"
    ],
    "categories": [
      "cs.LG",
      "cs.DL",
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T13:48:29.000Z",
    "updatedAt": "2025-10-13T13:48:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11409v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11409v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11408v1",
    "arxivId": "2510.11408v1",
    "title": "Valid Survey Simulations with Limited Human Data: The Roles of Prompting, Fine-Tuning, and Rectification",
    "abstract": "Surveys provide valuable insights into public opinion and behavior, but their execution is costly and slow. Large language models (LLMs) have been proposed as a scalable, low-cost substitute for human respondents, but their outputs are often biased and yield invalid estimates. We study the interplay between synthesis methods that use LLMs to generate survey responses and rectification methods that debias population estimates, and explore how human responses are best allocated between them. Using two panel surveys with questions on nutrition, politics, and economics, we find that synthesis alone introduces substantial bias (24-86%), whereas combining it with rectification reduces bias below 5% and increases effective sample size by up to 14%. Overall, we challenge the common practice of using all human responses for fine-tuning, showing that under a fixed budget, allocating most to rectification results in far more effective estimation.",
    "authors": [
      "Stefan Krsteski",
      "Giuseppe Russo",
      "Serina Chang",
      "Robert West",
      "Kristina Gligorić"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T13:48:07.000Z",
    "updatedAt": "2025-10-13T13:48:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11408v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11408v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11407v1",
    "arxivId": "2510.11407v1",
    "title": "KnowRL: Teaching Language Models to Know What They Know",
    "abstract": "Truly reliable AI requires more than simply scaling up knowledge; it demands the ability to know what it knows and when it does not. Yet recent research shows that even the best LLMs misjudge their own competence in more than one in five cases, making any response born of such internal uncertainty impossible to fully trust. Inspired by self-improvement reinforcement learning techniques that require minimal data, we present a simple but powerful framework KnowRL that strengthens a model's internal understanding of its own feasibility boundaries, enabling safer and more responsible behaviour. Our framework combines two components: (i) introspection, where the model generates and classifies tasks it judges feasible or infeasible, and (ii) consensus-based rewarding, where stability of self-knowledge assessment is reinforced through internal agreement. By using internally generated data, this design strengthens consistency in self-knowledge and entirely avoids costly external supervision. In experiments on LLaMA-3.1-8B and Qwen-2.5-7B, KnowRL steadily improved self-knowledge, validated by both intrinsic self-consistency and extrinsic benchmarking. With nothing more than a small seed set and no external supervision, our method drove gains as high as 28% in accuracy and 12% in F1, outperforming baselines in just a few iterations. Our framework essentially unlocks the untapped capacity of LLMs to self-improve their knowledge awareness, opening the door to reliable, more accountable AI and safer deployment in critical applications. Owing to its simplicity and independence from external effort, we encourage applying this reliability-enhancing process to all future models.",
    "authors": [
      "Sahil Kale",
      "Devendra Singh Dhami"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T13:47:14.000Z",
    "updatedAt": "2025-10-13T13:47:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11407v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11407v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11405v1",
    "arxivId": "2510.11405v1",
    "title": "Robust Recovery and Control of Cyber-physical Discrete Event Systems under Actuator Attacks",
    "abstract": "Critical real-world applications strongly rely on Cyber-physical systems (CPS), but their dependence on communication networks introduces significant security risks, as attackers can exploit vulnerabilities to compromise their integrity and availability. This work explores the topic of cybersecurity in the context of CPS modeled as discrete event systems (DES), focusing on recovery strategies following the detection of cyberattacks. Specifically, we address actuator enablement attacks and propose a method that preserves the system's full valid behavior under normal conditions. Upon detecting an attack, our proposed solution aims to guide the system toward a restricted yet robust behavior, ensuring operational continuity and resilience. Additionally, we introduce a property termed AE-robust recoverability, which characterizes the necessary and sufficient conditions for recovering a system from attacks while preventing further vulnerabilities. Finally, we showcase the proposed solution through a case study based on a manufacturing system.",
    "authors": [
      "Samuel Oliveira",
      "Mostafa Tavakkoli Anbarani",
      "Gregory Beal",
      "Ilya Kovalenko",
      "Marcelo Teixeira",
      "André B. Leal",
      "Rômulo Meira-Góes"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T13:44:45.000Z",
    "updatedAt": "2025-10-13T13:44:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11405v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11405v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11402v1",
    "arxivId": "2510.11402v1",
    "title": "On Inherited Popularity Bias in Cold-Start Item Recommendation",
    "abstract": "Collaborative filtering (CF) recommender systems struggle with making predictions on unseen, or 'cold', items. Systems designed to address this challenge are often trained with supervision from warm CF models in order to leverage collaborative and content information from the available interaction data. However, since they learn to replicate the behavior of CF methods, cold-start models may therefore also learn to imitate their predictive biases. In this paper, we show that cold-start systems can inherit popularity bias, a common cause of recommender system unfairness arising when CF models overfit to more popular items, thereby maximizing user-oriented accuracy but neglecting rarer items. We demonstrate that cold-start recommenders not only mirror the popularity biases of warm models, but are in fact affected more severely: because they cannot infer popularity from interaction data, they instead attempt to estimate it based solely on content features. This leads to significant over-prediction of certain cold items with similar content to popular warm items, even if their ground truth popularity is very low. Through experiments on three multimedia datasets, we analyze the impact of this behavior on three generative cold-start methods. We then describe a simple post-processing bias mitigation method that, by using embedding magnitude as a proxy for predicted popularity, can produce more balanced recommendations with limited harm to user-oriented cold-start accuracy.",
    "authors": [
      "Gregor Meehan",
      "Johan Pauwels"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T13:44:13.000Z",
    "updatedAt": "2025-10-13T13:44:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11402v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11402v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11401v1",
    "arxivId": "2510.11401v1",
    "title": "Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots",
    "abstract": "This paper proposes a novel framework for humanoid robots to execute inspection tasks with high efficiency and millimeter-level precision. The approach combines hierarchical planning, time-optimal standing position generation, and integrated \\ac{mpc} to achieve high speed and precision. A hierarchical planning strategy, leveraging \\ac{ik} and \\ac{mip}, reduces computational complexity by decoupling the high-dimensional planning problem. A novel MIP formulation optimizes standing position selection and trajectory length, minimizing task completion time. Furthermore, an MPC system with simplified kinematics and single-step position correction ensures millimeter-level end-effector tracking accuracy. Validated through simulations and experiments on the Kuavo 4Pro humanoid platform, the framework demonstrates low time cost and a high success rate in multi-location tasks, enabling efficient and precise execution of complex industrial operations.",
    "authors": [
      "Jiayang Wu",
      "Jiongye Li",
      "Shibowen Zhang",
      "Zhicheng He",
      "Zaijin Wang",
      "Xiaokun Leng",
      "Hangxin Liu",
      "Jingwen Zhang",
      "Jiayi Wang",
      "Song-Chun Zhu",
      "Yao Su"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T13:44:08.000Z",
    "updatedAt": "2025-10-13T13:44:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11401v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11401v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11400v1",
    "arxivId": "2510.11400v1",
    "title": "FedHybrid: Breaking the Memory Wall of Federated Learning via Hybrid Tensor Management",
    "abstract": "Federated Learning (FL) emerges as a new learning paradigm that enables multiple devices to collaboratively train a shared model while preserving data privacy. However, one fundamental and prevailing challenge that hinders the deployment of FL on mobile devices is the memory limitation. This paper proposes \\textit{FedHybrid}, a novel framework that effectively reduces the memory footprint during the training process while guaranteeing the model accuracy and the overall training progress. Specifically, \\textit{FedHybrid} first selects the participating devices for each training round by jointly evaluating their memory budget, computing capability, and data diversity. After that, it judiciously analyzes the computational graph and generates an execution plan for each selected client in order to meet the corresponding memory budget while minimizing the training delay through employing a hybrid of recomputation and compression techniques according to the characteristic of each tensor. During the local training process, \\textit{FedHybrid} carries out the execution plan with a well-designed activation compression technique to effectively achieve memory reduction with minimum accuracy loss. We conduct extensive experiments to evaluate \\textit{FedHybrid} on both simulation and off-the-shelf mobile devices. The experiment results demonstrate that \\textit{FedHybrid} achieves up to a 39.1\\% increase in model accuracy and a 15.5$\\times$ reduction in wall clock time under various memory budgets compared with the baselines.",
    "authors": [
      "Kahou Tam",
      "Chunlin Tian",
      "Li Li",
      "Haikai Zhao",
      "ChengZhong Xu"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T13:43:55.000Z",
    "updatedAt": "2025-10-13T13:43:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11400v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11400v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11398v1",
    "arxivId": "2510.11398v1",
    "title": "Living Off the LLM: How LLMs Will Change Adversary Tactics",
    "abstract": "In living off the land attacks, malicious actors use legitimate tools and processes already present on a system to avoid detection. In this paper, we explore how the on-device LLMs of the future will become a security concern as threat actors integrate LLMs into their living off the land attack pipeline and ways the security community may mitigate this threat.",
    "authors": [
      "Sean Oesch",
      "Jack Hutchins",
      "Luke Koch",
      "Kevin Kurian"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T13:41:27.000Z",
    "updatedAt": "2025-10-13T13:41:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11398v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11398v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11394v1",
    "arxivId": "2510.11394v1",
    "title": "VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for enhancing the responses of large language models (LLMs) with external knowledge sources. Despite the impressive performance in complex question-answering tasks, RAG still struggles with hallucinations. Attributing RAG-generated content through in-line citations has demonstrated potential in reducing hallucinations and facilitating human verification. Existing citation generation methods primarily rely on either fine-tuning the generator or employing post-processing approaches for citation matching. However, the former approach demands substantial annotated data and computational resources, while the latter often encounters difficulties in managing multiple citations and frequently produces suboptimal results. In this paper, we introduce a novel framework, called VeriCite, designed to rigorously validate supporting evidence and enhance answer attribution. Specifically, VeriCite breaks down into a three-stage generation: 1) The initial answer generation first generates a response based on all available contexts and has its claims verified through the NLI model; 2) the supporting evidence selection assesses the utility of each document and extracts useful supporting evidences; 3) the final answer refinement integrates the initial response and collected evidences to produce the final, refined answer.We conduct experiments across five open-source LLMs and four datasets, demonstrating that VeriCite can significantly improve citation quality while maintaining the correctness of the answers.",
    "authors": [
      "Haosheng Qian",
      "Yixing Fan",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Qi Chen",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T13:38:54.000Z",
    "updatedAt": "2025-10-13T13:38:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11394v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11394v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11393v1",
    "arxivId": "2510.11393v1",
    "title": "Robust Closed-Form Control for MIMO Nonlinear Systems under Conflicting Time-Varying Hard and Soft Constraints",
    "abstract": "This paper introduces a novel robust closed-form control law to handle time-varying hard and soft constraints in uncertain high-relative-degree nonlinear MIMO systems. These constraints represent spatiotemporal specifications in mechanical systems' operational space, with hard constraints ensuring safety-critical requirements and soft constraints encoding performance or task objectives. Initially, all constraints are consolidated into two separate scalar time-varying hard and soft constraint functions, whose positive level sets define feasible regions. A closed-form control law is developed to enforce these constraints using appropriately designed reciprocal barriers and nonlinear transformation functions. When conflicts between hard and soft constraints arise, the control law prioritizes hard constraints by virtually relaxing soft constraints via a dynamic relaxation law. Notably, the proposed control law maintains low complexity by avoiding approximation schemes for coping with system uncertainties. Simulation results confirm the effectiveness of the proposed method.",
    "authors": [
      "Farhad Mehdifar",
      "Charalampos P. Bechlioulis",
      "Dimos V. Dimarogonas"
    ],
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.DS"
    ],
    "publishedAt": "2025-10-13T13:38:30.000Z",
    "updatedAt": "2025-10-13T13:38:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11393v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11393v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11391v1",
    "arxivId": "2510.11391v1",
    "title": "DocReward: A Document Reward Model for Structuring and Stylizing",
    "abstract": "Recent advances in agentic workflows have enabled the automation of tasks such as professional document generation. However, they primarily focus on textual quality, neglecting visual structure and style, which are crucial for readability and engagement. This gap arises mainly from the absence of suitable reward models to guide agentic workflows toward producing documents with stronger structural and stylistic quality. To address this, we propose DocReward, a document reward model that evaluates documents based on their structure and style. We construct a multi-domain dataset DocPair of 117K paired documents, covering 32 domains and 267 document types, each including a high- and low-professionalism document with identical content but different structure and style. This enables the model to evaluate professionalism comprehensively, and in a textual-quality-agnostic way. DocReward is trained using the Bradley-Terry loss to score documents, penalizing predictions that contradict the annotated ranking. To assess the performance of reward models, we create a test dataset containing document bundles ranked by well-educated human evaluators. Notably, DocReward outperforms GPT-4o and GPT-5 in accuracy by 30.6 and 19.4 percentage points, respectively, demonstrating its superiority over baselines. In an extrinsic evaluation of document generation, DocReward achieves a significantly higher win rate of 60.8%, compared to GPT-5's 37.7% win rate, demonstrating its utility in guiding generation agents toward producing human-preferred documents.",
    "authors": [
      "Junpeng Liu",
      "Yuzhong Zhao",
      "Bowen Cao",
      "Jiayu Ding",
      "Yilin Jia",
      "Tengchao Lv",
      "Yupan Huang",
      "Shaohan Huang",
      "Nan Yang",
      "Li Dong",
      "Lei Cui",
      "Tao Ge",
      "Xun Wang",
      "Huitian Jiao",
      "Sun Mao",
      "FNU Kartik",
      "Si-Qing Chen",
      "Wai Lam",
      "Furu Wei"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T13:36:32.000Z",
    "updatedAt": "2025-10-13T13:36:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11391v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11391v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11390v1",
    "arxivId": "2510.11390v1",
    "title": "Medical Interpretability and Knowledge Maps of Large Language Models",
    "abstract": "We present a systematic study of medical-domain interpretability in Large Language Models (LLMs). We study how the LLMs both represent and process medical knowledge through four different interpretability techniques: (1) UMAP projections of intermediate activations, (2) gradient-based saliency with respect to the model weights, (3) layer lesioning/removal and (4) activation patching. We present knowledge maps of five LLMs which show, at a coarse-resolution, where knowledge about patient's ages, medical symptoms, diseases and drugs is stored in the models. In particular for Llama3.3-70B, we find that most medical knowledge is processed in the first half of the model's layers. In addition, we find several interesting phenomena: (i) age is often encoded in a non-linear and sometimes discontinuous manner at intermediate layers in the models, (ii) the disease progression representation is non-monotonic and circular at certain layers of the model, (iii) in Llama3.3-70B, drugs cluster better by medical specialty rather than mechanism of action, especially for Llama3.3-70B and (iv) Gemma3-27B and MedGemma-27B have activations that collapse at intermediate layers but recover by the final layers. These results can guide future research on fine-tuning, un-learning or de-biasing LLMs for medical tasks by suggesting at which layers in the model these techniques should be applied.",
    "authors": [
      "Razvan Marinescu",
      "Victoria-Elisabeth Gruber",
      "Diego Fajardo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T13:34:05.000Z",
    "updatedAt": "2025-10-13T13:34:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11390v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11390v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11389v1",
    "arxivId": "2510.11389v1",
    "title": "Beyond Survival: Evaluating LLMs in Social Deduction Games with Human-Aligned Strategies",
    "abstract": "Social deduction games like Werewolf combine language, reasoning, and strategy, providing a testbed for studying natural language and social intelligence. However, most studies reduce the game to LLM-based self-play, yielding templated utterances and anecdotal cases that overlook the richness of social gameplay. Evaluation further relies on coarse metrics such as survival time or subjective scoring due to the lack of quality reference data. To address these gaps, we curate a high-quality, human-verified multimodal Werewolf dataset containing over 100 hours of video, 32.4M utterance tokens, and 15 rule variants. Based on this dataset, we propose a novel strategy-alignment evaluation that leverages the winning faction's strategies as ground truth in two stages: 1) Speech evaluation, formulated as multiple-choice-style tasks that assess whether the model can adopt appropriate stances across five dimensions of social ability; and 2) Decision evaluation, which assesses the model's voting choices and opponent-role inferences. This framework enables a fine-grained evaluation of models' linguistic and reasoning capabilities, while capturing their ability to generate strategically coherent gameplay. Our experiments show that state-of-the-art LLMs show diverse performance, with roughly half remain below 0.50, revealing clear gaps in deception and counterfactual reasoning. We hope our dataset further inspires research on language, reasoning, and strategy in multi-agent interaction.",
    "authors": [
      "Zirui Song",
      "Yuan Huang",
      "Junchang Liu",
      "Haozhe Luo",
      "Chenxi Wang",
      "Lang Gao",
      "Zixiang Xu",
      "Mingfei Han",
      "Xiaojun Chang",
      "Xiuying Chen"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T13:33:30.000Z",
    "updatedAt": "2025-10-13T13:33:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11389v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11389v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11388v1",
    "arxivId": "2510.11388v1",
    "title": "Data-Driven Estimation of Quadrotor Motor Efficiency via Residual Minimization",
    "abstract": "A data-driven framework is proposed for online estimation of quadrotor motor efficiency via residual minimization. The problem is formulated as a constrained nonlinear optimization that minimizes trajectory residuals between measured flight data and predictions generated by a quadrotor dynamics model. A sliding-window strategy enables online estimation, and the optimization is efficiently solved using an iteratively reweighted least squares (IRLS) scheme combined with a primal-dual interior-point method, with inequality constraints enforced through a logarithmic barrier function. Robust z-score weighting is employed to reject outliers, which is particularly effective in motor clipping scenarios where the proposed estimator exhibits smaller spikes than an EKF baseline. Compared to traditional filter-based approaches, the batch-mode formulation offers greater flexibility by selectively incorporating informative data segments. This structure is well-suited for onboard implementation, particularly for applications such as fault detection and isolation (FDI), health monitoring, and predictive maintenance in aerial robotic systems. Simulation results under various degradation scenarios demonstrate the accuracy and robustness of the proposed estimator.",
    "authors": [
      "Sheng-Wen Cheng",
      "Teng-Hu Cheng"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T13:31:27.000Z",
    "updatedAt": "2025-10-13T13:31:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11388v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11388v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11387v1",
    "arxivId": "2510.11387v1",
    "title": "MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference",
    "abstract": "Modeling reflections from 2D images is essential for photorealistic rendering and novel view synthesis. Recent approaches enhance Gaussian primitives with reflection-related material attributes to enable physically based rendering (PBR) with Gaussian Splatting. However, the material inference often lacks sufficient constraints, especially under limited environment modeling, resulting in illumination aliasing and reduced generalization. In this work, we revisit the problem from a multi-view perspective and show that multi-view consistent material inference with more physically-based environment modeling is key to learning accurate reflections with Gaussian Splatting. To this end, we enforce 2D Gaussians to produce multi-view consistent material maps during deferred shading. We also track photometric variations across views to identify highly reflective regions, which serve as strong priors for reflection strength terms. To handle indirect illumination caused by inter-object occlusions, we further introduce an environment modeling strategy through ray tracing with 2DGS, enabling photorealistic rendering of indirect radiance. Experiments on widely used benchmarks show that our method faithfully recovers both illumination and geometry, achieving state-of-the-art rendering quality in novel views synthesis.",
    "authors": [
      "Wenyuan Zhang",
      "Jimin Tang",
      "Weiqi Zhang",
      "Yi Fang",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T13:29:20.000Z",
    "updatedAt": "2025-10-13T13:29:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11387v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11387v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11386v1",
    "arxivId": "2510.11386v1",
    "title": "High-Order Quarter-Wave Plate Optimization for Linear Birefringence Suppression in Reflective FOCS",
    "abstract": "Fiber optic current sensors (FOCS) are widely adopted in modern power grids due to high sensitivity, excellent insulation, and strong immunity to electromagnetic interference. This prominence necessitates precise investigation into their error sources and corresponding optimization. This study examines reflective FOCS based on the Faraday effect. A theoretical model is established to simulate phase error caused by linear birefringence from the quarter-wave plate. Conventional methods using circular birefringence are analyzed, revealing inherent limitations. Innovatively, a compensation strategy employing high-order quarter-wave plates is proposed to effectively eliminate linear birefringence effects. This approach significantly enhances the accuracy and practicality of FOCS in precision metrology.",
    "authors": [
      "Yuechen Liu",
      "Boqi Meng"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T13:28:21.000Z",
    "updatedAt": "2025-10-13T13:28:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11386v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11386v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11380v1",
    "arxivId": "2510.11380v1",
    "title": "AI-Driven anemia diagnosis: A review of advanced models and techniques",
    "abstract": "Anemia, a condition marked by insufficient levels of red blood cells or hemoglobin, remains a widespread health issue affecting millions of individuals globally. Accurate and timely diagnosis is essential for effective management and treatment of anemia. In recent years, there has been a growing interest in the use of artificial intelligence techniques, i.e., machine learning (ML) and deep learning (DL) for the detection, classification, and diagnosis of anemia. This paper provides a systematic review of the recent advancements in this field, with a focus on various models applied to anemia detection. The review also compares these models based on several performance metrics, including accuracy, sensitivity, specificity, and precision. By analyzing these metrics, the paper evaluates the strengths and limitation of discussed models in detecting and classifying anemia, emphasizing the importance of addressing these factors to improve diagnostic accuracy.",
    "authors": [
      "Abdullah Al Mahmud",
      "Prangon Chowdhury",
      "Mohammed Borhan Uddin",
      "Khaled Eabne Delowar",
      "Tausifur Rahman Talha",
      "Bijoy Dewanjee"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T13:22:45.000Z",
    "updatedAt": "2025-10-13T13:22:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11380v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11380v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11379v1",
    "arxivId": "2510.11379v1",
    "title": "Forward and backward error bounds for a mixed precision preconditioned conjugate gradient algorithm",
    "abstract": "The preconditioned conjugate gradient (PCG) algorithm is one of the most popular algorithms for solving large-scale linear systems Ax = b, where A is a symmetric positive definite matrix. Rather than computing residuals directly, it updates the residual vectors recursively. Current analyses of the conjugate gradient (CG) algorithm in finite precision typically assume that the norm of the recursively updated residual goes orders of magnitude below the machine precision, focusing mainly on bounding the residual gap thereafter. This work introduces a framework for the PCG algorithm and provides rigorous proofs that the relative backward and forward errors of the computed results of PCG can reach the levels O(u) and O(u)\\kappa(A)^{1/2}, respectively, after a sufficient number of iterations without relying on an assumption concerning the norm of the recursively updated residual, where u represents the unit roundoff and \\kappa(A) is the condition number of A. Our PCG framework further shows that applying preconditioners in low precision does not compromise the accuracy of the final results, provided that reasonable conditions are satisfied. Our theoretical results are illustrated through a set of numerical experiments.",
    "authors": [
      "Thomas Bake",
      "Erin Carson",
      "Yuxin Ma"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "65F10, 65F08, 65G50, 65Y20"
    ],
    "publishedAt": "2025-10-13T13:21:02.000Z",
    "updatedAt": "2025-10-13T13:21:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11379v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11379v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11374v1",
    "arxivId": "2510.11374v1",
    "title": "CIRSense: Rethinking WiFi Sensing with Channel Impulse Response",
    "abstract": "WiFi sensing based on channel state information (CSI) collected from commodity WiFi devices has shown great potential across a wide range of applications, including vital sign monitoring and indoor localization. Existing WiFi sensing approaches typically estimate motion information directly from CSI. However, they often overlook the inherent advantages of channel impulse response (CIR), a delay-domain representation that enables more intuitive and principled motion sensing by naturally concentrating motion energy and separating multipath components. Motivated by this, we revisit WiFi sensing and introduce CIRSense, a new framework that enhances the performance and interpretability of WiFi sensing with CIR. CIRSense is built upon a new motion model that characterizes fractional delay effects, a fundamental challenge in CIR-based sensing. This theoretical model underpins technical advances for the three challenges in WiFi sensing: hardware distortion compensation, high-resolution distance estimation, and subcarrier aggregation for extended range sensing. CIRSense, operating with a 160 MHz channel bandwidth, demonstrates versatile sensing capabilities through its dual-mode design, achieving a mean error of approximately 0.25 bpm in respiration monitoring and 0.09 m in distance estimation. Comprehensive evaluations across residential spaces, far-range scenarios, and multi-target settings demonstrate CIRSense's superior performance over state-of-the-art CSI-based baselines. Notably, at a challenging sensing distance of 20 m, CIRSense achieves at least 3x higher average accuracy with more than 4.5x higher computational efficiency.",
    "authors": [
      "Ruiqi Kong",
      "He Chen"
    ],
    "categories": [
      "eess.SP",
      "cs.NI"
    ],
    "publishedAt": "2025-10-13T13:13:24.000Z",
    "updatedAt": "2025-10-13T13:13:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11374v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11374v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11372v1",
    "arxivId": "2510.11372v1",
    "title": "Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning",
    "abstract": "Although large language models excel across many tasks, they can memorise training data and thereby expose private or copyrighted text. Most defences target the pre-training stage, leaving memorisation during fine-tuning, especially for domain adaptation and instruction tuning, poorly understood. We fine-tune Pythia, Llama3, and Mistral models spanning 1.4B-70B parameters on common evaluation datasets and track verbatim memorisation throughout training. We find that memorisation increases dramatically in the first few epochs, often significantly before either validation perplexity or evaluation performance is optimised. We use a simple but effective n-gram memorisation score which reliably precedes verbatim memorisation; using it as an early-stopping criterion mitigates memorisation with minimal performance loss. Further, we introduce an n-gram-aware loss regulariser and show that it reduces memorisation across all model families tested by up to 40% while minimising evaluation performance trade-offs when compared to an existing memorisation mitigation strategy. These results yield practical, scalable insights into memorisation dynamics during language model fine-tuning.",
    "authors": [
      "Dean L. Slack",
      "Noura Al Moubayed"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T13:12:46.000Z",
    "updatedAt": "2025-10-13T13:12:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11372v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11372v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11370v1",
    "arxivId": "2510.11370v1",
    "title": "Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers",
    "abstract": "Reinforcement learning (RL) has emerged as a crucial approach for enhancing the capabilities of large language models. However, in Mixture-of-Experts (MoE) models, the routing mechanism often introduces instability, even leading to catastrophic RL training collapse. We analyze the training-inference consistency of MoE models and identify a notable discrepancy in routing behaviors between the two phases. Moreover, even under identical conditions, the routing framework can yield divergent expert selections across repeated forward passes. To address this foundational inconsistency, we propose Rollout Routing Replay (R3), a method that records routing distributions from the inference engine and replays them during training. R3 significantly reduces training-inference policy KL divergence and mitigates extreme discrepancies without compromising training speed. Extensive experiments on various settings confirm that R3 succeeds in stabilizing RL training, preventing collapse and outperforming methods such as GSPO and TIS. We believe this work can offer a new solution for stabilizing RL in MoE models.",
    "authors": [
      "Wenhan Ma",
      "Hailin Zhang",
      "Liang Zhao",
      "Yifan Song",
      "Yudong Wang",
      "Zhifang Sui",
      "Fuli Luo"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T13:11:27.000Z",
    "updatedAt": "2025-10-13T13:11:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11370v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11370v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11369v1",
    "arxivId": "2510.11369v1",
    "title": "Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment",
    "abstract": "Reasoning-based image quality assessment (IQA) models trained through reinforcement learning (RL) exhibit exceptional generalization, yet the underlying mechanisms and critical factors driving this capability remain underexplored in current research. Moreover, despite their superior performance, these models incur inference energy usage and latency orders of magnitude higher than their earlier counterparts, restricting their deployment in specific scenarios. Through extensive experiments, this paper verifies and elaborates that through RL training, MLLMs leverage their reasoning capability to convert redundant visual representations into compact, cross-domain aligned text representations. This conversion is precisely the source of the generalization exhibited by these reasoning-based IQA models. Building on this fundamental insight, we propose a novel algorithm, RALI, which employs contrastive learning to directly align images with these generalizable text representations learned by RL. This approach eliminates the reliance on reasoning processes and even obviates the need to load an LLM. For the quality scoring task, this framework achieves generalization performance comparable to reasoning-based models while requiring less than 5% of their model parameters and inference time.",
    "authors": [
      "Shijie Zhao",
      "Xuanyu Zhang",
      "Weiqi Li",
      "Junlin Li",
      "Li Zhang",
      "Tianfan Xue",
      "Jian Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T13:11:08.000Z",
    "updatedAt": "2025-10-13T13:11:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11369v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11369v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11368v1",
    "arxivId": "2510.11368v1",
    "title": "An $O(n\\log n)$ Algorithm for Single-Item Capacitated Lot Sizing with a One-Breakpoint All-Units Discount and Non-Increasing Prices",
    "abstract": "This paper addresses the single-item capacitated lot sizing problem with a 1-breakpoint all-units quantity discount in a monotonic setting where the purchase prices are non-increasing over the planning horizon. For this case, we establish several novel properties of the optimal solution and develop a hybrid dynamic programming approach that maintains a compact representation of the solution space by storing only essential information about the states and using linear equations for intermediate values. Our algorithm runs in \\(O(n\\log n)\\) time, where \\(n\\) denotes the number of periods. Our result is an improvement over the previous state-of-the-art algorithm, which has an \\(O(n^2)\\) time complexity.",
    "authors": [
      "Kleitos Papadopoulos"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-13T13:10:23.000Z",
    "updatedAt": "2025-10-13T13:10:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11368v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11368v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11361v1",
    "arxivId": "2510.11361v1",
    "title": "A protocol to reduce worst-case latency in deflection-based on-chip networks",
    "abstract": "We present a novel protocol that reduces worst-case packet latency in deflection-based on-chip interconnect networks. It enforces the deflection of the header of a packet but not its payload, resulting in a reduction in overall network traffic and, more importantly, worst-case packet latency due to decreased pre-injection latency.",
    "authors": [
      "Leandro Soares Indrusiak"
    ],
    "categories": [
      "cs.NI",
      "cs.PF"
    ],
    "publishedAt": "2025-10-13T13:02:53.000Z",
    "updatedAt": "2025-10-13T13:02:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11361v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11361v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11360v1",
    "arxivId": "2510.11360v1",
    "title": "A mathematical model for pricing perishable goods for quick-commerce applications",
    "abstract": "Quick commerce (q-commerce) is one of the fastest growing sectors in India. It provides informal employment to approximately 4,50,000 workers, and it is estimated to become a USD 200 Billion industry by 2026. A significant portion of this industry deals with perishable goods. (e.g. milk, dosa batter etc.) These are food items which are consumed relatively fresh by the consumers and therefore their order volume is high and repetitive even when the average basket size is relatively small. The fundamental challenge for the retailer is that, increasing selling price would hamper sales and would lead to unsold inventory. On the other hand setting a price less, would lead to forgoing of potential revenue. This paper attempts to propose a mathematical model which formalizes this dilemma. The problem statement is not only important for improving the unit economics of the perennially loss making quick commerce firms, but also would lead to a trickle-down effect in improving the conditions of the gig workers as observed in [4]. The sections below describe the mathematical formulation. The results from the simulation would be published in a follow-up study.",
    "authors": [
      "Milon Bhattacharya"
    ],
    "categories": [
      "cs.CE",
      "econ.EM"
    ],
    "publishedAt": "2025-10-13T12:59:58.000Z",
    "updatedAt": "2025-10-13T12:59:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11360v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11360v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11358v1",
    "arxivId": "2510.11358v1",
    "title": "LLM-Specific Utility: A New Perspective for Retrieval-Augmented Generation",
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge. While traditional retrieval focuses on relevance, RAG's effectiveness depends on the utility of retrieved passages, i.e., the usefulness in facilitating the generation of an accurate and comprehensive answer. Existing studies often treat utility as a generic attribute, ignoring the fact that different LLMs may benefit differently from the same passage due to variations in internal knowledge and comprehension ability. In this work, we introduce and systematically investigate the notion of LLM-specific utility. Through large-scale experiments across multiple datasets and LLMs, we demonstrate that human-annotated passages are not optimal for LLMs and that ground-truth utilitarian passages are not transferable across different LLMs. These findings highlight the necessity of adopting the LLM-specific utility in RAG research. Our findings indicate that some human-annotated passages are not ground-truth utilitarian passages for specific LLMs, partially due to the varying readability of queries and passages for LLMs, a tendency for which perplexity is a key metric. Based on these findings, we propose a benchmarking procedure for LLM-specific utility judgments. We evaluate existing utility judgment methods on six datasets and find that while verbalized methods using pseudo-answers perform robustly, LLMs struggle to assess utility effectively-failing to reject all passages for known queries and to select truly useful ones for unknown queries.",
    "authors": [
      "Hengran Zhang",
      "Keping Bi",
      "Jiafeng Guo",
      "Jiaming Zhang",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T12:57:45.000Z",
    "updatedAt": "2025-10-13T12:57:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11358v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11358v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11354v1",
    "arxivId": "2510.11354v1",
    "title": "Understanding the Generalization of Stochastic Gradient Adam in Learning Neural Networks",
    "abstract": "Adam is a popular and widely used adaptive gradient method in deep learning, which has also received tremendous focus in theoretical research. However, most existing theoretical work primarily analyzes its full-batch version, which differs fundamentally from the stochastic variant used in practice. Unlike SGD, stochastic Adam does not converge to its full-batch counterpart even with infinitesimal learning rates. We present the first theoretical characterization of how batch size affects Adam's generalization, analyzing two-layer over-parameterized CNNs on image data. Our results reveal that while both Adam and AdamW with proper weight decay $\\lambda$ converge to poor test error solutions, their mini-batch variants can achieve near-zero test error. We further prove Adam has a strictly smaller effective weight decay bound than AdamW, theoretically explaining why Adam requires more sensitive $\\lambda$ tuning. Extensive experiments validate our findings, demonstrating the critical role of batch size and weight decay in Adam's generalization performance.",
    "authors": [
      "Xuan Tang",
      "Han Zhang",
      "Yuan Cao",
      "Difan Zou"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T12:48:22.000Z",
    "updatedAt": "2025-10-13T12:48:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11354v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11354v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11347v1",
    "arxivId": "2510.11347v1",
    "title": "Multi-View Graph Feature Propagation for Privacy Preservation and Feature Sparsity",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in node classification tasks over relational data, yet their effectiveness often depends on the availability of complete node features. In many real-world scenarios, however, feature matrices are highly sparse or contain sensitive information, leading to degraded performance and increased privacy risks. Furthermore, direct exposure of information can result in unintended data leakage, enabling adversaries to infer sensitive information. To address these challenges, we propose a novel Multi-view Feature Propagation (MFP) framework that enhances node classification under feature sparsity while promoting privacy preservation. MFP extends traditional Feature Propagation (FP) by dividing the available features into multiple Gaussian-noised views, each propagating information independently through the graph topology. The aggregated representations yield expressive and robust node embeddings. This framework is novel in two respects: it introduces a mechanism that improves robustness under extreme sparsity, and it provides a principled way to balance utility with privacy. Extensive experiments conducted on graph datasets demonstrate that MFP outperforms state-of-the-art baselines in node classification while substantially reducing privacy leakage. Moreover, our analysis demonstrates that propagated outputs serve as alternative imputations rather than reconstructions of the original features, preserving utility without compromising privacy. A comprehensive sensitivity analysis further confirms the stability and practical applicability of MFP across diverse scenarios. Overall, MFP provides an effective and privacy-aware framework for graph learning in domains characterized by missing or sensitive features.",
    "authors": [
      "Etzion Harari",
      "Moshe Unger"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T12:42:00.000Z",
    "updatedAt": "2025-10-13T12:42:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11347v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11347v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11346v1",
    "arxivId": "2510.11346v1",
    "title": "Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation",
    "abstract": "Generative Models are a valuable tool for the controlled creation of high-quality image data. Controlled diffusion models like the ControlNet have allowed the creation of labeled distributions. Such synthetic datasets can augment the original training distribution when discriminative models, like semantic segmentation, are trained. However, this augmentation effect is limited since ControlNets tend to reproduce the original training distribution. This work introduces a method to utilize data from unlabeled domains to train ControlNets by introducing the concept of uncertainty into the control mechanism. The uncertainty indicates that a given image was not part of the training distribution of a downstream task, e.g., segmentation. Thus, two types of control are engaged in the final network: an uncertainty control from an unlabeled dataset and a semantic control from the labeled dataset. The resulting ControlNet allows us to create annotated data with high uncertainty from the target domain, i.e., synthetic data from the unlabeled distribution with labels. In our scenario, we consider retinal OCTs, where typically high-quality Spectralis images are available with given ground truth segmentations, enabling the training of segmentation networks. The recent development in Home-OCT devices, however, yields retinal OCTs with lower quality and a large domain shift, such that out-of-the-pocket segmentation networks cannot be applied for this type of data. Synthesizing annotated images from the Home-OCT domain using the proposed approach closes this gap and leads to significantly improved segmentation results without adding any further supervision. The advantage of uncertainty-guidance becomes obvious when compared to style transfer: it enables arbitrary domain shifts without any strict learning of an image style. This is also demonstrated in a traffic scene experiment.",
    "authors": [
      "Joshua Niemeijer",
      "Jan Ehrhardt",
      "Heinz Handels",
      "Hristina Uzunova"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T12:41:28.000Z",
    "updatedAt": "2025-10-13T12:41:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11346v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11346v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11345v1",
    "arxivId": "2510.11345v1",
    "title": "Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with Asynchrony",
    "abstract": "Synchronous Reinforcement Learning (RL) post-training has emerged as a crucial step for enhancing Large Language Models (LLMs) with diverse capabilities. However, many systems designed to accelerate RL post-training still suffer from low resource utilization and limited scalability. We present ROLL Flash, a system that extends ROLL with native support for asynchronous RL post-training. ROLL Flash is built upon two core design principles: fine-grained parallelism and rollout-train decoupling. Guided by these principles, ROLL Flash provides flexible programming interfaces that enable a fully asynchronous training architecture and support efficient rollout mechanisms, including queue scheduling and environment-level asynchronous execution. Through comprehensive theoretical analysis and extensive experiments, we demonstrate that ROLL Flash significantly improves resource utilization and scalability over synchronous RL post-training. ROLL Flash achieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using the same GPU budget as synchronous baselines. Furthermore, we implement several popular off-policy algorithms and verify that asynchronous training can achieve performance on par with synchronous training.",
    "authors": [
      "Han Lu",
      "Zichen Liu",
      "Shaopan Xiong",
      "Yancheng He",
      "Wei Gao",
      "Yanan Wu",
      "Weixun Wang",
      "Jiashun Liu",
      "Yang Li",
      "Haizhou Zhao",
      "Ju Huang",
      "Siran Yang",
      "Xiaoyang Li",
      "Yijia Luo",
      "Zihe Liu",
      "Ling Pan",
      "Junchi Yan",
      "Wei Wang",
      "Wenbo Su",
      "Jiamang Wang",
      "Lin Qu",
      "Bo Zheng"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T12:41:27.000Z",
    "updatedAt": "2025-10-13T12:41:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11345v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11345v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11344v1",
    "arxivId": "2510.11344v1",
    "title": "MMAP: A Multi-Magnification and Prototype-Aware Architecture for Predicting Spatial Gene Expression",
    "abstract": "Spatial Transcriptomics (ST) enables the measurement of gene expression while preserving spatial information, offering critical insights into tissue architecture and disease pathology. Recent developments have explored the use of hematoxylin and eosin (H&E)-stained whole-slide images (WSIs) to predict transcriptome-wide gene expression profiles through deep neural networks. This task is commonly framed as a regression problem, where each input corresponds to a localized image patch extracted from the WSI. However, predicting spatial gene expression from histological images remains a challenging problem due to the significant modality gap between visual features and molecular signals. Recent studies have attempted to incorporate both local and global information into predictive models. Nevertheless, existing methods still suffer from two key limitations: (1) insufficient granularity in local feature extraction, and (2) inadequate coverage of global spatial context. In this work, we propose a novel framework, MMAP (Multi-MAgnification and Prototype-enhanced architecture), that addresses both challenges simultaneously. To enhance local feature granularity, MMAP leverages multi-magnification patch representations that capture fine-grained histological details. To improve global contextual understanding, it learns a set of latent prototype embeddings that serve as compact representations of slide-level information. Extensive experimental results demonstrate that MMAP consistently outperforms all existing state-of-the-art methods across multiple evaluation metrics, including Mean Absolute Error (MAE), Mean Squared Error (MSE), and Pearson Correlation Coefficient (PCC).",
    "authors": [
      "Hai Dang Nguyen",
      "Nguyen Dang Huy Pham",
      "The Minh Duc Nguyen",
      "Dac Thai Nguyen",
      "Hang Thi Nguyen",
      "Duong M. Nguyen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T12:41:09.000Z",
    "updatedAt": "2025-10-13T12:41:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11344v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11344v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11343v1",
    "arxivId": "2510.11343v1",
    "title": "TBRD: TESLA Authenticated UAS Broadcast Remote ID",
    "abstract": "Mysterious sightings of Unmanned Aircraft Systems (UAS) over U.S. military facilities, suburban neighborhoods, and commercial airports have intensified scrutiny of drone activity. To increase accountability, the Federal Aviation Administration (FAA) introduced a Remote ID mandate, requiring unmanned aircraft to broadcast their location, operator's location, and identity in real-time. However, current standards leave authentication mechanisms underspecified, enabling spoofing, relay, and replay attacks that can undermine surveillance efforts and potentially disrupt UAS-to-UAS coordination in future deployments. In this paper, we propose TBRD, a practical system for authenticating Remote ID messages in a manner that aligns with existing standards and UAS capabilities. TBRD leverages the TESLA protocol and mobile device TEEs, and introduces a verification mechanism to build a lightweight, mission-scoped authentication system that is both computationally efficient and requires a low communication footprint. We evaluate the performance of TBRD using both an FAA-requirements compatible proof-of-concept implementation for performance metrics and a simulated 4-drone swarm mission scenario to demonstrate its security guarantees under adversarial conditions. Our system provides a 50\\% reduction in authentication overhead compared to digital signatures and a 100x reduction in computation time. Our results demonstrate that TBRD can be integrated into current Remote ID infrastructures to provide a scalable, standards-compliant message authentication for both regulatory and operational use cases.",
    "authors": [
      "Jason Veara",
      "Manav Jain",
      "Kyle Moy",
      "Aanjhan Ranganathan"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T12:41:04.000Z",
    "updatedAt": "2025-10-13T12:41:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11343v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11343v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11341v1",
    "arxivId": "2510.11341v1",
    "title": "InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models",
    "abstract": "General SVG modeling remains challenging due to fragmented datasets, limited transferability of methods across tasks, and the difficulty of handling structural complexity. In response, we leverage the strong transfer and generalization capabilities of multimodal large language models (MLLMs) to achieve unified modeling for SVG understanding, editing, and generation. We present the InternSVG family, an integrated data-benchmark-model suite. At its core is SAgoge, the largest and most comprehensive multimodal dataset for SVG tasks, encompassing both static graphics and dynamic animations. It covers icons, long-sequence illustrations, scientific diagrams, and dynamic animations, supporting tasks of varied difficulty levels and providing deeper hierarchies with richer attributes compared to previous datasets. Based on this resource, we introduce SArena, a companion benchmark with comprehensive task definitions and standardized evaluation that aligns with the domains and difficulty spectrum covered by SAgoge. Building on these foundations, we propose InternSVG, a unified MLLM for SVG understanding, editing, and generation with SVG-specific special tokens, subword-based embedding initialization, and a two-stage training strategy that progresses from short static SVGs to long-sequence illustrations and complex animations. This unified formulation induces positive transfer and improves overall performance. Experiments on SArena and prior benchmark confirm that InternSVG achieves substantial gains and consistently outperforms leading open and proprietary counterparts.",
    "authors": [
      "Haomin Wang",
      "Jinhui Yin",
      "Qi Wei",
      "Wenguang Zeng",
      "Lixin Gu",
      "Shenglong Ye",
      "Zhangwei Gao",
      "Yaohui Wang",
      "Yanting Zhang",
      "Yuanqi Li",
      "Yanwen Guo",
      "Wenhai Wang",
      "Kai Chen",
      "Yu Qiao",
      "Hongjie Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T12:38:04.000Z",
    "updatedAt": "2025-10-13T12:38:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11341v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11341v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11340v1",
    "arxivId": "2510.11340v1",
    "title": "REACT3D: Recovering Articulations for Interactive Physical 3D Scenes",
    "abstract": "Interactive 3D scenes are increasingly vital for embodied intelligence, yet existing datasets remain limited due to the labor-intensive process of annotating part segmentation, kinematic types, and motion trajectories. We present REACT3D, a scalable zero-shot framework that converts static 3D scenes into simulation-ready interactive replicas with consistent geometry, enabling direct use in diverse downstream tasks. Our contributions include: (i) openable-object detection and segmentation to extract candidate movable parts from static scenes, (ii) articulation estimation that infers joint types and motion parameters, (iii) hidden-geometry completion followed by interactive object assembly, and (iv) interactive scene integration in widely supported formats to ensure compatibility with standard simulation platforms. We achieve state-of-the-art performance on detection/segmentation and articulation metrics across diverse indoor scenes, demonstrating the effectiveness of our framework and providing a practical foundation for scalable interactive scene generation, thereby lowering the barrier to large-scale research on articulated scene understanding. Our project page is \\textit{\\hypersetup{urlcolor=black}\\href{https://react3d.github.io/}{react3d.github.io}}.",
    "authors": [
      "Zhao Huang",
      "Boyang Sun",
      "Alexandros Delitzas",
      "Jiaqi Chen",
      "Marc Pollefeys"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T12:37:59.000Z",
    "updatedAt": "2025-10-13T12:37:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11340v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11340v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11339v1",
    "arxivId": "2510.11339v1",
    "title": "Event-Aware Prompt Learning for Dynamic Graphs",
    "abstract": "Real-world graph typically evolve via a series of events, modeling dynamic interactions between objects across various domains. For dynamic graph learning, dynamic graph neural networks (DGNNs) have emerged as popular solutions. Recently, prompt learning methods have been explored on dynamic graphs. However, existing methods generally focus on capturing the relationship between nodes and time, while overlooking the impact of historical events. In this paper, we propose EVP, an event-aware dynamic graph prompt learning framework that can serve as a plug-in to existing methods, enhancing their ability to leverage historical events knowledge. First, we extract a series of historical events for each node and introduce an event adaptation mechanism to align the fine-grained characteristics of these events with downstream tasks. Second, we propose an event aggregation mechanism to effectively integrate historical knowledge into node representations. Finally, we conduct extensive experiments on four public datasets to evaluate and analyze EVP.",
    "authors": [
      "Xingtong Yu",
      "Ruijuan Liang",
      "Xinming Zhang",
      "Yuan Fang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T12:37:53.000Z",
    "updatedAt": "2025-10-13T12:37:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11339v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11339v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11335v1",
    "arxivId": "2510.11335v1",
    "title": "DiffStyleTS: Diffusion Model for Style Transfer in Time Series",
    "abstract": "Style transfer combines the content of one signal with the style of another. It supports applications such as data augmentation and scenario simulation, helping machine learning models generalize in data-scarce domains. While well developed in vision and language, style transfer methods for time series data remain limited. We introduce DiffTSST, a diffusion-based framework that disentangles a time series into content and style representations via convolutional encoders and recombines them through a self-supervised attention-based diffusion process. At inference, encoders extract content and style from two distinct series, enabling conditional generation of novel samples to achieve style transfer. We demonstrate both qualitatively and quantitatively that DiffTSST achieves effective style transfer. We further validate its real-world utility by showing that data augmentation with DiffTSST improves anomaly detection in data-scarce regimes.",
    "authors": [
      "Mayank Nagda",
      "Phil Ostheimer",
      "Justus Arweiler",
      "Indra Jungjohann",
      "Jennifer Werner",
      "Dennis Wagner",
      "Aparna Muraleedharan",
      "Pouya Jafari",
      "Jochen Schmid",
      "Fabian Jirasek",
      "Jakob Burger",
      "Michael Bortz",
      "Hans Hasse",
      "Stephan Mandt",
      "Marius Kloft",
      "Sophie Fellenz"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T12:30:10.000Z",
    "updatedAt": "2025-10-13T12:30:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11335v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11335v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11334v1",
    "arxivId": "2510.11334v1",
    "title": "Exponential convergence of multiagent systems with lack of connection",
    "abstract": "Finding conditions ensuring consensus, i.e. convergence to a common value, for a networked system is of crucial interest, both for theoretical reasons and applications. This goal is harder to achieve when connections between agents are temporarily lost. Here, we prove that known conditions (introduced by Moreau) ensure an exponential convergence to consensus, with explicit rate of convergence. The key result is related to the length of the graph (i.e. the number of connections to reach a common agent): if this is large, then convergence is slow. This general result also provides conditions for convergence of second-order cooperative systems with lack of connections.",
    "authors": [
      "Fabio Ancona",
      "Mohamed Bentaibi",
      "Francesco Rossi"
    ],
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-13T12:28:47.000Z",
    "updatedAt": "2025-10-13T12:28:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11334v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11334v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11331v1",
    "arxivId": "2510.11331v1",
    "title": "Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding",
    "abstract": "Large language model (LLM) inference at the network edge is a promising serving paradigm that leverages distributed edge resources to run inference near users and enhance privacy. Existing edge-based LLM inference systems typically adopt autoregressive decoding (AD), which only generates one token per forward pass. This iterative process, compounded by the limited computational resources of edge nodes, results in high serving latency and constrains the system's ability to support multiple users under growing demands.To address these challenges, we propose a speculative decoding (SD)-based LLM serving framework that deploys small and large models across heterogeneous edge nodes to collaboratively deliver inference services. Specifically, the small model rapidly generates draft tokens that the large model verifies in parallel, enabling multi-token generation per forward pass and thus reducing serving latency. To improve resource utilization of edge nodes, we incorporate pipeline parallelism to overlap drafting and verification across multiple inference tasks. Based on this framework, we analyze and derive a comprehensive latency model incorporating both communication and inference latency. Then, we formulate a joint optimization problem for speculation length, task batching, and wireless communication resource allocation to minimize total serving latency. To address this problem, we derive the closed-form solutions for wireless communication resource allocation, and develop a dynamic programming algorithm for joint batching and speculation control strategies. Experimental results demonstrate that the proposed framework achieves lower serving latency compared to AD-based serving systems. In addition,the proposed joint optimization method delivers up to 44.9% latency reduction compared to benchmark schemes.",
    "authors": [
      "Bingjie Zhu",
      "Zhixiong Chen",
      "Liqiang Zhao",
      "Hyundong Shin",
      "Arumugam Nallanathan"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T12:25:55.000Z",
    "updatedAt": "2025-10-13T12:25:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11331v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11331v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11330v1",
    "arxivId": "2510.11330v1",
    "title": "Diffusion-Link: Diffusion Probabilistic Model for Bridging the Audio-Text Modality Gap",
    "abstract": "Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance https://github.com/DevKiHyun/Diffusion-Link",
    "authors": [
      "KiHyun Nam",
      "Jongmin Choi",
      "Hyeongkeun Lee",
      "Jungwoo Heo",
      "Joon Son Chung"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "publishedAt": "2025-10-13T12:25:33.000Z",
    "updatedAt": "2025-10-13T12:25:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11330v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11330v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11328v1",
    "arxivId": "2510.11328v1",
    "title": "Do LLMs \"Feel\"? Emotion Circuits Discovery and Control",
    "abstract": "As the demand for emotional intelligence in large language models (LLMs) grows, a key challenge lies in understanding the internal mechanisms that give rise to emotional expression and in controlling emotions in generated text. This study addresses three core questions: (1) Do LLMs contain context-agnostic mechanisms shaping emotional expression? (2) What form do these mechanisms take? (3) Can they be harnessed for universal emotion control? We first construct a controlled dataset, SEV (Scenario-Event with Valence), to elicit comparable internal states across emotions. Subsequently, we extract context-agnostic emotion directions that reveal consistent, cross-context encoding of emotion (Q1). We identify neurons and attention heads that locally implement emotional computation through analytical decomposition and causal analysis, and validate their causal roles via ablation and enhancement interventions. Next, we quantify each sublayer's causal influence on the model's final emotion representation and integrate the identified local components into coherent global emotion circuits that drive emotional expression (Q2). Directly modulating these circuits achieves 99.65% emotion-expression accuracy on the test set, surpassing prompting- and steering-based methods (Q3). To our knowledge, this is the first systematic study to uncover and validate emotion circuits in LLMs, offering new insights into interpretability and controllable emotional intelligence.",
    "authors": [
      "Chenxi Wang",
      "Yixuan Zhang",
      "Ruiji Yu",
      "Yufei Zheng",
      "Lang Gao",
      "Zirui Song",
      "Zixiang Xu",
      "Gus Xia",
      "Huishuai Zhang",
      "Dongyan Zhao",
      "Xiuying Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T12:24:24.000Z",
    "updatedAt": "2025-10-13T12:24:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11328v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11328v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11323v1",
    "arxivId": "2510.11323v1",
    "title": "Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate Marketing",
    "abstract": "In recent years, affiliate marketing has emerged as a revenue-sharing strategy where merchants collaborate with promoters to promote their products. It not only increases product exposure but also allows promoters to earn a commission. This paper addresses the pivotal yet under-explored challenge in affiliate marketing: accurately assessing and predicting the contributions of promoters in product promotion. We design a novel metric for evaluating the indirect contributions of the promoter, called propagation scale. Unfortunately, existing time series forecasting techniques fail to deliver accurate predictions due to the propagation scale being influenced by multiple factors and the inherent complexities arising from dynamic scenarios. To address this issue, we decouple the network structure from the node signals and propose a two-stage solution: initially, the basic self-sales and network structure prediction are conducted separately, followed by the synthesis of the propagation scale. Specifically, we design a graph convolution encoding scheme based on descendant neighbors and incorporate hypergraph convolution to efficiently capture complex promotional dynamics. Additionally, three auxiliary tasks are employed: self-sales prediction for base estimations, descendant prediction to synthesize propagation scale, and promoter activation prediction to mitigate high volatility issues. Extensive offline experiments on large-scale industrial datasets validate the superiority of our method. We further deploy our model on Alimama platform with over $100,000$ promoters, achieving a $9.29\\%$ improvement in GMV and a $5.89\\%$ increase in sales volume.",
    "authors": [
      "Zhe Wang",
      "Yaming Yang",
      "Ziyu Guan",
      "Bin Tong",
      "Rui Wang",
      "Wei Zhao",
      "Hongbo Deng"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T12:21:29.000Z",
    "updatedAt": "2025-10-13T12:21:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11323v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11323v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11321v1",
    "arxivId": "2510.11321v1",
    "title": "HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data",
    "abstract": "Effective generalization in robotic manipulation requires representations that capture invariant patterns of interaction across environments and tasks. We present a self-supervised framework for learning hierarchical manipulation concepts that encode these invariant patterns through cross-modal sensory correlations and multi-level temporal abstractions without requiring human annotation. Our approach combines a cross-modal correlation network that identifies persistent patterns across sensory modalities with a multi-horizon predictor that organizes representations hierarchically across temporal scales. Manipulation concepts learned through this dual structure enable policies to focus on transferable relational patterns while maintaining awareness of both immediate actions and longer-term goals. Empirical evaluation across simulated benchmarks and real-world deployments demonstrates significant performance improvements with our concept-enhanced policies. Analysis reveals that the learned concepts resemble human-interpretable manipulation primitives despite receiving no semantic supervision. This work advances both the understanding of representation learning for manipulation and provides a practical approach to enhancing robotic performance in complex scenarios.",
    "authors": [
      "Ruizhe Liu",
      "Pei Zhou",
      "Qian Luo",
      "Li Sun",
      "Jun Cen",
      "Yibing Song",
      "Yanchao Yang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T12:19:07.000Z",
    "updatedAt": "2025-10-13T12:19:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11321v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11321v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11320v1",
    "arxivId": "2510.11320v1",
    "title": "A Denotational Product Construction for Temporal Verification of Effectful Higher-Order Programs",
    "abstract": "We propose a categorical framework for linear-time temporal verification of effectful higher-order programs, including probabilistic higher-order programs. Our framework provides a generic denotational reduction -- namely, a denotational product construction -- from linear-time safety verification of effectful higher-order programs to computation of weakest pre-conditions of product programs. This reduction enables us to apply existing algorithms for such well-studied computations of weakest pre-conditions, some of which are available as off-the-shelf solvers. We show the correctness of our denotational product construction by proving a preservation theorem under strong monad morphisms and an existence of suitable liftings along a fibration. We instantiate our framework with both probabilistic and angelic nondeterministic higher-order programs, and implement an automated solver for the probabilistic case based on the existing solver developed by Kura and Unno. To the best of our knowledge, this is the first automated verifier for linear-time temporal verification of probabilistic higher-order programs with recursion.",
    "authors": [
      "Kazuki Watanabe",
      "Mayuko Kori",
      "Taro Sekiyama",
      "Satoshi Kura",
      "Hiroshi Unno"
    ],
    "categories": [
      "cs.LO"
    ],
    "publishedAt": "2025-10-13T12:19:05.000Z",
    "updatedAt": "2025-10-13T12:19:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11320v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11320v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11318v1",
    "arxivId": "2510.11318v1",
    "title": "On a sequence of Kimberling and its relationship to the Tribonacci word",
    "abstract": "In 2017, Clark Kimberling defined an interesting sequence ${\\bf B} = 0100101100 \\cdots$ of $0$'s and $1$'s by certain inflation rules, and he made a number of conjectures about this sequence and some related ones. In this note we prove his conjectures using, in part, the Walnut theorem-prover. We show how his word is related to the infinite Tribonacci word, and we determine both the subword complexity and critical exponent of $\\bf B$.",
    "authors": [
      "Lubomíra Dvořáková",
      "Edita Pelantová",
      "Jeffrey Shallit"
    ],
    "categories": [
      "math.CO",
      "cs.FL"
    ],
    "publishedAt": "2025-10-13T12:17:51.000Z",
    "updatedAt": "2025-10-13T12:17:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11318v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11318v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11317v1",
    "arxivId": "2510.11317v1",
    "title": "Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines",
    "abstract": "Click-Through Rate (CTR) prediction, a cornerstone of modern recommender systems, has been dominated by discriminative models that react to past user behavior rather than proactively modeling user intent. Existing generative paradigms attempt to address this but suffer from critical limitations: Large Language Model (LLM) based methods create a semantic mismatch by forcing e-commerce signals into a linguistic space, while ID-based generation is constrained by item memorization and cold-start issues. To overcome these limitations, we propose a novel generative pre-training paradigm. Our model learns to predict the Next Interest Flow, a dense vector sequence representing a user's future intent, while simultaneously modeling its internal Interest Diversity and Interest Evolution Velocity to ensure the representation is both rich and coherent. However, this two-stage approach introduces a critical objective mismatch between the generative and discriminative stages. We resolve this via a bidirectional alignment strategy, which harmonizes the two stages through cross-stage weight initialization and a dynamic Semantic Alignment Module for fine-tuning. Additionally, we enhance the underlying discriminative model with a Temporal Sequential Pairwise (TSP) mechanism to better capture temporal causality. We present the All-domain Moveline Evolution Network (AMEN), a unified framework implementing our entire pipeline. Extensive offline experiments validate AMEN's superiority over strong baselines, and a large-scale online A/B test demonstrates its significant real-world impact, delivering substantial improvements in key business metrics.",
    "authors": [
      "Chen Gao",
      "Zixin Zhao",
      "Lv Shao",
      "Tong Liu"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T12:13:17.000Z",
    "updatedAt": "2025-10-13T12:13:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11317v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11317v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11316v1",
    "arxivId": "2510.11316v1",
    "title": "pyspect: An Extensible Toolbox for Automatic Construction of Temporal Logic Trees via Reachability Analysis",
    "abstract": "In this paper, we present pyspect, a Python toolbox that simplifies the use of reachability analysis for temporal logic problems. Currently, satisfying complex requirements in cyber-physical systems requires significant manual effort and domain expertise to develop the underlying reachability programs. This high development effort limits the broader adoption of reachability analysis for complex verification problems. To address this, pyspect provides a method-agnostic approach to performing reachability analysis for verifying a temporal logic specification via temporal logic trees (TLTs). It enables the specification of complex safety and liveness requirements using high-level logic formulations that are independent of any particular reachability technique or set representation. As a result, pyspect allows for the comparison of different reachability implementations, such as Hamilton-Jacobi and Hybrid Zonotope-based reachability analysis, for the same temporal logic specification. This design separates the concerns of implementation developers (who develop numerical procedures for reachability) and end-users (who write specifications). Through a simple vehicle example, we demonstrate how pyspect simplifies the synthesis of reachability programs, promotes specification reusability, and facilitates side-by-side comparisons of reachability techniques for complex tasks.",
    "authors": [
      "Kaj Munhoz Arfvidsson",
      "Loizos Hadjiloizou",
      "Frank J. Jiang",
      "Karl H. Johansson",
      "Jonas Mårtensson"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T12:09:40.000Z",
    "updatedAt": "2025-10-13T12:09:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11316v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11316v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11314v1",
    "arxivId": "2510.11314v1",
    "title": "Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications",
    "abstract": "Individuals with intellectual disabilities often have difficulties in comprehending complex texts. While many text-to-image models prioritize aesthetics over accessibility, it is not clear how visual illustrations relate to text simplifications (TS) generated from them. This paper presents a structured vision-language model (VLM) prompting framework for generating accessible images from simplified texts. We designed five prompt templates, i.e., Basic Object Focus, Contextual Scene, Educational Layout, Multi-Level Detail, and Grid Layout, each following distinct spatial arrangements while adhering to accessibility constraints such as object count limits, spatial separation, and content restrictions. Using 400 sentence-level simplifications from four established TS datasets (OneStopEnglish, SimPA, Wikipedia, and ASSET), we conducted a two-phase evaluation: Phase 1 assessed prompt template effectiveness with CLIPScores, and Phase 2 involved human annotation of generated images across ten visual styles by four accessibility experts. Results show that the Basic Object Focus prompt template achieved the highest semantic alignment, indicating that visual minimalism enhances language accessibility. Expert evaluation further identified Retro style as the most accessible and Wikipedia as the most effective data source. Inter-annotator agreement varied across dimensions, with Text Simplicity showing strong reliability and Image Quality proving more subjective. Overall, our framework offers practical guidelines for accessible content generation and underscores the importance of structured prompting in AI-generated visual accessibility tools.",
    "authors": [
      "Belkiss Souayed",
      "Sarah Ebling",
      "Yingqiang Gao"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T12:03:36.000Z",
    "updatedAt": "2025-10-13T12:03:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11314v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11314v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11313v1",
    "arxivId": "2510.11313v1",
    "title": "Automated Skill Decomposition Meets Expert Ontologies: Bridging the Granularity Gap with LLMs",
    "abstract": "This paper investigates automated skill decomposition using Large Language Models (LLMs) and proposes a rigorous, ontology-grounded evaluation framework. Our framework standardizes the pipeline from prompting and generation to normalization and alignment with ontology nodes. To evaluate outputs, we introduce two metrics: a semantic F1-score that uses optimal embedding-based matching to assess content accuracy, and a hierarchy-aware F1-score that credits structurally correct placements to assess granularity. We conduct experiments on ROME-ESCO-DecompSkill, a curated subset of parents, comparing two prompting strategies: zero-shot and leakage-safe few-shot with exemplars. Across diverse LLMs, zero-shot offers a strong baseline, while few-shot consistently stabilizes phrasing and granularity and improves hierarchy-aware alignment. A latency analysis further shows that exemplar-guided prompts are competitive - and sometimes faster - than unguided zero-shot due to more schema-compliant completions. Together, the framework, benchmark, and metrics provide a reproducible foundation for developing ontology-faithful skill decomposition systems.",
    "authors": [
      "Le Ngoc Luyen",
      "Marie-Hélène Abel"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T12:03:06.000Z",
    "updatedAt": "2025-10-13T12:03:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11313v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11313v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11310v1",
    "arxivId": "2510.11310v1",
    "title": "Detection of Performance Changes in MooBench Results Using Nyrkiö on GitHub Actions",
    "abstract": "In GitHub with its 518 million hosted projects, performance changes within these projects are highly relevant to the project's users. Although performance measurement is supported by GitHub CI/CD, performance change detection is a challenging topic. In this paper, we demonstrate how we incorporated Nyrki\\\"o to MooBench. Prior to this work, Moobench continuously ran on GitHub virtual machines, measuring overhead of tracing agents, but without change detection. By adding the upload of the measurements to the Nyrki\\\"o change detection service, we made it possible to detect performance changes. We identified one major performance regression and examined the performance change in depth. We report that (1) it is reproducible with GitHub actions, and (2) the performance regression is caused by a Linux Kernel version change.",
    "authors": [
      "Shinhyung Yang",
      "David Georg Reichelt",
      "Henrik Ingo",
      "Wilhelm Hasselbring"
    ],
    "categories": [
      "cs.SE",
      "cs.OS",
      "cs.PF",
      "D.2.8; D.4.8; C.4"
    ],
    "publishedAt": "2025-10-13T12:02:18.000Z",
    "updatedAt": "2025-10-13T12:02:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11310v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11310v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11308v1",
    "arxivId": "2510.11308v1",
    "title": "Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments",
    "abstract": "Robot person following (RPF) is a core capability in human-robot interaction, enabling robots to assist users in daily activities, collaborative work, and other service scenarios. However, achieving practical RPF remains challenging due to frequent occlusions, particularly in dynamic and crowded environments. Existing approaches often rely on fixed-point following or sparse candidate-point selection with oversimplified heuristics, which cannot adequately handle complex occlusions caused by moving obstacles such as pedestrians. To address these limitations, we propose an adaptive trajectory sampling method that generates dense candidate points within socially aware zones and evaluates them using a multi-objective cost function. Based on the optimal point, a person-following trajectory is estimated relative to the predicted motion of the target. We further design a prediction-aware model predictive path integral (MPPI) controller that simultaneously tracks this trajectory and proactively avoids collisions using predicted pedestrian motions. Extensive experiments show that our method outperforms state-of-the-art baselines in smoothness, safety, robustness, and human comfort, with its effectiveness further demonstrated on a mobile robot in real-world scenarios.",
    "authors": [
      "Weixi Situ",
      "Hanjing Ye",
      "Jianwei Peng",
      "Yu Zhan",
      "Hong Zhang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T11:56:14.000Z",
    "updatedAt": "2025-10-13T11:56:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11308v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11308v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11307v1",
    "arxivId": "2510.11307v1",
    "title": "FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks",
    "abstract": "Current approaches to embodied AI tend to learn policies from expert demonstrations. However, without a mechanism to evaluate the quality of demonstrated actions, they are limited to learning from optimal behaviour, or they risk replicating errors and inefficiencies. While reinforcement learning offers one alternative, the associated exploration typically results in sacrificing data efficiency. This work explores how agents trained with imitation learning can learn robust representations from both optimal and suboptimal demonstrations when given access to constructive language feedback as a means to contextualise different modes of behaviour. We directly provide language feedback embeddings as part of the input sequence into a Transformer-based policy, and optionally complement the traditional next action prediction objective with auxiliary self-supervised learning objectives for feedback prediction. We test our approach on a range of embodied Vision-and-Language tasks in our custom BabyAI-XGen environment and show significant improvements in agents' compositional generalisation abilities and robustness, suggesting that our data-efficient method allows models to successfully convert suboptimal behaviour into learning opportunities. Overall, our results suggest that language feedback is a competitive and intuitive alternative to intermediate scalar rewards for language-specified embodied tasks.",
    "authors": [
      "Sabrina McCallum",
      "Amit Parekh",
      "Alessandro Suglia"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T11:55:21.000Z",
    "updatedAt": "2025-10-13T11:55:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11307v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11307v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11306v1",
    "arxivId": "2510.11306v1",
    "title": "Rotor-Failure-Aware Quadrotors Flight in Unknown Environments",
    "abstract": "Rotor failures in quadrotors may result in high-speed rotation and vibration due to rotor imbalance, which introduces significant challenges for autonomous flight in unknown environments. The mainstream approaches against rotor failures rely on fault-tolerant control (FTC) and predefined trajectory tracking. To the best of our knowledge, online failure detection and diagnosis (FDD), trajectory planning, and FTC of the post-failure quadrotors in unknown and complex environments have not yet been achieved. This paper presents a rotor-failure-aware quadrotor navigation system designed to mitigate the impacts of rotor imbalance. First, a composite FDD-based nonlinear model predictive controller (NMPC), incorporating motor dynamics, is designed to ensure fast failure detection and flight stability. Second, a rotor-failure-aware planner is designed to leverage FDD results and spatial-temporal joint optimization, while a LiDAR-based quadrotor platform with four anti-torque plates is designed to enable reliable perception under high-speed rotation. Lastly, extensive benchmarks against state-of-the-art methods highlight the superior performance of the proposed approach in addressing rotor failures, including propeller unloading and motor stoppage. The experimental results demonstrate, for the first time, that our approach enables autonomous quadrotor flight with rotor failures in challenging environments, including cluttered rooms and unknown forests.",
    "authors": [
      "Xiaobin Zhou",
      "Miao Wang",
      "Chengao Li",
      "Can Cui",
      "Ruibin Zhang",
      "Yongchao Wang",
      "Chao Xu",
      "Fei Gao"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T11:54:49.000Z",
    "updatedAt": "2025-10-13T11:54:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11306v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11306v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11305v1",
    "arxivId": "2510.11305v1",
    "title": "Evaluating the effects of preprocessing, method selection, and hyperparameter tuning on SAR-based flood mapping and water depth estimation",
    "abstract": "Flood mapping and water depth estimation from Synthetic Aperture Radar (SAR) imagery are crucial for calibrating and validating hydraulic models. This study uses SAR imagery to evaluate various preprocessing (especially speckle noise reduction), flood mapping, and water depth estimation methods. The impact of the choice of method at different steps and its hyperparameters is studied by considering an ensemble of preprocessed images, flood maps, and water depth fields. The evaluation is conducted for two flood events on the Garonne River (France) in 2019 and 2021, using hydrodynamic simulations and in-situ observations as reference data. Results show that the choice of speckle filter alters flood extent estimations with variations of several square kilometers. Furthermore, the selection and tuning of flood mapping methods also affect performance. While supervised methods outperformed unsupervised ones, tuned unsupervised approaches (such as local thresholding or change detection) can achieve comparable results. The compounded uncertainty from preprocessing and flood mapping steps also introduces high variability in the water depth field estimates. This study highlights the importance of considering the entire processing pipeline, encompassing preprocessing, flood mapping, and water depth estimation methods and their associated hyperparameters. Rather than relying on a single configuration, adopting an ensemble approach and accounting for methodological uncertainty should be privileged. For flood mapping, the method choice has the most influence. For water depth estimation, the most influential processing step was the flood map input resulting from the flood mapping step and the hyperparameters of the methods.",
    "authors": [
      "Jean-Paul Travert",
      "Cédric Goeury",
      "Sébastien Boyaval",
      "Vito Bacchi",
      "Fabrice Zaoui"
    ],
    "categories": [
      "cs.CV",
      "physics.geo-ph"
    ],
    "publishedAt": "2025-10-13T11:54:42.000Z",
    "updatedAt": "2025-10-13T11:54:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11305v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11305v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11303v1",
    "arxivId": "2510.11303v1",
    "title": "sketch2symm: Symmetry-aware sketch-to-shape generation via semantic bridging",
    "abstract": "Sketch-based 3D reconstruction remains a challenging task due to the abstract and sparse nature of sketch inputs, which often lack sufficient semantic and geometric information. To address this, we propose Sketch2Symm, a two-stage generation method that produces geometrically consistent 3D shapes from sketches. Our approach introduces semantic bridging via sketch-to-image translation to enrich sparse sketch representations, and incorporates symmetry constraints as geometric priors to leverage the structural regularity commonly found in everyday objects. Experiments on mainstream sketch datasets demonstrate that our method achieves superior performance compared to existing sketch-based reconstruction methods in terms of Chamfer Distance, Earth Mover's Distance, and F-Score, verifying the effectiveness of the proposed semantic bridging and symmetry-aware design.",
    "authors": [
      "Yan Zhou",
      "Mingji Li",
      "Xiantao Zeng",
      "Jie Lin",
      "Yuexia Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T11:49:45.000Z",
    "updatedAt": "2025-10-13T11:49:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11303v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11303v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11302v1",
    "arxivId": "2510.11302v1",
    "title": "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models",
    "abstract": "Object detection systems have traditionally relied on supervised learning with manually annotated bounding boxes, achieving high accuracy at the cost of substantial annotation investment. The emergence of Vision-Language Models (VLMs) offers an alternative paradigm enabling zero-shot detection through natural language queries, eliminating annotation requirements but operating with reduced accuracy. This paper presents the first comprehensive cost-effectiveness analysis comparing supervised detection (YOLO) with zero-shot VLM inference (Gemini Flash 2.5). Through systematic evaluation on 1,000 stratified COCO images and 200 diverse product images spanning consumer electronics and rare categories, combined with detailed Total Cost of Ownership modeling, we establish quantitative break-even thresholds governing architecture selection. Our findings reveal that supervised YOLO achieves 91.2% accuracy versus 68.5% for zero-shot Gemini on standard categories, representing a 22.7 percentage point advantage that costs $10,800 in annotation for 100-category systems. However, this advantage justifies investment only beyond 55 million inferences, equivalent to 151,000 images daily for one year. Zero-shot Gemini demonstrates 52.3% accuracy on diverse product categories (ranging from highly web-prevalent consumer electronics at 75-85% to rare specialized equipment at 25-40%) where supervised YOLO achieves 0% due to architectural constraints preventing detection of untrained classes. Cost per Correct Detection analysis reveals substantially lower per-detection costs for Gemini ($0.00050 vs $0.143) at 100,000 inferences despite accuracy deficits. We develop decision frameworks demonstrating that optimal architecture selection depends critically on deployment volume, category stability, budget constraints, and accuracy requirements rather than purely technical performance metrics.",
    "authors": [
      "Samer Al-Hamadani"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T11:48:48.000Z",
    "updatedAt": "2025-10-13T11:48:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11302v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11302v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11301v1",
    "arxivId": "2510.11301v1",
    "title": "TDADL-IE: A Deep Learning-Driven Cryptographic Architecture for Medical Image Security",
    "abstract": "The rise of digital medical imaging, like MRI and CT, demands strong encryption to protect patient data in telemedicine and cloud storage. Chaotic systems are popular for image encryption due to their sensitivity and unique characteristics, but existing methods often lack sufficient security. This paper presents the Three-dimensional Diffusion Algorithm and Deep Learning Image Encryption system (TDADL-IE), built on three key elements. First, we propose an enhanced chaotic generator using an LSTM network with a 1D-Sine Quadratic Chaotic Map (1D-SQCM) for better pseudorandom sequence generation. Next, a new three-dimensional diffusion algorithm (TDA) is applied to encrypt permuted images. TDADL-IE is versatile for images of any size. Experiments confirm its effectiveness against various security threats. The code is available at \\href{https://github.com/QuincyQAQ/TDADL-IE}{https://github.com/QuincyQAQ/TDADL-IE}.",
    "authors": [
      "Junhua Zhou",
      "Quanjun Li",
      "Weixuan Li",
      "Guang Yu",
      "Yihua Shao",
      "Yihang Dong",
      "Mengqian Wang",
      "Zimeng Li",
      "Changwei Gong",
      "Xuhang Chen"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T11:47:55.000Z",
    "updatedAt": "2025-10-13T11:47:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11301v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11301v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11300v1",
    "arxivId": "2510.11300v1",
    "title": "Beyond touch-based HMI: Control your machines in natural language by utilizing large language models and OPC UA",
    "abstract": "This paper proposes an agent-based approach toward a more natural interface between humans and machines. Large language models equipped with tools and the communication standard OPC UA are utilized to control machines in natural language. Instead of touch interaction, which is currently the state-of-the-art medium for interaction in operations, the proposed approach enables operators to talk or text with machines. This allows commands such as 'Please decrease the temperature by 20 % in machine 1 and set the motor speed to 5000 rpm in machine 2.' The large language model receives the user input and selects one of three predefined tools that connect to an OPC UA server and either change or read the value of a node. Afterwards, the result of the tool execution is passed back to the language model, which then provides a final response to the user. The approach is universally designed and can therefore be applied to any machine that supports the OPC UA standard. The large language model is neither fine-tuned nor requires training data, only the relevant machine credentials and a parameter dictionary are included within the system prompt. The approach is evaluated on a Siemens S7-1500 programmable logic controller with four machine parameters in a case study of fifty synthetically generated commands on five different models. The results demonstrate high success rate, with proprietary GPT 5 models achieving accuracies between 96.0 % and 98.0 %, and open-weight models reaching up to 90.0 %. The proposed approach of this empirical study contributes to advancing natural interaction in industrial human-machine interfaces.",
    "authors": [
      "Bernd Hofmann",
      "Sven Kreitlein",
      "Joerg Franke",
      "Patrick Bruendl"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T11:46:47.000Z",
    "updatedAt": "2025-10-13T11:46:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11300v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11300v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11299v1",
    "arxivId": "2510.11299v1",
    "title": "How to Get Actual Privacy and Utility from Privacy Models: the k-Anonymity and Differential Privacy Families",
    "abstract": "Privacy models were introduced in privacy-preserving data publishing and statistical disclosure control with the promise to end the need for costly empirical assessment of disclosure risk. We examine how well this promise is kept by the main privacy models. We find they may fail to provide adequate protection guarantees because of problems in their definition or incur unacceptable trade-offs between privacy protection and utility preservation. Specifically, k-anonymity may not entirely exclude disclosure if enforced with deterministic mechanisms or without constraints on the confidential values. On the other hand, differential privacy (DP) incurs unacceptable utility loss for small budgets and its privacy guarantee becomes meaningless for large budgets. In the latter case, an ex post empirical assessment of disclosure risk becomes necessary, undermining the main appeal of privacy models. Whereas the utility preservation of DP can only be improved by relaxing its privacy guarantees, we argue that a semantic reformulation of k-anonymity can offer more robust privacy without losing utility with respect to traditional syntactic k-anonymity.",
    "authors": [
      "Josep Domingo-Ferrer",
      "David Sánchez"
    ],
    "categories": [
      "cs.CR",
      "cs.DB",
      "68",
      "K.4.1"
    ],
    "publishedAt": "2025-10-13T11:41:12.000Z",
    "updatedAt": "2025-10-13T11:41:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11299v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11299v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11297v1",
    "arxivId": "2510.11297v1",
    "title": "Are Large Language Models Effective Knowledge Graph Constructors?",
    "abstract": "Knowledge graphs (KGs) are vital for knowledge-intensive tasks and have shown promise in reducing hallucinations in large language models (LLMs). However, constructing high-quality KGs remains difficult, requiring accurate information extraction and structured representations that support interpretability and downstream utility. Existing LLM-based approaches often focus narrowly on entity and relation extraction, limiting coverage to sentence-level contexts or relying on predefined schemas. We propose a hierarchical extraction framework that organizes information at multiple levels, enabling the creation of semantically rich and well-structured KGs. Using state-of-the-art LLMs, we extract and construct knowledge graphs and evaluate them comprehensively from both structural and semantic perspectives. Our results highlight the strengths and shortcomings of current LLMs in KG construction and identify key challenges for future work. To advance research in this area, we also release a curated dataset of LLM-generated KGs derived from research papers on children's mental well-being. This resource aims to foster more transparent, reliable, and impactful applications in high-stakes domains such as healthcare.",
    "authors": [
      "Ruirui Chen",
      "Weifeng Jiang",
      "Chengwei Qin",
      "Bo Xiong",
      "Fiona Liausvia",
      "Dongkyu Choi",
      "Boon Kiat Quek"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T11:37:48.000Z",
    "updatedAt": "2025-10-13T11:37:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11297v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11297v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11296v1",
    "arxivId": "2510.11296v1",
    "title": "$Δ\\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization",
    "abstract": "Recent approaches for vision-language models (VLMs) have shown remarkable success in achieving fast downstream adaptation. When applied to real-world downstream tasks, VLMs inevitably encounter both the in-distribution (ID) data and out-of-distribution (OOD) data. The OOD datasets often include both covariate shifts (e.g., known classes with changes in image styles) and semantic shifts (e.g., test-time unseen classes). This highlights the importance of improving VLMs' generalization ability to covariate-shifted OOD data, while effectively detecting open-set semantic-shifted OOD classes. In this paper, inspired by the substantial energy change observed in closed-set data when re-aligning vision-language modalities (specifically by directly reducing the maximum cosine similarity to a low value), we introduce a novel OOD score, named {\\Delta}Energy. {\\Delta}Energy significantly outperforms the vanilla energy-based OOD score and provides a more reliable approach for OOD detection. Furthermore, {\\Delta}Energy can simultaneously improve OOD generalization under covariate shifts, which is achieved by lower-bound maximization for {\\Delta}Energy (termed EBM). EBM is theoretically proven to not only enhance OOD detection but also yields a domain-consistent Hessian, which serves as a strong indicator for OOD generalization. Based on this finding, we developed a unified fine-tuning framework that allows for improving VLMs' robustness in both OOD generalization and OOD detection. Extensive experiments on challenging OOD detection and generalization benchmarks demonstrate the superiority of our method, outperforming recent approaches by 10% to 25% in AUROC.",
    "authors": [
      "Lin Zhu",
      "Yifeng Yang",
      "Xinbing Wang",
      "Qinying Gu",
      "Nanyang Ye"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T11:36:58.000Z",
    "updatedAt": "2025-10-13T11:36:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11296v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11296v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11295v1",
    "arxivId": "2510.11295v1",
    "title": "Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering",
    "abstract": "Large vision-language models (VLMs) achieve strong performance in Visual Question Answering but still rely heavily on supervised fine-tuning (SFT) with massive labeled datasets, which is costly due to human annotations. Crucially, real-world datasets often exhibit human uncertainty (HU) -- variation in human confidence across annotations -- but standard SFT simply optimizes toward the most frequent label, disregarding HU distributions. This leaves two open questions: How does HU affect SFT, and how can HU be effectively leveraged in training? In this work, we first conduct a systematic evaluation of VLMs across varying HU levels. We have two key findings: (i) surprisingly, high-HU samples contribute little or even degrade model performance, and (ii) naively training on the full dataset yields under-calibrated models that fail to capture HU distributions. Motivated by these findings, we introduce HaDola, a human uncertainty-aware data selection and automatic labeling framework. HaDola operates in four stages -- discriminate, self-annotate, error trigger, and training -- to iteratively identify harmful samples, prioritize informative ones, and bootstrap from a small seed set (5\\% of data). Our approach substantially reduces reliance on costly HU annotations and makes VLMs more accurate and better calibrated. Extensive experiments on VQAv2 and VizWiz datasets demonstrate that HaDola consistently matches or outperforms state-of-the-art baselines with less training data. Our work highlights the importance of explicitly modeling HU in SFT, suggesting that better utilization of HU is more effective than merely scaling up dataset size.",
    "authors": [
      "Jian Lan",
      "Zhicheng Liu",
      "Udo Schlegel",
      "Raoyuan Zhao",
      "Yihong Liu",
      "Hinrich Schütze",
      "Michael A. Hedderich",
      "Thomas Seidl"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T11:35:30.000Z",
    "updatedAt": "2025-10-13T11:35:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11295v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11295v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11293v1",
    "arxivId": "2510.11293v1",
    "title": "Cut-elimination for the alternation-free modal mu-calculus",
    "abstract": "We present a syntactic cut-elimination procedure for the alternation-free fragment of the modal mu-calculus. Cut reduction is carried out within a cyclic proof system, where proofs are finitely branching but may be non-wellfounded. The structure of such proofs is exploited to directly transform a cyclic proof with cuts into a cut-free one, without detouring through other logics or relying on intermediate machinery for regularisation. Novel ingredients include the use of multicuts and results from the theory of well-quasi-orders, the later used in the termination argument.",
    "authors": [
      "Bahareh Afshari",
      "Johannes Kloibhofer"
    ],
    "categories": [
      "cs.LO",
      "math.LO"
    ],
    "publishedAt": "2025-10-13T11:29:19.000Z",
    "updatedAt": "2025-10-13T11:29:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11293v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11293v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11292v1",
    "arxivId": "2510.11292v1",
    "title": "LouisKV: Efficient KV Cache Retrieval for Long Input-Output Sequences",
    "abstract": "While Key-Value (KV) cache succeeds in reducing redundant computations in auto-regressive models, it introduces significant memory overhead, limiting its practical deployment in long-sequence scenarios. Existing KV retrieval methods mitigate this by dynamically retaining only a subset of KV entries on the GPU. However, they still suffer from notable efficiency and accuracy bottlenecks due to per-token retrieval and coarse-grained page-level KV management, especially in long-output reasoning scenarios. With the emergence of large reasoning models, efficiently handling such scenarios has become increasingly important. To address this issue, we present two key observations: (1) critical KVs exhibit strong temporal locality during decoding, and (2) these KVs exhibit distinct distribution patterns across the input prompt and generated output. Building on these observations, we propose LouisKV, an efficient KV cache retrieval framework designed for various long-sequence scenarios. Specifically, LouisKV introduces a semantic-aware retrieval strategy leveraging temporal locality to trigger retrieval only at semantic boundaries, drastically reducing computation and data transfer overhead. LouisKV also designs a decoupled, fine-grained management scheme that tailors differentiated strategies for input and output sequences to create retrieval units that better match the model's attention patterns, enabling precise identification of critical KVs. Furthermore, to boost efficiency, LouisKV incorporates several kernel-level optimizations, including custom Triton and CUDA kernels to accelerate the KV clustering and retrieval. Evaluations show that LouisKV achieves up to 4.7$\\times$ speedup over state-of-the-art KV retrieval methods while maintaining near-lossless accuracy across diverse long-sequence tasks, including long-input short-output, short-input long-output, and long-input long-output scenarios.",
    "authors": [
      "Wenbo Wu",
      "Qingyi Si",
      "Xiurui Pan",
      "Ye Wang",
      "Jie Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T11:28:30.000Z",
    "updatedAt": "2025-10-13T11:28:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11292v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11292v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11291v1",
    "arxivId": "2510.11291v1",
    "title": "Network-Optimised Spiking Neural Network (NOS) Scheduling for 6G O-RAN: Spectral Margin and Delay-Tail Control",
    "abstract": "This work presents a Network-Optimised Spiking (NOS) delay-aware scheduler for 6G radio access. The scheme couples a bounded two-state kernel to a clique-feasible proportional-fair (PF) grant head: the excitability state acts as a finite-buffer proxy, the recovery state suppresses repeated grants, and neighbour pressure is injected along the interference graph via delayed spikes. A small-signal analysis yields a delay-dependent threshold $k_\\star(\\Delta)$ and a spectral margin $\\delta = k_\\star(\\Delta) - gH\\rho(W)$ that compress topology, controller gain, and delay into a single design parameter. Under light assumptions on arrivals, we prove geometric ergodicity for $\\delta>0$ and derive sub-Gaussian backlog and delay tail bounds with exponents proportional to $\\delta$. A numerical study, aligned with the analysis and a DU compute budget, compares NOS with PF and delayed backpressure (BP) across interference topologies over a $5$--$20$\\,ms delay sweep. With a single gain fixed at the worst spectral radius, NOS sustains higher utilisation and a smaller 99.9th-percentile delay while remaining clique-feasible on integer PRBs.",
    "authors": [
      "Muhammad Bilal",
      "Xiaolong Xu"
    ],
    "categories": [
      "cs.NI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "68M20, 60K25, 93C23, 93D05, 90B18, 68M10, 68T07",
      "C.2.1; C.2.3; C.4; I.2.6; I.6.5; G.3"
    ],
    "publishedAt": "2025-10-13T11:28:28.000Z",
    "updatedAt": "2025-10-13T11:28:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11291v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11291v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11290v1",
    "arxivId": "2510.11290v1",
    "title": "Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics",
    "abstract": "Large language models (LLMs) based Agents are increasingly pivotal in simulating and understanding complex human systems and interactions. We propose the AI-Agent School (AAS) system, built around a self-evolving mechanism that leverages agents for simulating complex educational dynamics. Addressing the fragmented issues in teaching process modeling and the limitations of agents performance in simulating diverse educational participants, AAS constructs the Zero-Exp strategy, employs a continuous \"experience-reflection-optimization\" cycle, grounded in a dual memory base comprising experience and knowledge bases and incorporating short-term and long-term memory components. Through this mechanism, agents autonomously evolve via situated interactions within diverse simulated school scenarios. This evolution enables agents to more accurately model the nuanced, multi-faceted teacher-student engagements and underlying learning processes found in physical schools. Experiment confirms that AAS can effectively simulate intricate educational dynamics and is effective in fostering advanced agent cognitive abilities, providing a foundational stepping stone from the \"Era of Experience\" to the \"Era of Simulation\" by generating high-fidelity behavioral and interaction data.",
    "authors": [
      "Sheng Jin",
      "Haoming Wang",
      "Zhiqi Gao",
      "Yongbo Yang",
      "Bao Chunjia",
      "Chengliang Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.6; J.4"
    ],
    "publishedAt": "2025-10-13T11:27:53.000Z",
    "updatedAt": "2025-10-13T11:27:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11290v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11290v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11288v1",
    "arxivId": "2510.11288v1",
    "title": "Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs",
    "abstract": "Recent work has shown that narrow finetuning can produce broadly misaligned LLMs, a phenomenon termed emergent misalignment (EM). While concerning, these findings were limited to finetuning and activation steering, leaving out in-context learning (ICL). We therefore ask: does EM emerge in ICL? We find that it does: across three datasets, three frontier models produce broadly misaligned responses at rates between 2% and 17% given 64 narrow in-context examples, and up to 58% with 256 examples. We also examine mechanisms of EM by eliciting step-by-step reasoning (while leaving in-context examples unchanged). Manual analysis of the resulting chain-of-thought shows that 67.5% of misaligned traces explicitly rationalize harmful outputs by adopting a reckless or dangerous ''persona'', echoing prior results on finetuning-induced EM.",
    "authors": [
      "Nikita Afonin",
      "Nikita Andriyanov",
      "Nikhil Bageshpura",
      "Kyle Liu",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Alexander Panchenko",
      "Oleg Rogov",
      "Elena Tutubalina",
      "Mikhail Seleznyov"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T11:23:56.000Z",
    "updatedAt": "2025-10-13T11:23:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11288v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11288v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11287v1",
    "arxivId": "2510.11287v1",
    "title": "EEMS: Edge-Prompt Enhanced Medical Image Segmentation Based on Learnable Gating Mechanism",
    "abstract": "Medical image segmentation is vital for diagnosis, treatment planning, and disease monitoring but is challenged by complex factors like ambiguous edges and background noise. We introduce EEMS, a new model for segmentation, combining an Edge-Aware Enhancement Unit (EAEU) and a Multi-scale Prompt Generation Unit (MSPGU). EAEU enhances edge perception via multi-frequency feature extraction, accurately defining boundaries. MSPGU integrates high-level semantic and low-level spatial features using a prompt-guided approach, ensuring precise target localization. The Dual-Source Adaptive Gated Fusion Unit (DAGFU) merges edge features from EAEU with semantic features from MSPGU, enhancing segmentation accuracy and robustness. Tests on datasets like ISIC2018 confirm EEMS's superior performance and reliability as a clinical tool.",
    "authors": [
      "Han Xia",
      "Quanjun Li",
      "Qian Li",
      "Zimeng Li",
      "Hongbin Ye",
      "Yupeng Liu",
      "Haolun Li",
      "Xuhang Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T11:21:57.000Z",
    "updatedAt": "2025-10-13T11:21:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11287v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11287v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11286v1",
    "arxivId": "2510.11286v1",
    "title": "Edge-to-Cloud Computations-as-a-Service in Software-Defined Energy Networks for Smart Grids",
    "abstract": "Modern power grids face an acute mismatch between where data is generated and where it can be processed: protection relays, EV (Electric Vehicle) charging, and distributed renewables demand millisecond analytics at the edge, while energy-hungry workloads often sit in distant clouds leading to missed real-time deadlines and wasted power. We address this by proposing, to our knowledge, the first-ever SDEN (Software Defined Energy Network) for CaaS (Computations-as-a-Service) that unifies edge, fog, and cloud compute with 5G URLLC (Ultra-Reliable Low-Latency Communications), SDN (Software Defined Networking), and NFV (Network Functions Virtualization) to co-optimize energy, latency, and reliability end-to-end. Our contributions are threefold: (i) a joint task offloading formulation that couples computation placement with network capacity under explicit URLLC constraints; (ii) a feasibility preserving, lightweight greedy heuristic that scales while closely tracking optimal energy and latency trade-offs; and (iii) a tiered AI (Artificial Intelligence) pipeline-reactive at the edge, predictive in the fog, strategic in the cloud-featuring privacy-preserving, federated GNNs (Graph Neural Networks) for fault detection and microgrid coordination. Unlike prior edge-only or cloud-only schemes, SDEN turns fragmented grid compute into a single, programmable substrate that delivers dependable, energy-aware, real time analytics establishing a first-ever, software defined path to practical, grid-scale CaaS.",
    "authors": [
      "Jack Jackman",
      "David Ryan",
      "Arun Narayanan",
      "Pedro Nardelli",
      "Indrakshi Dey"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T11:21:14.000Z",
    "updatedAt": "2025-10-13T11:21:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11286v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11286v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11283v1",
    "arxivId": "2510.11283v1",
    "title": "Gym-TORAX: Open-source software for integrating RL with plasma control simulators",
    "abstract": "This paper presents Gym-TORAX, a Python package enabling the implementation of Reinforcement Learning (RL) environments for simulating plasma dynamics and control in tokamaks. Users define succinctly a set of control actions and observations, and a control objective from which Gym-TORAX creates a Gymnasium environment that wraps TORAX for simulating the plasma dynamics. The objective is formulated through rewards depending on the simulated state of the plasma and control action to optimize specific characteristics of the plasma, such as performance and stability. The resulting environment instance is then compatible with a wide range of RL algorithms and libraries and will facilitate RL research in plasma control. In its current version, one environment is readily available, based on a ramp-up scenario of the International Thermonuclear Experimental Reactor (ITER).",
    "authors": [
      "Antoine Mouchamps",
      "Arthur Malherbe",
      "Adrien Bolland",
      "Damien Ernst"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T11:16:25.000Z",
    "updatedAt": "2025-10-13T11:16:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11283v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11283v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11282v1",
    "arxivId": "2510.11282v1",
    "title": "Vision-LLMs for Spatiotemporal Traffic Forecasting",
    "abstract": "Accurate spatiotemporal traffic forecasting is a critical prerequisite for proactive resource management in dense urban mobile networks. While Large Language Models (LLMs) have shown promise in time series analysis, they inherently struggle to model the complex spatial dependencies of grid-based traffic data. Effectively extending LLMs to this domain is challenging, as representing the vast amount of information from dense geographical grids can be inefficient and overwhelm the model's context. To address these challenges, we propose ST-Vision-LLM, a novel framework that reframes spatiotemporal forecasting as a vision-language fusion problem. Our approach leverages a Vision-LLM visual encoder to process historical global traffic matrices as image sequences, providing the model with a comprehensive global view to inform cell-level predictions. To overcome the inefficiency of LLMs in handling numerical data, we introduce an efficient encoding scheme that represents floating-point values as single tokens via a specialized vocabulary, coupled with a two-stage numerical alignment fine-tuning process. The model is first trained with Supervised Fine-Tuning (SFT) and then further optimized for predictive accuracy using Group Relative Policy Optimization (GRPO), a memory-efficient reinforcement learning method. Evaluations on real-world mobile traffic datasets demonstrate that ST-Vision-LLM outperforms existing methods by 15.6% in long-term prediction accuracy and exceeds the second-best baseline by over 30.04% in cross-domain few-shot scenarios. Our extensive experiments validate the model's strong generalization capabilities across various data-scarce environments.",
    "authors": [
      "Ning Yang",
      "Hengyu Zhong",
      "Haijun Zhang",
      "Randall Berry"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T11:15:56.000Z",
    "updatedAt": "2025-10-13T11:15:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11282v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11282v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11281v1",
    "arxivId": "2510.11281v1",
    "title": "PADME: Procedure Aware DynaMic Execution",
    "abstract": "Learning to autonomously execute long-horizon procedures from natural language remains a core challenge for intelligent agents. Free-form instructions such as recipes, scientific protocols, or business workflows encode rich procedural knowledge, but their variability and lack of structure cause agents driven by large language models (LLMs) to drift or fail during execution. We introduce Procedure Aware DynaMic Execution (PADME), an agent framework that produces and exploits a graph-based representation of procedures. Unlike prior work that relies on manual graph construction or unstructured reasoning, PADME autonomously transforms procedural text into executable graphs that capture task dependencies, decision points, and reusable subroutines. Central to PADME is a two-phase methodology; Teach phase, which focuses on systematic structuring, enrichment with executable logic of procedures, followed by Execute phase, which enables dynamic execution in response to real-time inputs and environment feedback. This separation ensures quality assurance and scalability, allowing expert knowledge to be encoded once and reliably reused across varying contexts. The graph representation also provides an inductive bias that reduces error accumulation in long-horizon reasoning, underscoring the importance of structured procedure modeling for reliable agent-driven automation. Empirically, PADME achieves state-of-the-art performance on four diverse benchmarks, including ALFWorld and ScienceWorld. These results demonstrate that agents equipped with graph-based procedure representations offer a powerful intermediate abstraction for robust and generalizable execution.",
    "authors": [
      "Deepeka Garg",
      "Sihan Zeng",
      "Annapoorani L. Narayanan",
      "Sumitra Ganesh",
      "Leo Ardon"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T11:15:49.000Z",
    "updatedAt": "2025-10-13T11:15:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11281v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11281v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11280v1",
    "arxivId": "2510.11280v1",
    "title": "Proceedings of the Access InContext Workshop @ CHI'25 Conference on Human Factors in Computing Systems",
    "abstract": "This is the Proceedings of the Access InContext Workshop, which was held at the CHI'25 Conference on Human Factors in Computing Systems, in Yokohama, Japan, on April 26th 2025.",
    "authors": [
      "Patricia Piedade"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T11:15:43.000Z",
    "updatedAt": "2025-10-13T11:15:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11280v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11280v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11278v1",
    "arxivId": "2510.11278v1",
    "title": "ENIGMA: The Geometry of Reasoning and Alignment in Large-Language Models",
    "abstract": "We present Entropic Mutual-Information Geometry Large-Language Model Alignment (ENIGMA), a novel approach to Large-Language Model (LLM) training that jointly improves reasoning, alignment and robustness by treating an organisation's policies/principles as directions to move on a model's information manifold. Our single-loop trainer combines Group-Relative Policy Optimisation (GRPO), an on-policy, critic-free RL method with Chain-of-Thought (CoT)-format only rewards; a Self-Supervised Alignment with Mutual Information (SAMI)-style symmetric InfoNCE auxiliary; and an entropic Sinkhorn optimal-transport regulariser on hidden-state distributions to bound geometry drift. We also introduce infoNCE metrics that specialise to a standard MI lower bound under matched negatives to measure how strongly a model's CoT encodes these policies. These metrics include a Sufficiency Index (SI) that enables the selection and creation of principles that maximise downstream performance prior to training. In our experiments using small (1B) LLMs, high-SI principles predict steadier training dynamics and improved benchmark performance over GRPO ablations. Our information-geometry analysis of trained models validates desirable structural change in the manifold. These results support our hypothesis that reasoning, alignment, and robustness are projections of a single informationgeometric objective, and that models trained using ENIGMA demonstrate principled reasoning without the use of a reward model, offering a path to trusted capability",
    "authors": [
      "Gareth Seneque",
      "Lap-Hang Ho",
      "Nafise Erfanian Saeedi",
      "Jeffrey Molendijk",
      "Ariel Kupermann",
      "Tim Elson"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "publishedAt": "2025-10-13T11:13:09.000Z",
    "updatedAt": "2025-10-13T11:13:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11278v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11278v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11277v1",
    "arxivId": "2510.11277v1",
    "title": "Towards Real-Time Fake News Detection under Evidence Scarcity",
    "abstract": "Fake news detection becomes particularly challenging in real-time scenarios, where emerging events often lack sufficient supporting evidence. Existing approaches often rely heavily on external evidence and therefore struggle to generalize under evidence scarcity. To address this issue, we propose Evaluation-Aware Selection of Experts (EASE), a novel framework for real-time fake news detection that dynamically adapts its decision-making process according to the assessed sufficiency of available evidence. EASE introduces a sequential evaluation mechanism comprising three independent perspectives: (1) Evidence-based evaluation, which assesses evidence and incorporates it into decision-making only when the evidence is sufficiently supportive; (2) Reasoning-based evaluation, which leverages the world knowledge of large language models (LLMs) and applies them only when their reliability is adequately established; and (3) Sentiment-based fallback, which integrates sentiment cues when neither evidence nor reasoning is reliable. To enhance the accuracy of evaluation processes, EASE employs instruction tuning with pseudo labels to guide each evaluator in justifying its perspective-specific knowledge through interpretable reasoning. Furthermore, the expert modules integrate the evaluators' justified assessments with the news content to enable evaluation-aware decision-making, thereby enhancing overall detection accuracy. Moreover, we introduce RealTimeNews-25, a new benchmark comprising recent news for evaluating model generalization on emerging news with limited evidence. Extensive experiments demonstrate that EASE not only achieves state-of-the-art performance across multiple benchmarks, but also significantly improves generalization to real-time news. The code and dataset are available: https://github.com/wgyhhhh/EASE.",
    "authors": [
      "Guangyu Wei",
      "Ke Han",
      "Yueming Lyu",
      "Yu Luo",
      "Yue Jiang",
      "Caifeng Shan",
      "Nicu Sebe"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T11:11:46.000Z",
    "updatedAt": "2025-10-13T11:11:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11277v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11277v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11276v1",
    "arxivId": "2510.11276v1",
    "title": "Information-theoretic analysis of temporal dependence in discrete stochastic processes: Application to precipitation predictability",
    "abstract": "Understanding the temporal dependence of precipitation is key to improving weather predictability and developing efficient stochastic rainfall models. We introduce an information-theoretic approach to quantify memory effects in discrete stochastic processes and apply it to daily precipitation records across the contiguous United States. The method is based on the predictability gain, a quantity derived from block entropy that measures the additional information provided by higher-order temporal dependencies. This statistic, combined with a bootstrap-based hypothesis testing and Fisher's method, enables a robust memory estimator from finite data. Tests with generated sequences show that this estimator outperforms other model-selection criteria such as AIC and BIC. Applied to precipitation data, the analysis reveals that daily rainfall occurrence is well described by low-order Markov chains, exhibiting regional and seasonal variations, with stronger correlations in winter along the West Coast and in summer in the Southeast, consistent with known climatological patterns. Overall, our findings establish a framework for building parsimonious stochastic descriptions, useful when addressing spatial heterogeneity in the memory structure of precipitation dynamics, and support further advances in real-time, data-driven forecasting schemes.",
    "authors": [
      "Juan De Gregorio",
      "David Sánchez",
      "Raúl Toral"
    ],
    "categories": [
      "physics.data-an",
      "cs.IT",
      "math.IT",
      "physics.app-ph"
    ],
    "publishedAt": "2025-10-13T11:11:16.000Z",
    "updatedAt": "2025-10-13T11:11:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11276v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11276v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11275v1",
    "arxivId": "2510.11275v1",
    "title": "SeFEF: A Seizure Forecasting Evaluation Framework",
    "abstract": "The lack of standardization in seizure forecasting slows progress in the field and limits the clinical translation of forecasting models. In this work, we introduce a Python-based framework aimed at streamlining the development, assessment, and documentation of individualized seizure forecasting algorithms. The framework automates data labeling, cross-validation splitting, forecast post-processing, performance evaluation, and reporting. It supports various forecasting horizons and includes a model card that documents implementation details, training and evaluation settings, and performance metrics. Three different models were implemented as a proof-of-concept. The models leveraged features extracted from time series data and seizure periodicity. Model performance was assessed using time series cross-validation and key deterministic and probabilistic metrics. Implementation of the three models was successful, demonstrating the flexibility of the framework. The results also emphasize the importance of careful model interpretation due to variations in probability scaling, calibration, and subject-specific differences. Although formal usability metrics were not recorded, empirical observations suggest reduced development time and methodological consistency, minimizing unintentional variations that could affect the comparability of different approaches. As a proof-of-concept, this validation is inherently limited, relying on a single-user experiment without statistical analyses or replication across independent datasets. At this stage, our objective is to make the framework publicly available to foster community engagement, facilitate experimentation, and gather feedback. In the long term, we aim to contribute to the establishment of a consensus on a standardized methodology for the development and validation of seizure forecasting algorithms in people with epilepsy.",
    "authors": [
      "Ana Sofia Carmo",
      "Lourenço Abrunhosa Rodrigues",
      "Ana Rita Peralta",
      "Ana Fred",
      "Carla Bentes",
      "Hugo Plácido da Silva"
    ],
    "categories": [
      "q-bio.QM",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T11:10:27.000Z",
    "updatedAt": "2025-10-13T11:10:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11275v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11275v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11274v1",
    "arxivId": "2510.11274v1",
    "title": "FedLoRA-Optimizer: Federated LoRA Fine-Tuning with Global and Local Optimization in Heterogeneous Data Scenarios",
    "abstract": "Federated efficient fine-tuning has emerged as an approach that leverages distributed data and computational resources across nodes to address the challenges of large-scale fine-tuning and privacy preservation. The Low-Rank Adaptation (LoRA) enables efficient fine-tuning of large-scale pre-trained models by introducing trainable low-rank matrices into weight updates.However, in heterogeneous data scenarios, client drift weakens the generalization of the global model, and local models often fail to meet the personalized needs of individual clients.Moreover, existing federated LoRA efficient fine-tuning techniques overlook fine-grained analysis of the tuning matrices. To address this, we conducted preliminary experiments and found that different LoRA matrices exhibit different sensitivity to changes in the direction and magnitude of their vectors.We thus propose a fine-grained federated LoRA tuning method. By fine-tuning the more sensitive directional vectors in the A matrix, which encode shared knowledge, our method learns shared features more effectively across clients and enhances global generalization. Simultaneously, by fine-tuning the more sensitive magnitude vectors in the B matrix, which encode personalized knowledge, our method better captures personalized knowledge, enabling detailed adaptation to local data. The method uses a pipeline combining global and local optimizers. Global optimization further improves local models, achieving collaborative optimization between global and local levels. This improves both the generalization ability of the global model and the personalized adaptation of local models under heterogeneous data scenarios. Experiments on Databricks-Dolly-15k and Natural Instructions with LLaMA2-7B and Deepseek-7B confirm that our method improves global performance by 0.39% and local performance by 0.59%.",
    "authors": [
      "Jianzhe Zhao",
      "Hailin Zhu",
      "Yu Zhang",
      "Ziqi Chen",
      "Guibing Guo"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T11:06:36.000Z",
    "updatedAt": "2025-10-13T11:06:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11274v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11274v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11269v1",
    "arxivId": "2510.11269v1",
    "title": "From Prompts to Packets: A View from the Network on ChatGPT, Copilot, and Gemini",
    "abstract": "Generative AI (GenAI) chatbots are now pervasive in digital ecosystems, yet their network traffic remains largely underexplored. This study presents an in-depth investigation of traffic generated by three leading chatbots (ChatGPT, Copilot, and Gemini) when accessed via Android mobile apps for both text and image generation. Using a dedicated capture architecture, we collect and label two complementary workloads: a 60-hour generic dataset with unconstrained prompts, and a controlled dataset built from identical prompts across GenAI apps and replicated via conventional messaging apps to enable one-to-one comparisons. This dual design allows us to address practical research questions on the distinctiveness of GenAI traffic, its differences from widely deployed traffic categories, and its novel implications for network usage. To this end, we provide fine-grained traffic characterization at trace, flow, and protocol levels, and model packet-sequence dynamics with Multimodal Markov Chains. Our analyses reveal app- and content-specific traffic patterns, particularly in volume, uplink/downlink profiles, and protocol adoption. We highlight the predominance of TLS, with Gemini extensively leveraging QUIC, ChatGPT exclusively using TLS 1.3, and app- and content-specific Server Name Indication (SNI) values. A payload-based occlusion analysis quantifies SNI's contribution to classification: masking it reduces F1-score by up to 20 percentage points in GenAI app traffic classification. Finally, compared with conventional messaging apps when carrying the same content, GenAI chatbots exhibit unique traffic characteristics, highlighting new stress factors for mobile networks, such as sustained upstream activity, with direct implications for network monitoring and management. We publicly release the datasets to support reproducibility and foster extensions to other use cases.",
    "authors": [
      "Antonio Montieri",
      "Alfredo Nascita",
      "Antonio Pescapè"
    ],
    "categories": [
      "cs.NI",
      "cs.AI",
      "C.2.3; C.2.4; C.2.5"
    ],
    "publishedAt": "2025-10-13T10:58:54.000Z",
    "updatedAt": "2025-10-13T10:58:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11269v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11269v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11268v1",
    "arxivId": "2510.11268v1",
    "title": "Exploring and Leveraging Class Vectors for Classifier Editing",
    "abstract": "Image classifiers play a critical role in detecting diseases in medical imaging and identifying anomalies in manufacturing processes. However, their predefined behaviors after extensive training make post hoc model editing difficult, especially when it comes to forgetting specific classes or adapting to distribution shifts. Existing classifier editing methods either focus narrowly on correcting errors or incur extensive retraining costs, creating a bottleneck for flexible editing. Moreover, such editing has seen limited investigation in image classification. To overcome these challenges, we introduce Class Vectors, which capture class-specific representation adjustments during fine-tuning. Whereas task vectors encode task-level changes in weight space, Class Vectors disentangle each class's adaptation in the latent space. We show that Class Vectors capture each class's semantic shift and that classifier editing can be achieved either by steering latent features along these vectors or by mapping them into weight space to update the decision boundaries. We also demonstrate that the inherent linearity and orthogonality of Class Vectors support efficient, flexible, and high-level concept editing via simple class arithmetic. Finally, we validate their utility in applications such as unlearning, environmental adaptation, adversarial defense, and adversarial trigger optimization.",
    "authors": [
      "Jaeik Kim",
      "Jaeyoung Do"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T10:57:51.000Z",
    "updatedAt": "2025-10-13T10:57:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11268v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11268v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11266v1",
    "arxivId": "2510.11266v1",
    "title": "Online Allocation with Concave, Diminishing-Returns Objectives",
    "abstract": "Online resource allocation problems are central challenges in economics and computer science, modeling situations in which $n$ items arriving one at a time must each be immediately allocated among $m$ agents. In such problems, our objective is to maximize a monotone reward function $f(\\mathbf{x})$ over the allocation vector $\\mathbf{x} = (x_{ij})_{i, j}$, which describes the amount of each item given to each agent. In settings where $f$ is concave and has \"diminishing returns\" (monotone decreasing gradient), several lines of work over the past two decades have had great success designing constant-competitive algorithms, including the foundational work of Mehta et al. (2005) on the Adwords problem and many follow-ups. Notably, while a greedy algorithm is $\\frac{1}{2}$-competitive in such settings, these works have shown that one can often obtain a competitive ratio of $1-\\frac{1}{e} \\approx 0.632$ in a variety of settings when items are divisible (i.e. allowing fractional allocations). However, prior works have thus far used a variety of problem-specific techniques, leaving open the general question: Does a $(1-\\frac{1}{e})$-competitive fractional algorithm always exist for online resource allocation problems with concave, diminishing-returns objectives? In this work, we answer this question affirmatively, thereby unifying and generalizing prior results for special cases. Our algorithm is one which makes continuous greedy allocations with respect to an auxiliary objective $U(\\mathbf{x})$. Using the online primal-dual method, we show that if $U$ satisfies a \"balanced\" property with respect to $f$, then one can bound the competitiveness of such an algorithm. Our crucial observation is that there is a simple expression for $U$ which has this balanced property for any $f$, yielding our general $(1-\\frac{1}{e})$-competitive algorithm.",
    "authors": [
      "Kalen Patton"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-13T10:54:15.000Z",
    "updatedAt": "2025-10-13T10:54:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11266v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11266v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11264v1",
    "arxivId": "2510.11264v1",
    "title": "Learning Hanzi Character Through VR-Based Mortise-Tenon",
    "abstract": "This paper introduces a novel VR-based system that redefines the acquisition of Hanzi character literacy by integrating traditional mortise-tenon joinery principles (HVRMT).Addressing the challenge of abstract character memorization in digital learning,our system deconstructs Hanzi components into interactive \"structural radicals\"akin to wooden joint modules.Leveraging PICO's 6DoF spatial tracking and LLM's morphological analysis,learners assemble stroke sequences with haptic feedback simulating wood-to-wood friction.Our system also supports multiplayer online experiences, enhancing engagement and memory retention while preserving intangible cultural heritage. This innovative approach not only enhances engagement and memory retention but also reconstructs the craft wisdom embedded in Chinese writing systems, offering new pathways for preserving intangible cultural heritage in digital ecosystems.For the demo,please refer to this link{https://youtu.be/oUwfFTRpFyo}.",
    "authors": [
      "Conglin Ma",
      "Jiatong Li",
      "Sen-Zhe Xu",
      "Ju Dai",
      "Jie Liu",
      "Feng Zhou"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T10:53:29.000Z",
    "updatedAt": "2025-10-13T10:53:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11264v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11264v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11260v1",
    "arxivId": "2510.11260v1",
    "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images",
    "abstract": "Microscopic characterizations, such as Scanning Electron Microscopy (SEM), are widely used in scientific research for visualizing and analyzing microstructures. Determining the scale bars is an important first step of accurate SEM analysis; however, currently, it mainly relies on manual operations, which is both time-consuming and prone to errors. To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent. The proposed framework operates in four phases; i) Automatic Dataset Generation (Auto-DG) model to synthesize a diverse dataset of SEM images ensuring robust training and high generalizability of the model, ii) scale bar object detection, iii) information extraction using a hybrid Optical Character Recognition (OCR) system with DenseNet and Convolutional Recurrent Neural Network (CRNN) based algorithms, iv) an LLM agent to analyze and verify accuracy of the results. The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95. The hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the Auto-DG dataset, significantly outperforming several mainstream standalone engines, highlighting its reliability for scientific image analysis. The LLM is introduced as a reasoning engine as well as an intelligent assistant that suggests follow-up steps and verifies the results. This automated method powered by an LLM agent significantly enhances the efficiency and accuracy of scale bar detection and extraction in SEM images, providing a valuable tool for microscopic analysis and advancing the field of scientific imaging.",
    "authors": [
      "Yuxuan Chen",
      "Ruotong Yang",
      "Zhengyang Zhang",
      "Mehreen Ahmed",
      "Yanming Wang"
    ],
    "categories": [
      "cs.CV",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.data-an"
    ],
    "publishedAt": "2025-10-13T10:50:54.000Z",
    "updatedAt": "2025-10-13T10:50:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11260v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11260v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11259v1",
    "arxivId": "2510.11259v1",
    "title": "DTEA: Dynamic Topology Weaving and Instability-Driven Entropic Attenuation for Medical Image Segmentation",
    "abstract": "In medical image segmentation, skip connections are used to merge global context and reduce the semantic gap between encoder and decoder. Current methods often struggle with limited structural representation and insufficient contextual modeling, affecting generalization in complex clinical scenarios. We propose the DTEA model, featuring a new skip connection framework with the Semantic Topology Reconfiguration (STR) and Entropic Perturbation Gating (EPG) modules. STR reorganizes multi-scale semantic features into a dynamic hypergraph to better model cross-resolution anatomical dependencies, enhancing structural and semantic representation. EPG assesses channel stability after perturbation and filters high-entropy channels to emphasize clinically important regions and improve spatial attention. Extensive experiments on three benchmark datasets show our framework achieves superior segmentation accuracy and better generalization across various clinical settings. The code is available at \\href{https://github.com/LWX-Research/DTEA}{https://github.com/LWX-Research/DTEA}.",
    "authors": [
      "Weixuan Li",
      "Quanjun Li",
      "Guang Yu",
      "Song Yang",
      "Zimeng Li",
      "Chi-Man Pun",
      "Yupeng Liu",
      "Xuhang Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T10:50:41.000Z",
    "updatedAt": "2025-10-13T10:50:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11259v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11259v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11258v1",
    "arxivId": "2510.11258v1",
    "title": "DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation",
    "abstract": "Loco-manipulation is a fundamental challenge for humanoid robots to achieve versatile interactions in human environments. Although recent studies have made significant progress in humanoid whole-body control, loco-manipulation remains underexplored and often relies on hard-coded task definitions or costly real-world data collection, which limits autonomy and generalization. We present DemoHLM, a framework for humanoid loco-manipulation that enables generalizable loco-manipulation on a real humanoid robot from a single demonstration in simulation. DemoHLM adopts a hierarchy that integrates a low-level universal whole-body controller with high-level manipulation policies for multiple tasks. The whole-body controller maps whole-body motion commands to joint torques and provides omnidirectional mobility for the humanoid robot. The manipulation policies, learned in simulation via our data generation and imitation learning pipeline, command the whole-body controller with closed-loop visual feedback to execute challenging loco-manipulation tasks. Experiments show a positive correlation between the amount of synthetic data and policy performance, underscoring the effectiveness of our data generation pipeline and the data efficiency of our approach. Real-world experiments on a Unitree G1 robot equipped with an RGB-D camera validate the sim-to-real transferability of DemoHLM, demonstrating robust performance under spatial variations across ten loco-manipulation tasks.",
    "authors": [
      "Yuhui Fu",
      "Feiyang Xie",
      "Chaoyi Xu",
      "Jing Xiong",
      "Haoqi Yuan",
      "Zongqing Lu"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T10:49:40.000Z",
    "updatedAt": "2025-10-13T10:49:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11258v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11258v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11257v1",
    "arxivId": "2510.11257v1",
    "title": "MIEO: encoding clinical data to enhance cardiovascular event prediction",
    "abstract": "As clinical data are becoming increasingly available, machine learning methods have been employed to extract knowledge from them and predict clinical events. While promising, approaches suffer from at least two main issues: low availability of labelled data and data heterogeneity leading to missing values. This work proposes the use of self-supervised auto-encoders to efficiently address these challenges. We apply our methodology to a clinical dataset from patients with ischaemic heart disease. Patient data is embedded in a latent space, built using unlabelled data, which is then used to train a neural network classifier to predict cardiovascular death. Results show improved balanced accuracy compared to applying the classifier directly to the raw data, demonstrating that this solution is promising, especially in conditions where availability of unlabelled data could increase.",
    "authors": [
      "Davide Borghini",
      "Davide Marchi",
      "Angelo Nardone",
      "Giordano Scerra",
      "Silvia Giulia Galfrè",
      "Alessandro Pingitore",
      "Giuseppe Prencipe",
      "Corrado Priami",
      "Alina Sîrbu"
    ],
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "publishedAt": "2025-10-13T10:47:49.000Z",
    "updatedAt": "2025-10-13T10:47:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11257v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11257v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11255v1",
    "arxivId": "2510.11255v1",
    "title": "Temporal Cooperative Games",
    "abstract": "Classical cooperative game theory assumes that the worth of a coalition depends only on the set of agents involved, but in practice, it may also depend on the order in which agents arrive. Motivated by such scenarios, we introduce temporal cooperative games (TCG), where the worth $v$ becomes a function of the sequence of agents $\\pi$ rather than just the set $S$. This shift calls for rethinking the underlying axioms. A key property in this temporal framework is the incentive for optimal arrival (I4OA), which encourages agents to join in the order maximizing total worth. Alongside, we define two additional properties: online individual rationality (OIR), incentivizing earlier agents to invite more participants, and sequential efficiency (SE), ensuring that the total worth of any sequence is fully distributed among its agents. We identify a class of reward-sharing mechanisms uniquely characterized by these three properties. The classical Shapley value does not directly apply here, so we construct its natural analogs in two variants: the sequential world, where rewards are defined for each sequence-player pair, and the extended world, where rewards are defined for each player alone. Properties of efficiency, additivity, and null player uniquely determine these Shapley analogs in both worlds. Importantly, the Shapley analogs are disjoint from mechanisms satisfying I4OA, OIR, and SE, and this conflict persists even for restricted classes such as convex and simple TCGs. Our findings thus uncover a fundamental tension: when players arrive sequentially, reward-sharing mechanisms satisfying desirable temporal properties must inherently differ from Shapley-inspired ones, opening new questions for defining fair and efficient solution concepts in TCGs.",
    "authors": [
      "Ashwin Goyal",
      "Drashthi Doshi",
      "Swaprava Nath"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-13T10:44:10.000Z",
    "updatedAt": "2025-10-13T10:44:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11255v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11255v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11254v1",
    "arxivId": "2510.11254v1",
    "title": "Do Psychometric Tests Work for Large Language Models? Evaluation of Tests on Sexism, Racism, and Morality",
    "abstract": "Psychometric tests are increasingly used to assess psychological constructs in large language models (LLMs). However, it remains unclear whether these tests -- originally developed for humans -- yield meaningful results when applied to LLMs. In this study, we systematically evaluate the reliability and validity of human psychometric tests for three constructs: sexism, racism, and morality. We find moderate reliability across multiple item and prompt variations. Validity is evaluated through both convergent (i.e., testing theory-based inter-test correlations) and ecological approaches (i.e., testing the alignment between tests scores and behavior in real-world downstream tasks). Crucially, we find that psychometric test scores do not align, and in some cases even negatively correlate with, model behavior in downstream tasks, indicating low ecological validity. Our results highlight that systematic evaluations of psychometric tests is essential before interpreting their scores. They also suggest that psychometric tests designed for humans cannot be applied directly to LLMs without adaptation.",
    "authors": [
      "Jana Jung",
      "Marlene Lutz",
      "Indira Sen",
      "Markus Strohmaier"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T10:43:49.000Z",
    "updatedAt": "2025-10-13T10:43:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11254v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11254v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11253v1",
    "arxivId": "2510.11253v1",
    "title": "Likes, Budgets, and Equilibria: Designing Contests for Socially Optimal Advertising",
    "abstract": "Firms (businesses, service providers, entertainment organizations, political parties, etc.) advertise on social networks to draw people's attention and improve their awareness of the brands of the firms. In all such cases, the competitive nature of their engagements gives rise to a game where the firms need to decide how to distribute their budget over the agents on a network to maximize their brand's awareness. The firms (players) therefore need to optimize how much budget they should put on the vertices of the network so that the spread improves via direct (via advertisements or free promotional offers) and indirect marketing (words-of-mouth). We propose a two-timescale model of decisions where the communication between the vertices happen in a faster timescale and the strategy update of the firms happen in a slower timescale. We show that under fairly standard conditions, the best response dynamics of the firms converge to a pure strategy Nash equilibrium. However, such equilibria can be away from a socially optimal one. We provide a characterization of the contest success functions and provide examples for the designers of such contests (e.g., regulators, social network providers, etc.) such that the Nash equilibrium becomes unique and social welfare maximizing. Our experiments show that for realistic scenarios, such contest success functions perform fairly well.",
    "authors": [
      "Sayantika Mandal",
      "Harman Agrawal",
      "Swaprava Nath"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-13T10:43:38.000Z",
    "updatedAt": "2025-10-13T10:43:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11253v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11253v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11251v1",
    "arxivId": "2510.11251v1",
    "title": "Large Language Models Are Effective Code Watermarkers",
    "abstract": "The widespread use of large language models (LLMs) and open-source code has raised ethical and security concerns regarding the distribution and attribution of source code, including unauthorized redistribution, license violations, and misuse of code for malicious purposes. Watermarking has emerged as a promising solution for source attribution, but existing techniques rely heavily on hand-crafted transformation rules, abstract syntax tree (AST) manipulation, or task-specific training, limiting their scalability and generality across languages. Moreover, their robustness against attacks remains limited. To address these limitations, we propose CodeMark-LLM, an LLM-driven watermarking framework that embeds watermark into source code without compromising its semantics or readability. CodeMark-LLM consists of two core components: (i) Semantically Consistent Embedding module that applies functionality-preserving transformations to encode watermark bits, and (ii) Differential Comparison Extraction module that identifies the applied transformations by comparing the original and watermarked code. Leveraging the cross-lingual generalization ability of LLM, CodeMark-LLM avoids language-specific engineering and training pipelines. Extensive experiments across diverse programming languages and attack scenarios demonstrate its robustness, effectiveness, and scalability.",
    "authors": [
      "Rui Xu",
      "Jiawei Chen",
      "Zhaoxia Yin",
      "Cong Kong",
      "Xinpeng Zhang"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T10:40:24.000Z",
    "updatedAt": "2025-10-13T10:40:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11251v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11251v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11250v1",
    "arxivId": "2510.11250v1",
    "title": "FUSE: Fast Semi-Supervised Node Embedding Learning via Structural and Label-Aware Optimization",
    "abstract": "Graph-based learning is a cornerstone for analyzing structured data, with node classification as a central task. However, in many real-world graphs, nodes lack informative feature vectors, leaving only neighborhood connectivity and class labels as available signals. In such cases, effective classification hinges on learning node embeddings that capture structural roles and topological context. We introduce a fast semi-supervised embedding framework that jointly optimizes three complementary objectives: (i) unsupervised structure preservation via scalable modularity approximation, (ii) supervised regularization to minimize intra-class variance among labeled nodes, and (iii) semi-supervised propagation that refines unlabeled nodes through random-walk-based label spreading with attention-weighted similarity. These components are unified into a single iterative optimization scheme, yielding high-quality node embeddings. On standard benchmarks, our method consistently achieves classification accuracy at par with or superior to state-of-the-art approaches, while requiring significantly less computational cost.",
    "authors": [
      "Sujan Chakraborty",
      "Rahul Bordoloi",
      "Anindya Sengupta",
      "Olaf Wolkenhauer",
      "Saptarshi Bej"
    ],
    "categories": [
      "cs.LG",
      "I.5.2"
    ],
    "publishedAt": "2025-10-13T10:39:58.000Z",
    "updatedAt": "2025-10-13T10:39:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11250v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11250v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11246v1",
    "arxivId": "2510.11246v1",
    "title": "Collaborative Shadows: Distributed Backdoor Attacks in LLM-Based Multi-Agent Systems",
    "abstract": "LLM-based multi-agent systems (MAS) demonstrate increasing integration into next-generation applications, but their safety in backdoor attacks remains largely underexplored. However, existing research has focused exclusively on single-agent backdoor attacks, overlooking the novel attack surfaces introduced by agent collaboration in MAS. To bridge this gap, we present the first Distributed Backdoor Attack tailored to MAS. We decompose the backdoor into multiple distributed attack primitives that are embedded within MAS tools. These primitives remain dormant individually but collectively activate only when agents collaborate in a specific sequence, thereby assembling the full backdoor to execute targeted attacks such as data exfiltration. To fully assess this threat, we introduce a benchmark for multi-role collaborative tasks and a sandboxed framework to evaluate. Extensive experiments demonstrate that our attack achieves an attack success rate exceeding 95% without degrading performance on benign tasks. This work exposes novel backdoor attack surfaces that exploit agent collaboration, underscoring the need to move beyond single-agent protection. Code and benchmark are available at https://github.com/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS.",
    "authors": [
      "Pengyu Zhu",
      "Lijun Li",
      "Yaxing Lyu",
      "Li Sun",
      "Sen Su",
      "Jing Shao"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T10:34:05.000Z",
    "updatedAt": "2025-10-13T10:34:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11246v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11246v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11245v1",
    "arxivId": "2510.11245v1",
    "title": "Learning the Structure of Connection Graphs",
    "abstract": "Connection graphs (CGs) extend traditional graph models by coupling network topology with orthogonal transformations, enabling the representation of global geometric consistency. They play a key role in applications such as synchronization, Riemannian signal processing, and neural sheaf diffusion. In this work, we address the inverse problem of learning CGs directly from observed signals. We propose a principled framework based on maximum pseudo-likelihood under a consistency assumption, which enforces spectral properties linking the connection Laplacian to the underlying combinatorial Laplacian. Based on this formulation, we introduce the Structured Connection Graph Learning (SCGL) algorithm, a block-optimization procedure over Riemannian manifolds that jointly infers network topology, edge weights, and geometric structure. Our experiments show that SCGL consistently outperforms existing baselines in both topological recovery and geometric fidelity, while remaining computationally efficient.",
    "authors": [
      "Leonardo Di Nino",
      "Gabriele D'Acunto",
      "Sergio Barbarossa",
      "Paolo Di Lorenzo"
    ],
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "publishedAt": "2025-10-13T10:33:31.000Z",
    "updatedAt": "2025-10-13T10:33:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11245v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11245v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11243v1",
    "arxivId": "2510.11243v1",
    "title": "Nepali Sign Language Characters Recognition: Dataset Development and Deep Learning Approaches",
    "abstract": "Sign languages serve as essential communication systems for individuals with hearing and speech impairments. However, digital linguistic dataset resources for underrepresented sign languages, such as Nepali Sign Language (NSL), remain scarce. This study introduces the first benchmark dataset for NSL, consisting of 36 gesture classes with 1,500 samples per class, designed to capture the structural and visual features of the language. To evaluate recognition performance, we fine-tuned MobileNetV2 and ResNet50 architectures on the dataset, achieving classification accuracies of 90.45% and 88.78%, respectively. These findings demonstrate the effectiveness of convolutional neural networks in sign recognition tasks, particularly within low-resource settings. To the best of our knowledge, this work represents the first systematic effort to construct a benchmark dataset and assess deep learning approaches for NSL recognition, highlighting the potential of transfer learning and fine-tuning for advancing research in underexplored sign languages.",
    "authors": [
      "Birat Poudel",
      "Satyam Ghimire",
      "Sijan Bhattarai",
      "Saurav Bhandari",
      "Suramya Sharma Dahal"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T10:29:08.000Z",
    "updatedAt": "2025-10-13T10:29:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11243v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11243v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11242v1",
    "arxivId": "2510.11242v1",
    "title": "Analyzing Data Quality and Decay in Mega-Constellations: A Physics-Informed Machine Learning Approach",
    "abstract": "In the era of mega-constellations, the need for accurate and publicly available information has become fundamental for satellite operators to guarantee the safety of spacecrafts and the Low Earth Orbit (LEO) space environment. This study critically evaluates the accuracy and reliability of publicly available ephemeris data for a LEO mega-constellation - Starlink. The goal of this work is twofold: (i) compare and analyze the quality of the data against high-precision numerical propagation. (ii) Leverage Physics-Informed Machine Learning to extract relevant satellite quantities, such as non-conservative forces, during the decay process. By analyzing two months of real orbital data for approximately 1500 Starlink satellites, we identify discrepancies between high precision numerical algorithms and the published ephemerides, recognizing the use of simplified dynamics at fixed thresholds, planned maneuvers, and limitations in uncertainty propagations. Furthermore, we compare data obtained from multiple sources to track and analyze deorbiting satellites over the same period. Empirically, we extract the acceleration profile of satellites during deorbiting and provide insights relating to the effects of non-conservative forces during reentry. For non-deorbiting satellites, the position Root Mean Square Error (RMSE) was approximately 300 m, while for deorbiting satellites it increased to about 600 m. Through this in-depth analysis, we highlight potential limitations in publicly available data for accurate and robust Space Situational Awareness (SSA), and importantly, we propose a data-driven model of satellite decay in mega-constellations.",
    "authors": [
      "Katarina Dyreby",
      "Francisco Caldas",
      "Cláudia Soares"
    ],
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T10:28:23.000Z",
    "updatedAt": "2025-10-13T10:28:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11242v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11242v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11238v1",
    "arxivId": "2510.11238v1",
    "title": "Attacks by Content: Automated Fact-checking is an AI Security Issue",
    "abstract": "When AI agents retrieve and reason over external documents, adversaries can manipulate the data they receive to subvert their behaviour. Previous research has studied indirect prompt injection, where the attacker injects malicious instructions. We argue that injection of instructions is not necessary to manipulate agents - attackers could instead supply biased, misleading, or false information. We term this an attack by content. Existing defenses, which focus on detecting hidden commands, are ineffective against attacks by content. To defend themselves and their users, agents must critically evaluate retrieved information, corroborating claims with external evidence and evaluating source trustworthiness. We argue that this is analogous to an existing NLP task, automated fact-checking, which we propose to repurpose as a cognitive self-defense tool for agents.",
    "authors": [
      "Michael Schlichtkrull"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T10:18:48.000Z",
    "updatedAt": "2025-10-13T10:18:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11238v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11238v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11237v1",
    "arxivId": "2510.11237v1",
    "title": "Randomized flexible Krylov methods for $\\ell_p$ regularization",
    "abstract": "The computation of sparse solutions of large-scale linear discrete ill-posed problems remains a computationally demanding task. A powerful framework in this context is the use of iteratively reweighted schemes, which are based on constructing a sequence of quadratic tangent majorants of the $\\ell_2$-$\\ell_1$ regularization functional (with additional smoothing to ensure differentiability at the origin), and solving them successively. Recently, flexible Krylov-Tikhonov methods have been used to partially solve each problem in the sequence efficiently. However, in order to guarantee convergence, the complexity of the algorithm at each iteration increases with respect to more traditional methods. We propose a randomized flexible Krylov method to alleviate the increase of complexity, which leverages the adaptability of the flexible Krylov subspaces with the efficiency of `sketch-and-solve' methods. A possible caveat of the mentioned methods is their memory requirements. In this case, one needs to rely instead on inner-outer schemes. In these scenarios, we propose a `sketch-to-precondition' method to speed up the convergence of each of the subproblems in the sequence. The performance of these algorithms is shown through a variety of numerical examples.",
    "authors": [
      "Malena Sabaté Landman",
      "Yuji Nakatsukasa"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "65F22, 65K10, 65F10, 68W20"
    ],
    "publishedAt": "2025-10-13T10:18:22.000Z",
    "updatedAt": "2025-10-13T10:18:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11237v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11237v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11236v1",
    "arxivId": "2510.11236v1",
    "title": "XQuant: Achieving Ultra-Low Bit KV Cache Quantization with Cross-Layer Compression",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language processing tasks. However, their extensive memory requirements, particularly due to KV cache growth during long-text understanding and generation, present significant challenges for deployment in resource-constrained environments. Quantization has emerged as a promising solution to reduce memory consumption while preserving historical information. We propose XQuant, a training-free and plug-and-play framework that achieves ultra-low equivalent bit-width KV cache quantization. XQuant introduces two key innovations: a computationally negligible data-free calibration method and cross-layer KV cache compression, enabling quantization to sub-1.4 bits. Extensive experiments on TruthfulQA and LongBench demonstrate that XQuant outperforms state-of-the-art methods (e.g., KIVI-2bit and AsymKV-1.5bit) by achieving lower bit-width while maintaining superior performance, establishing a better trade-off between memory efficiency and model accuracy.",
    "authors": [
      "Haoqi Yang",
      "Yao Yao",
      "Zuchao Li",
      "Baoyuan Qi",
      "Guoming Liu",
      "Hai Zhao"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T10:17:21.000Z",
    "updatedAt": "2025-10-13T10:17:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11236v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11236v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11235v1",
    "arxivId": "2510.11235v1",
    "title": "AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures?",
    "abstract": "AI alignment research aims to develop techniques to ensure that AI systems do not cause harm. However, every alignment technique has failure modes, which are conditions in which there is a non-negligible chance that the technique fails to provide safety. As a strategy for risk mitigation, the AI safety community has increasingly adopted a defense-in-depth framework: Conceding that there is no single technique which guarantees safety, defense-in-depth consists in having multiple redundant protections against safety failure, such that safety can be maintained even if some protections fail. However, the success of defense-in-depth depends on how (un)correlated failure modes are across alignment techniques. For example, if all techniques had the exact same failure modes, the defense-in-depth approach would provide no additional protection at all. In this paper, we analyze 7 representative alignment techniques and 7 failure modes to understand the extent to which they overlap. We then discuss our results' implications for understanding the current level of risk and how to prioritize AI alignment research in the future.",
    "authors": [
      "Leonard Dung",
      "Florian Mai"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T10:16:59.000Z",
    "updatedAt": "2025-10-13T10:16:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11235v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11235v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11234v1",
    "arxivId": "2510.11234v1",
    "title": "Neural Weight Compression for Language Models",
    "abstract": "The efficient storage and transmission of language model weights is becoming increasingly important, as their scale and adoption continue to grow. However, as our understanding of this new data modality is limited, designing a good compression algorithm for language model weights heavily relies on manual, trial-and-error approaches. In this paper, we propose a learned compression framework that trains neural codecs directly from pretrained language model weights. Unlike conventional data (e.g., images), language model weights pose unique challenges: the sizes and shapes of weight tensors vary significantly, and the reconstruction quality must be judged by downstream model predictions rather than na\\\"ive MSE loss. To address this, we introduce Neural Weight Compression (NWC), a novel autoencoder-based neural codec tailored to model weight compression. The proposed method inherits the advantages of autoencoder-based codecs while incorporating three technical components: (1) column-wise tensor chunking and normalization; (2) an importance-aware training loss; (3) an inference-time error compensation mechanism guided by model outputs. Experiments on open-weight language models show that NWC achieves competitive or state-of-the-art accuracy-compression tradeoffs, with particularly strong results at 4-6 bit precisions where accuracy remains nearly on par with FP16 models.",
    "authors": [
      "Jegwang Ryu",
      "Minkyu Kim",
      "Seungjun Shin",
      "Hee Min Choi",
      "Dokwan Oh",
      "Jaeho Lee"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T10:16:20.000Z",
    "updatedAt": "2025-10-13T10:16:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11234v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11234v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11233v1",
    "arxivId": "2510.11233v1",
    "title": "CNSocialDepress: A Chinese Social Media Dataset for Depression Risk Detection and Structured Analysis",
    "abstract": "Depression is a pressing global public health issue, yet publicly available Chinese-language resources for risk detection remain scarce and are mostly limited to binary classification. To address this limitation, we release CNSocialDepress, a benchmark dataset for depression risk detection from Chinese social media posts. The dataset contains 44,178 texts from 233 users, within which psychological experts annotated 10,306 depression-related segments. CNSocialDepress provides binary risk labels together with structured multi-dimensional psychological attributes, enabling interpretable and fine-grained analysis of depressive signals. Experimental results demonstrate its utility across a wide range of NLP tasks, including structured psychological profiling and fine-tuning of large language models for depression detection. Comprehensive evaluations highlight the dataset's effectiveness and practical value for depression risk identification and psychological analysis, thereby providing insights to mental health applications tailored for Chinese-speaking populations.",
    "authors": [
      "Jinyuan Xu",
      "Tian Lan",
      "Xintao Yu",
      "Xue He",
      "Hezhi Zhang",
      "Ying Wang",
      "Pierre Magistry",
      "Mathieu Valette",
      "Lei Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T10:14:18.000Z",
    "updatedAt": "2025-10-13T10:14:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11233v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11233v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11232v1",
    "arxivId": "2510.11232v1",
    "title": "LightPneumoNet: Lightweight Pneumonia Classifier",
    "abstract": "Effective pneumonia diagnosis is often challenged by the difficulty of deploying large, computationally expensive deep learning models in resource-limited settings. This study introduces LightPneumoNet, an efficient, lightweight convolutional neural network (CNN) built from scratch to provide an accessible and accurate diagnostic solution for pneumonia detection from chest X-rays. Our model was trained on a public dataset of 5,856 chest X-ray images. Preprocessing included image resizing to 224x224, grayscale conversion, and pixel normalization, with data augmentation (rotation, zoom, shear) to prevent overfitting. The custom architecture features four blocks of stacked convolutional layers and contains only 388,082 trainable parameters, resulting in a minimal 1.48 MB memory footprint. On the independent test set, our model delivered exceptional performance, achieving an overall accuracy of 0.942, precision of 0.92, and an F1-Score of 0.96. Critically, it obtained a sensitivity (recall) of 0.99, demonstrating a near-perfect ability to identify true pneumonia cases and minimize clinically significant false negatives. Notably, LightPneumoNet achieves this high recall on the same dataset where existing approaches typically require significantly heavier architectures or fail to reach comparable sensitivity levels. The model's efficiency enables deployment on low-cost hardware, making advanced computer-aided diagnosis accessible in underserved clinics and serving as a reliable second-opinion tool to improve patient outcomes.",
    "authors": [
      "Neilansh Chauhan",
      "Piyush Kumar Gupta",
      "Faraz Doja"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T10:14:17.000Z",
    "updatedAt": "2025-10-13T10:14:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11232v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11232v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11227v1",
    "arxivId": "2510.11227v1",
    "title": "Enforcing convex constraints in Graph Neural Networks",
    "abstract": "Many machine learning applications require outputs that satisfy complex, dynamic constraints. This task is particularly challenging in Graph Neural Network models due to the variable output sizes of graph-structured data. In this paper, we introduce ProjNet, a Graph Neural Network framework which satisfies input-dependant constraints. ProjNet combines a sparse vector clipping method with the Component-Averaged Dykstra (CAD) algorithm, an iterative scheme for solving the best-approximation problem. We establish a convergence result for CAD and develop a GPU-accelerated implementation capable of handling large-scale inputs efficiently. To enable end-to-end training, we introduce a surrogate gradient for CAD that is both computationally efficient and better suited for optimization than the exact gradient. We validate ProjNet on four classes of constrained optimisation problems: linear programming, two classes of non-convex quadratic programs, and radio transmit power optimization, demonstrating its effectiveness across diverse problem settings.",
    "authors": [
      "Ahmed Rashwan",
      "Keith Briggs",
      "Chris Budd",
      "Lisa Kreusser"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T10:10:46.000Z",
    "updatedAt": "2025-10-13T10:10:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11227v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11227v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11225v1",
    "arxivId": "2510.11225v1",
    "title": "A Theorem-Proving-Based Evaluation of Neural Semantic Parsing",
    "abstract": "Graph-matching metrics such as Smatch are the de facto standard for evaluating neural semantic parsers, yet they capture surface overlap rather than logical equivalence. We reassess evaluation by pairing graph-matching with automated theorem proving. We compare two approaches to building parsers: supervised fine-tuning (T5-Small/Base) and few-shot in-context learning (GPT-4o/4.1/5), under normalized and unnormalized targets. We evaluate outputs using graph-matching, bidirectional entailment between source and target formulas with a first-order logic theorem prover, and well-formedness. Across settings, we find that models performing well on graph-matching often fail to produce logically equivalent formulas. Normalization reduces incidental target variability, improves well-formedness, and strengthens logical adequacy. Error analysis shows performance degrades with increasing formula complexity and with coordination, prepositional phrases, and passive voice; the dominant failures involve variable binding and indexing, and predicate naming. These findings highlight limits of graph-based metrics for reasoning-oriented applications and motivate logic-sensitive evaluation and training objectives together with simplified, normalized target representations. All code and data for our experiments are publicly available.",
    "authors": [
      "Hayate Funakura",
      "Hyunsoo Kim",
      "Koji Mineshima"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T10:09:38.000Z",
    "updatedAt": "2025-10-13T10:09:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11225v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11225v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11224v1",
    "arxivId": "2510.11224v1",
    "title": "MPCitH-based Signatures from Restricted Decoding Problems",
    "abstract": "Threshold-Computation-in-the-Head (TCitH) and VOLE-in-the-Head (VOLEitH), two recent developments of the MPC-in-the-Head (MPCitH) paradigm, have significantly improved the performance of digital signature schemes in this framework. In this note, we embed the restricted decoding problem within these frameworks. We propose a structurally simple modeling that achieves competitive signature sizes. Specifically, by instantiating the restricted decoding problem with the same hardness assumption underlying CROSS, we reduce sizes by more than a factor of two compared to the NIST submission. Moreover, we observe that ternary full-weight decoding, closely related to the hardness assumption underlying WAVE, is a restricted decoding problem. Using ternary full-weight decoding, we obtain signature sizes comparable to the smallest MPCitH-based candidates in the NIST competition.",
    "authors": [
      "Michele Battagliola",
      "Sebastian Bitzer",
      "Antonia Wachter-Zeh",
      "Violetta Weger"
    ],
    "categories": [
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T10:09:32.000Z",
    "updatedAt": "2025-10-13T10:09:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11224v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11224v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11223v1",
    "arxivId": "2510.11223v1",
    "title": "Investigating Identity Signals in Conversational Facial Dynamics via Disentangled Expression Features",
    "abstract": "This work investigates whether individuals can be identified solely through the pure dynamical components of their facial expressions, independent of static facial appearance. We leverage the FLAME 3D morphable model to achieve explicit disentanglement between facial shape and expression dynamics, extracting frame-by-frame parameters from conversational videos while retaining only expression and jaw coefficients. On the CANDOR dataset of 1,429 speakers in naturalistic conversations, our Conformer model with supervised contrastive learning achieves 61.14\\%accuracy on 1,429-way classification -- 458 times above chance -- demonstrating that facial dynamics carry strong identity signatures. We introduce a drift-to-noise ratio (DNR) that quantifies the reliability of shape expression separation by measuring across-session shape changes relative to within-session variability. DNR strongly negatively correlates with recognition performance, confirming that unstable shape estimation compromises dynamic identification. Our findings reveal person-specific signatures in conversational facial dynamics, with implications for social perception and clinical assessment.",
    "authors": [
      "Masoumeh Chapariniya",
      "Pierre Vuillecard",
      "Jean-Marc Odobez",
      "Volker Dellwo",
      "Teodora Vukovic"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T10:06:25.000Z",
    "updatedAt": "2025-10-13T10:06:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11223v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11223v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11222v1",
    "arxivId": "2510.11222v1",
    "title": "Fairness Metric Design Exploration in Multi-Domain Moral Sentiment Classification using Transformer-Based Models",
    "abstract": "Ensuring fairness in natural language processing for moral sentiment classification is challenging, particularly under cross-domain shifts where transformer models are increasingly deployed. Using the Moral Foundations Twitter Corpus (MFTC) and Moral Foundations Reddit Corpus (MFRC), this work evaluates BERT and DistilBERT in a multi-label setting with in-domain and cross-domain protocols. Aggregate performance can mask disparities: we observe pronounced asymmetry in transfer, with Twitter->Reddit degrading micro-F1 by 14.9% versus only 1.5% for Reddit->Twitter. Per-label analysis reveals fairness violations hidden by overall scores; notably, the authority label exhibits Demographic Parity Differences of 0.22-0.23 and Equalized Odds Differences of 0.40-0.41. To address this gap, we introduce the Moral Fairness Consistency (MFC) metric, which quantifies the cross-domain stability of moral foundation detection. MFC shows strong empirical validity, achieving a perfect negative correlation with Demographic Parity Difference (rho = -1.000, p < 0.001) while remaining independent of standard performance metrics. Across labels, loyalty demonstrates the highest consistency (MFC = 0.96) and authority the lowest (MFC = 0.78). These findings establish MFC as a complementary, diagnosis-oriented metric for fairness-aware evaluation of moral reasoning models, enabling more reliable deployment across heterogeneous linguistic contexts. .",
    "authors": [
      "Battemuulen Naranbat",
      "Seyed Sahand Mohammadi Ziabari",
      "Yousuf Nasser Al Husaini",
      "Ali Mohammed Mansoor Alsahag"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T10:05:57.000Z",
    "updatedAt": "2025-10-13T10:05:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11222v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11222v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11221v1",
    "arxivId": "2510.11221v1",
    "title": "WebRouter: Query-specific Router via Variational Information Bottleneck for Cost-sensitive Web Agent",
    "abstract": "LLM-brained web agents offer powerful capabilities for web automation but face a critical cost-performance trade-off. The challenge is amplified by web agents' inherently complex prompts that include goals, action histories, and environmental states, leading to degraded LLM ensemble performance. To address this, we introduce WebRouter, a novel query-specific router trained from an information-theoretic perspective. Our core contribution is a cost-aware Variational Information Bottleneck (ca-VIB) objective, which learns a compressed representation of the input prompt while explicitly penalizing the expected operational cost. Experiments on five real-world websites from the WebVoyager benchmark show that WebRouter reduces operational costs by a striking 87.8\\% compared to a GPT-4o baseline, while incurring only a 3.8\\% accuracy drop.",
    "authors": [
      "Tao Li",
      "Jinlong Hu",
      "Yang Wang",
      "Junfeng Liu",
      "Xuejun Liu"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T10:05:43.000Z",
    "updatedAt": "2025-10-13T10:05:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11221v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11221v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11218v1",
    "arxivId": "2510.11218v1",
    "title": "The Curious Case of Factual (Mis)Alignment between LLMs' Short- and Long-Form Answers",
    "abstract": "Large language models (LLMs) can correctly answer \"When was Einstein born?\" yet fail to provide the same date when writing about Einstein's life revealing a fundamental inconsistency in how models access factual knowledge across task complexities. While models display impressive accuracy on factual question-answering benchmarks, the reliability gap between simple and complex queries remains poorly understood, eroding their trustworthiness. In this work, we introduce Short-Long Form Alignment for Factual Question Answering (SLAQ), a controlled evaluation framework that compares LLMs' answers to the same factual questions asked (a) in isolation (short) vs. (b) integrated into complex queries (long). Looking at 16 LLMs across 600 queries, we find a systematic misalignment of answers to the corresponding short and long queries. We further uncover position-dependent accuracy loss and momentum effects where consecutive correct or incorrect answers create self-reinforcing patterns. Through mechanistic analysis, we find that aligned facts activate overlapping model internals, and that metrics based on mechanistic similarity can predict short-long answer alignment with up to 78% accuracy. Our work establishes factual consistency over query complexity as an important aspect of LLMs' trustworthiness and challenges current evaluation practices, which implicitly assume that good performance for simple factual queries implies reliability in more complex knowledge-seeking tasks too.",
    "authors": [
      "Saad Obaid ul Islam",
      "Anne Lauscher",
      "Goran Glavaš"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T10:00:58.000Z",
    "updatedAt": "2025-10-13T10:00:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11218v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11218v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11217v1",
    "arxivId": "2510.11217v1",
    "title": "Domain-Specific Data Generation Framework for RAG Adaptation",
    "abstract": "Retrieval-Augmented Generation (RAG) combines the language understanding and reasoning power of large language models (LLMs) with external retrieval to enable domain-grounded responses. Effectively adapting RAG systems to domain-specific settings requires specialized, context-rich training data beyond general-purpose question-answering. Here, we propose RAGen, a scalable and modular framework for generating domain-grounded question-answer-context (QAC) triples tailored to diverse RAG adaptation approaches. RAGen produces these QAC triples by identifying key concepts in documents, generating diverse questions guided by Bloom's Taxonomy-inspired principles, and pairing them with precise answers extracted from relevant contexts. RAGen supports multiple RAG adaptation strategies, including the optimization of key components such as the LLM, retriever, and embedding model, etc. Its modular pipeline features semantic chunking, hierarchical concept extraction, and multi-chunk retrieval, along with the introduction of curated distractor contexts to promote robust reasoning. Designed for scalability, RAGen efficiently handles large and evolving document corpora without redundant processing, making it especially suitable for dynamic evolving domains such as scientific research and enterprise knowledge bases.",
    "authors": [
      "Chris Xing Tian",
      "Weihao Xie",
      "Zhen Chen",
      "Zhengyuan Yi",
      "Hui Liu",
      "Haoliang Li",
      "Shiqi Wang",
      "Siwei Ma"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T09:59:49.000Z",
    "updatedAt": "2025-10-13T09:59:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11217v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11217v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11214v1",
    "arxivId": "2510.11214v1",
    "title": "CSI Prediction Using Diffusion Models",
    "abstract": "Acquiring accurate channel state information (CSI) is critical for reliable and efficient wireless communication, but challenges such as high pilot overhead and channel aging hinder timely and accurate CSI acquisition. CSI prediction, which forecasts future CSI from historical observations, offers a promising solution. Recent deep learning approaches, including recurrent neural networks and Transformers, have achieved notable success but typically learn deterministic mappings, limiting their ability to capture the stochastic and multimodal nature of wireless channels. In this paper, we introduce a novel probabilistic framework for CSI prediction based on diffusion models, offering a flexible design that supports integration of diverse prediction schemes. We decompose the CSI prediction task into two components: a temporal encoder, which extracts channel dynamics, and a diffusion-based generator, which produces future CSI samples. We investigate two inference schemes-autoregressive and sequence-to-sequence- and explore multiple diffusion backbones, including U-Net and Transformer-based architectures. Furthermore, we examine a diffusion-based approach without an explicit temporal encoder and utilize the DDIM scheduling to reduce model complexity. Extensive simulations demonstrate that our diffusion-based models significantly outperform state-of-the-art baselines.",
    "authors": [
      "Mehdi Sattari",
      "Javad Aliakbari",
      "Alexandre Graell i Amat",
      "Tommy Svensson"
    ],
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T09:50:51.000Z",
    "updatedAt": "2025-10-13T09:50:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11214v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11214v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11212v1",
    "arxivId": "2510.11212v1",
    "title": "Gröbner Bases Native to Term-ordered Commutative Algebras, with Application to the Hodge Algebra of Minors",
    "abstract": "Motivated by better understanding the bideterminant (=product of minors) basis on the polynomial ring in $n \\times m$ variables, we develop theory \\& algorithms for Gr\\\"obner bases in not only algebras with straightening law (ASLs or Hodge algebras), but in any commutative algebra over a field that comes equipped with a notion of \"monomial\" (generalizing the standard monomials of ASLs) and a suitable term order. Rather than treating such an algebra $A$ as a quotient of a polynomial ring and then \"lifting\" ideals from $A$ to ideals in the polynomial ring, the theory we develop is entirely \"native\" to $A$ and its given notion of monomial. When applied to the case of bideterminants, this enables us to package several standard results on bideterminants in a clean way that enables new results. In particular, once the theory is set up, it lets us give an almost-trivial proof of a universal Gr\\\"obner basis (in our sense) for the ideal of $t$-minors for any $t$. We note that here it was crucial that theory be native to $A$ and its given monomial structure, as in the standard monomial structure given by bideterminants each $t$-minor is a single variable rather than a sum of $t!$ many terms (in the \"ordinary monomial\" structure).",
    "authors": [
      "Joshua A. Grochow",
      "Abhiram Natarajan"
    ],
    "categories": [
      "math.AC",
      "cs.SC",
      "math.AG",
      "math.RA"
    ],
    "publishedAt": "2025-10-13T09:46:33.000Z",
    "updatedAt": "2025-10-13T09:46:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11212v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11212v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11211v1",
    "arxivId": "2510.11211v1",
    "title": "An Explorative Study on Distributed Computing Techniques in Training and Inference of Large Language Models",
    "abstract": "Large language models (LLM) are advanced AI systems trained on extensive textual data, leveraging deep learning techniques to understand and generate human-like language. Today's LLMs with billions of parameters are so huge that hardly any single computing node can train, fine-tune, or infer from them. Therefore, several distributed computing techniques are being introduced in the literature to properly utilize LLMs. We have explored the application of distributed computing techniques in LLMs from two angles. \\begin{itemize} \\item We study the techniques that democratize the LLM, that is, how large models can be run on consumer-grade computers. Here, we also implement a novel metaheuristics-based modification to an existing system. \\item We perform a comparative study on three state-of-the-art LLM serving techniques. \\end{itemize}",
    "authors": [
      "Sheikh Azizul Hakim",
      "Saem Hasan"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-13T09:46:12.000Z",
    "updatedAt": "2025-10-13T09:46:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11211v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11211v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11210v1",
    "arxivId": "2510.11210v1",
    "title": "Discursive Circuits: How Do Language Models Understand Discourse Relations?",
    "abstract": "Which components in transformer language models are responsible for discourse understanding? We hypothesize that sparse computational graphs, termed as discursive circuits, control how models process discourse relations. Unlike simpler tasks, discourse relations involve longer spans and complex reasoning. To make circuit discovery feasible, we introduce a task called Completion under Discourse Relation (CuDR), where a model completes a discourse given a specified relation. To support this task, we construct a corpus of minimal contrastive pairs tailored for activation patching in circuit discovery. Experiments show that sparse circuits ($\\approx 0.2\\%$ of a full GPT-2 model) recover discourse understanding in the English PDTB-based CuDR task. These circuits generalize well to unseen discourse frameworks such as RST and SDRT. Further analysis shows lower layers capture linguistic features such as lexical semantics and coreference, while upper layers encode discourse-level abstractions. Feature utility is consistent across frameworks (e.g., coreference supports Expansion-like relations).",
    "authors": [
      "Yisong Miao",
      "Min-Yen Kan"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T09:45:49.000Z",
    "updatedAt": "2025-10-13T09:45:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11210v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11210v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11209v1",
    "arxivId": "2510.11209v1",
    "title": "Cross-Scale Reservoir Computing for large spatio-temporal forecasting and modeling",
    "abstract": "We propose a new reservoir computing method for forecasting high-resolution spatiotemporal datasets. By combining multi-resolution inputs from coarser to finer layers, our architecture better captures both local and global dynamics. Applied to Sea Surface Temperature data, it outperforms standard parallel reservoir models in long-term forecasting, demonstrating the effectiveness of cross-layers coupling in improving predictive accuracy. Finally, we show that the optimal network dynamics in each layer become increasingly linear, revealing the slow modes propagated to subsequent layers.",
    "authors": [
      "Nicola Alboré",
      "Gabriele Di Antonio",
      "Fabrizio Coccetti",
      "Andrea Gabrielli"
    ],
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "publishedAt": "2025-10-13T09:43:29.000Z",
    "updatedAt": "2025-10-13T09:43:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11209v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11209v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11204v1",
    "arxivId": "2510.11204v1",
    "title": "Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos",
    "abstract": "The recent growth in the consumption of online media by children during early childhood necessitates data-driven tools enabling educators to filter out appropriate educational content for young learners. This paper presents an approach for detecting educational content in online videos. We focus on two widely used educational content classes: literacy and math. For each class, we choose prominent codes (sub-classes) based on the Common Core Standards. For example, literacy codes include `letter names', `letter sounds', and math codes include `counting', `sorting'. We pose this as a fine-grained multilabel classification problem as videos can contain multiple types of educational content and the content classes can get visually similar (e.g., `letter names' vs `letter sounds'). We propose a novel class prototypes based supervised contrastive learning approach that can handle fine-grained samples associated with multiple labels. We learn a class prototype for each class and a loss function is employed to minimize the distances between a class prototype and the samples from the class. Similarly, distances between a class prototype and the samples from other classes are maximized. As the alignment between visual and audio cues are crucial for effective comprehension, we consider a multimodal transformer network to capture the interaction between visual and audio cues in videos while learning the embedding for videos. For evaluation, we present a dataset, APPROVE, employing educational videos from YouTube labeled with fine-grained education classes by education researchers. APPROVE consists of 193 hours of expert-annotated videos with 19 classes. The proposed approach outperforms strong baselines on APPROVE and other benchmarks such as Youtube-8M, and COIN. The dataset is available at https://github.com/rohit-gupta/MMContrast/tree/main/APPROVE",
    "authors": [
      "Rohit Gupta",
      "Anirban Roy",
      "Claire Christensen",
      "Sujeong Kim",
      "Sarah Gerard",
      "Madeline Cincebeaux",
      "Ajay Divakaran",
      "Todd Grindal",
      "Mubarak Shah"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:36:26.000Z",
    "updatedAt": "2025-10-13T09:36:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11204v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11204v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11203v1",
    "arxivId": "2510.11203v1",
    "title": "TraceAegis: Securing LLM-Based Agents via Hierarchical and Behavioral Anomaly Detection",
    "abstract": "LLM-based agents have demonstrated promising adaptability in real-world applications. However, these agents remain vulnerable to a wide range of attacks, such as tool poisoning and malicious instructions, that compromise their execution flow and can lead to serious consequences like data breaches and financial loss. Existing studies typically attempt to mitigate such anomalies by predefining specific rules and enforcing them at runtime to enhance safety. Yet, designing comprehensive rules is difficult, requiring extensive manual effort and still leaving gaps that result in false negatives. As agent systems evolve into complex software systems, we take inspiration from software system security and propose TraceAegis, a provenance-based analysis framework that leverages agent execution traces to detect potential anomalies. In particular, TraceAegis constructs a hierarchical structure to abstract stable execution units that characterize normal agent behaviors. These units are then summarized into constrained behavioral rules that specify the conditions necessary to complete a task. By validating execution traces against both hierarchical and behavioral constraints, TraceAegis is able to effectively detect abnormal behaviors. To evaluate the effectiveness of TraceAegis, we introduce TraceAegis-Bench, a dataset covering two representative scenarios: healthcare and corporate procurement. Each scenario includes 1,300 benign behaviors and 300 abnormal behaviors, where the anomalies either violate the agent's execution order or break the semantic consistency of its execution sequence. Experimental results demonstrate that TraceAegis achieves strong performance on TraceAegis-Bench, successfully identifying the majority of abnormal behaviors.",
    "authors": [
      "Jiahao Liu",
      "Bonan Ruan",
      "Xianglin Yang",
      "Zhiwei Lin",
      "Yan Liu",
      "Yang Wang",
      "Tao Wei",
      "Zhenkai Liang"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T09:35:06.000Z",
    "updatedAt": "2025-10-13T09:35:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11203v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11203v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11202v1",
    "arxivId": "2510.11202v1",
    "title": "Evaluating Line-level Localization Ability of Learning-based Code Vulnerability Detection Models",
    "abstract": "To address the extremely concerning problem of software vulnerability, system security is often entrusted to Machine Learning (ML) algorithms. Despite their now established detection capabilities, such models are limited by design to flagging the entire input source code function as vulnerable, rather than precisely localizing the concerned code lines. However, the detection granularity is crucial to support human operators during software development, ensuring that such predictions reflect the true code semantics to help debug, evaluate, and fix the detected vulnerabilities. To address this issue, recent work made progress toward improving the detector's localization ability, thus narrowing down the vulnerability detection \"window\" and providing more fine-grained predictions. Such approaches, however, implicitly disregard the presence of spurious correlations and biases in the data, which often predominantly influence the performance of ML algorithms. In this work, we investigate how detectors comply with this requirement by proposing an explainability-based evaluation procedure. Our approach, defined as Detection Alignment (DA), quantifies the agreement between the input source code lines that most influence the prediction and the actual localization of the vulnerability as per the ground truth. Through DA, which is model-agnostic and adaptable to different detection tasks, not limited to our use case, we analyze multiple learning-based vulnerability detectors and datasets. As a result, we show how the predictions of such models are consistently biased by non-vulnerable lines, ultimately highlighting the high impact of biases and spurious correlations. The code is available at https://github.com/pralab/vuln-localization-eval.",
    "authors": [
      "Marco Pintore",
      "Giorgio Piras",
      "Angelo Sotgiu",
      "Maura Pintor",
      "Battista Biggio"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T09:34:40.000Z",
    "updatedAt": "2025-10-13T09:34:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11202v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11202v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11199v1",
    "arxivId": "2510.11199v1",
    "title": "Proceedings Twentieth International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice",
    "abstract": "These are the contributed papers presented at the 20th International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice (LFMTP 2025), at Birmingham, UK on 19 July as a satellite event of the FSCD conference. The program committee for this edition of LFMTP was chaired by Kaustuv Chaudhuri and Daniele Nantes-Sobrinho. More information about LFMTP can be found on https://lfmtp.org.",
    "authors": [
      "Kaustuv Chaudhuri",
      "Daniele Nantes-Sobrinho"
    ],
    "categories": [
      "cs.LO",
      "cs.PL"
    ],
    "publishedAt": "2025-10-13T09:31:16.000Z",
    "updatedAt": "2025-10-13T09:31:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11199v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11199v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11198v1",
    "arxivId": "2510.11198v1",
    "title": "Age of Information-Aware Cognitive Shared Access Networks with Energy Harvesting",
    "abstract": "This study investigates a cognitive shared access network with energy harvesting capabilities operating under Age of Information (AoI) constraints for the primary user. Secondary transmitters are spatially distributed according to a homogeneous Poisson Point Process (PPP), while the primary user is located at a fixed position. The primary transmitter handles bursty packet arrivals, whereas secondary users operate under saturated traffic conditions. To manage interference and energy, two distinct zones are introduced: an energy harvesting zone around the primary transmitter and a guard zone around the primary receiver, within which secondary transmissions are prohibited. Secondary users access the channel probabilistically, with access decisions depending on their current battery state (charged or empty) and their location relative to the guard zone. Our objective is to analyze the primary user's AoI performance under three distinct packet management policies.",
    "authors": [
      "Georgios Smpokos",
      "Dionysis Xenakis",
      "Marios Kountouris",
      "Nikolaos Pappas"
    ],
    "categories": [
      "cs.NI"
    ],
    "publishedAt": "2025-10-13T09:30:53.000Z",
    "updatedAt": "2025-10-13T09:30:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11198v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11198v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11196v1",
    "arxivId": "2510.11196v1",
    "title": "Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations",
    "abstract": "Vision-language models (VLMs) often produce chain-of-thought (CoT) explanations that sound plausible yet fail to reflect the underlying decision process, undermining trust in high-stakes clinical use. Existing evaluations rarely catch this misalignment, prioritizing answer accuracy or adherence to formats. We present a clinically grounded framework for chest X-ray visual question answering (VQA) that probes CoT faithfulness via controlled text and image modifications across three axes: clinical fidelity, causal attribution, and confidence calibration. In a reader study (n=4), evaluator-radiologist correlations fall within the observed inter-radiologist range for all axes, with strong alignment for attribution (Kendall's $\\tau_b=0.670$), moderate alignment for fidelity ($\\tau_b=0.387$), and weak alignment for confidence tone ($\\tau_b=0.091$), which we report with caution. Benchmarking six VLMs shows that answer accuracy and explanation quality are decoupled, acknowledging injected cues does not ensure grounding, and text cues shift explanations more than visual cues. While some open-source models match final answer accuracy, proprietary models score higher on attribution (25.0% vs. 1.4%) and often on fidelity (36.1% vs. 31.7%), highlighting deployment risks and the need to evaluate beyond final answer accuracy.",
    "authors": [
      "Johannes Moll",
      "Markus Graf",
      "Tristan Lemke",
      "Nicolas Lenhart",
      "Daniel Truhn",
      "Jean-Benoit Delbrouck",
      "Jiazhen Pan",
      "Daniel Rueckert",
      "Lisa C. Adams",
      "Keno K. Bressem"
    ],
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:28:22.000Z",
    "updatedAt": "2025-10-13T09:28:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11196v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11196v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11195v1",
    "arxivId": "2510.11195v1",
    "title": "RAG-Pull: Imperceptible Attacks on RAG Systems for Code Generation",
    "abstract": "Retrieval-Augmented Generation (RAG) increases the reliability and trustworthiness of the LLM response and reduces hallucination by eliminating the need for model retraining. It does so by adding external data into the LLM's context. We develop a new class of black-box attack, RAG-Pull, that inserts hidden UTF characters into queries or external code repositories, redirecting retrieval toward malicious code, thereby breaking the models' safety alignment. We observe that query and code perturbations alone can shift retrieval toward attacker-controlled snippets, while combined query-and-target perturbations achieve near-perfect success. Once retrieved, these snippets introduce exploitable vulnerabilities such as remote code execution and SQL injection. RAG-Pull's minimal perturbations can alter the model's safety alignment and increase preference towards unsafe code, therefore opening up a new class of attacks on LLMs.",
    "authors": [
      "Vasilije Stambolic",
      "Aritra Dhar",
      "Lukas Cavigelli"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T09:27:26.000Z",
    "updatedAt": "2025-10-13T09:27:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11195v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11195v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11194v1",
    "arxivId": "2510.11194v1",
    "title": "Aligning Deep Implicit Preferences by Learning to Reason Defensively",
    "abstract": "Personalized alignment is crucial for enabling Large Language Models (LLMs) to engage effectively in user-centric interactions. However, current methods face a dual challenge: they fail to infer users' deep implicit preferences (including unstated goals, semantic context and risk tolerances), and they lack the defensive reasoning required to navigate real-world ambiguity. This cognitive gap leads to responses that are superficial, brittle and short-sighted. To address this, we propose Critique-Driven Reasoning Alignment (CDRA), which reframes alignment from a scalar reward-matching task into a structured reasoning process. First, to bridge the preference inference gap, we introduce the DeepPref benchmark. This dataset, comprising 3000 preference-query pairs across 20 topics, is curated by simulating a multi-faceted cognitive council that produces critique-annotated reasoning chains to deconstruct query semantics and reveal latent risks. Second, to instill defensive reasoning, we introduce the Personalized Generative Process Reward Model (Pers-GenPRM), which frames reward modeling as a personalized reasoning task. It generates a critique chain to evaluate a response's alignment with user preferences before outputting a final score based on this rationale. Ultimately, this interpretable, structured reward signal guides policy model through Critique-Driven Policy Alignment, a process-level online reinforcement learning algorithm integrating both numerical and natural language feedback. Experiments demonstrate that CDRA excels at discovering and aligning with users' true preferences while executing robust reasoning. Our code and dataset are available at https://github.com/Zephyrian-Hugh/Deep-pref.",
    "authors": [
      "Peiming Li",
      "Zhiyuan Hu",
      "Yang Tang",
      "Shiyu Li",
      "Xi Chen"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T09:26:47.000Z",
    "updatedAt": "2025-10-13T09:26:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11194v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11194v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11192v1",
    "arxivId": "2510.11192v1",
    "title": "Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs",
    "abstract": "Structured sparsity enables deploying large language models (LLMs) on resource-constrained systems. Approaches like dense-to-sparse fine-tuning are particularly compelling, achieving remarkable structured sparsity by reducing the model size by over 6.7x, while still maintaining acceptable accuracy. Despite this reduction, LLM inference, especially the decode stage being inherently memory-bound, is extremely expensive on conventional Von-Neumann architectures. Compute-in-memory (CIM) architectures mitigate this by performing computations directly in memory, and when paired with sparse LLMs, enable storing and computing the entire model in memory, eliminating the data movement on the off-chip bus and improving efficiency. Nonetheless, naively mapping sparse matrices onto CIM arrays leads to poor array utilization and diminished computational efficiency. In this paper, we present an automated framework with novel mapping and scheduling strategies to accelerate sparse LLM inference on CIM accelerators. By exploiting block-diagonal sparsity, our approach improves CIM array utilization by over 50%, achieving more than 4x reduction in both memory footprint and the number of required floating-point operations.",
    "authors": [
      "João Paulo Cardoso de Lima",
      "Marc Dietrich",
      "Jeronimo Castrillon",
      "Asif Ali Khan"
    ],
    "categories": [
      "cs.AR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T09:25:48.000Z",
    "updatedAt": "2025-10-13T09:25:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11192v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11192v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11190v1",
    "arxivId": "2510.11190v1",
    "title": "FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models",
    "abstract": "Multimodal large language models (MLLMs) face an inherent trade-off between faithfulness and creativity, as different tasks require varying degrees of associative reasoning. However, existing methods lack the flexibility to modulate this reasoning strength, limiting MLLMs' adaptability across factual and creative scenarios. To bridge this gap, we propose equipping MLLMs with mechanisms that enable flexible control over associative reasoning. We begin by investigating the internal mechanisms underlying associative behavior in MLLMs and find that: (1) middle layers play a pivotal role in shaping model's associative tendencies, (2) modifying representations in these layers effectively regulates associative reasoning strength, and (3) hallucinations can be exploited to derive steering vectors that guide this modulation. Building on these findings, we introduce Flexible Association Control (FlexAC), a lightweight and training-free framework for modulating associative behavior in MLLMs. FlexAC first induces hallucination-guided intermediate representations to encode associative directions. Then, it selects high-association instances to construct effective associative steering vectors, whose strengths are adaptively calibrated to balance creative guidance with output stability. Finally, recognizing the multi-dimensional nature of associative reasoning, FlexAC incorporates task-specific associative vectors derived from a forward pass on a few target-domain samples, enabling models to follow diverse associative directions and better adapt to creative tasks. Notably, our method achieves up to a 5.8x improvement in creativity on Creation-MMBench and a 29% reduction in hallucination rate on CHAIR, surpassing existing baselines and demonstrating its effectiveness in enabling flexible control over associative reasoning in MLLMs. Our code is available at https://github.com/ylhz/FlexAC.",
    "authors": [
      "Shengming Yuan",
      "Xinyu Lyu",
      "Shuailong Wang",
      "Beitao Chen",
      "Jingkuan Song",
      "Lianli Gao"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:22:12.000Z",
    "updatedAt": "2025-10-13T09:22:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11190v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11190v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11189v1",
    "arxivId": "2510.11189v1",
    "title": "A Decentralized Microservice Scheduling Approach Using Service Mesh in Cloud-Edge Systems",
    "abstract": "As microservice-based systems scale across the cloud-edge continuum, traditional centralized scheduling mechanisms increasingly struggle with latency, coordination overhead, and fault tolerance. This paper presents a new architectural direction: leveraging service mesh sidecar proxies as decentralized, in-situ schedulers to enable scalable, low-latency coordination in large-scale, cloud-native environments. We propose embedding lightweight, autonomous scheduling logic into each sidecar, allowing scheduling decisions to be made locally without centralized control. This approach leverages the growing maturity of service mesh infrastructures, which support programmable distributed traffic management. We describe the design of such an architecture and present initial results demonstrating its scalability potential in terms of response time and latency under varying request rates. Rather than delivering a finalized scheduling algorithm, this paper presents a system-level architectural direction and preliminary evidence to support its scalability potential.",
    "authors": [
      "Yangyang Wen",
      "Paul Townend",
      "Per-Olov Östberg",
      "Abel Souza",
      "Clément Courageux-Sudan"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-13T09:21:50.000Z",
    "updatedAt": "2025-10-13T09:21:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11189v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11189v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11188v1",
    "arxivId": "2510.11188v1",
    "title": "Protein as a Second Language for LLMs",
    "abstract": "Deciphering the function of unseen protein sequences is a fundamental challenge with broad scientific impact, yet most existing methods depend on task-specific adapters or large-scale supervised fine-tuning. We introduce the \"Protein-as-Second-Language\" framework, which reformulates amino-acid sequences as sentences in a novel symbolic language that large language models can interpret through contextual exemplars. Our approach adaptively constructs sequence-question-answer triples that reveal functional cues in a zero-shot setting, without any further training. To support this process, we curate a bilingual corpus of 79,926 protein-QA instances spanning attribute prediction, descriptive understanding, and extended reasoning. Empirically, our method delivers consistent gains across diverse open-source LLMs and GPT-4, achieving up to 17.2% ROUGE-L improvement (average +7%) and even surpassing fine-tuned protein-specific language models. These results highlight that generic LLMs, when guided with protein-as-language cues, can outperform domain-specialized models, offering a scalable pathway for protein understanding in foundation models.",
    "authors": [
      "Xinhui Chen",
      "Zuchao Li",
      "Mengqi Gao",
      "Yufeng Zhang",
      "Chak Tou Leong",
      "Haoyang Li",
      "Jiaqi Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "publishedAt": "2025-10-13T09:21:45.000Z",
    "updatedAt": "2025-10-13T09:21:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11188v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11188v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11185v1",
    "arxivId": "2510.11185v1",
    "title": "Principles of Safe AI Companions for Youth: Parent and Expert Perspectives",
    "abstract": "AI companions are increasingly popular among teenagers, yet current platforms lack safeguards to address developmental risks and harmful normalization. Despite growing concerns, little is known about how parents and developmental psychology experts assess these interactions or what protections they consider necessary. We conducted 26 semi structured interviews with parents and experts, who reviewed real world youth GenAI companion conversation snippets. We found that stakeholders assessed risks contextually, attending to factors such as youth maturity, AI character age, and how AI characters modeled values and norms. We also identified distinct logics of assessment: parents flagged single events, such as a mention of suicide or flirtation, as high risk, whereas experts looked for patterns over time, such as repeated references to self harm or sustained dependence. Both groups proposed interventions, with parents favoring broader oversight and experts preferring cautious, crisis-only escalation paired with youth facing safeguards. These findings provide directions for embedding safety into AI companion design.",
    "authors": [
      "Yaman Yu",
      "Mohi",
      "Aishi Debroy",
      "Xin Cao",
      "Karen Rudolph",
      "Yang Wang"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T09:19:22.000Z",
    "updatedAt": "2025-10-13T09:19:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11185v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11185v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11184v1",
    "arxivId": "2510.11184v1",
    "title": "Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?",
    "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in reasoning and tool utilization. However, the generalization of tool-augmented reinforcement learning (RL) across diverse domains remains underexplored. In this work, we investigate the cross-domain generalization of an LLM agent equipped with a code interpreter tool, which is exclusively trained on mathematical problem-solving tasks. Despite the restricted training domain, we evaluate the agent's performance across several distinct reasoning domains. The results reveal that RL-based tool usage learned from mathematical tasks can be effectively transferred to complex tasks in other domains, enabling great task performance and high token efficiency. To facilitate this cross-domain transfer, we propose a Tool Generalization Reinforcement Learning (TGRL) framework designed to promote domain-agnostic learning and skill migration, encompassing: (i) a standardized tool interface that abstracts domain-specific nuances through consistent formatting and explicit termination, fostering transferable invocation patterns; (ii) a dual-component reward system that decomposes rewards to incentivize generalizable behaviors like tool efficiency and reasoning abstraction, ensuring alignment and robustness across domain shifts; and (iii) an XML-based prompt template that separates thinking, tool calls, and responses to encourage modular, domain-invariant planning and coherent multi-turn interactions. Extensive experiments across diverse benchmarks validate our approach, achieving state-of-the-art performance and highlighting the cross-domain potential of Tool RL for LLM reasoning.",
    "authors": [
      "Zhengyu Chen",
      "Jinluan Yang",
      "Teng Xiao",
      "Ruochen Zhou",
      "Luan Zhang",
      "Xiangyu Xi",
      "Xiaowei Shi",
      "Wei Wang",
      "Jinggang Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T09:19:13.000Z",
    "updatedAt": "2025-10-13T09:19:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11184v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11184v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11183v1",
    "arxivId": "2510.11183v1",
    "title": "Saudi Sign Language Translation Using T5",
    "abstract": "This paper explores the application of T5 models for Saudi Sign Language (SSL) translation using a novel dataset. The SSL dataset includes three challenging testing protocols, enabling comprehensive evaluation across different scenarios. Additionally, it captures unique SSL characteristics, such as face coverings, which pose challenges for sign recognition and translation. In our experiments, we investigate the impact of pre-training on American Sign Language (ASL) data by comparing T5 models pre-trained on the YouTubeASL dataset with models trained directly on the SSL dataset. Experimental results demonstrate that pre-training on YouTubeASL significantly improves models' performance (roughly $3\\times$ in BLEU-4), indicating cross-linguistic transferability in sign language models. Our findings highlight the benefits of leveraging large-scale ASL data to improve SSL translation and provide insights into the development of more effective sign language translation systems. Our code is publicly available at our GitHub repository.",
    "authors": [
      "Ali Alhejab",
      "Tomas Zelezny",
      "Lamya Alkanhal",
      "Ivan Gruber",
      "Yazeed Alharbi",
      "Jakub Straka",
      "Vaclav Javorek",
      "Marek Hruz",
      "Badriah Alkalifah",
      "Ahmed Ali"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:18:34.000Z",
    "updatedAt": "2025-10-13T09:18:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11183v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11183v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11182v1",
    "arxivId": "2510.11182v1",
    "title": "Generalisation of automatic tumour segmentation in histopathological whole-slide images across multiple cancer types",
    "abstract": "Deep learning is expected to aid pathologists by automating tasks such as tumour segmentation. We aimed to develop one universal tumour segmentation model for histopathological images and examine its performance in different cancer types. The model was developed using over 20 000 whole-slide images from over 4 000 patients with colorectal, endometrial, lung, or prostate carcinoma. Performance was validated in pre-planned analyses on external cohorts with over 3 000 patients across six cancer types. Exploratory analyses included over 1 500 additional patients from The Cancer Genome Atlas. Average Dice coefficient was over 80% in all validation cohorts with en bloc resection specimens and in The Cancer Genome Atlas cohorts. No loss of performance was observed when comparing the universal model with models specialised on single cancer types. In conclusion, extensive and rigorous evaluations demonstrate that generic tumour segmentation by a single model is possible across cancer types, patient populations, sample preparations, and slide scanners.",
    "authors": [
      "Ole-Johan Skrede",
      "Manohar Pradhan",
      "Maria Xepapadakis Isaksen",
      "Tarjei Sveinsgjerd Hveem",
      "Ljiljana Vlatkovic",
      "Arild Nesbakken",
      "Kristina Lindemann",
      "Gunnar B Kristensen",
      "Jenneke Kasius",
      "Alain G Zeimet",
      "Odd Terje Brustugun",
      "Lill-Tove Rasmussen Busund",
      "Elin H Richardsen",
      "Erik Skaaheim Haug",
      "Bjørn Brennhovd",
      "Emma Rewcastle",
      "Melinda Lillesand",
      "Vebjørn Kvikstad",
      "Emiel Janssen",
      "David J Kerr",
      "Knut Liestøl",
      "Fritz Albregtsen",
      "Andreas Kleppe"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:18:15.000Z",
    "updatedAt": "2025-10-13T09:18:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11182v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11182v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11181v1",
    "arxivId": "2510.11181v1",
    "title": "Utilizing Bayesian Optimization for Timetable-Independent Railway Junction Performance Determination",
    "abstract": "The efficiency of railway infrastructure is significantly influenced by the mix of trains that utilize it, as different service types have competing operational requirements. While freight services might require extended service times, passenger services demand more predictable schedules. Traditional methods for addressing long-term traffic assignment problems often rely on fixed-value capacity limitations, determined based on specific assumptions about traffic composition. This paper introduces a methodology for determining timetable-independent capacity within the traffic rate assignment problem, enabling the calculation of junction capacities under dynamic traffic distributions. We solve the underlying non-linear constrained optimization problem maximizing the traffic throughput using Bayesian optimization (BO). This setting combines a known objective function with expensive- to-compute capacity constraints, motivating an adaption of standard BO problems, where objective functions are usually unknown. We tailor the acquisition process in BO to this specific setting and increase performance by incorporating prior knowledge about the shape of the constraint functions into the Gaussian process surrogate model. Our derived approaches are benchmarked on a railway junction near Paris, significantly outperforming fixed traffic composition models and highlighting the benefits of dynamic capacity allocation.",
    "authors": [
      "Tamme Emunds",
      "Paul Brunzema",
      "Sebastian Trimpe",
      "Nils Nießen"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T09:15:19.000Z",
    "updatedAt": "2025-10-13T09:15:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11181v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11181v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11179v1",
    "arxivId": "2510.11179v1",
    "title": "Interoperability From OpenTelemetry to Kieker: Demonstrated as Export from the Astronomy Shop",
    "abstract": "The observability framework Kieker provides a range of analysis capabilities, but it is currently only able to instrument a smaller selection of languages and technologies, including Java, C, Fortran, and Python. The OpenTelemetry standard aims for providing reference implementations for most programming languages, including C# and JavaScript, that are currently not supported by Kieker. In this work, we describe how to transform OpenTelemetry tracing data into the Kieker framework. Thereby, it becomes possible to create for example call trees from OpenTelemetry instrumentations. We demonstrate the usability of our approach by visualizing trace data of the Astronomy Shop, which is an OpenTelemetry demo application.",
    "authors": [
      "David Georg Reichelt",
      "Shinhyung Yang",
      "Wilhelm Hasselbring"
    ],
    "categories": [
      "cs.SE",
      "astro-ph.IM"
    ],
    "publishedAt": "2025-10-13T09:10:38.000Z",
    "updatedAt": "2025-10-13T09:10:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11179v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11179v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11178v1",
    "arxivId": "2510.11178v1",
    "title": "BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models",
    "abstract": "As vision-language models (VLMs) are deployed globally, their ability to understand culturally situated knowledge becomes essential. Yet, existing evaluations largely assess static recall or isolated visual grounding, leaving unanswered whether VLMs possess robust and transferable cultural understanding. We introduce BLEnD-Vis, a multimodal, multicultural benchmark designed to evaluate the robustness of everyday cultural knowledge in VLMs across linguistic rephrasings and visual modalities. Building on the BLEnD dataset, BLEnD-Vis constructs 313 culturally grounded question templates spanning 16 regions and generates three aligned multiple-choice formats: (i) a text-only baseline querying from Region $\\to$ Entity, (ii) an inverted text-only variant (Entity $\\to$ Region), and (iii) a VQA-style version of (ii) with generated images. The resulting benchmark comprises 4,916 images and over 21,000 multiple-choice question (MCQ) instances, validated through human annotation. BLEnD-Vis reveals significant fragility in current VLM cultural knowledge; models exhibit performance drops under linguistic rephrasing and, whilst visual cues often aid performance, low cross-modal consistency highlights challenges in robustly integrating textual and visual understanding, particularly for lower-resource regions. BLEnD-Vis thus provides a crucial testbed for systematically analysing cultural robustness and multimodal grounding, exposing limitations and guiding the development of more culturally competent VLMs.",
    "authors": [
      "Bryan Chen Zhengyu Tan",
      "Zheng Weihua",
      "Zhengyuan Liu",
      "Nancy F. Chen",
      "Hwaran Lee",
      "Kenny Tsu Wei Choo",
      "Roy Ka-Wei Lee"
    ],
    "categories": [
      "cs.CV",
      "cs.CY"
    ],
    "publishedAt": "2025-10-13T09:10:05.000Z",
    "updatedAt": "2025-10-13T09:10:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11178v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11178v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11176v1",
    "arxivId": "2510.11176v1",
    "title": "G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation",
    "abstract": "Recent studies in pathology foundation models have shown that scaling training data, diversifying cancer types, and increasing model size consistently improve their performance. However, giga-scale foundation models, which are trained on hundreds of thousands of slides covering tens of cancer types and contain billions of parameters, pose significant challenges for practical use due to their tremendous computational costs in both development and deployment. In this work, we present a novel strategy, named the G2L framework, to increase the performance of large-scale foundation models, which consist of only $15\\%$ of the parameters of giga-scale models, to a comparable performance level of giga-scale models in cancer-specific tasks. Our approach applies knowledge distillation, transferring the capabilities of a giga-scale model to a large-scale model, using just 1K pathology slides of a target cancer (e.g., breast, prostate, etc.). The resulting distilled model not only outperformed state-of-the-art models of the same size (i.e., large-scale) across several benchmarks but also, interestingly, surpassed the giga-scale teacher and huge-scale models in some benchmarks. In addition, the distilled model exhibited a higher robustness index, indicating improved resilience to image variations originating from multiple institutions. These findings suggest that the proposed distillation approach for a large-scale model is a data- and parameter-efficient way to achieve giga-scale-level performance for cancer-specific applications without prohibitive computational burden.",
    "authors": [
      "Yesung Cho",
      "Sungmin Lee",
      "Geongyu Lee",
      "Minkyung Lee",
      "Jongbae Park",
      "Dongmyung Shin"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T09:08:59.000Z",
    "updatedAt": "2025-10-13T09:08:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11176v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11176v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11175v1",
    "arxivId": "2510.11175v1",
    "title": "Reliable Cross-modal Alignment via Prototype Iterative Construction",
    "abstract": "Cross-modal alignment is an important multi-modal task, aiming to bridge the semantic gap between different modalities. The most reliable fundamention for achieving this objective lies in the semantic consistency between matched pairs. Conventional methods implicitly assume embeddings contain solely semantic information, ignoring the impact of non-semantic information during alignment, which inevitably leads to information bias or even loss. These non-semantic information primarily manifest as stylistic variations in the data, which we formally define as style information. An intuitive approach is to separate style from semantics, aligning only the semantic information. However, most existing methods distinguish them based on feature columns, which cannot represent the complex coupling relationship between semantic and style information. In this paper, we propose PICO, a novel framework for suppressing style interference during embedding interaction. Specifically, we quantify the probability of each feature column representing semantic information, and regard it as the weight during the embedding interaction. To ensure the reliability of the semantic probability, we propose a prototype iterative construction method. The key operation of this method is a performance feedback-based weighting function, and we have theoretically proven that the function can assign higher weight to prototypes that bring higher performance improvements. Extensive experiments on various benchmarks and model backbones demonstrate the superiority of PICO, outperforming state-of-the-art methods by 5.2\\%-14.1\\%.",
    "authors": [
      "Xiang Ma",
      "Litian Xu",
      "Lexin Fang",
      "Caiming Zhang",
      "Lizhen Cui"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:08:27.000Z",
    "updatedAt": "2025-10-13T09:08:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11175v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11175v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11174v1",
    "arxivId": "2510.11174v1",
    "title": "Machine Learning-Integrated Hybrid Fluid-Kinetic Framework for Quantum Electrodynamic Laser Plasma Simulations",
    "abstract": "High-intensity laser plasma interactions create complex computational problems because they involve both fluid and kinetic regimes, which need models that maintain physical precision while keeping computational speed. The research introduces a machine learning-based three-dimensional hybrid fluid-particle-in-cell (PIC) system, which links relativistic plasma behavior to automatic regime transitions. The technique employs fluid approximations for stable areas but activates the PIC solver when SwitchNet directs it to unstable sections through its training on physics-based synthetic data. The model uses a smooth transition between Ammosov-Delone-Krainov (ADK) tunneling and multiphoton ionization rates to simulate ionization, while Airy-function approximations simulate quantum electrodynamic (QED) effects for radiation reaction and pair production. The convolutional neural network applies energy conservation through physics-based loss functions, which operate on normalized fields per channel. Monte Carlo dropout provides uncertainty measurement. The hybrid model produces precise predictions with coefficient of determination (R^2) values above 0.95 and mean squared errors below 10^-4 for all field components. This adaptive approach enhances the accuracy and scalability of laser-plasma simulations, providing a unified predictive framework for high-energy-density and particle acceleration applications.",
    "authors": [
      "Sadra Saremi",
      "Amirhossein Ahmadkhan Kordbacheh"
    ],
    "categories": [
      "physics.plasm-ph",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T09:07:59.000Z",
    "updatedAt": "2025-10-13T09:07:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11174v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11174v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11173v1",
    "arxivId": "2510.11173v1",
    "title": "CoPRS: Learning Positional Prior from Chain-of-Thought for Reasoning Segmentation",
    "abstract": "Existing works on reasoning segmentation either connect hidden features from a language model directly to a mask decoder or represent positions in text, which limits interpretability and semantic detail. To solve this, we present CoPRS, a Multi-modal Chain-of-Thought (MCoT)-based positional perception model that bridges language reasoning to segmentation through a differentiable and interpretable positional prior instantiated as a heatmap. By making the reasoning process clear via MCoT and expressing it as a dense, differentiable heatmap, this interface enhances interpretability and diagnostic analysis and yields more concentrated evidence on the target. A learnable concentration token aggregates features of the image and reasoning text to generate this positional prior, which is decoded to precise masks through a lightweight decoder, providing a direct connection between reasoning and segmentation. Across the RefCOCO series and ReasonSeg, CoPRS matches or surpasses the best reported metrics on each standard split under comparable protocols, with performance at or above prior state of the art across both validation and test partitions. Extensive experiments reveal that the quality of the heatmap strongly influences the resulting mask quality, supporting a consistent association between the reasoning output and downstream mask generation. Collectively, these findings support the utility of this paradigm in bridging reasoning and segmentation and show advantages in concentration driven by reasoning and predicting masks more precisely. Code, checkpoints and logs are released at https://github.com/ZhenyuLU-Heliodore/CoPRS.git.",
    "authors": [
      "Zhenyu Lu",
      "Liupeng Li",
      "Jinpeng Wang",
      "Yan Feng",
      "Bin Chen",
      "Ke Chen",
      "Yaowei Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "publishedAt": "2025-10-13T09:07:54.000Z",
    "updatedAt": "2025-10-13T09:07:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11173v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11173v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11171v1",
    "arxivId": "2510.11171v1",
    "title": "Multiview Manifold Evidential Fusion for PolSAR Image Classification",
    "abstract": "Polarimetric Synthetic Aperture Radar (PolSAR) covariance matrices and their extracted multi-features - such as scattering angle, entropy, texture, and boundary descriptors - provide complementary and physically interpretable information for image classification. Traditional fusion strategies typically concatenate these features or employ deep learning networks to combine them. However, the covariance matrices and multi-features, as two complementary views, lie on different manifolds with distinct geometric structures. Existing fusion methods also overlook the varying importance of different views and ignore uncertainty, often leading to unreliable predictions. To address these issues, we propose a Multiview Manifold Evidential Fusion (MMEFnet) method to effectively fuse these two views. It gives a new framework to integrate PolSAR manifold learning and evidence fusion into a unified architecture. Specifically, covariance matrices are represented on the Hermitian Positive Definite (HPD) manifold, while multi-features are modeled on the Grassmann manifold. Two different kernel metric learning networks are constructed to learn their manifold representations. Subsequently, a trusted multiview evidence fusion, replacing the conventional softmax classifier, estimates belief mass and quantifies the uncertainty of each view from the learned deep features. Finally, a Dempster-Shafer theory-based fusion strategy combines evidence, enabling a more reliable and interpretable classification. Extensive experiments on three real-world PolSAR datasets demonstrate that the proposed method consistently outperforms existing approaches in accuracy, robustness, and interpretability.",
    "authors": [
      "Junfei Shi",
      "Haojia Zhang",
      "Haiyan Jin",
      "Junhuai Li",
      "Xiaogang Song",
      "Yuanfan Guo",
      "Haonan Su",
      "Weisi Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T09:05:51.000Z",
    "updatedAt": "2025-10-13T09:05:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11171v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11171v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11170v1",
    "arxivId": "2510.11170v1",
    "title": "EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling",
    "abstract": "With the rise of reasoning language models and test-time scaling methods as a paradigm for improving model performance, substantial computation is often required to generate multiple candidate sequences from the same prompt. This enables exploration of different reasoning paths toward the correct solution, however, allocates the same compute budget for each prompt. Grounded on the assumption that different prompts carry different degrees of complexity, and thus different computation needs, we propose EAGer, a training-free generation method that leverages model uncertainty through token-wise entropy distribution to reduce redundant computation and concurrently improve overall performance. EAGer allows branching to multiple reasoning paths only in the presence of high-entropy tokens, and then reallocates the saved compute budget to the instances where exploration of alternative paths is most needed. We find that across multiple open-source models on complex reasoning benchmarks such as AIME 2025, EAGer can reallocate the budget without accessing target labels, achieving the best efficiency-performance trade-off in terms of reasoning length and Pass@k. When target labels are accessible, EAGer generates up to 65% fewer tokens (hence saving compute) and achieves up to 37% improvement in Pass@k compared to the Full Parallel Sampling.",
    "authors": [
      "Daniel Scalena",
      "Leonidas Zotos",
      "Elisabetta Fersini",
      "Malvina Nissim",
      "Ahmet Üstün"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T09:04:28.000Z",
    "updatedAt": "2025-10-13T09:04:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11170v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11170v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11169v1",
    "arxivId": "2510.11169v1",
    "title": "PAC-Bayesian Bounds on Constrained f-Entropic Risk Measures",
    "abstract": "PAC generalization bounds on the risk, when expressed in terms of the expected loss, are often insufficient to capture imbalances between subgroups in the data. To overcome this limitation, we introduce a new family of risk measures, called constrained f-entropic risk measures, which enable finer control over distributional shifts and subgroup imbalances via f-divergences, and include the Conditional Value at Risk (CVaR), a well-known risk measure. We derive both classical and disintegrated PAC-Bayesian generalization bounds for this family of risks, providing the first disintegratedPAC-Bayesian guarantees beyond standard risks. Building on this theory, we design a self-bounding algorithm that minimizes our bounds directly, yielding models with guarantees at the subgroup level. Finally, we empirically demonstrate the usefulness of our approach.",
    "authors": [
      "Hind Atbir",
      "Farah Cherfaoui",
      "Guillaume Metzler",
      "Emilie Morvant",
      "Paul Viallard"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T09:02:13.000Z",
    "updatedAt": "2025-10-13T09:02:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11169v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11169v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11168v1",
    "arxivId": "2510.11168v1",
    "title": "ELMO: Efficiency via Low-precision and Peak Memory Optimization in Large Output Spaces",
    "abstract": "Large output spaces, also referred to as Extreme multilabel classification (XMC), is a setting that arises, e.g., in large-scale tagging and product-to-product recommendation, and is characterized by the number of labels ranging from hundreds of thousands to millions. This means that the linear classification head, usually only a tiny fraction of the overall model, turns into the main driver for compute and memory demand. Current state-of-the-art XMC methods predominantly rely on FP16-FP32 mixed-precision training, which we show can be unstable, and inefficient in terms of memory usage and computational overhead. Meanwhile, existing low-precision methods typically retain higher precision for the classification layer. In this work, we propose ELMO, a pure low-precision training framework for XMC models using BFloat16 and Float8 data types. By leveraging Kahan summation and stochastic rounding, we demonstrate that XMC models can be effectively trained entirely in Float8, without relying on single-precision master weights or tensor scaling. Low-precision training, combined with our proposed memory optimizations -- gradient fusion and chunking -- enables significant reductions in GPU memory usage. For example, we train a 3-million-label XMC model with only 6.6 GiB of GPU memory, compared to the 39.7 GiB required by the optimized SOTA method, Renee without compromising accuracy.",
    "authors": [
      "Jinbin Zhang",
      "Nasib Ullah",
      "Erik Schultheis",
      "Rohit Babbar"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T08:59:13.000Z",
    "updatedAt": "2025-10-13T08:59:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11168v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11168v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11167v1",
    "arxivId": "2510.11167v1",
    "title": "Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for Low-Resource Iberian Languages",
    "abstract": "Hate speech poses a serious threat to social cohesion and individual well-being, particularly on social media, where it spreads rapidly. While research on hate speech detection has progressed, it remains largely focused on English, resulting in limited resources and benchmarks for low-resource languages. Moreover, many of these languages have multiple linguistic varieties, a factor often overlooked in current approaches. At the same time, large language models require substantial amounts of data to perform reliably, a requirement that low-resource languages often cannot meet. In this work, we address these gaps by compiling a meta-collection of hate speech datasets for European Spanish, standardised with unified labels and metadata. This collection is based on a systematic analysis and integration of existing resources, aiming to bridge the data gap and support more consistent and scalable hate speech detection. We extended this collection by translating it into European Portuguese and into a Galician standard that is more convergent with Spanish and another Galician variant that is more convergent with Portuguese, creating aligned multilingual corpora. Using these resources, we establish new benchmarks for hate speech detection in Iberian languages. We evaluate state-of-the-art large language models in zero-shot, few-shot, and fine-tuning settings, providing baseline results for future research. Moreover, we perform a cross-lingual analysis with our target languages. Our findings underscore the importance of multilingual and variety-aware approaches in hate speech detection and offer a foundation for improved benchmarking in underrepresented European languages.",
    "authors": [
      "Paloma Piot",
      "José Ramom Pichel Campos",
      "Javier Parapar"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T08:58:02.000Z",
    "updatedAt": "2025-10-13T08:58:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11167v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11167v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11166v1",
    "arxivId": "2510.11166v1",
    "title": "Poseidon: A OneGraph Engine",
    "abstract": "We present the Poseidon engine behind the Neptune Analytics graph database service. Customers interact with Poseidon using the declarative openCypher query language, which enables requests that seamlessly combine traditional querying paradigms (such as graph pattern matching, variable length paths, aggregation) with algorithm invocations and has been syntactically extended to facilitate OneGraph interoperability, such as the disambiguation between globally unique IRIs (as exposed via RDF) vs. local identifiers (as encountered in LPG data). Poseidon supports a broad range of graph workloads, from simple transactions, to top-k beam search algorithms on dynamic graphs, to whole graph analytics requiring multiple full passes over the data. For example, real-time fraud detection, like many other use cases, needs to reflect current committed state of the dynamic graph. If a users cell phone is compromised, then all newer actions by that user become immediately suspect. To address such dynamic graph use cases, Poseidon combines state-of-the-art transaction processing with novel graph data indexing, including lock-free maintenance of adjacency lists, secondary succinct indices, partitioned heaps for data tuple storage with uniform placement, and innovative statistics for cost-based query optimization. The Poseidon engine uses a logical log for durability, enabling rapid evolution of in-memory data structures. Bulk data loads achieve more than 10 million property values per second on many data sets while simple transactions can execute in under 20ms against the storage engine.",
    "authors": [
      "Brad Bebee",
      "Ümit V. Çatalyürek",
      "Olaf Hartig",
      "Ankesh Khandelwal",
      "Simone Rondelli",
      "Michael Schmidt",
      "Lefteris Sidirourgos",
      "Bryan Thompson"
    ],
    "categories": [
      "cs.DB"
    ],
    "publishedAt": "2025-10-13T08:56:23.000Z",
    "updatedAt": "2025-10-13T08:56:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11166v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11166v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11164v1",
    "arxivId": "2510.11164v1",
    "title": "Beyond single-model XAI: aggregating multi-model explanations for enhanced trustworthiness",
    "abstract": "The use of Artificial Intelligence (AI) models in real-world and high-risk applications has intensified the discussion about their trustworthiness and ethical usage, from both a technical and a legislative perspective. The field of eXplainable Artificial Intelligence (XAI) addresses this challenge by proposing explanations that bring to light the decision-making processes of complex black-box models. Despite being an essential property, the robustness of explanations is often an overlooked aspect during development: only robust explanation methods can increase the trust in the system as a whole. This paper investigates the role of robustness through the usage of a feature importance aggregation derived from multiple models ($k$-nearest neighbours, random forest and neural networks). Preliminary results showcase the potential in increasing the trustworthiness of the application, while leveraging multiple model's predictive power.",
    "authors": [
      "Ilaria Vascotto",
      "Alex Rodriguez",
      "Alessandro Bonaita",
      "Luca Bortolussi"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T08:55:45.000Z",
    "updatedAt": "2025-10-13T08:55:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11164v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11164v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11162v1",
    "arxivId": "2510.11162v1",
    "title": "Emergence of hybrid computational dynamics through reinforcement learning",
    "abstract": "Understanding how learning algorithms shape the computational strategies that emerge in neural networks remains a fundamental challenge in machine intelligence. While network architectures receive extensive attention, the role of the learning paradigm itself in determining emergent dynamics remains largely unexplored. Here we demonstrate that reinforcement learning (RL) and supervised learning (SL) drive recurrent neural networks (RNNs) toward fundamentally different computational solutions when trained on identical decision-making tasks. Through systematic dynamical systems analysis, we reveal that RL spontaneously discovers hybrid attractor architectures, combining stable fixed-point attractors for decision maintenance with quasi-periodic attractors for flexible evidence integration. This contrasts sharply with SL, which converges almost exclusively to simpler fixed-point-only solutions. We further show that RL sculpts functionally balanced neural populations through a powerful form of implicit regularization -- a structural signature that enhances robustness and is conspicuously absent in the more heterogeneous solutions found by SL-trained networks. The prevalence of these complex dynamics in RL is controllably modulated by weight initialization and correlates strongly with performance gains, particularly as task complexity increases. Our results establish the learning algorithm as a primary determinant of emergent computation, revealing how reward-based optimization autonomously discovers sophisticated dynamical mechanisms that are less accessible to direct gradient-based optimization. These findings provide both mechanistic insights into neural computation and actionable principles for designing adaptive AI systems.",
    "authors": [
      "Roman A. Kononov",
      "Nikita A. Pospelov",
      "Konstantin V. Anokhin",
      "Vladimir V. Nekorkin",
      "Oleg V. Maslennikov"
    ],
    "categories": [
      "cs.LG",
      "cs.NE",
      "nlin.AO",
      "q-bio.NC"
    ],
    "publishedAt": "2025-10-13T08:53:59.000Z",
    "updatedAt": "2025-10-13T08:53:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11162v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11162v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11160v1",
    "arxivId": "2510.11160v1",
    "title": "One Size Does Not Fit All: Exploring Variable Thresholds for Distance-Based Multi-Label Text Classification",
    "abstract": "Distance-based unsupervised text classification is a method within text classification that leverages the semantic similarity between a label and a text to determine label relevance. This method provides numerous benefits, including fast inference and adaptability to expanding label sets, as opposed to zero-shot, few-shot, and fine-tuned neural networks that require re-training in such cases. In multi-label distance-based classification and information retrieval algorithms, thresholds are required to determine whether a text instance is \"similar\" to a label or query. Similarity between a text and label is determined in a dense embedding space, usually generated by state-of-the-art sentence encoders. Multi-label classification complicates matters, as a text instance can have multiple true labels, unlike in multi-class or binary classification, where each instance is assigned only one label. We expand upon previous literature on this underexplored topic by thoroughly examining and evaluating the ability of sentence encoders to perform distance-based classification. First, we perform an exploratory study to verify whether the semantic relationships between texts and labels vary across models, datasets, and label sets by conducting experiments on a diverse collection of realistic multi-label text classification (MLTC) datasets. We find that similarity distributions show statistically significant differences across models, datasets and even label sets. We propose a novel method for optimizing label-specific thresholds using a validation set. Our label-specific thresholding method achieves an average improvement of 46% over normalized 0.5 thresholding and outperforms uniform thresholding approaches from previous work by an average of 14%. Additionally, the method demonstrates strong performance even with limited labeled examples.",
    "authors": [
      "Jens Van Nooten",
      "Andriy Kosar",
      "Guy De Pauw",
      "Walter Daelemans"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T08:52:14.000Z",
    "updatedAt": "2025-10-13T08:52:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11160v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11160v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11153v1",
    "arxivId": "2510.11153v1",
    "title": "Hot-Starting Quantum Portfolio Optimization",
    "abstract": "Combinatorial optimization with a smooth and convex objective function arises naturally in applications such as discrete mean-variance portfolio optimization, where assets must be traded in integer quantities. Although optimal solutions to the associated smooth problem can be computed efficiently, existing adiabatic quantum optimization methods cannot leverage this information. Moreover, while various warm-starting strategies have been proposed for gate-based quantum optimization, none of them explicitly integrate insights from the relaxed continuous solution into the QUBO formulation. In this work, a novel approach is introduced that restricts the search space to discrete solutions in the vicinity of the continuous optimum by constructing a compact Hilbert space, thereby reducing the number of required qubits. Experiments on software solvers and a D-Wave Advantage quantum annealer demonstrate that our method outperforms state-of-the-art techniques.",
    "authors": [
      "Sebastian Schlütter",
      "Tomislav Maras",
      "Alexander Dotterweich",
      "Nico Piatkowski"
    ],
    "categories": [
      "quant-ph",
      "cs.CE"
    ],
    "publishedAt": "2025-10-13T08:47:43.000Z",
    "updatedAt": "2025-10-13T08:47:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11153v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11153v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11152v1",
    "arxivId": "2510.11152v1",
    "title": "A GPU-Accelerated Matrix-Free FAS Multigrid Solver for Navier-Stokes Equations with Memory-Efficient Implementations",
    "abstract": "We develop a matrix-free Full Approximation Storage (FAS) multigrid solver based on staggered finite differences and implemented on GPU in MATLAB. To enhance performance, intermediate variables are reused, and an X-shape Multi-Color Gauss-Seidel (X-MCGS) smoother is introduced, which eliminates conditional branching by partitioning the grid into four submatrices. Restriction and prolongation operators are also GPU-accelerated. Convergence tests verify robustness and accuracy, while benchmarks show substantial speedups: for the 2D heat equation on an $8192^2$ grid, the RTX~4090 achieves $61\\times$ over a single-core CPU, and in 3D at $512^3$, $46\\times$. A memory-efficient implementation of first- and second-order projection schemes reduces GPU-resident variables from 12/15 to 8, lowering memory footprint and improving performance by 20--30%, enabling $512^3$ Navier-Stokes simulations on a single GPU. Grain growth on a $512^2$ grid accommodates up to $q=1189$ (2D) and $q=123$ (3D) orientations, reproducing expected scaling laws. Coupled with Cahn-Hilliard equations, air-water two-bubble coalescence is simulated on a $256\\times 256\\times 1024$ grid, agreeing with experimental observations.",
    "authors": [
      "Jiale Meng",
      "Shuqi Tang",
      "Steven M. Wise",
      "Zhenlin Guo"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T08:44:33.000Z",
    "updatedAt": "2025-10-13T08:44:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11152v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11152v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11151v1",
    "arxivId": "2510.11151v1",
    "title": "TypePilot: Leveraging the Scala Type System for Secure LLM-generated Code",
    "abstract": "Large language Models (LLMs) have shown remarkable proficiency in code generation tasks across various programming languages. However, their outputs often contain subtle but critical vulnerabilities, posing significant risks when deployed in security-sensitive or mission-critical systems. This paper introduces TypePilot, an agentic AI framework designed to enhance the security and robustness of LLM-generated code by leveraging strongly typed and verifiable languages, using Scala as a representative example. We evaluate the effectiveness of our approach in two settings: formal verification with the Stainless framework and general-purpose secure code generation. Our experiments with leading open-source LLMs reveal that while direct code generation often fails to enforce safety constraints, just as naive prompting for more secure code, our type-focused agentic pipeline substantially mitigates input validation and injection vulnerabilities. The results demonstrate the potential of structured, type-guided LLM workflows to improve the SotA of the trustworthiness of automated code generation in high-assurance domains.",
    "authors": [
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Ljiljana Dolamic"
    ],
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T08:44:01.000Z",
    "updatedAt": "2025-10-13T08:44:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11151v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11151v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11148v1",
    "arxivId": "2510.11148v1",
    "title": "Enhanced Sampling for Efficient Learning of Coarse-Grained Machine Learning Potentials",
    "abstract": "Coarse-graining (CG) enables molecular dynamics (MD) simulations of larger systems and longer timescales that are otherwise infeasible with atomistic models. Machine learning potentials (MLPs), with their capacity to capture many-body interactions, can provide accurate approximations of the potential of mean force (PMF) in CG models. Current CG MLPs are typically trained in a bottom-up manner via force matching, which in practice relies on configurations sampled from the unbiased equilibrium Boltzmann distribution to ensure thermodynamic consistency. This convention poses two key limitations: first, sufficiently long atomistic trajectories are needed to reach convergence; and second, even once equilibrated, transition regions remain poorly sampled. To address these issues, we employ enhanced sampling to bias along CG degrees of freedom for data generation, and then recompute the forces with respect to the unbiased potential. This strategy simultaneously shortens the simulation time required to produce equilibrated data and enriches sampling in transition regions, while preserving the correct PMF. We demonstrate its effectiveness on the M\\\"uller-Brown potential and capped alanine, achieving notable improvements. Our findings support the use of enhanced sampling for force matching as a promising direction to improve the accuracy and reliability of CG MLPs.",
    "authors": [
      "Weilong Chen",
      "Franz Görlich",
      "Paul Fuchs",
      "Julija Zavadlav"
    ],
    "categories": [
      "physics.chem-ph",
      "cs.LG",
      "physics.comp-ph"
    ],
    "publishedAt": "2025-10-13T08:40:13.000Z",
    "updatedAt": "2025-10-13T08:40:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11148v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11148v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11147v1",
    "arxivId": "2510.11147v1",
    "title": "torchsom: The Reference PyTorch Library for Self-Organizing Maps",
    "abstract": "This paper introduces torchsom, an open-source Python library that provides a reference implementation of the Self-Organizing Map (SOM) in PyTorch. This package offers three main features: (i) dimensionality reduction, (ii) clustering, and (iii) friendly data visualization. It relies on a PyTorch backend, enabling (i) fast and efficient training of SOMs through GPU acceleration, and (ii) easy and scalable integrations with PyTorch ecosystem. Moreover, torchsom follows the scikit-learn API for ease of use and extensibility. The library is released under the Apache 2.0 license with 90% test coverage, and its source code and documentation are available at https://github.com/michelin/TorchSOM.",
    "authors": [
      "Louis Berthier",
      "Ahmed Shokry",
      "Maxime Moreaud",
      "Guillaume Ramelet",
      "Eric Moulines"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "68T07, 68T05, 68-04",
      "I.2.6; I.5.1; I.5.3"
    ],
    "publishedAt": "2025-10-13T08:40:00.000Z",
    "updatedAt": "2025-10-13T08:40:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11147v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11147v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11144v1",
    "arxivId": "2510.11144v1",
    "title": "$How^{2}$: How to learn from procedural How-to questions",
    "abstract": "An agent facing a planning problem can use answers to how-to questions to reduce uncertainty and fill knowledge gaps, helping it solve both current and future tasks. However, their open ended nature, where valid answers to \"How do I X?\" range from executable actions to high-level descriptions of X's sub-goals, makes them challenging for AI agents to ask, and for AI experts to answer, in ways that support efficient planning. We introduce $How^{2}$, a memory agent framework that enables agents to ask how-to questions, store the answers, and reuse them for lifelong learning in interactive environments. We evaluate our approach in Plancraft, a Minecraft crafting environment, where agents must complete an assembly task by manipulating inventory items. Using teacher models that answer at varying levels of abstraction, from executable action sequences to high-level subgoal descriptions, we show that lifelong learning agents benefit most from answers that are abstracted and decoupled from the current state. $How^{2}$ offers a way for LLM-based agents to improve their planning capabilities over time by asking questions in interactive environments.",
    "authors": [
      "Gautier Dagan",
      "Frank Keller",
      "Alex Lascarides"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T08:35:20.000Z",
    "updatedAt": "2025-10-13T08:35:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11144v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11144v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11143v1",
    "arxivId": "2510.11143v1",
    "title": "Spec-Driven AI for Science: The ARIA Framework for Automated and Reproducible Data Analysis",
    "abstract": "The rapid expansion of scientific data has widened the gap between analytical capability and research intent. Existing AI-based analysis tools, ranging from AutoML frameworks to agentic research assistants, either favor automation over transparency or depend on manual scripting that hinders scalability and reproducibility. We present ARIA (Automated Research Intelligence Assistant), a spec-driven, human-in-the-loop framework for automated and interpretable data analysis. ARIA integrates six interoperable layers, namely Command, Context, Code, Data, Orchestration, and AI Module, within a document-centric workflow that unifies human reasoning and machine execution. Through natural-language specifications, researchers define analytical goals while ARIA autonomously generates executable code, validates computations, and produces transparent documentation. Beyond achieving high predictive accuracy, ARIA can rapidly identify optimal feature sets and select suitable models, minimizing redundant tuning and repetitive experimentation. In the Boston Housing case, ARIA discovered 25 key features and determined XGBoost as the best performing model (R square = 0.93) with minimal overfitting. Evaluations across heterogeneous domains demonstrate ARIA's strong performance, interpretability, and efficiency compared with state-of-the-art systems. By combining AI for research and AI for science principles within a spec-driven architecture, ARIA establishes a new paradigm for transparent, collaborative, and reproducible scientific discovery.",
    "authors": [
      "Chuke Chen",
      "Biao Luo",
      "Nan Li",
      "Boxiang Wang",
      "Hang Yang",
      "Jing Guo",
      "Ming Xu"
    ],
    "categories": [
      "cs.AI",
      "cs.HC",
      "68U35, 62P30",
      "I.2.2"
    ],
    "publishedAt": "2025-10-13T08:32:43.000Z",
    "updatedAt": "2025-10-13T08:32:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11143v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11143v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11142v1",
    "arxivId": "2510.11142v1",
    "title": "Validation of an Artificial Intelligence Tool for the Detection of Sperm DNA Fragmentation Using the TUNEL In Situ Hybridization Assay",
    "abstract": "Sperm DNA fragmentation (SDF) is a critical parameter in male fertility assessment that conventional semen analysis fails to evaluate. This study presents the validation of a novel artificial intelligence (AI) tool designed to detect SDF through digital analysis of phase contrast microscopy images, using the terminal deoxynucleotidyl transferase dUTP nick end labeling (TUNEL) assay as the gold standard reference. Utilising the established link between sperm morphology and DNA integrity, the present work proposes a morphology assisted ensemble AI model that combines image processing techniques with state-of-the-art transformer based machine learning models (GC-ViT) for the prediction of DNA fragmentation in sperm from phase contrast images. The ensemble model is benchmarked against a pure transformer `vision' model as well as a `morphology-only` model. Promising results show the proposed framework is able to achieve sensitivity of 60\\% and specificity of 75\\%. This non-destructive methodology represents a significant advancement in reproductive medicine by enabling real-time sperm selection based on DNA integrity for clinical diagnostic and therapeutic applications.",
    "authors": [
      "Byron Alexander Jacobs",
      "Aqeel Morris",
      "Ifthakaar Shaik",
      "Frando Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T08:32:11.000Z",
    "updatedAt": "2025-10-13T08:32:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11142v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11142v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11141v1",
    "arxivId": "2510.11141v1",
    "title": "A Comprehensive Forecasting-Based Framework for Time Series Anomaly Detection: Benchmarking on the Numenta Anomaly Benchmark (NAB)",
    "abstract": "Time series anomaly detection is critical for modern digital infrastructures, yet existing methods lack systematic cross-domain evaluation. We present a comprehensive forecasting-based framework unifying classical methods (Holt-Winters, SARIMA) with deep learning architectures (LSTM, Informer) under a common residual-based detection interface. Our modular pipeline integrates preprocessing (normalization, STL decomposition), four forecasting models, four detection methods, and dual evaluation through forecasting metrics (MAE, RMSE, PCC) and detection metrics (Precision, Recall, F1, AUC). We conduct the first complete evaluation on the Numenta Anomaly Benchmark (58 datasets, 7 categories) with 232 model training runs and 464 detection evaluations achieving 100\\% success rate. LSTM achieves best performance (F1: 0.688, ranking first or second on 81\\% of datasets) with exceptional correlation on complex patterns (PCC: 0.999). Informer provides competitive accuracy (F1: 0.683) with 30\\% faster training. Classical methods achieve perfect predictions on simple synthetic data with 60 lower cost but show 2-3 worse F1-scores on real-world datasets. Forecasting quality dominates detection performance: differences between detection methods (F1: 0.621-0.688) are smaller than between forecasting models (F1: 0.344-0.688). Our findings provide evidence-based guidance: use LSTM for complex patterns, Informer for efficiency-critical deployments, and classical methods for simple periodic data with resource constraints. The complete implementation and results establish baselines for future forecasting-based anomaly detection research.",
    "authors": [
      "Mohammad Karami",
      "Mostafa Jalali",
      "Fatemeh Ghassemi"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T08:31:42.000Z",
    "updatedAt": "2025-10-13T08:31:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11141v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11141v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11140v1",
    "arxivId": "2510.11140v1",
    "title": "DUAL: Learning Diverse Kernels for Aggregated Two-sample and Independence Testing",
    "abstract": "To adapt kernel two-sample and independence testing to complex structured data, aggregation of multiple kernels is frequently employed to boost testing power compared to single-kernel tests. However, we observe a phenomenon that directly maximizing multiple kernel-based statistics may result in highly similar kernels that capture highly overlapping information, limiting the effectiveness of aggregation. To address this, we propose an aggregated statistic that explicitly incorporates kernel diversity based on the covariance between different kernels. Moreover, we identify a fundamental challenge: a trade-off between the diversity among kernels and the test power of individual kernels, i.e., the selected kernels should be both effective and diverse. This motivates a testing framework with selection inference, which leverages information from the training phase to select kernels with strong individual performance from the learned diverse kernel pool. We provide rigorous theoretical statements and proofs to show the consistency on the test power and control of Type-I error, along with asymptotic analysis of the proposed statistics. Lastly, we conducted extensive empirical experiments demonstrating the superior performance of our proposed approach across various benchmarks for both two-sample and independence testing.",
    "authors": [
      "Zhijian Zhou",
      "Xunye Tian",
      "Liuhua Peng",
      "Chao Lei",
      "Antonin Schrab",
      "Danica J. Sutherland",
      "Feng Liu"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T08:30:42.000Z",
    "updatedAt": "2025-10-13T08:30:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11140v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11140v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11138v1",
    "arxivId": "2510.11138v1",
    "title": "What Slows Down FMware Development? An Empirical Study of Developer Challenges and Resolution Times",
    "abstract": "Foundation Models (FMs), such as OpenAI's GPT, are fundamentally transforming the practice of software engineering by enabling the development of \\emph{FMware} -- applications and infrastructures built around these models. FMware systems now support tasks such as code generation, natural-language interaction, knowledge integration, and multi-modal content creation, underscoring their disruptive impact on current software engineering workflows. However, the design, implementation, and evolution of FMware present significant new challenges, particularly across cloud-based and on-premise platforms where goals, processes, and tools often diverge from those of traditional software development. To our knowledge, this is the first large-scale analysis of FMware development across both cloud-based platforms and open-source repositories. We empirically investigate the FMware ecosystem through three focus areas: (1) the most common application domains of FMware, (2) the key challenges developers encounter, and (3) the types of issues that demand the greatest effort to resolve. Our analysis draws on data from GitHub repositories and from leading FMware platforms, including HuggingFace, GPTStore, Ora, and Poe. Our findings reveal a strong focus on education, content creation, and business strategy, alongside persistent technical challenges in memory management, dependency handling, and tokenizer configuration. On GitHub, bug reports and core functionality issues are the most frequently reported problems, while code review, similarity search, and prompt template design are the most time-consuming to resolve. By uncovering developer practices and pain points, this study points to opportunities to improve FMware tools, workflows, and community support, and provides actionable insights to help guide the future of FMware development.",
    "authors": [
      "Zitao Wang",
      "Zhimin Zhao",
      "Michael W. Godfrey"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-13T08:26:48.000Z",
    "updatedAt": "2025-10-13T08:26:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11138v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11138v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11137v1",
    "arxivId": "2510.11137v1",
    "title": "CoSPED: Consistent Soft Prompt Targeted Data Extraction and Defense",
    "abstract": "Large language models have gained widespread attention recently, but their potential security vulnerabilities, especially privacy leakage, are also becoming apparent. To test and evaluate for data extraction risks in LLM, we proposed CoSPED, short for Consistent Soft Prompt targeted data Extraction and Defense. We introduce several innovative components, including Dynamic Loss, Additive Loss, Common Loss, and Self Consistency Decoding Strategy, and tested to enhance the consistency of the soft prompt tuning process. Through extensive experimentation with various combinations, we achieved an extraction rate of 65.2% at a 50-token prefix comparison. Our comparisons of CoSPED with other reference works confirm our superior extraction rates. We evaluate CoSPED on more scenarios, achieving Pythia model extraction rate of 51.7% and introducing cross-model comparison. Finally, we explore defense through Rank-One Model Editing and achieve a reduction in the extraction rate to 1.6%, which proves that our analysis of extraction mechanisms can directly inform effective mitigation strategies against soft prompt-based attacks.",
    "authors": [
      "Yang Zhuochen",
      "Fok Kar Wai",
      "Thing Vrizlynn"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T08:26:47.000Z",
    "updatedAt": "2025-10-13T08:26:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11137v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11137v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11133v1",
    "arxivId": "2510.11133v1",
    "title": "Test-Time Adaptation by Causal Trimming",
    "abstract": "Test-time adaptation aims to improve model robustness under distribution shifts by adapting models with access to unlabeled target samples. A primary cause of performance degradation under such shifts is the model's reliance on features that lack a direct causal relationship with the prediction target. We introduce Test-time Adaptation by Causal Trimming (TACT), a method that identifies and removes non-causal components from representations for test distributions. TACT applies data augmentations that preserve causal features while varying non-causal ones. By analyzing the changes in the representations using Principal Component Analysis, TACT identifies the highest variance directions associated with non-causal features. It trims the representations by removing their projections on the identified directions, and uses the trimmed representations for the predictions. During adaptation, TACT continuously tracks and refines these directions to get a better estimate of non-causal features. We theoretically analyze the effectiveness of this approach and empirically validate TACT on real-world out-of-distribution benchmarks. TACT consistently outperforms state-of-the-art methods by a significant margin.",
    "authors": [
      "Yingnan Liu",
      "Rui Qiao",
      "Mong Li Lee",
      "Wynne Hsu"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T08:22:38.000Z",
    "updatedAt": "2025-10-13T08:22:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11133v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11133v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11131v1",
    "arxivId": "2510.11131v1",
    "title": "SocioBench: Modeling Human Behavior in Sociological Surveys with Large Language Models",
    "abstract": "Large language models (LLMs) show strong potential for simulating human social behaviors and interactions, yet lack large-scale, systematically constructed benchmarks for evaluating their alignment with real-world social attitudes. To bridge this gap, we introduce SocioBench-a comprehensive benchmark derived from the annually collected, standardized survey data of the International Social Survey Programme (ISSP). The benchmark aggregates over 480,000 real respondent records from more than 30 countries, spanning 10 sociological domains and over 40 demographic attributes. Our experiments indicate that LLMs achieve only 30-40% accuracy when simulating individuals in complex survey scenarios, with statistically significant differences across domains and demographic subgroups. These findings highlight several limitations of current LLMs in survey scenarios, including insufficient individual-level data coverage, inadequate scenario diversity, and missing group-level modeling.",
    "authors": [
      "Jia Wang",
      "Ziyu Zhao",
      "Tingjuntao Ni",
      "Zhongyu Wei"
    ],
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "publishedAt": "2025-10-13T08:22:20.000Z",
    "updatedAt": "2025-10-13T08:22:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11131v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11131v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11129v1",
    "arxivId": "2510.11129v1",
    "title": "video-SALMONN S: Streaming Audio-Visual LLMs Beyond Length Limits via Memory",
    "abstract": "Continuous, high-frame-rate, high-resolution processing of long video streams is critical for future AI agents, yet current video-understanding LLMs struggle to scale. Offline, fixed-frame-number methods require the stream length to adapt frame rates; streaming methods constrain memory by merging or discarding tokens, losing information. We propose video-SALMONN S, a streaming audio-visual LLM that, to our knowledge, is the first to process 3-hour videos at 1 FPS and 360p resolution under a fixed memory budget. Our model introduces (i) a test-time-training (TTT) memory module that continually updates token representations to capture long-range dependencies by replacing token merging, and (ii) a prompt-dependent memory reader that selectively retrieves context-relevant content from fixed-size memory. The TTT module is optimised with a Hessian-free conjugate-gradient procedure (TTT_HF) for efficient adaptation. On long-video benchmarks (Video-MME, LVBench, VideoEvalPro), video-SALMONN S sustains high-quality understanding on multi-hour videos with 10k frames and 1M tokens. Our 8B-parameter model achieves 74.2% overall and 67.8% on the Video-MME long split, outperforming both offline and streaming baselines.",
    "authors": [
      "Guangzhi Sun",
      "Yixuan Li",
      "Xiaodong Wu",
      "Yudong Yang",
      "Wei Li",
      "Zejun Ma",
      "Chao Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T08:20:15.000Z",
    "updatedAt": "2025-10-13T08:20:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11129v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11129v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11128v1",
    "arxivId": "2510.11128v1",
    "title": "Lightweight Facial Landmark Detection in Thermal Images via Multi-Level Cross-Modal Knowledge Transfer",
    "abstract": "Facial Landmark Detection (FLD) in thermal imagery is critical for applications in challenging lighting conditions, but it is hampered by the lack of rich visual cues. Conventional cross-modal solutions, like feature fusion or image translation from RGB data, are often computationally expensive or introduce structural artifacts, limiting their practical deployment. To address this, we propose Multi-Level Cross-Modal Knowledge Distillation (MLCM-KD), a novel framework that decouples high-fidelity RGB-to-thermal knowledge transfer from model compression to create both accurate and efficient thermal FLD models. A central challenge during knowledge transfer is the profound modality gap between RGB and thermal data, where traditional unidirectional distillation fails to enforce semantic consistency across disparate feature spaces. To overcome this, we introduce Dual-Injected Knowledge Distillation (DIKD), a bidirectional mechanism designed specifically for this task. DIKD establishes a connection between modalities: it not only guides the thermal student with rich RGB features but also validates the student's learned representations by feeding them back into the frozen teacher's prediction head. This closed-loop supervision forces the student to learn modality-invariant features that are semantically aligned with the teacher, ensuring a robust and profound knowledge transfer. Experiments show that our approach sets a new state-of-the-art on public thermal FLD benchmarks, notably outperforming previous methods while drastically reducing computational overhead.",
    "authors": [
      "Qiyi Tong",
      "Olivia Nocentini",
      "Marta Lagomarsino",
      "Kuanqi Cai",
      "Marta Lorenzini",
      "Arash Ajoudani"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T08:19:56.000Z",
    "updatedAt": "2025-10-13T08:19:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11128v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11128v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11124v1",
    "arxivId": "2510.11124v1",
    "title": "Perturbation Self-Supervised Representations for Cross-Lingual Emotion TTS: Stage-Wise Modeling of Emotion and Speaker",
    "abstract": "Cross-lingual emotional text-to-speech (TTS) aims to produce speech in one language that captures the emotion of a speaker from another language while maintaining the target voice's timbre. This process of cross-lingual emotional speech synthesis presents a complex challenge, necessitating flexible control over emotion, timbre, and language. However, emotion and timbre are highly entangled in speech signals, making fine-grained control challenging. To address this issue, we propose EMM-TTS, a novel two-stage cross-lingual emotional speech synthesis framework based on perturbed self-supervised learning (SSL) representations. In the first stage, the model explicitly and implicitly encodes prosodic cues to capture emotional expressiveness, while the second stage restores the timbre from perturbed SSL representations. We further investigate the effect of different speaker perturbation strategies-formant shifting and speaker anonymization-on the disentanglement of emotion and timbre. To strengthen speaker preservation and expressive control, we introduce Speaker Consistency Loss (SCL) and Speaker-Emotion Adaptive Layer Normalization (SEALN) modules. Additionally, we find that incorporating explicit acoustic features (e.g., F0, energy, and duration) alongside pretrained latent features improves voice cloning performance. Comprehensive multi-metric evaluations, including both subjective and objective measures, demonstrate that EMM-TTS achieves superior naturalness, emotion transferability, and timbre consistency across languages.",
    "authors": [
      "Cheng Gong",
      "Chunyu Qiang",
      "Tianrui Wang",
      "Yu Jiang",
      "Yuheng Lu",
      "Ruihao Jing",
      "Xiaoxiao Miao",
      "Xiaolei Zhang",
      "Longbiao Wang",
      "Jianwu Dang"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-13T08:11:19.000Z",
    "updatedAt": "2025-10-13T08:11:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11124v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11124v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11123v1",
    "arxivId": "2510.11123v1",
    "title": "Visible Light Communication for Vehicular Networks: A Tutorial",
    "abstract": "The advent of the fifth-generation technology promises to bring about more vertical applications and emerging services that include vehicular networks and intelligent transportation systems (ITSs). To achieve their vision of real-time and safetyapplications, vehicular networks rely on short-range to medium-range communications. One emerging technology that aims to provide reliability and high-data rate in short-range communications is the visible light communications (VLC). Due to its remarkable advantages, some studies have recently investigated the integration of VLC in vehicular networks and ITSs. Despite their attractive features, such networks also face several implementation issues. This paper provides an extended tutorial on the implementation of VLC-based vehicular networks. To begin with, we present the implementation characteristics of these systems and discuss some related issues. The underlying system considers a general structure with transmitters, channels, and receivers based on photodetectors and cameras, as well as standardization efforts and types of topologies. In addition, we discuss the impact of the sun and artificial light sources, flickering, dimming, throughput enhancement, uplink security, and mobility on practical implementation. Finally, we highlight some key challenges and potential solutions and provide some directions for future research investigations that could constitute an advancement toward the development of commercial VLC-based vehicular systems.",
    "authors": [
      "Pedro E. Gória Silva",
      "Eduardo S. Lima",
      "Jules M. Moualeu",
      "Mohamed Korium",
      "Pedro H. J. Nardelli"
    ],
    "categories": [
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-13T08:09:37.000Z",
    "updatedAt": "2025-10-13T08:09:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11123v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11123v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11122v1",
    "arxivId": "2510.11122v1",
    "title": "DyKnow-RAG: Dynamic Knowledge Utilization Reinforcement Framework for Noisy Retrieval-Augmented Generation in E-commerce Search Relevance",
    "abstract": "Accurately modeling query-item relevance drives e-commerce ranking, yet long-tail, knowledge-heavy, and fast-evolving queries exceed parametric LLM coverage. External context (reviews, attribute encyclopedias, UGC) can help but is noisy, and single-pass latency and cost forbid any clean-then-summarize step. The model must, per query, judge relevance and decide whether to use, partially use, or ignore the context. DyKnow-RAG is a dynamic noisy-RAG framework built on Group Relative Policy Optimization. It trains two rollout groups (no external context vs a single retrieved chunk) and applies posterior-driven inter-group advantage scaling that adaptively reweights their contributions by the per-query correctness gap. This teaches when to trust retrieval versus fall back to parametric knowledge, without process labels, value networks, or extra inference passes, preserving single-pass, single-chunk deployment under production latency. Training combines: (1) supervised initialization with a structured rationale that explicitly records the context-usage decision; (2) an RL pool prioritized by SFT uncertainty to focus where context choice is most consequential; and (3) an optional lightweight DPO warm start to stabilize with-context calibration. Under a unified retrieval/index and fixed latency budget, DyKnow-RAG outperforms SFT, DPO, and vanilla GRPO in offline tests, and delivers consistent lifts on GSB, Query Goodrate, and Item Goodrate in Taobao A/B testing. It is deployed in Taobao's production relevance system, serving live traffic. To our knowledge, it is among the first single-pass RAG solutions for e-commerce relevance, turning noisy external signals into reliable gains without added online complexity.",
    "authors": [
      "Tingqiao Xu",
      "Shaowei Yao",
      "Chenhe Dong",
      "Yiming Jin",
      "Zerui Huang",
      "Dan Ou",
      "Haihong Tang"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T08:08:59.000Z",
    "updatedAt": "2025-10-13T08:08:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11122v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11122v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11121v1",
    "arxivId": "2510.11121v1",
    "title": "Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM",
    "abstract": "While large language models (LLMs) are increasingly used as automated heuristic designers for vehicle routing problems (VRPs), current state-of-the-art methods predominantly rely on prompting massive, general-purpose models like GPT-4. This work challenges that paradigm by demonstrating that a smaller, specialized LLM, when meticulously fine-tuned, can generate components that surpass expert-crafted heuristics within advanced solvers. We propose RFTHGS, a novel Reinforcement learning (RL) framework for Fine-Tuning a small LLM to generate high-performance crossover operators for the Hybrid Genetic Search (HGS) solver, applied to the Capacitated VRP (CVRP). Our method employs a multi-tiered, curriculum-based reward function that progressively guides the LLM to master generating first compilable, then executable, and finally, superior-performing operators that exceed human expert designs. This is coupled with an operator caching mechanism that discourages plagiarism and promotes diversity during training. Comprehensive experiments show that our fine-tuned LLM produces crossover operators which significantly outperform the expert-designed ones in HGS. The performance advantage remains consistent, generalizing from small-scale instances to large-scale problems with up to 1000 nodes. Furthermore, RFTHGS exceeds the performance of leading neuro-combinatorial baselines, prompt-based methods, and commercial LLMs such as GPT-4o and GPT-4o-mini.",
    "authors": [
      "Rongjie Zhu",
      "Cong Zhang",
      "Zhiguang Cao"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T08:08:58.000Z",
    "updatedAt": "2025-10-13T08:08:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11121v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11121v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11119v1",
    "arxivId": "2510.11119v1",
    "title": "Improving AI Efficiency in Data Centres by Power Dynamic Response",
    "abstract": "The steady growth of artificial intelligence (AI) has accelerated in the recent years, facilitated by the development of sophisticated models such as large language models and foundation models. Ensuring robust and reliable power infrastructures is fundamental to take advantage of the full potential of AI. However, AI data centres are extremely hungry for power, putting the problem of their power management in the spotlight, especially with respect to their impact on environment and sustainable development. In this work, we investigate the capacity and limits of solutions based on an innovative approach for the power management of AI data centres, i.e., making part of the input power as dynamic as the power used for data-computing functions. The performance of passive and active devices are quantified and compared in terms of computational gain, energy efficiency, reduction of capital expenditure, and management costs by analysing power trends from multiple data platforms worldwide. This strategy, which identifies a paradigm shift in the AI data centre power management, has the potential to strongly improve the sustainability of AI hyperscalers, enhancing their footprint on environmental, financial, and societal fields.",
    "authors": [
      "Andrea Marinoni",
      "Sai Shivareddy",
      "Pietro Lio'",
      "Weisi Lin",
      "Erik Cambria",
      "Clare Grey"
    ],
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.DC"
    ],
    "publishedAt": "2025-10-13T08:08:21.000Z",
    "updatedAt": "2025-10-13T08:08:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11119v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11119v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11117v1",
    "arxivId": "2510.11117v1",
    "title": "Demystifying Numerosity in Diffusion Models -- Limitations and Remedies",
    "abstract": "Numerosity remains a challenge for state-of-the-art text-to-image generation models like FLUX and GPT-4o, which often fail to accurately follow counting instructions in text prompts. In this paper, we aim to study a fundamental yet often overlooked question: Can diffusion models inherently generate the correct number of objects specified by a textual prompt simply by scaling up the dataset and model size? To enable rigorous and reproducible evaluation, we construct a clean synthetic numerosity benchmark comprising two complementary datasets: GrayCount250 for controlled scaling studies, and NaturalCount6 featuring complex naturalistic scenes. Second, we empirically show that the scaling hypothesis does not hold: larger models and datasets alone fail to improve counting accuracy on our benchmark. Our analysis identifies a key reason: diffusion models tend to rely heavily on the noise initialization rather than the explicit numerosity specified in the prompt. We observe that noise priors exhibit biases toward specific object counts. In addition, we propose an effective strategy for controlling numerosity by injecting count-aware layout information into the noise prior. Our method achieves significant gains, improving accuracy on GrayCount250 from 20.0\\% to 85.3\\% and on NaturalCount6 from 74.8\\% to 86.3\\%, demonstrating effective generalization across settings.",
    "authors": [
      "Yaqi Zhao",
      "Xiaochen Wang",
      "Li Dong",
      "Wentao Zhang",
      "Yuhui Yuan"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T08:07:24.000Z",
    "updatedAt": "2025-10-13T08:07:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11117v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11117v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11116v1",
    "arxivId": "2510.11116v1",
    "title": "N-output Mechanism: Estimating Statistical Information from Numerical Data under Local Differential Privacy",
    "abstract": "Local Differential Privacy (LDP) addresses significant privacy concerns in sensitive data collection. In this work, we focus on numerical data collection under LDP, targeting a significant gap in the literature: existing LDP mechanisms are optimized for either a very small ($|\\Omega| \\in \\{2, 3\\}$) or infinite output spaces. However, no generalized method for constructing an optimal mechanism for an arbitrary output size $N$ exists. To fill this gap, we propose the \\textbf{N-output mechanism}, a generalized framework that maps numerical data to one of $N$ discrete outputs. We formulate the mechanism's design as an optimization problem to minimize estimation variance for any given $N \\geq 2$ and develop both numerical and analytical solutions. This results in a mechanism that is highly accurate and adaptive, as its design is determined by solving an optimization problem for any chosen $N$. Furthermore, we extend our framework and existing mechanisms to the task of distribution estimation. Empirical evaluations show that the N-output mechanism achieves state-of-the-art accuracy for mean, variance, and distribution estimation with small communication costs.",
    "authors": [
      "Incheol Baek",
      "Yon Dohn Chung"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T08:06:59.000Z",
    "updatedAt": "2025-10-13T08:06:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11116v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11116v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11115v1",
    "arxivId": "2510.11115v1",
    "title": "Connecting Giants: Synergistic Knowledge Transfer of Large Multimodal Models for Few-Shot Learning",
    "abstract": "Few-shot learning (FSL) addresses the challenge of classifying novel classes with limited training samples. While some methods leverage semantic knowledge from smaller-scale models to mitigate data scarcity, these approaches often introduce noise and bias due to the data's inherent simplicity. In this paper, we propose a novel framework, Synergistic Knowledge Transfer (SynTrans), which effectively transfers diverse and complementary knowledge from large multimodal models to empower the off-the-shelf few-shot learner. Specifically, SynTrans employs CLIP as a robust teacher and uses a few-shot vision encoder as a weak student, distilling semantic-aligned visual knowledge via an unsupervised proxy task. Subsequently, a training-free synergistic knowledge mining module facilitates collaboration among large multimodal models to extract high-quality semantic knowledge. Building upon this, a visual-semantic bridging module enables bi-directional knowledge transfer between visual and semantic spaces, transforming explicit visual and implicit semantic knowledge into category-specific classifier weights. Finally, SynTrans introduces a visual weight generator and a semantic weight reconstructor to adaptively construct optimal multimodal FSL classifiers. Experimental results on four FSL datasets demonstrate that SynTrans, even when paired with a simple few-shot vision encoder, significantly outperforms current state-of-the-art methods.",
    "authors": [
      "Hao Tang",
      "Shengfeng He",
      "Jing Qin"
    ],
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "publishedAt": "2025-10-13T08:06:23.000Z",
    "updatedAt": "2025-10-13T08:06:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11115v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11115v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11112v1",
    "arxivId": "2510.11112v1",
    "title": "Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment",
    "abstract": "Longitudinal multimodal data, including electronic health records (EHR) and sequential chest X-rays (CXRs), is critical for modeling disease progression, yet remains underutilized due to two key challenges: (1) redundancy in consecutive CXR sequences, where static anatomical regions dominate over clinically-meaningful dynamics, and (2) temporal misalignment between sparse, irregular imaging and continuous EHR data. We introduce $\\texttt{DiPro}$, a novel framework that addresses these challenges through region-aware disentanglement and multi-timescale alignment. First, we disentangle static (anatomy) and dynamic (pathology progression) features in sequential CXRs, prioritizing disease-relevant changes. Second, we hierarchically align these static and dynamic CXR features with asynchronous EHR data via local (pairwise interval-level) and global (full-sequence) synchronization to model coherent progression pathways. Extensive experiments on the MIMIC dataset demonstrate that $\\texttt{DiPro}$ could effectively extract temporal clinical dynamics and achieve state-of-the-art performance on both disease progression identification and general ICU prediction tasks.",
    "authors": [
      "Chen Liu",
      "Wenfang Yao",
      "Kejing Yin",
      "William K. Cheung",
      "Jing Qin"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T08:02:36.000Z",
    "updatedAt": "2025-10-13T08:02:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11112v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11112v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11110v1",
    "arxivId": "2510.11110v1",
    "title": "PhysioME: A Robust Multimodal Self-Supervised Framework for Physiological Signals with Missing Modalities",
    "abstract": "Missing or corrupted modalities are common in physiological signal-based medical applications owing to hardware constraints or motion artifacts. However, most existing methods assume the availability of all modalities, resulting in substantial performance degradation in the absence of any modality. To overcome this limitation, this study proposes PhysioME, a robust framework designed to ensure reliable performance under missing modality conditions. PhysioME adopts: (1) a multimodal self-supervised learning approach that combines contrastive learning with masked prediction; (2) a Dual-PathNeuroNet backbone tailored to capture the temporal dynamics of each physiological signal modality; and (3) a restoration decoder that reconstructs missing modality tokens, enabling flexible processing of incomplete inputs. The experimental results show that PhysioME achieves high consistency and generalization performance across various missing modality scenarios. These findings highlight the potential of PhysioME as a reliable tool for supporting clinical decision-making in real-world settings with imperfect data availability.",
    "authors": [
      "Cheol-Hui Lee",
      "Hwa-Yeon Lee",
      "Min-Kyung Jung",
      "Dong-Joo Kim"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T08:00:55.000Z",
    "updatedAt": "2025-10-13T08:00:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11110v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11110v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11109v1",
    "arxivId": "2510.11109v1",
    "title": "Graph Neural Network-Based Multicast Routing for On-Demand Streaming Services in 6G Networks",
    "abstract": "The increase of bandwidth-intensive applications in sixth-generation (6G) wireless networks, such as real-time volumetric streaming and multi-sensory extended reality, demands intelligent multicast routing solutions capable of delivering differentiated quality-of-service (QoS) at scale. Traditional shortest-path and multicast routing algorithms are either computationally prohibitive or structurally rigid, and they often fail to support heterogeneous user demands, leading to suboptimal resource utilization. Neural network-based approaches, while offering improved inference speed, typically lack topological generalization and scalability. To address these limitations, this paper presents a graph neural network (GNN)-based multicast routing framework that jointly minimizes total transmission cost and supports user-specific video quality requirements. The routing problem is formulated as a constrained minimum-flow optimization task, and a reinforcement learning algorithm is developed to sequentially construct efficient multicast trees by reusing paths and adapting to network dynamics. A graph attention network (GAT) is employed as the encoder to extract context-aware node embeddings, while a long short-term memory (LSTM) module models the sequential dependencies in routing decisions. Extensive simulations demonstrate that the proposed method closely approximates optimal dynamic programming-based solutions while significantly reducing computational complexity. The results also confirm strong generalization to large-scale and dynamic network topologies, highlighting the method's potential for real-time deployment in 6G multimedia delivery scenarios. Code is available at https://github.com/UNIC-Lab/GNN-Routing.",
    "authors": [
      "Xiucheng Wang",
      "Zien Wang",
      "Nan Cheng",
      "Wenchao Xu",
      "Wei Quan",
      "Xuemin Shen"
    ],
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T08:00:45.000Z",
    "updatedAt": "2025-10-13T08:00:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11109v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11109v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11108v1",
    "arxivId": "2510.11108v1",
    "title": "A Vision for Access Control in LLM-based Agent Systems",
    "abstract": "The autonomy and contextual complexity of LLM-based agents render traditional access control (AC) mechanisms insufficient. Static, rule-based systems designed for predictable environments are fundamentally ill-equipped to manage the dynamic information flows inherent in agentic interactions. This position paper argues for a paradigm shift from binary access control to a more sophisticated model of information governance, positing that the core challenge is not merely about permission, but about governing the flow of information. We introduce Agent Access Control (AAC), a novel framework that reframes AC as a dynamic, context-aware process of information flow governance. AAC operates on two core modules: (1) multi-dimensional contextual evaluation, which assesses not just identity but also relationships, scenarios, and norms; and (2) adaptive response formulation, which moves beyond simple allow/deny decisions to shape information through redaction, summarization, and paraphrasing. This vision, powered by a dedicated AC reasoning engine, aims to bridge the gap between human-like nuanced judgment and scalable Al safety, proposing a new conceptual lens for future research in trustworthy agent design.",
    "authors": [
      "Xinfeng Li",
      "Dong Huang",
      "Jie Li",
      "Hongyi Cai",
      "Zhenhong Zhou",
      "Wei Dong",
      "XiaoFeng Wang",
      "Yang Liu"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T07:57:09.000Z",
    "updatedAt": "2025-10-13T07:57:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11108v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11108v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11107v1",
    "arxivId": "2510.11107v1",
    "title": "MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps",
    "abstract": "This paper addresses the challenge of learning semantically and functionally meaningful 3D motion priors from real-world videos, in order to enable prediction of future 3D scene motion from a single input image. We propose a novel pixel-aligned Motion Map (MoMap) representation for 3D scene motion, which can be generated from existing generative image models to facilitate efficient and effective motion prediction. To learn meaningful distributions over motion, we create a large-scale database of MoMaps from over 50,000 real videos and train a diffusion model on these representations. Our motion generation not only synthesizes trajectories in 3D but also suggests a new pipeline for 2D video synthesis: first generate a MoMap, then warp an image accordingly and complete the warped point-based renderings. Experimental results demonstrate that our approach generates plausible and semantically consistent 3D scene motion.",
    "authors": [
      "Jiahui Lei",
      "Kyle Genova",
      "George Kopanas",
      "Noah Snavely",
      "Leonidas Guibas"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T07:56:19.000Z",
    "updatedAt": "2025-10-13T07:56:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11107v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11107v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11106v1",
    "arxivId": "2510.11106v1",
    "title": "Compositional Zero-Shot Learning: A Survey",
    "abstract": "Compositional Zero-Shot Learning (CZSL) is a critical task in computer vision that enables models to recognize unseen combinations of known attributes and objects during inference, addressing the combinatorial challenge of requiring training data for every possible composition. This is particularly challenging because the visual appearance of primitives is highly contextual; for example, ``small'' cats appear visually distinct from ``older'' ones, and ``wet'' cars differ significantly from ``wet'' cats. Effectively modeling this contextuality and the inherent compositionality is crucial for robust compositional zero-shot recognition. This paper presents, to our knowledge, the first comprehensive survey specifically focused on Compositional Zero-Shot Learning. We systematically review the state-of-the-art CZSL methods, introducing a taxonomy grounded in disentanglement, with four families of approaches: no explicit disentanglement, textual disentanglement, visual disentanglement, and cross-modal disentanglement. We provide a detailed comparative analysis of these methods, highlighting their core advantages and limitations in different problem settings, such as closed-world and open-world CZSL. Finally, we identify the most significant open challenges and outline promising future research directions. This survey aims to serve as a foundational resource to guide and inspire further advancements in this fascinating and important field. Papers studied in this survey with their official code are available on our github: https://github.com/ans92/Compositional-Zero-Shot-Learning",
    "authors": [
      "Ans Munir",
      "Faisal Z. Qureshi",
      "Mohsen Ali",
      "Muhammad Haris Khan"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T07:54:47.000Z",
    "updatedAt": "2025-10-13T07:54:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11106v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11106v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11104v1",
    "arxivId": "2510.11104v1",
    "title": "Enhancing LLM Reasoning via Non-Human-Like Reasoning Path Preference Optimization",
    "abstract": "Current approaches for strengthening LLM reasoning tend to introduce a training bias toward human-like reasoning trajectories. In step-wise preference optimization, in particular, dependence on human or higher-capacity model annotations for intermediate steps limits exploration of alternative, non-human-like reasoning paths and thus constrains achievable performance. Furthermore, through a small-scale pilot study, we observed that in approximately 75% of cases, the model's first erroneous step occurs after the lowest-confidence point. This suggests that guiding the model at its lowest-confidence point before an error provides more accurate supervision than locating the first explicit error. In this paper, we propose Confidence-Guided Reasoning Path Preference Optimization (CGPO), a method that leverages a confidence signal to identify points of maximal uncertainty in the model's reasoning process and applies self-generated, non-human-like reasoning-path guidance to mitigate trajectory drift. Our experiments span diverse models applied to both code and mathematical reasoning tasks. The results show that, with the same amount of training data, our method using data generated by a small model can achieve better performance in most cases compared with approaches using data generated by a strong model or human-annotated.",
    "authors": [
      "Junjie Lu",
      "Yuliang Liu",
      "Chaofeng Qu",
      "Wei Shen",
      "Zhouhan Lin",
      "Min Xu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:51:16.000Z",
    "updatedAt": "2025-10-13T07:51:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11104v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11104v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11103v1",
    "arxivId": "2510.11103v1",
    "title": "A Primer on SO(3) Action Representations in Deep Reinforcement Learning",
    "abstract": "Many robotic control tasks require policies to act on orientations, yet the geometry of SO(3) makes this nontrivial. Because SO(3) admits no global, smooth, minimal parameterization, common representations such as Euler angles, quaternions, rotation matrices, and Lie algebra coordinates introduce distinct constraints and failure modes. While these trade-offs are well studied for supervised learning, their implications for actions in reinforcement learning remain unclear. We systematically evaluate SO(3) action representations across three standard continuous control algorithms, PPO, SAC, and TD3, under dense and sparse rewards. We compare how representations shape exploration, interact with entropy regularization, and affect training stability through empirical studies and analyze the implications of different projections for obtaining valid rotations from Euclidean network outputs. Across a suite of robotics benchmarks, we quantify the practical impact of these choices and distill simple, implementation-ready guidelines for selecting and using rotation actions. Our results highlight that representation-induced geometry strongly influences exploration and optimization and show that representing actions as tangent vectors in the local frame yields the most reliable results across algorithms.",
    "authors": [
      "Martin Schuck",
      "Sherif Samy",
      "Angela P. Schoellig"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:49:21.000Z",
    "updatedAt": "2025-10-13T07:49:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11103v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11103v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11100v1",
    "arxivId": "2510.11100v1",
    "title": "HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction",
    "abstract": "Click-through rate (CTR) prediction, which models behavior sequence and non-sequential features (e.g., user/item profiles or cross features) to infer user interest, underpins industrial recommender systems. However, most methods face three forms of heterogeneity that degrade predictive performance: (i) Feature Heterogeneity persists when limited sequence side features provide less granular interest representation compared to extensive non-sequential features, thereby impairing sequence modeling performance; (ii) Context Heterogeneity arises because a user's interest in an item will be influenced by other items, yet point-wise prediction neglects cross-item interaction context from the entire item set; (iii) Architecture Heterogeneity stems from the fragmented integration of specialized network modules, which compounds the model's effectiveness, efficiency and scalability in industrial deployments. To tackle the above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for modeling sequential and set-wise contexts. First, we align sequence side features with non-sequential features for accurate sequence modeling and fine-grained interest representation. Second, we shift the prediction paradigm from point-wise to set-wise, facilitating cross-item interaction in a highly parallel manner. Third, HoMer's unified encoder-decoder architecture achieves dual optimization through structural simplification and shared computation, ensuring computational efficiency while maintaining scalability with model size. Without arduous modification to the prediction pipeline, HoMer successfully scales up and outperforms our industrial baseline by 0.0099 in the AUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%. Additionally, HoMer saves 27% of GPU resources via preliminary engineering optimization, further validating its superiority and practicality.",
    "authors": [
      "Shuwei Chen",
      "Jiajun Cui",
      "Zhengqi Xu",
      "Fan Zhang",
      "Jiangke Fan",
      "Teng Zhang",
      "Xingxing Wang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:47:03.000Z",
    "updatedAt": "2025-10-13T07:47:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11100v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11100v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11098v1",
    "arxivId": "2510.11098v1",
    "title": "VCB Bench: An Evaluation Benchmark for Audio-Grounded Large Language Model Conversational Agents",
    "abstract": "Recent advances in large audio language models (LALMs) have greatly enhanced multimodal conversational systems. However, existing benchmarks remain limited -- they are mainly English-centric, rely on synthetic speech, and lack comprehensive, discriminative evaluation across multiple dimensions. To address these gaps, we present Voice Chat Bot Bench (VCB Bench) -- a high-quality Chinese benchmark built entirely on real human speech. VCB Bench evaluates LALMs from three complementary perspectives: instruction following (including speech-level control beyond text commands), knowledge understanding (general knowledge, reasoning, and daily dialogue), and robustness (stability under perturbations in content, environment, and speaker traits). Experiments on representative LALMs reveal notable performance gaps and highlight future directions for improvement. VCB Bench provides a reproducible and fine-grained evaluation framework, offering standardized methodology and practical insights for advancing Chinese voice conversational models.",
    "authors": [
      "Jiliang Hu",
      "Wenfu Wang",
      "Zuchao Li",
      "Chenxing Li",
      "Yiyang Zhao",
      "Hanzhao Li",
      "Liqiang Zhang",
      "Meng Yu",
      "Dong Yu"
    ],
    "categories": [
      "cs.SD",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T07:45:52.000Z",
    "updatedAt": "2025-10-13T07:45:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11098v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11098v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11096v1",
    "arxivId": "2510.11096v1",
    "title": "CoDefend: Cross-Modal Collaborative Defense via Diffusion Purification and Prompt Optimization",
    "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in tasks such as image captioning, visual question answering, and cross-modal reasoning by integrating visual and textual modalities. However, their multimodal nature also exposes them to adversarial threats, where attackers can perturb either modality or both jointly to induce harmful, misleading, or policy violating outputs. Existing defense strategies, such as adversarial training and input purification, face notable limitations: adversarial training typically improves robustness only against known attacks while incurring high computational costs, whereas conventional purification approaches often suffer from degraded image quality and insufficient generalization to complex multimodal tasks. In this work, we focus on defending the visual modality, which frequently serves as the primary entry point for adversarial manipulation. We propose a supervised diffusion based denoising framework that leverages paired adversarial clean image datasets to fine-tune diffusion models with directional, task specific guidance. Unlike prior unsupervised purification methods such as DiffPure, our approach achieves higher quality reconstructions while significantly improving defense robustness in multimodal tasks. Furthermore, we incorporate prompt optimization as a complementary defense mechanism, enhancing resistance against diverse and unseen attack strategies. Extensive experiments on image captioning and visual question answering demonstrate that our method not only substantially improves robustness but also exhibits strong transferability to unknown adversarial attacks. These results highlight the effectiveness of supervised diffusion based denoising for multimodal defense, paving the way for more reliable and secure deployment of MLLMs in real world applications.",
    "authors": [
      "Fengling Zhu",
      "Boshi Liu",
      "Jingyu Hua",
      "Sheng Zhong"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T07:44:54.000Z",
    "updatedAt": "2025-10-13T07:44:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11096v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11096v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11095v1",
    "arxivId": "2510.11095v1",
    "title": "Multi-Physics-Enhanced Bayesian Inverse Analysis: Information Gain from Additional Fields",
    "abstract": "Many real-world inverse problems suffer from limited data, often because they rely on measurements of a single physical field. Such data frequently fail to sufficiently reduce parameter uncertainty in Bayesian inverse analysis. Incorporating easily available data from additional physical fields can substantially decrease this uncertainty. We focus on Bayesian inverse analyses based on computational models, e.g., those using the finite element method. To incorporate data from additional physical fields, the computational model must be extended to include these fields. While this model extension may have little to no effect on forward model predictions, it can greatly enhance inverse analysis by leveraging the multi-physics data. Our work proposes this multi-physics-enhanced inverse approach and demonstrates its potential using two models: a simple model with one-way coupled fields and a complex computational model with fully coupled fields. We quantify the uncertainty reduction by comparing the effect of single-physics and multi-physics data on the information gain from the prior to the posterior. Our results show that even a few or noisy data points from an additional physical field can considerably increase the information gain, even if this field is weakly or one-way coupled. Although multi-physics data are often readily available, it is remarkable that their potential has been largely neglected in model calibration so far. Instead, costly and time-consuming additional experimental setups are often pursued. In contrast, incorporating multi-physics data requires minimal effort when multi-physics models are readily available or easy to implement, as is the case with uncoupled and one-way coupled models. This work proposes and promotes the future use of multi-physics-enhanced Bayesian inverse analysis as a cost- and time-saving game-changer across various fields of science and industry.",
    "authors": [
      "Lea J. Haeusel",
      "Jonas Nitzler",
      "Lea J. Köglmeier",
      "Wolfgang A. Wall"
    ],
    "categories": [
      "cs.CE"
    ],
    "publishedAt": "2025-10-13T07:44:16.000Z",
    "updatedAt": "2025-10-13T07:44:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11095v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11095v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11094v1",
    "arxivId": "2510.11094v1",
    "title": "Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation",
    "abstract": "Effective rehabilitation methods are essential for the recovery of lower limb dysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great potentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are usually heavy and need a lot of work to help the patients to put them on. Moreover, it also requires extra compliance control to guarantee the safety. In contrast, soft exoskeletons are easy and comfortable to wear and have intrinsic compliance, but their complex nonlinear human-robot interaction dynamics would pose significant challenges for control. In this work, based on the pneumatic actuators inspired by origami, we design a rehabilitation exoskeleton for knee that is easy and comfortable to wear. To guarantee the control performance and enable a nice human-robot interaction, we first use Deep Koopman Network to model the human-robot interaction dynamics. In particular, by viewing the electromyography (EMG) signals and the duty cycle of the PWM wave that controls the pneumatic robot's valves and pump as the inputs, the linear Koopman model accurately captures the complex human-robot interaction dynamics. Next, based on the obtained Koopman model, we further use Model Predictive Control (MPC) to control the soft robot and help the user to do rehabilitation training in real-time. The goal of the rehabilitation training is to track a given reference signal shown on the screen. Experiments show that by integrating the EMG signals into the Koopman model, we have improved the model accuracy to great extent. In addition, a personalized Koopman model trained from the individual's own data performs better than the non-personalized model. Consequently, our control framework outperforms the traditional PID control in both passive and active training modes. Hence the proposed method provides a new control framework for soft rehabilitation robots.",
    "authors": [
      "Junxiang Wang",
      "Han Zhang",
      "Zehao Wang",
      "Huaiyuan Chen",
      "Pu Wang",
      "Weidong Chen"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T07:44:03.000Z",
    "updatedAt": "2025-10-13T07:44:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11094v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11094v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11092v1",
    "arxivId": "2510.11092v1",
    "title": "Future-Aware End-to-End Driving: Bidirectional Modeling of Trajectory Planning and Scene Evolution",
    "abstract": "End-to-end autonomous driving methods aim to directly map raw sensor inputs to future driving actions such as planned trajectories, bypassing traditional modular pipelines. While these approaches have shown promise, they often operate under a one-shot paradigm that relies heavily on the current scene context, potentially underestimating the importance of scene dynamics and their temporal evolution. This limitation restricts the model's ability to make informed and adaptive decisions in complex driving scenarios. We propose a new perspective: the future trajectory of an autonomous vehicle is closely intertwined with the evolving dynamics of its environment, and conversely, the vehicle's own future states can influence how the surrounding scene unfolds. Motivated by this bidirectional relationship, we introduce SeerDrive, a novel end-to-end framework that jointly models future scene evolution and trajectory planning in a closed-loop manner. Our method first predicts future bird's-eye view (BEV) representations to anticipate the dynamics of the surrounding scene, then leverages this foresight to generate future-context-aware trajectories. Two key components enable this: (1) future-aware planning, which injects predicted BEV features into the trajectory planner, and (2) iterative scene modeling and vehicle planning, which refines both future scene prediction and trajectory generation through collaborative optimization. Extensive experiments on the NAVSIM and nuScenes benchmarks show that SeerDrive significantly outperforms existing state-of-the-art methods.",
    "authors": [
      "Bozhou Zhang",
      "Nan Song",
      "Jingyu Li",
      "Xiatian Zhu",
      "Jiankang Deng",
      "Li Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T07:41:47.000Z",
    "updatedAt": "2025-10-13T07:41:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11092v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11092v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11091v1",
    "arxivId": "2510.11091v1",
    "title": "Text-Enhanced Panoptic Symbol Spotting in CAD Drawings",
    "abstract": "With the widespread adoption of Computer-Aided Design(CAD) drawings in engineering, architecture, and industrial design, the ability to accurately interpret and analyze these drawings has become increasingly critical. Among various subtasks, panoptic symbol spotting plays a vital role in enabling downstream applications such as CAD automation and design retrieval. Existing methods primarily focus on geometric primitives within the CAD drawings to address this task, but they face following major problems: they usually overlook the rich textual annotations present in CAD drawings and they lack explicit modeling of relationships among primitives, resulting in incomprehensive understanding of the holistic drawings. To fill this gap, we propose a panoptic symbol spotting framework that incorporates textual annotations. The framework constructs unified representations by jointly modeling geometric and textual primitives. Then, using visual features extract by pretrained CNN as the initial representations, a Transformer-based backbone is employed, enhanced with a type-aware attention mechanism to explicitly model the different types of spatial dependencies between various primitives. Extensive experiments on the real-world dataset demonstrate that the proposed method outperforms existing approaches on symbol spotting tasks involving textual annotations, and exhibits superior robustness when applied to complex CAD drawings.",
    "authors": [
      "Xianlin Liu",
      "Yan Gong",
      "Bohao Li",
      "Jiajing Huang",
      "Bowen Du",
      "Junchen Ye",
      "Liyan Xu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:41:15.000Z",
    "updatedAt": "2025-10-13T07:41:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11091v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11091v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11090v1",
    "arxivId": "2510.11090v1",
    "title": "Source-Free Object Detection with Detection Transformer",
    "abstract": "Source-Free Object Detection (SFOD) enables knowledge transfer from a source domain to an unsupervised target domain for object detection without access to source data. Most existing SFOD approaches are either confined to conventional object detection (OD) models like Faster R-CNN or designed as general solutions without tailored adaptations for novel OD architectures, especially Detection Transformer (DETR). In this paper, we introduce Feature Reweighting ANd Contrastive Learning NetworK (FRANCK), a novel SFOD framework specifically designed to perform query-centric feature enhancement for DETRs. FRANCK comprises four key components: (1) an Objectness Score-based Sample Reweighting (OSSR) module that computes attention-based objectness scores on multi-scale encoder feature maps, reweighting the detection loss to emphasize less-recognized regions; (2) a Contrastive Learning with Matching-based Memory Bank (CMMB) module that integrates multi-level features into memory banks, enhancing class-wise contrastive learning; (3) an Uncertainty-weighted Query-fused Feature Distillation (UQFD) module that improves feature distillation through prediction quality reweighting and query feature fusion; and (4) an improved self-training pipeline with a Dynamic Teacher Updating Interval (DTUI) that optimizes pseudo-label quality. By leveraging these components, FRANCK effectively adapts a source-pre-trained DETR model to a target domain with enhanced robustness and generalization. Extensive experiments on several widely used benchmarks demonstrate that our method achieves state-of-the-art performance, highlighting its effectiveness and compatibility with DETR-based SFOD models.",
    "authors": [
      "Huizai Yao",
      "Sicheng Zhao",
      "Shuo Lu",
      "Hui Chen",
      "Yangyang Li",
      "Guoping Liu",
      "Tengfei Xing",
      "Chenggang Yan",
      "Jianhua Tao",
      "Guiguang Ding"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:35:04.000Z",
    "updatedAt": "2025-10-13T07:35:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11090v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11090v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11089v1",
    "arxivId": "2510.11089v1",
    "title": "Establishing assembly-oriented modular product architectures through Design for Assembly enhanced Modular Function Deployment",
    "abstract": "Modular product design has become a strategic enabler for companies seeking to balance product variety, operational efficiency, and market responsiveness, making the alignment between modular architecture and manufacturing considerations increasingly critical. Modular Function Deployment (MFD) is a widely adopted method for defining modular product architectures, yet it lacks systematic support for assembly considerations during early concept and system-level development. This limitation increases the risk of delayed production ramp-up and lifecycle inefficiencies. This paper proposes a set of enhancements to MFD that integrate Design for Assembly (DFA) logic into architectural synthesis. The extended method introduces structured heuristics, assembly-oriented module drivers, a coded interface taxonomy, and quantitative metrics for assessing assembly feasibility and automation readiness. These additions preserve compatibility with standard MFD workflows while enriching decision-making with traceable, production-informed reasoning. An illustrative case study involving a handheld leaf blower demonstrates the method's usability and effectiveness. The redesigned architecture shows reduced assembly effort, simplified interfaces, and increased automation potential. By supporting early-stage evaluation of architectural alternatives through an assembly lens, the method enables faster transition to efficient volume production and provides a foundation for continuous improvement throughout the product lifecycle.",
    "authors": [
      "Fabio Marco Monetti",
      "Adam Lundström",
      "Colin de Kwant",
      "Magnus Gyllenskepp",
      "Antonio Maffei"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T07:33:39.000Z",
    "updatedAt": "2025-10-13T07:33:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11089v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11089v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11087v1",
    "arxivId": "2510.11087v1",
    "title": "UXer-AI Collaboration Process for Enhancing Trust",
    "abstract": "In recent years, discussions on integrating Artificial Intelligence (AI) into UX design have intensified. However, the practical application of AI tools in design is limited by their operation within overly simplified scenarios, inherent complexity and unpredictability, and a general lack of relevant education. This study proposes an effective UXer-AI collaboration process to address these issues and seeks to identify efficient AI collaboration strategies through a series of user studies. In a preliminary study, two participatory design workshops identified major barriers to UXer-AI collaboration, including unfamiliarity with AI, inadequate internal support, and trust issues. To address the particularly critical issue of diminished trust, this study developed a new AI prototype model, TW-AI, that incorporates verification and decision-making processes to enhance trust and operational efficiency in UX design tasks. Task performance experiments and in-depth interviews evaluated the TW-AI model, revealing significant improvements in practitioners' trust, work efficiency, understanding of usage timing, and controllability. The \"Source\" function, based on Retrieval-Augmented Generation (RAG) technology, notably enhanced the reliability of the AI tool. Participants noted improved communication efficiency and reduced decision-making time, attributing these outcomes to the model's comprehensive verification features and streamlined approach to complex verification tasks. This study advances UXer-AI collaboration by providing key insights, bridging research and practice with actionable strategies, and establishing guidelines for AI tool designs tailored to UX. It contributes to the HCI community by outlining a scalable UXer-AI collaboration framework that addresses immediate operational challenges and lays the foundation for future advancements in AI-driven UX methodologies.",
    "authors": [
      "Harin Yoon",
      "Dongwhan Kim",
      "Changhoon Oh",
      "Soojin Jun"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T07:30:31.000Z",
    "updatedAt": "2025-10-13T07:30:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11087v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11087v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11085v1",
    "arxivId": "2510.11085v1",
    "title": "Modeling AI-Driven Production and Competitiveness A Multi-Agent Economic Simulation of China and the United States",
    "abstract": "With the rapid development of artificial intelligence (AI) technology, socio-economic systems are entering a new stage of \"human-AI co-creation.\" Building upon a previously established multi-level intelligent agent economic model, this paper conducts simulation-based comparisons of macroeconomic output evolution in China and the United States under different mechanisms-AI collaboration, network effects, and AI autonomous production. The results show that: (1) when AI functions as an independent productive entity, the overall growth rate of social output far exceeds that of traditional human-labor-based models; (2) China demonstrates clear potential for acceleration in both the expansion of intelligent agent populations and the pace of technological catch-up, offering the possibility of achieving technological convergence or even partial surpassing. This study provides a systematic, model-based analytical framework for understanding AI-driven production system transformation and shifts in international competitiveness, as well as quantitative insights for relevant policy formulation.",
    "authors": [
      "Yuxinyue Qian",
      "Jun Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:28:14.000Z",
    "updatedAt": "2025-10-13T07:28:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11085v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11085v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11084v1",
    "arxivId": "2510.11084v1",
    "title": "Causal Disentanglement Learning for Accurate Anomaly Detection in Multivariate Time Series",
    "abstract": "Disentangling complex causal relationships is important for accurate detection of anomalies. In multivariate time series analysis, dynamic interactions among data variables over time complicate the interpretation of causal relationships. Traditional approaches assume statistical independence between variables in unsupervised settings, whereas recent methods capture feature correlations through graph representation learning. However, their representations fail to explicitly infer the causal relationships over different time periods. To solve the problem, we propose Causally Disentangled Representation Learning for Anomaly Detection (CDRL4AD) to detect anomalies and identify their causal relationships in multivariate time series. First, we design the causal process as model input, the temporal heterogeneous graph, and causal relationships. Second, our representation identifies causal relationships over different time periods and disentangles latent variables to infer the corresponding causal factors. Third, our experiments on real-world datasets demonstrate that CDRL4AD outperforms state-of-the-art methods in terms of accuracy and root cause analysis. Fourth, our model analysis validates hyperparameter sensitivity and the time complexity of CDRL4AD. Last, we conduct a case study to show how our approach assists human experts in diagnosing the root causes of anomalies.",
    "authors": [
      "Wonah Kim",
      "Jeonghyeon Park",
      "Dongsan Jun",
      "Jungkyu Han",
      "Sejin Chun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:26:20.000Z",
    "updatedAt": "2025-10-13T07:26:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11084v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11084v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11083v1",
    "arxivId": "2510.11083v1",
    "title": "Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling",
    "abstract": "Modeling interactive driving behaviors in complex scenarios remains a fundamental challenge for autonomous driving planning. Learning-based approaches attempt to address this challenge with advanced generative models, removing the dependency on over-engineered architectures for representation fusion. However, brute-force implementation by simply stacking transformer blocks lacks a dedicated mechanism for modeling interactive behaviors that are common in real driving scenarios. The scarcity of interactive driving data further exacerbates this problem, leaving conventional imitation learning methods ill-equipped to capture high-value interactive behaviors. We propose Flow Planner, which tackles these problems through coordinated innovations in data modeling, model architecture, and learning scheme. Specifically, we first introduce fine-grained trajectory tokenization, which decomposes the trajectory into overlapping segments to decrease the complexity of whole trajectory modeling. With a sophisticatedly designed architecture, we achieve efficient temporal and spatial fusion of planning and scene information, to better capture interactive behaviors. In addition, the framework incorporates flow matching with classifier-free guidance for multi-modal behavior generation, which dynamically reweights agent interactions during inference to maintain coherent response strategies, providing a critical boost for interactive scenario understanding. Experimental results on the large-scale nuPlan dataset and challenging interactive interPlan dataset demonstrate that Flow Planner achieves state-of-the-art performance among learning-based approaches while effectively modeling interactive behaviors in complex driving scenarios.",
    "authors": [
      "Tianyi Tan",
      "Yinan Zheng",
      "Ruiming Liang",
      "Zexu Wang",
      "Kexin Zheng",
      "Jinliang Zheng",
      "Jianxiong Li",
      "Xianyuan Zhan",
      "Jingjing Liu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:25:13.000Z",
    "updatedAt": "2025-10-13T07:25:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11083v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11083v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11082v1",
    "arxivId": "2510.11082v1",
    "title": "On Runge-Kutta convolution quadrature based fractional variational integrators",
    "abstract": "Lagrangian systems subject to fractional damping can be incorporated into a variational formalism. The construction can be made by doubling the state variables and introducing fractional derivatives \\cite{JiOb2}. The main objective of this paper is to use the Runge-Kutta convolution quadrature (RKCQ) method for approximating fractional derivatives, combined with higher order Galerkin methods in order to derive fractional variational integrators (FVIs). We are specially interested in the CQ based on Lobatto IIIC. Preservation properties such as energy decay as well as convergence properties are investigated numerically and proved for 2nd order schemes. The presented schemes reach 2nd, 4th and 6th accuracy order. A brief discussion on the midpoint fractional integrator is also included.",
    "authors": [
      "Khaled Hariz",
      "Sina Ober-Blöbaum",
      "Fernando Jimenez"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T07:24:14.000Z",
    "updatedAt": "2025-10-13T07:24:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11082v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11082v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11080v1",
    "arxivId": "2510.11080v1",
    "title": "Non-Expansive Fuzzy Coalgebraic Logic",
    "abstract": "Fuzzy logic extends the classical truth values \"true\" and \"false\" with additional truth degrees in between, typically real numbers in the unit interval. More specifically, fuzzy modal logics in this sense are given by a choice of fuzzy modalities and a fuzzy propositional base. It has been noted that fuzzy modal logics over the Zadeh base, which interprets disjunction as maximum, are often computationally tractable but on the other hand add little in the way of expressivity to their classical counterparts. Contrastingly, fuzzy modal logics over the more expressive Lukasiewicz base have attractive logical properties but are often computationally less tractable or even undecidable. In the basic case of the modal logic of fuzzy relations, sometimes termed fuzzy ALC, it has recently been shown that an intermediate non-expansive propositional base, known from characteristic logics for behavioural distances of quantitative systems, strikes a balance between these poles: It provides increased expressiveness over the Zadeh base while avoiding the computational problems of the Lukasiewicz base, in fact allowing for reasoning in PSpace. Modal logics, in particular fuzzy modal logics, generally vary widely in terms of syntax and semantics, involving, for instance, probabilistic, preferential, or weighted structures. Coalgebraic modal logic provides a unifying framework for wide ranges of semantically different modal logics, both two-valued and fuzzy. In the present work, we focus on non-expansive coalgebraic fuzzy modal logics, providing a criterion for decidability in PSpace. Using this criterion, we recover the mentioned complexity result for non-expansive fuzzy ALC and moreover obtain new PSpace upper bounds for various quantitative modal logics for probabilistic and metric transition systems.",
    "authors": [
      "Stefan Gebhart",
      "Lutz Schröder",
      "Paul Wild"
    ],
    "categories": [
      "cs.LO"
    ],
    "publishedAt": "2025-10-13T07:19:28.000Z",
    "updatedAt": "2025-10-13T07:19:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11080v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11080v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11079v1",
    "arxivId": "2510.11079v1",
    "title": "Argumentation-Based Explainability for Legal AI: Comparative and Regulatory Perspectives",
    "abstract": "Artificial Intelligence (AI) systems are increasingly deployed in legal contexts, where their opacity raises significant challenges for fairness, accountability, and trust. The so-called ``black box problem'' undermines the legitimacy of automated decision-making, as affected individuals often lack access to meaningful explanations. In response, the field of Explainable AI (XAI) has proposed a variety of methods to enhance transparency, ranging from example-based and rule-based techniques to hybrid and argumentation-based approaches. This paper promotes computational models of arguments and their role in providing legally relevant explanations, with particular attention to their alignment with emerging regulatory frameworks such as the EU General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AIA). We analyze the strengths and limitations of different explanation strategies, evaluate their applicability to legal reasoning, and highlight how argumentation frameworks -- by capturing the defeasible, contestable, and value-sensitive nature of law -- offer a particularly robust foundation for explainable legal AI. Finally, we identify open challenges and research directions, including bias mitigation, empirical validation in judicial settings, and compliance with evolving ethical and legal standards, arguing that computational argumentation is best positioned to meet both technical and normative requirements of transparency in the law domain.",
    "authors": [
      "Andrada Iulia Prajescu",
      "Roberto Confalonieri"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T07:19:15.000Z",
    "updatedAt": "2025-10-13T07:19:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11079v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11079v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11076v1",
    "arxivId": "2510.11076v1",
    "title": "DebugTA: An LLM-Based Agent for Simplifying Debugging and Teaching in Programming Education",
    "abstract": "In programming education, Debugging and Teaching (DT) task is a common scenario where students receive assistance in correcting their erroneous code. The task involves multiple inputs, including erroneous code, error messages, reference solutions, and the question description, with the goal of generating modification suggestions to the erroneous code. However, two key challenges hinder the effectiveness of existing approaches. Firstly, the complexity and heterogeneity of inputs inherent in DT tasks significantly elevate the reasoning challenges faced by LLMs. Second, existing approaches often fail to fully leverage the availability of standard code in DT tasks, forcing models to rely solely on complex multi-step reasoning, which limits the potential of LLMs in addressing DT tasks effectively. To address these challenges, we propose DebugTA, a novel LLM-based debugging and teaching agent with specialized tools for standard code retrieval, variable substitution to align reference code, and an external compiler for real-time code analysis. Guided by explicit pedagogical and debugging principles, DebugTA acts as an agent that decomposes a complex task into sequential LLM interactions, each utilizing distinct tools for specific subtasks, thereby simplifying the logical reasoning at each step and reducing overall reasoning complexity. Furthermore, DebugTA utilizes tool calls to align the standard code with the erroneous code as much as possible, allowing the LLM to focus on logic errors within the erroneous code and improving the accuracy of the generated suggestions. To rigorously assess the quality of modification suggestions, we introduce a student simulator-teacher interaction paradigm. Experimental results on three real-world code datasets demonstrate that DebugTA consistently improves teaching effectiveness while significantly reducing computational costs.",
    "authors": [
      "Lingyue Fu",
      "Haowei Yuan",
      "Datong Chen",
      "Xinyi Dai",
      "Qingyao Li",
      "Weinan Zhang",
      "Weiwen Liu",
      "Yong Yu"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-13T07:17:18.000Z",
    "updatedAt": "2025-10-13T07:17:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11076v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11076v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11073v1",
    "arxivId": "2510.11073v1",
    "title": "ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer",
    "abstract": "Patient face images provide a convenient mean for evaluating eye diseases, while also raising privacy concerns. Here, we introduce ROFI, a deep learning-based privacy protection framework for ophthalmology. Using weakly supervised learning and neural identity translation, ROFI anonymizes facial features while retaining disease features (over 98\\% accuracy, $\\kappa > 0.90$). It achieves 100\\% diagnostic sensitivity and high agreement ($\\kappa > 0.90$) across eleven eye diseases in three cohorts, anonymizing over 95\\% of images. ROFI works with AI systems, maintaining original diagnoses ($\\kappa > 0.80$), and supports secure image reversal (over 98\\% similarity), enabling audits and long-term care. These results show ROFI's effectiveness of protecting patient privacy in the digital medicine era.",
    "authors": [
      "Yuan Tian",
      "Min Zhou",
      "Yitong Chen",
      "Fang Li",
      "Lingzi Qi",
      "Shuo Wang",
      "Xieyang Xu",
      "Yu Yu",
      "Shiqiong Xu",
      "Chaoyu Lei",
      "Yankai Jiang",
      "Rongzhao Zhang",
      "Jia Tan",
      "Li Wu",
      "Hong Chen",
      "Xiaowei Liu",
      "Wei Lu",
      "Lin Li",
      "Huifang Zhou",
      "Xuefei Song",
      "Guangtao Zhai",
      "Xianqun Fan"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T07:12:23.000Z",
    "updatedAt": "2025-10-13T07:12:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11073v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11073v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11072v1",
    "arxivId": "2510.11072v1",
    "title": "PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System",
    "abstract": "Deploying humanoid robots to interact with real-world environments--such as carrying objects or sitting on chairs--requires generalizable, lifelike motions and robust scene perception. Although prior approaches have advanced each capability individually, combining them in a unified system is still an ongoing challenge. In this work, we present a physical-world humanoid-scene interaction system, PhysHSI, that enables humanoids to autonomously perform diverse interaction tasks while maintaining natural and lifelike behaviors. PhysHSI comprises a simulation training pipeline and a real-world deployment system. In simulation, we adopt adversarial motion prior-based policy learning to imitate natural humanoid-scene interaction data across diverse scenarios, achieving both generalization and lifelike behaviors. For real-world deployment, we introduce a coarse-to-fine object localization module that combines LiDAR and camera inputs to provide continuous and robust scene perception. We validate PhysHSI on four representative interactive tasks--box carrying, sitting, lying, and standing up--in both simulation and real-world settings, demonstrating consistently high success rates, strong generalization across diverse task goals, and natural motion patterns.",
    "authors": [
      "Huayi Wang",
      "Wentao Zhang",
      "Runyi Yu",
      "Tao Huang",
      "Junli Ren",
      "Feiyu Jia",
      "Zirui Wang",
      "Xiaojie Niu",
      "Xiao Chen",
      "Jiahe Chen",
      "Qifeng Chen",
      "Jingbo Wang",
      "Jiangmiao Pang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-13T07:11:37.000Z",
    "updatedAt": "2025-10-13T07:11:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11072v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11072v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11068v1",
    "arxivId": "2510.11068v1",
    "title": "Efficient Edge Test-Time Adaptation via Latent Feature Coordinate Correction",
    "abstract": "Edge devices face significant challenges due to limited computational resources and distribution shifts, making efficient and adaptable machine learning essential. Existing test-time adaptation (TTA) methods often rely on gradient-based optimization or batch processing, which are inherently unsuitable for resource-constrained edge scenarios due to their reliance on backpropagation and high computational demands. Gradient-free alternatives address these issues but often suffer from limited learning capacity, lack flexibility, or impose architectural constraints. To overcome these limitations, we propose a novel single-instance TTA method tailored for edge devices (TED), which employs forward-only coordinate optimization in the principal subspace of latent using the covariance matrix adaptation evolution strategy (CMA-ES). By updating a compact low-dimensional vector, TED not only enhances output confidence but also aligns the latent representation closer to the source latent distribution within the latent principal subspace. This is achieved without backpropagation, keeping the model parameters frozen, and enabling efficient, forgetting-free adaptation with minimal memory and computational overhead. Experiments on image classification and keyword spotting tasks across the ImageNet and Google Speech Commands series datasets demonstrate that TED achieves state-of-the-art performance while $\\textit{reducing computational complexity by up to 63 times}$, offering a practical and scalable solution for real-world edge applications. Furthermore, we successfully $\\textit{deployed TED on the ZYNQ-7020 platform}$, demonstrating its feasibility and effectiveness for resource-constrained edge devices in real-world deployments.",
    "authors": [
      "Xinyu Luo",
      "Jie Liu",
      "Kecheng Chen",
      "Junyi Yang",
      "Bo Ding",
      "Arindam Basu",
      "Haoliang Li"
    ],
    "categories": [
      "cs.LG",
      "eess.AS",
      "eess.IV"
    ],
    "publishedAt": "2025-10-13T07:08:52.000Z",
    "updatedAt": "2025-10-13T07:08:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11068v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11068v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11066v1",
    "arxivId": "2510.11066v1",
    "title": "Decoupled Multimodal Fusion for User Interest Modeling in Click-Through Rate Prediction",
    "abstract": "Modern industrial recommendation systems improve recommendation performance by integrating multimodal representations from pre-trained models into ID-based Click-Through Rate (CTR) prediction frameworks. However, existing approaches typically adopt modality-centric modeling strategies that process ID-based and multimodal embeddings independently, failing to capture fine-grained interactions between content semantics and behavioral signals. In this paper, we propose Decoupled Multimodal Fusion (DMF), which introduces a modality-enriched modeling strategy to enable fine-grained interactions between ID-based collaborative representations and multimodal representations for user interest modeling. Specifically, we construct target-aware features to bridge the semantic gap across different embedding spaces and leverage them as side information to enhance the effectiveness of user interest modeling. Furthermore, we design an inference-optimized attention mechanism that decouples the computation of target-aware features and ID-based embeddings before the attention layer, thereby alleviating the computational bottleneck introduced by incorporating target-aware features. To achieve comprehensive multimodal integration, DMF combines user interest representations learned under the modality-centric and modality-enriched modeling strategies. Offline experiments on public and industrial datasets demonstrate the effectiveness of DMF. Moreover, DMF has been deployed on the product recommendation system of the international e-commerce platform Lazada, achieving relative improvements of 5.30% in CTCVR and 7.43% in GMV with negligible computational overhead.",
    "authors": [
      "Alin Fan",
      "Hanqing Li",
      "Sihan Lu",
      "Jingsong Yuan",
      "Jiandong Zhang"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T07:06:26.000Z",
    "updatedAt": "2025-10-13T07:06:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11066v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11066v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11065v1",
    "arxivId": "2510.11065v1",
    "title": "Stabilizing the Staking Rate, Dynamically Distributed Inflation and Delay Induced Oscillations",
    "abstract": "Dynamically distributed inflation is a common mechanism used to guide a blockchain's staking rate towards a desired equilibrium between network security and token liquidity. However, the high sensitivity of the annual percentage yield to changes in the staking rate, coupled with the inherent feedback delays in staker responses, can induce undesirable oscillations around this equilibrium. This paper investigates this instability phenomenon. We analyze the dynamics of inflation-based reward systems and propose a novel distribution model designed to stabilize the staking rate. Our solution effectively dampens oscillations, stabilizing the yield within a target staking range.",
    "authors": [
      "Carlo Brunetta",
      "Amit Chaudhary",
      "Stefano Galatolo",
      "Massimiliano Sala"
    ],
    "categories": [
      "cs.CR",
      "econ.GN",
      "math.DS",
      "q-fin.EC"
    ],
    "publishedAt": "2025-10-13T07:04:52.000Z",
    "updatedAt": "2025-10-13T07:04:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11065v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11065v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11064v1",
    "arxivId": "2510.11064v1",
    "title": "Detecting Gender Stereotypes in Scratch Programming Tutorials",
    "abstract": "Gender stereotypes in introductory programming courses often go unnoticed, yet they can negatively influence young learners' interest and learning, particularly under-represented groups such as girls. Popular tutorials on block-based programming with Scratch may unintentionally reinforce biases through character choices, narrative framing, or activity types. Educators currently lack support in identifying and addressing such bias. With large language models~(LLMs) increasingly used to generate teaching materials, this problem is potentially exacerbated by LLMs trained on biased datasets. However, LLMs also offer an opportunity to address this issue. In this paper, we explore the use of LLMs for automatically identifying gender-stereotypical elements in Scratch tutorials, thus offering feedback on how to improve teaching content. We develop a framework for assessing gender bias considering characters, content, instructions, and programming concepts. Analogous to how code analysis tools provide feedback on code in terms of code smells, we operationalise this framework using an automated tool chain that identifies *gender stereotype smells*. Evaluation on 73 popular Scratch tutorials from leading educational platforms demonstrates that stereotype smells are common in practice. LLMs are not effective at detecting them, but our gender bias evaluation framework can guide LLMs in generating tutorials with fewer stereotype smells.",
    "authors": [
      "Isabella Graßl",
      "Benedikt Fein",
      "Gordon Fraser"
    ],
    "categories": [
      "cs.CY"
    ],
    "publishedAt": "2025-10-13T07:04:26.000Z",
    "updatedAt": "2025-10-13T07:04:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11064v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11064v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11063v1",
    "arxivId": "2510.11063v1",
    "title": "LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation",
    "abstract": "This report presents an overview of the 7th Large-scale Video Object Segmentation (LSVOS) Challenge held in conjunction with ICCV 2025. Besides the two traditional tracks of LSVOS that jointly target robustness in realistic video scenarios: Classic VOS (VOS), and Referring VOS (RVOS), the 2025 edition features a newly introduced track, Complex VOS (MOSEv2). Building upon prior insights, MOSEv2 substantially increases difficulty, introducing more challenging but realistic scenarios including denser small objects, frequent disappear/reappear events, severe occlusions, adverse weather and lighting, etc., pushing long-term consistency and generalization beyond curated benchmarks. The challenge retains standard ${J}$, $F$, and ${J\\&F}$ metrics for VOS and RVOS, while MOSEv2 adopts ${J\\&\\dot{F}}$ as the primary ranking metric to better evaluate objects across scales and disappearance cases. We summarize datasets and protocols, highlight top-performing solutions, and distill emerging trends, such as the growing role of LLM/MLLM components and memory-aware propagation, aiming to chart future directions for resilient, language-aware video segmentation in the wild.",
    "authors": [
      "Chang Liu",
      "Henghui Ding",
      "Kaining Ying",
      "Lingyi Hong",
      "Ning Xu",
      "Linjie Yang",
      "Yuchen Fan",
      "Mingqi Gao",
      "Jingkun Chen",
      "Yunqi Miao",
      "Gengshen Wu",
      "Zhijin Qin",
      "Jungong Han",
      "Zhixiong Zhang",
      "Shuangrui Ding",
      "Xiaoyi Dong",
      "Yuhang Zang",
      "Yuhang Cao",
      "Jiaqi Wang",
      "Chang Soo Lim",
      "Joonyoung Moon",
      "Donghyeon Cho",
      "Tingmin Li",
      "Yixuan Li",
      "Yang Yang",
      "An Yan",
      "Leilei Cao",
      "Feng Lu",
      "Ran Hong",
      "Youhai Jiang",
      "Fengjie Zhu",
      "Yujie Xie",
      "Hongyang Zhang",
      "Zhihui Liu",
      "Shihai Ruan",
      "Quanzhu Niu",
      "Dengxian Gong",
      "Shihao Chen",
      "Tao Zhang",
      "Yikang Zhou",
      "Haobo Yuan",
      "Lu Qi",
      "Xiangtai Li",
      "Shunping Ji",
      "Ran Hong",
      "Feng Lu",
      "Leilei Cao",
      "An Yan",
      "Alexey Nekrasov",
      "Ali Athar",
      "Daan de Geus",
      "Alexander Hermans",
      "Bastian Leibe"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T07:02:09.000Z",
    "updatedAt": "2025-10-13T07:02:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11063v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11063v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11062v1",
    "arxivId": "2510.11062v1",
    "title": "Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs",
    "abstract": "Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to enhance the agentic capabilities of large language models (LLMs). MAS improves task performance through role-based orchestration, while RL uses environmental rewards to learn stronger policies, such as GRPO-style optimization. However, applying on-policy RL to MAS remains underexplored and presents unique challenges. Algorithmically, standard GRPO grouping assumptions break down because prompts vary by role and by turn. System-wise, the training stack must support MAS-workflow rollouts and on-policy updates for both single-policy and multi-policy models. We propose AT-GRPO, which includes (i) an agent- and turn-wise grouped RL algorithm tailored to MAS and (ii) a training system that supports both single- and multi-policy regimes. Across game, planning, coding, and math tasks, AT-GRPO delivers substantial gains. On long-horizon planning, it increases accuracy from a 14.0 to 47.0 percent single-agent RL baseline to 96.0 to 99.5 percent. It also improves reasoning performance, with average gains of 3.87 to 7.62 percent on coding tasks and 9.0 to 17.93 percent on math. Code and environments are available at: https://github.com/pettingllms-ai/PettingLLMs.",
    "authors": [
      "Yujie Zhao",
      "Lanxiang Hu",
      "Yang Wang",
      "Minmin Hou",
      "Hao Zhang",
      "Ke Ding",
      "Jishen Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "publishedAt": "2025-10-13T06:55:09.000Z",
    "updatedAt": "2025-10-13T06:55:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11062v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11062v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11059v1",
    "arxivId": "2510.11059v1",
    "title": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
    "abstract": "Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to the lack of high-quality, open-source benchmarks tailored for C/C++. To address this issue, we introduce Defects4C, a comprehensive and executable benchmark specifically designed for C/C++ program repair. Our dataset is constructed from real-world C/C++ repositories and includes a large collection of bug-relevant commits (9M in total), 248 high-quality buggy functions, and 102 vulnerable functions, all paired with test cases for reproduction. These resources enable rigorous evaluation of repair techniques and support the retraining of learning-based approaches for enhanced performance. Using Defects4C, we conduct a comprehensive empirical study evaluating the effectiveness of 24 state-of-the-art large language models (LLMs) in repairing C/C++ faults. Our findings offer valuable insights into the strengths and limitations of current LLM-based APR techniques in this domain, highlighting both the need for more robust methods and the critical role of Defects4C in advancing future research",
    "authors": [
      "Jian Wang",
      "Xiaofei Xie",
      "Qiang Hu",
      "Shangqing Liu",
      "Jiongchi Yu",
      "Jiaolong Klong",
      "Yi Li"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-13T06:49:28.000Z",
    "updatedAt": "2025-10-13T06:49:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11059v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11059v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11058v1",
    "arxivId": "2510.11058v1",
    "title": "Robust Photoplethysmography Signal Denoising via Mamba Networks",
    "abstract": "Photoplethysmography (PPG) is widely used in wearable health monitoring, but its reliability is often degraded by noise and motion artifacts, limiting downstream applications such as heart rate (HR) estimation. This paper presents a deep learning framework for PPG denoising with an emphasis on preserving physiological information. In this framework, we propose DPNet, a Mamba-based denoising backbone designed for effective temporal modeling. To further enhance denoising performance, the framework also incorporates a scale-invariant signal-to-distortion ratio (SI-SDR) loss to promote waveform fidelity and an auxiliary HR predictor (HRP) that provides physiological consistency through HR-based supervision. Experiments on the BIDMC dataset show that our method achieves strong robustness against both synthetic noise and real-world motion artifacts, outperforming conventional filtering and existing neural models. Our method can effectively restore PPG signals while maintaining HR accuracy, highlighting the complementary roles of SI-SDR loss and HR-guided supervision. These results demonstrate the potential of our approach for practical deployment in wearable healthcare systems.",
    "authors": [
      "I Chiu",
      "Yu-Tung Liu",
      "Kuan-Chen Wang",
      "Hung-Yu Wei",
      "Yu Tsao"
    ],
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "publishedAt": "2025-10-13T06:47:44.000Z",
    "updatedAt": "2025-10-13T06:47:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11058v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11058v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11057v1",
    "arxivId": "2510.11057v1",
    "title": "Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models",
    "abstract": "Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often breaks sample fidelity. In this paper, we propose a general solution to address the off-manifold phenomenon observed in diffusion models. Our approach leverages a time predictor to estimate deviations from the desired data manifold at each timestep, identifying that a larger time gap is associated with reduced generation quality. We then design a novel guidance mechanism, `Temporal Alignment Guidance' (TAG), attracting the samples back to the desired manifold at every timestep during generation. Through extensive experiments, we demonstrate that TAG consistently produces samples closely aligned with the desired manifold at each timestep, leading to significant improvements in generation quality across various downstream tasks.",
    "authors": [
      "Youngrok Park",
      "Hojung Jung",
      "Sangmin Bae",
      "Se-Young Yun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T06:46:57.000Z",
    "updatedAt": "2025-10-13T06:46:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11057v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11057v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11056v1",
    "arxivId": "2510.11056v1",
    "title": "From Reasoning LLMs to BERT: A Two-Stage Distillation Framework for Search Relevance",
    "abstract": "Query-service relevance prediction in e-commerce search systems faces strict latency requirements that prevent the direct application of Large Language Models (LLMs). To bridge this gap, we propose a two-stage reasoning distillation framework to transfer reasoning capabilities from a powerful teacher LLM to a lightweight, deployment-friendly student model. In the first stage, we address the limitations of general-purpose LLMs by constructing a domain-adapted teacher model. This is achieved through a three-step process: domain-adaptive pre-training to inject platform knowledge, supervised fine-tuning to elicit reasoning skills, and preference optimization with a multi-dimensional reward model to ensure the generation of reliable and preference-aligned reasoning paths. This teacher can then automatically annotate massive query-service pairs from search logs with both relevance labels and reasoning chains. In the second stage, to address the challenges of architectural heterogeneity in standard distillation, we introduce Contrastive Reasoning Self-Distillation (CRSD). By modeling the behavior of the same student model under \"standard\" and \"reasoning-augmented\" inputs as a teacher-student relationship, CRSD enables the lightweight model to internalize the teacher's complex decision-making mechanisms without needing the explicit reasoning path at inference. Offline evaluations and online A/B testing in the Meituan search advertising system demonstrate that our framework achieves significant improvements across multiple metrics, validating its effectiveness and practical value.",
    "authors": [
      "Runze Xia",
      "Yupeng Ji",
      "Yuxi Zhou",
      "Haodong Liu",
      "Teng Zhang",
      "Piji Li"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T06:46:43.000Z",
    "updatedAt": "2025-10-13T06:46:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11056v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11056v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11053v1",
    "arxivId": "2510.11053v1",
    "title": "Assessing the Role of Communication in Modular Multi-Core Quantum Systems",
    "abstract": "The scalability of quantum computing is constrained by the physical and architectural limitations of monolithic quantum processors. Modular multi-core quantum architectures, which interconnect multiple quantum cores (QCs) via classical and quantum-coherent links, offer a promising alternative to address these challenges. However, transitioning to a modular architecture introduces communication overhead, where classical communication plays a crucial role in executing quantum algorithms by transmitting measurement outcomes and synchronizing operations across QCs. Understanding the impact of classical communication on execution time is therefore essential for optimizing system performance. In this work, we introduce \\qcomm, an open-source simulator designed to evaluate the role of classical communication in modular quantum computing architectures. \\qcomm{} provides a high-level execution and timing model that captures the interplay between quantum gate execution, entanglement distribution, teleportation protocols, and classical communication latency. We conduct an extensive experimental analysis to quantify the impact of classical communication bandwidth, interconnect types, and quantum circuit mapping strategies on overall execution time. Furthermore, we assess classical communication overhead when executing real quantum benchmarks mapped onto a cryogenically-controlled multi-core quantum system. Our results show that, while classical communication is generally not the dominant contributor to execution time, its impact becomes increasingly relevant in optimized scenarios -- such as improved quantum technology, large-scale interconnects, or communication-aware circuit mappings. These findings provide useful insights for the design of scalable modular quantum architectures and highlight the importance of evaluating classical communication as a performance-limiting factor in future systems.",
    "authors": [
      "Maurizio Palesi",
      "Enrico Russo",
      "Giuseppe Ascia",
      "Hamaad Rafique",
      "Davide Patti",
      "Vincenzo Catania",
      "Sergi Abadal",
      "Abhijit Das",
      "Pau Escofet",
      "Eduard Alarcon",
      "Carmen G. Almudéver"
    ],
    "categories": [
      "quant-ph",
      "cs.ET"
    ],
    "publishedAt": "2025-10-13T06:41:41.000Z",
    "updatedAt": "2025-10-13T06:41:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11053v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11053v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11052v1",
    "arxivId": "2510.11052v1",
    "title": "Latent Refinement Decoding: Enhancing Diffusion-Based Language Models by Refining Belief States",
    "abstract": "Autoregressive (AR) models remain the standard for natural language generation but still suffer from high latency due to strictly sequential decoding. Recent diffusion-inspired approaches, such as LlaDA and Dream, mitigate this by generating in parallel, yet they suffer from two core limitations: information loss, as predictive distributions for non-finalized tokens are discarded at each step, and premature commitment, where local decisions are made without sufficient global coordination. We introduce Latent Refinement Decoding (LRD), a two-stage framework with Latent Refinement and a Predictive Feedback Loop. The first stage maintains masked positions as distributional mixtures of predicted tokens and the mask embedding, allowing the model to establish more globally consistent beliefs. The second stage progressively finalizes confident tokens while retaining uncertain ones for iterative feedback. KL-divergence dynamics provide a principled and reliable criterion for convergence and early stopping. Experiments across coding (HumanEval +6.3, MBPP +2.6) and reasoning (GSM8K +2.9, MATH500 +3.8) show that LRD improves accuracy while delivering speedups of up to 10.6x, making it a strong and versatile alternative for parallel sequence generation.",
    "authors": [
      "Qinglin Zhu",
      "Yizhen Yao",
      "Runcong Zhao",
      "Yanzheng Xiang",
      "Amrutha Saseendran",
      "Chen Jin",
      "Philip Alexander Teare",
      "Bin Liang",
      "Yulan He",
      "Lin Gui"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T06:38:13.000Z",
    "updatedAt": "2025-10-13T06:38:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11052v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11052v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11050v1",
    "arxivId": "2510.11050v1",
    "title": "Zero-shot Face Editing via ID-Attribute Decoupled Inversion",
    "abstract": "Recent advancements in text-guided diffusion models have shown promise for general image editing via inversion techniques, but often struggle to maintain ID and structural consistency in real face editing tasks. To address this limitation, we propose a zero-shot face editing method based on ID-Attribute Decoupled Inversion. Specifically, we decompose the face representation into ID and attribute features, using them as joint conditions to guide both the inversion and the reverse diffusion processes. This allows independent control over ID and attributes, ensuring strong ID preservation and structural consistency while enabling precise facial attribute manipulation. Our method supports a wide range of complex multi-attribute face editing tasks using only text prompts, without requiring region-specific input, and operates at a speed comparable to DDIM inversion. Comprehensive experiments demonstrate its practicality and effectiveness.",
    "authors": [
      "Yang Hou",
      "Minggu Wang",
      "Jianjun Zhao"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T06:34:40.000Z",
    "updatedAt": "2025-10-13T06:34:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11050v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11050v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11049v1",
    "arxivId": "2510.11049v1",
    "title": "Conformal Inference for Time Series over Graphs",
    "abstract": "Trustworthy decision making in networked, dynamic environments calls for innovative uncertainty quantification substrates in predictive models for graph time series. Existing conformal prediction (CP) methods have been applied separately to multivariate time series and static graphs, but they either ignore the underlying graph topology or neglect temporal dynamics. To bridge this gap, here we develop a CP-based sequential prediction region framework tailored for graph time series. A key technical innovation is to leverage the graph structure and thus capture pairwise dependencies across nodes, while providing user-specified coverage guarantees on the predictive outcomes. We formally establish that our scheme yields an exponential shrinkage in the volume of the ellipsoidal prediction set relative to its graph-agnostic counterpart. Using real-world datasets, we demonstrate that the novel uncertainty quantification framework maintains desired empirical coverage while achieving markedly smaller (up to 80% reduction) prediction regions than existing approaches.",
    "authors": [
      "Sonakshi Dua",
      "Gonzalo Mateos",
      "Sundeep Prabhakar Chepuri"
    ],
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "publishedAt": "2025-10-13T06:32:09.000Z",
    "updatedAt": "2025-10-13T06:32:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11049v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11049v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11047v1",
    "arxivId": "2510.11047v1",
    "title": "Benchmarking Deep Learning Models for Laryngeal Cancer Staging Using the LaryngealCT Dataset",
    "abstract": "Laryngeal cancer imaging research lacks standardised datasets to enable reproducible deep learning (DL) model development. We present LaryngealCT, a curated benchmark of 1,029 computed tomography (CT) scans aggregated from six collections from The Cancer Imaging Archive (TCIA). Uniform 1 mm isotropic volumes of interest encompassing the larynx were extracted using a weakly supervised parameter search framework validated by clinical experts. 3D DL architectures (3D CNN, ResNet18,50,101, DenseNet121) were benchmarked on (i) early (Tis,T1,T2) vs. advanced (T3,T4) and (ii) T4 vs. non-T4 classification tasks. 3D CNN (AUC-0.881, F1-macro-0.821) and ResNet18 (AUC-0.892, F1-macro-0.646) respectively outperformed the other models in the two tasks. Model explainability assessed using 3D GradCAMs with thyroid cartilage overlays revealed greater peri-cartilage attention in non-T4 cases and focal activations in T4 predictions. Through open-source data, pretrained models, and integrated explainability tools, LaryngealCT offers a reproducible foundation for AI-driven research to support clinical decisions in laryngeal oncology.",
    "authors": [
      "Nivea Roy",
      "Son Tran",
      "Atul Sajjanhar",
      "K. Devaraja",
      "Prakashini Koteshwara",
      "Yong Xiang",
      "Divya Rao"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T06:25:19.000Z",
    "updatedAt": "2025-10-13T06:25:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11047v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11047v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11043v1",
    "arxivId": "2510.11043v1",
    "title": "Zephyrus: Scaling Gateways Beyond the Petabit-Era with DPU-Augmented Hierarchical Co-Offloading",
    "abstract": "Operating at petabit-scale, ByteDance's cloud gateways are deployed at critical aggregation points to orchestrate a wide array of business traffic. However, this massive scale imposes significant resource pressure on our previous-generation cloud gateways, rendering them unsustainable in the face of ever-growing cloud-network traffic. As the DPU market rapidly expands, we see a promising path to meet our escalating business traffic demands by integrating DPUs with our established Tofino-based gateways. DPUs augment these gateways with substantially larger table capacities and richer programmability without compromising previously low-latency and high-throughput forwarding. Despite compelling advantages, the practical integration of DPUs into cloud gateways remains unexplored, primarily due to underlying challenges. In this paper, we present Zephyrus, a production-scale gateway built upon a unified P4 pipeline spanning high-performance Tofino and feature-rich DPUs, which successfully overcomes these challenges. We further introduce a hierarchical co-offloading architecture (HLCO) to orchestrate traffic flow within this heterogeneous gateway, achieving > 99% hardware offloading while retaining software fallback paths for complex operations. Zephyrus outperforms LuoShen (NSDI '24) with 33% higher throughput and our evaluation further indicates 21% lower power consumption and 14% lower hardware cost. Against FPGA-based systems, Albatross (SIGCOMM '25), it doubles the throughput at a substantially lower Total Cost of Ownership (TCO), showcasing its superior performance-per-dollar. Beyond these performance gains, we also share key lessons from several years of developing and operating Zephyrus at production scale. We believe these insights provide valuable references for researchers and practitioners designing performant cloud gateways.",
    "authors": [
      "Yuemeng Xu",
      "Haoran Chen",
      "Jiarui Guo",
      "Mingwei Cui",
      "Qiuheng Yin",
      "Cheng Dong",
      "Daxiang Kang",
      "Xian Wu",
      "Chenmin Sun",
      "Peng He",
      "Yang Gao",
      "Lirong Lai",
      "Kai Wang",
      "Hongyu Wu",
      "Tong Yang",
      "Xiyun Xu"
    ],
    "categories": [
      "cs.NI"
    ],
    "publishedAt": "2025-10-13T06:19:54.000Z",
    "updatedAt": "2025-10-13T06:19:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11043v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11043v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11041v1",
    "arxivId": "2510.11041v1",
    "title": "Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy",
    "abstract": "In future intelligent transportation systems, autonomous cooperative planning (ACP), becomes a promising technique to increase the effectiveness and security of multi-vehicle interactions. However, multiple uncertainties cannot be fully addressed for existing ACP strategies, e.g. perception, planning, and communication uncertainties. To address these, a novel deep reinforcement learning-based autonomous cooperative planning (DRLACP) framework is proposed to tackle various uncertainties on cooperative motion planning schemes. Specifically, the soft actor-critic (SAC) with the implementation of gate recurrent units (GRUs) is adopted to learn the deterministic optimal time-varying actions with imperfect state information occurred by planning, communication, and perception uncertainties. In addition, the real-time actions of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act (CARLA) simulation platform. Evaluation results show that the proposed DRLACP learns and performs cooperative planning effectively, which outperforms other baseline methods under different scenarios with imperfect AV state information.",
    "authors": [
      "Shiyao Zhang",
      "Liwei Deng",
      "Shuyu Zhang",
      "Weijie Yuan",
      "Hong Zhang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T06:19:15.000Z",
    "updatedAt": "2025-10-13T06:19:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11041v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11041v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11040v1",
    "arxivId": "2510.11040v1",
    "title": "Enabling Doctor-Centric Medical AI with LLMs through Workflow-Aligned Tasks and Benchmarks",
    "abstract": "The rise of large language models (LLMs) has transformed healthcare by offering clinical guidance, yet their direct deployment to patients poses safety risks due to limited domain expertise. To mitigate this, we propose repositioning LLMs as clinical assistants that collaborate with experienced physicians rather than interacting with patients directly. We conduct a two-stage inspiration-feedback survey to identify real-world needs in clinical workflows. Guided by this, we construct DoctorFLAN, a large-scale Chinese medical dataset comprising 92,000 Q&A instances across 22 clinical tasks and 27 specialties. To evaluate model performance in doctor-facing applications, we introduce DoctorFLAN-test (550 single-turn Q&A items) and DotaBench (74 multi-turn conversations). Experimental results with over ten popular LLMs demonstrate that DoctorFLAN notably improves the performance of open-source LLMs in medical contexts, facilitating their alignment with physician workflows and complementing existing patient-oriented models. This work contributes a valuable resource and framework for advancing doctor-centered medical LLM development",
    "authors": [
      "Wenya Xie",
      "Qingying Xiao",
      "Yu Zheng",
      "Xidong Wang",
      "Junying Chen",
      "Ke Ji",
      "Anningzhe Gao",
      "Prayag Tiwari",
      "Xiang Wan",
      "Feng Jiang",
      "Benyou Wang"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T06:18:27.000Z",
    "updatedAt": "2025-10-13T06:18:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11040v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11040v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11039v1",
    "arxivId": "2510.11039v1",
    "title": "RepoSummary: Feature-Oriented Summarization and Documentation Generation for Code Repositories",
    "abstract": "Repository summarization is a crucial research question in development and maintenance for software engineering. Existing repository summarization techniques primarily focus on summarizing code according to the directory tree, which is insufficient for tracing high-level features to the methods that collaboratively implement them. To address these limitations, we propose RepoSummary, a feature-oriented code repository summarization approach that simultaneously generates repository documentation automatically. Furthermore, it establishes more accurate traceability links from functional features to the corresponding code elements, enabling developers to rapidly locate relevant methods and files during code comprehension and maintenance. Comprehensive experiments against the state-of-the-art baseline (HGEN) demonstrate that RepoSummary achieves higher feature coverage and more accurate traceability. On average, it increases the rate of completely covered features in manual documentation from 61.2% to 71.1%, improves file-level traceability recall from 29.9% to 53.0%, and generates documentation that is more conceptually consistent, easier to understand, and better formatted than that produced by existing approaches.",
    "authors": [
      "Yifeng Zhu",
      "Xianlin Zhao",
      "Xutian Li",
      "Yanzhen Zou",
      "Haizhuo Yuan",
      "Yue Wang",
      "Bing Xie"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-13T06:16:44.000Z",
    "updatedAt": "2025-10-13T06:16:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11039v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11039v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11036v1",
    "arxivId": "2510.11036v1",
    "title": "XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation",
    "abstract": "Most robotic grasping methods are typically designed for single gripper types, which limits their applicability in real-world scenarios requiring diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp detection framework that efficiently handles multiple gripper configurations. The proposed method addresses data scarcity by systematically augmenting existing datasets with multi-gripper annotations. XGrasp employs a hierarchical two-stage architecture. In the first stage, a Grasp Point Predictor (GPP) identifies optimal locations using global scene information and gripper specifications. In the second stage, an Angle-Width Predictor (AWP) refines the grasp angle and width using local features. Contrastive learning in the AWP module enables zero-shot generalization to unseen grippers by learning fundamental grasping characteristics. The modular framework integrates seamlessly with vision foundation models, providing pathways for future vision-language capabilities. The experimental results demonstrate competitive grasp success rates across various gripper types, while achieving substantial improvements in inference speed compared to existing gripper-aware methods. Project page: https://sites.google.com/view/xgrasp",
    "authors": [
      "Yeonseo Lee",
      "Jungwook Mun",
      "Hyosup Shin",
      "Guebin Hwang",
      "Junhee Nam",
      "Taeyeop Lee",
      "Sungho Jo"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T06:13:25.000Z",
    "updatedAt": "2025-10-13T06:13:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11036v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11036v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11035v1",
    "arxivId": "2510.11035v1",
    "title": "SusBench: An Online Benchmark for Evaluating Dark Pattern Susceptibility of Computer-Use Agents",
    "abstract": "As LLM-based computer-use agents (CUAs) begin to autonomously interact with real-world interfaces, understanding their vulnerability to manipulative interface designs becomes increasingly critical. We introduce SusBench, an online benchmark for evaluating the susceptibility of CUAs to UI dark patterns, designs that aim to manipulate or deceive users into taking unintentional actions. Drawing nine common dark pattern types from existing taxonomies, we developed a method for constructing believable dark patterns on real-world consumer websites through code injections, and designed 313 evaluation tasks across 55 websites. Our study with 29 participants showed that humans perceived our dark pattern injections to be highly realistic, with the vast majority of participants not noticing that these had been injected by the research team. We evaluated five state-of-the-art CUAs on the benchmark. We found that both human participants and agents are particularly susceptible to the dark patterns of Preselection, Trick Wording, and Hidden Information, while being resilient to other overt dark patterns. Our findings inform the development of more trustworthy CUAs, their use as potential human proxies in evaluating deceptive designs, and the regulation of an online environment increasingly navigated by autonomous agents.",
    "authors": [
      "Longjie Guo",
      "Chenjie Yuan",
      "Mingyuan Zhong",
      "Robert Wolfe",
      "Ruican Zhong",
      "Yue Xu",
      "Bingbing Wen",
      "Hua Shen",
      "Lucy Lu Wang",
      "Alexis Hiniker"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-13T06:12:03.000Z",
    "updatedAt": "2025-10-13T06:12:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11035v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11035v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11031v1",
    "arxivId": "2510.11031v1",
    "title": "LogiNumSynth: Synthesizing Joint Logical-Numerical Reasoning Problems for Language Models",
    "abstract": "Joint logical-numerical reasoning remains a major challenge for language models, yet existing datasets rely on fixed rule sets and offer limited control over task complexity, constraining their generalizability for evaluation and training. We present LogiNumSynth, a flexible natural language problem synthesizer that synthesizes tasks requiring proficiency in joint logical reasoning (e.g., rule-based reasoning) and numerical reasoning (e.g., arithmetic computation). LogiNumSynth supports fine-grained control over reasoning world richness, logical reasoning depth, and the complexity of numerical computations, enabling flexible data synthesis across difficulty levels. We demonstrate three key contributions: (1) Synthesizer -- synthesizing fully controllable joint reasoning tasks over natural language; (2) Evaluation & Process Analysis -- evaluating both process accuracy and answer accuracy; (3) Targeted Training -- using synthesized data to enhance LLMs' reasoning performance. Experiments with multiple LLMs highlight persistent weaknesses in logical-numerical reasoning, showing that LogiNumSynth can serve as both a diagnostic tool and a source of targeted supervision for advancing integrated reasoning skills.",
    "authors": [
      "Yiwei Liu",
      "Yucheng Li",
      "Xiao Li",
      "Gong Cheng"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T06:01:02.000Z",
    "updatedAt": "2025-10-13T06:01:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11031v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11031v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11028v1",
    "arxivId": "2510.11028v1",
    "title": "Enhancing Zero-Shot Anomaly Detection: CLIP-SAM Collaboration with Cascaded Prompts",
    "abstract": "Recently, the powerful generalization ability exhibited by foundation models has brought forth new solutions for zero-shot anomaly segmentation tasks. However, guiding these foundation models correctly to address downstream tasks remains a challenge. This paper proposes a novel two-stage framework, for zero-shot anomaly segmentation tasks in industrial anomaly detection. This framework excellently leverages the powerful anomaly localization capability of CLIP and the boundary perception ability of SAM.(1) To mitigate SAM's inclination towards object segmentation, we propose the Co-Feature Point Prompt Generation (PPG) module. This module collaboratively utilizes CLIP and SAM to generate positive and negative point prompts, guiding SAM to focus on segmenting anomalous regions rather than the entire object. (2) To further optimize SAM's segmentation results and mitigate rough boundaries and isolated noise, we introduce the Cascaded Prompts for SAM (CPS) module. This module employs hybrid prompts cascaded with a lightweight decoder of SAM, achieving precise segmentation of anomalous regions. Across multiple datasets, consistent experimental validation demonstrates that our approach achieves state-of-the-art zero-shot anomaly segmentation results. Particularly noteworthy is our performance on the Visa dataset, where we outperform the state-of-the-art methods by 10.3\\% and 7.7\\% in terms of {$F_1$-max} and AP metrics, respectively.",
    "authors": [
      "Yanning Hou",
      "Ke Xu",
      "Junfa Li",
      "Yanran Ruan",
      "Jianfeng Qiu"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:53:49.000Z",
    "updatedAt": "2025-10-13T05:53:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11028v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11028v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11027v1",
    "arxivId": "2510.11027v1",
    "title": "Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning",
    "abstract": "While significant research has focused on developing embodied reasoning capabilities using Vision-Language Models (VLMs) or integrating advanced VLMs into Vision-Language-Action (VLA) models for end-to-end robot control, few studies directly address the critical gap between upstream VLM-based reasoning and downstream VLA policy learning. In this work, we take an initial step toward bridging embodied reasoning with VLA policy learning by introducing Vlaser - a Vision-Language-Action Model with synergistic embodied reasoning capability, which is a foundational vision-language model designed to integrate high-level reasoning with low-level control for embodied agents. Built upon the high-quality Vlaser-6M dataset, Vlaser achieves state-of-the-art performance across a range of embodied reasoning benchmarks - including spatial reasoning, embodied grounding, embodied QA, and task planning. Furthermore, we systematically examine how different VLM initializations affect supervised VLA fine-tuning, offering novel insights into mitigating the domain shift between internet-scale pre-training data and embodied-specific policy learning data. Based on these insights, our approach achieves state-of-the-art results on the WidowX benchmark and competitive performance on the Google Robot benchmark.",
    "authors": [
      "Ganlin Yang",
      "Tianyi Zhang",
      "Haoran Hao",
      "Weiyun Wang",
      "Yibin Liu",
      "Dehui Wang",
      "Guanzhou Chen",
      "Zijian Cai",
      "Junting Chen",
      "Weijie Su",
      "Wengang Zhou",
      "Yu Qiao",
      "Jifeng Dai",
      "Jiangmiao Pang",
      "Gen Luo",
      "Wenhai Wang",
      "Yao Mu",
      "Zhi Hou"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:51:22.000Z",
    "updatedAt": "2025-10-13T05:51:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11027v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11027v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11026v1",
    "arxivId": "2510.11026v1",
    "title": "GIR-Bench: Versatile Benchmark for Generating Images with Reasoning",
    "abstract": "Unified multimodal models integrate the reasoning capacity of large language models with both image understanding and generation, showing great promise for advanced multimodal intelligence. However, the community still lacks a rigorous reasoning-centric benchmark to systematically evaluate the alignment between understanding and generation, and their generalization potential in complex visual tasks. To this end, we introduce \\textbf{GIR-Bench}, a comprehensive benchmark that evaluates unified models across three complementary perspectives. Firstly, we investigate understanding-generation consistency (GIR-Bench-UGC), asking whether models can consistently leverage the same knowledge in both understanding and generation tasks. Secondly, we investigate whether models can perform reasoning-centric text-to-image generation that requires applying logical constraints and implicit knowledge to generate faithful visual content (GIR-Bench-T2I). Thirdly, we evaluate whether models can handle multi-step reasoning in editing (GIR-Bench-Edit). For each subset, we carefully design different task-specific evaluation pipelines tailored for each task. This enables fine-grained and interpretable evaluation while mitigating biases from the prevalent MLLM-as-a-Judge paradigm. Extensive ablations over various unified models and generation-only systems have shown that: Although unified models are more capable of reasoning-driven visual tasks, they still exhibit a persistent gap between understanding and generation. The data and code for GIR-Bench are available at \\href{https://hkust-longgroup.github.io/GIR-Bench}{https://hkust-longgroup.github.io/GIR-Bench}.",
    "authors": [
      "Hongxiang Li",
      "Yaowei Li",
      "Bin Lin",
      "Yuwei Niu",
      "Yuhang Yang",
      "Xiaoshuang Huang",
      "Jiayin Cai",
      "Xiaolong Jiang",
      "Yao Hu",
      "Long Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:50:44.000Z",
    "updatedAt": "2025-10-13T05:50:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11026v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11026v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11023v1",
    "arxivId": "2510.11023v1",
    "title": "Parareal in time and spectral in space fast L1 quasilinear subdiffusion solver",
    "abstract": "We consider the initial-boundary value problem for a quasilinear time-fractional diffusion equation, and develop a fully discrete solver combining the parareal algorithm in time with a L1 finite-difference approximation of the Caputo derivative and a spectral Galerkin discretization in space. Our main contribution is the first rigorous convergence proof for the parareal-L1 scheme in this nonlinear subdiffusive setting. By constructing suitable energy norms and exploiting the orthogonality of the spectral basis, we establish that the parareal iterations converge exactly to the fully serial L1-spectral solution in a finite number of steps, with rates independent of the fractional exponent. The spectral spatial discretization yields exponential accuracy in space, while the parareal structure induces a clock speedup proportional to the number of processors, making the overall method highly efficient. Numerical experiments for both subdiffusive and classical diffusion problems confirm our theoretical estimates and demonstrate up to an order of magnitude reduction in computational time compared to the conventional sequential solver. We observe that the speedup of the parareal method increases linearly with the fine integrator degrees of freedom.",
    "authors": [
      "Josefa Caballero",
      "Łukasz Płociniczak",
      "Kishin Sadarangani"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T05:41:32.000Z",
    "updatedAt": "2025-10-13T05:41:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11023v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11023v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11020v1",
    "arxivId": "2510.11020v1",
    "title": "GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation",
    "abstract": "Auxiliary lines are essential for solving complex geometric problems but remain challenging for large vision-language models (LVLMs). Rather than editing diagrams to draw auxiliary lines, which current image editing models struggle to render with geometric precision, we generate textual descriptions of auxiliary-line constructions to better align with the representational strengths of LVLMs. To bridge the gap between textual descriptions and spatial structure, we propose a reinforcement learning framework that enhances diagram-text alignment. At the core of our approach is a cross-modal reward that evaluates how well the generated auxiliary-line description for an original diagram matches a ground-truth auxiliary-line diagram. Built on this reward, we present GeoVLMath, an open-source LVLM tailored to auxiliary-line reasoning in solid geometry. This fine-grained signal drives a GRPO-based RL stage, yielding precise diagram-text alignment. To support training, we develop a scalable data creation pipeline and construct AuxSolidMath, a dataset of 3,018 real-exam geometry problems with paired diagrams and aligned textual fields. At the 3B and 7B scales, GeoVLMath achieves competitive and often superior performance compared with strong open-source and proprietary LVLMs on auxiliary-line reasoning benchmarks.",
    "authors": [
      "Shasha Guo",
      "Liang Pang",
      "Xi Wang",
      "Yanling Wang",
      "Huawei Shen",
      "Jing Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T05:33:51.000Z",
    "updatedAt": "2025-10-13T05:33:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11020v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11020v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11019v1",
    "arxivId": "2510.11019v1",
    "title": "Refinery: Active Fine-tuning and Deployment-time Optimization for Contact-Rich Policies",
    "abstract": "Simulation-based learning has enabled policies for precise, contact-rich tasks (e.g., robotic assembly) to reach high success rates (~80%) under high levels of observation noise and control error. Although such performance may be sufficient for research applications, it falls short of industry standards and makes policy chaining exceptionally brittle. A key limitation is the high variance in individual policy performance across diverse initial conditions. We introduce Refinery, an effective framework that bridges this performance gap, robustifying policy performance across initial conditions. We propose Bayesian Optimization-guided fine-tuning to improve individual policies, and Gaussian Mixture Model-based sampling during deployment to select initializations that maximize execution success. Using Refinery, we improve mean success rates by 10.98% over state-of-the-art methods in simulation-based learning for robotic assembly, reaching 91.51% in simulation and comparable performance in the real world. Furthermore, we demonstrate that these fine-tuned policies can be chained to accomplish long-horizon, multi-part assembly$\\unicode{x2013}$successfully assembling up to 8 parts without requiring explicit multi-step training.",
    "authors": [
      "Bingjie Tang",
      "Iretiayo Akinola",
      "Jie Xu",
      "Bowen Wen",
      "Dieter Fox",
      "Gaurav S. Sukhatme",
      "Fabio Ramos",
      "Abhishek Gupta",
      "Yashraj Narang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T05:31:10.000Z",
    "updatedAt": "2025-10-13T05:31:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11019v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11019v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11018v1",
    "arxivId": "2510.11018v1",
    "title": "The Easy Path to Robustness: Coreset Selection using Sample Hardness",
    "abstract": "Designing adversarially robust models from a data-centric perspective requires understanding which input samples are most crucial for learning resilient features. While coreset selection provides a mechanism for efficient training on data subsets, current algorithms are designed for clean accuracy and fall short in preserving robustness. To address this, we propose a framework linking a sample's adversarial vulnerability to its \\textit{hardness}, which we quantify using the average input gradient norm (AIGN) over training. We demonstrate that \\textit{easy} samples (with low AIGN) are less vulnerable and occupy regions further from the decision boundary. Leveraging this insight, we present EasyCore, a coreset selection algorithm that retains only the samples with low AIGN for training. We empirically show that models trained on EasyCore-selected data achieve significantly higher adversarial accuracy than those trained with competing coreset methods under both standard and adversarial training. As AIGN is a model-agnostic dataset property, EasyCore is an efficient and widely applicable data-centric method for improving adversarial robustness. We show that EasyCore achieves up to 7\\% and 5\\% improvement in adversarial accuracy under standard training and TRADES adversarial training, respectively, compared to existing coreset methods.",
    "authors": [
      "Pranav Ramesh",
      "Arjun Roy",
      "Deepak Ravikumar",
      "Kaushik Roy",
      "Gopalakrishnan Srinivasan"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:28:16.000Z",
    "updatedAt": "2025-10-13T05:28:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11018v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11018v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11017v1",
    "arxivId": "2510.11017v1",
    "title": "High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation",
    "abstract": "Modeling high-resolution spatiotemporal representations, including both global dynamic contexts (e.g., holistic human motion tendencies) and local motion details (e.g., high-frequency changes of keypoints), is essential for video-based human pose estimation (VHPE). Current state-of-the-art methods typically unify spatiotemporal learning within a single type of modeling structure (convolution or attention-based blocks), which inherently have difficulties in balancing global and local dynamic modeling and may bias the network to one of them, leading to suboptimal performance. Moreover, existing VHPE models suffer from quadratic complexity when capturing global dependencies, limiting their applicability especially for high-resolution sequences. Recently, the state space models (known as Mamba) have demonstrated significant potential in modeling long-range contexts with linear complexity; however, they are restricted to 1D sequential data. In this paper, we present a novel framework that extends Mamba from two aspects to separately learn global and local high-resolution spatiotemporal representations for VHPE. Specifically, we first propose a Global Spatiotemporal Mamba, which performs 6D selective space-time scan and spatial- and temporal-modulated scan merging to efficiently extract global representations from high-resolution sequences. We further introduce a windowed space-time scan-based Local Refinement Mamba to enhance the high-frequency details of localized keypoint motions. Extensive experiments on four benchmark datasets demonstrate that the proposed model outperforms state-of-the-art VHPE approaches while achieving better computational trade-offs.",
    "authors": [
      "Runyang Feng",
      "Hyung Jin Chang",
      "Tze Ho Elden Tse",
      "Boeun Kim",
      "Yi Chang",
      "Yixing Gao"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:18:27.000Z",
    "updatedAt": "2025-10-13T05:18:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11017v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11017v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11016v1",
    "arxivId": "2510.11016v1",
    "title": "Instruction-aware User Embedding via Synergistic Language and Representation Modeling",
    "abstract": "User representation modeling has become increasingly crucial for personalized applications, yet existing approaches struggle with generalizability across domains and sensitivity to noisy behavioral signals. We present InstructUE, an instruction-aware user embedding foundation model that leverages large language models (LLMs) to generate general and instruction-aware user representations. InstructUE introduces a multi-encoder architecture with a lightweight adapter that efficiently processes heterogeneous data from six different sources while preserving their structural characteristics. Additionally, it proposes a novel contrastive-autoregressive training framework that bridges language and representation spaces through a curated UserQA dataset. The contrastive-autoregressive training framework simultaneously leverages autoregressive learning to capture domain knowledge in language space and contrastive learning to align user-text embeddings in representation space, thereby enhancing the instruction-awareness and noise-robustness of user embeddings. Through extensive experiments on real-world applications, we demonstrate that InstructUE significantly outperforms existing methods across multiple domains including user prediction, marketing, and recommendation scenarios. Our results show that instruction-aware user modeling can effectively achieve instruction-guided denoising of user information in specific scenarios, paving the way for more generalizable and robust user representation learning.",
    "authors": [
      "Ziyi Gao",
      "Yike Xu",
      "Jiahao Yuan",
      "Baokun Wang",
      "Jinyong Wen",
      "Xiaotong Lin",
      "Yun Liu",
      "Xing Fu",
      "Yu Cheng",
      "Yongchao Liu",
      "Weiqiang Wang",
      "Zhongle Xie"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T05:15:34.000Z",
    "updatedAt": "2025-10-13T05:15:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11016v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11016v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11015v1",
    "arxivId": "2510.11015v1",
    "title": "A new $1/(1-ρ)$-scaling bound for multiserver queues via a leave-one-out technique",
    "abstract": "Bounding the queue length in a multiserver queue is a central challenge in queueing theory. Even for the classic $GI/GI/n$ queue with homogeneous servers, it is highly non-trivial to derive a simple and accurate bound for the steady-state queue length that holds across all scaling regimes. A recent breakthrough by Li and Goldberg (2025) establishes bounds that scale as $1/(1-\\rho)$ for any load $\\rho < 1$ and number of servers $n$, which is the correct scaling in many well-known scaling regimes, including classic heavy-traffic, Halfin-Whitt and Nondegenerate-Slowdown. However, their bounds entail large constant factors and a highly intricate proof, suggesting room for further improvement. In this paper, we present a new $1/(1-\\rho)$-scaling bound for the $GI/GI/n$ queue. Our bound, while restricted to the light-tailed case and the first moment of the queue length, has a more interpretable and often tighter leading constant. Our proof is relatively simple, utilizing a modified $GI/GI/n$ queue, the stationarity of a quadratic test function, and a novel leave-one-out coupling technique. Finally, we also extend our method to $GI/GI/n$ queues with fully heterogeneous service-time distributions.",
    "authors": [
      "Yige Hong"
    ],
    "categories": [
      "math.PR",
      "cs.PF",
      "60K25, 68M20, 90B22",
      "C.4; G.3; I.6"
    ],
    "publishedAt": "2025-10-13T05:13:23.000Z",
    "updatedAt": "2025-10-13T05:13:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11015v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11015v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11014v1",
    "arxivId": "2510.11014v1",
    "title": "Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces",
    "abstract": "Priors are vital for planning under partial observability, yet difficult to obtain in practice. We present a sampling-based pipeline that leverages large-scale pretrained generative models to produce probabilistic priors capturing environmental uncertainty and spatio-semantic relationships in a zero-shot manner. Conditioned on partial observations, the pipeline recovers complete RGB-D point cloud samples with occupancy and target semantics, formulated to be directly useful in configuration-space planning. We establish a Matterport3D benchmark of rooms partially visible through doorways, where a robot must navigate to an unobserved target object. Effective priors for this setting must represent both occupancy and target-location uncertainty in unobserved regions. Experiments show that our approach recovers commonsense spatial semantics consistent with ground truth, yielding diverse, clean 3D point clouds usable in motion planning, highlight the promise of generative models as a rich source of priors for robotic planning.",
    "authors": [
      "Subhransu S. Bhattacharjee",
      "Hao Lu",
      "Dylan Campbell",
      "Rahul Shome"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:08:48.000Z",
    "updatedAt": "2025-10-13T05:08:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11014v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11014v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11012v1",
    "arxivId": "2510.11012v1",
    "title": "COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models",
    "abstract": "Compositional reasoning remains a persistent weakness of modern vision language models (VLMs): they often falter when a task hinges on understanding how multiple objects, attributes, and relations interact within an image. Multiple research works have attempted to improve compositionality performance by creative tricks such as improving prompt structure, chain of thought reasoning, etc. A more recent line of work attempts to impart additional reasoning in VLMs using well-trained Large Language Models (LLMs), which are far superior in linguistic understanding than VLMs to compensate for the limited linguistic prowess of VLMs. However, these approaches are either resource-intensive or do not provide an interpretable reasoning process. In this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs with carefully designed neurosymbolic concept trees learned from LLMs to improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning process boosts compositionality performance and provides a rationale behind VLM predictions. Empirical results on four compositionality benchmarks, Winoground, EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with varying sizes, demonstrate that COCO-Tree significantly improves compositional generalization by 5-10% over baselines.",
    "authors": [
      "Sanchit Sinha",
      "Guangzhi Xiong",
      "Aidong Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T05:07:13.000Z",
    "updatedAt": "2025-10-13T05:07:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11012v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11012v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11011v1",
    "arxivId": "2510.11011v1",
    "title": "GrASP: A Generalizable Address-based Semantic Prefetcher for Scalable Transactional and Analytical Workloads",
    "abstract": "Data prefetching--loading data into the cache before it is requested--is essential for reducing I/O overhead and improving database performance. While traditional prefetchers focus on sequential patterns, recent learning-based approaches, especially those leveraging data semantics, achieve higher accuracy for complex access patterns. However, these methods often struggle with today's dynamic, ever-growing datasets and require frequent, timely fine-tuning. Privacy constraints may also restrict access to complete datasets, necessitating prefetchers that can learn effectively from samples. To address these challenges, we present GrASP, a learning-based prefetcher designed for both analytical and transactional workloads. GrASP enhances prefetching accuracy and scalability by leveraging logical block address deltas and combining query representations with result encodings. It frames prefetching as a context-aware multi-label classification task, using multi-layer LSTMs to predict delta patterns from embedded context. This delta modeling approach enables GrASP to generalize predictions from small samples to larger, dynamic datasets without requiring extensive retraining. Experiments on real-world datasets and industrial benchmarks demonstrate that GrASP generalizes to datasets 250 times larger than the training data, achieving up to 45% higher hit ratios, 60% lower I/O time, and 55% lower end-to-end query execution latency than existing baselines. On average, GrASP attains a 91.4% hit ratio, a 90.8% I/O time reduction, and a 57.1% execution latency reduction.",
    "authors": [
      "Farzaneh Zirak",
      "Farhana Choudhury",
      "Renata Borovica-Gajic"
    ],
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T05:03:23.000Z",
    "updatedAt": "2025-10-13T05:03:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11011v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11011v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11007v1",
    "arxivId": "2510.11007v1",
    "title": "Abstract String Domain Defined with Word Equations as a Reduced Product (Extended Version)",
    "abstract": "We introduce a string-interval abstract domain, where string intervals are characterized by systems of word equations (encoding lower bounds on string values) and word disequalities (encoding upper bounds). Building upon the lattice structure of string intervals, we define an abstract string object as a reduced product on a string property semilattice, determined by length-non-increasing morphisms. We consider several reduction strategies for abstract string objects and show that upon these strategies the string object domain forms a lattice. We define basic abstract string operations on the domain, aiming to minimize computational overheads on the reduction, and show how the domain can be used to analyse properties of JavaScript string manipulating programs.",
    "authors": [
      "Antonina Nepeivoda",
      "Ilya Afanasyev"
    ],
    "categories": [
      "cs.PL",
      "cs.FL"
    ],
    "publishedAt": "2025-10-13T04:55:40.000Z",
    "updatedAt": "2025-10-13T04:55:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11007v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11007v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11005v1",
    "arxivId": "2510.11005v1",
    "title": "Frequency Domain Unlocks New Perspectives for Abdominal Medical Image Segmentation",
    "abstract": "Accurate segmentation of tumors and adjacent normal tissues in medical images is essential for surgical planning and tumor staging. Although foundation models generally perform well in segmentation tasks, they often struggle to focus on foreground areas in complex, low-contrast backgrounds, where some malignant tumors closely resemble normal organs, complicating contextual differentiation. To address these challenges, we propose the Foreground-Aware Spectrum Segmentation (FASS) framework. First, we introduce a foreground-aware module to amplify the distinction between background and the entire volume space, allowing the model to concentrate more effectively on target areas. Next, a feature-level frequency enhancement module, based on wavelet transform, extracts discriminative high-frequency features to enhance boundary recognition and detail perception. Eventually, we introduce an edge constraint module to preserve geometric continuity in segmentation boundaries. Extensive experiments on multiple medical datasets demonstrate superior performance across all metrics, validating the effectiveness of our framework, particularly in robustness under complex conditions and fine structure recognition. Our framework significantly enhances segmentation of low-contrast images, paving the way for applications in more diverse and complex medical imaging scenarios.",
    "authors": [
      "Kai Han",
      "Siqi Ma",
      "Chengxuan Qian",
      "Jun Chen",
      "Chongwen Lyu",
      "Yuqing Song",
      "Zhe Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T04:44:43.000Z",
    "updatedAt": "2025-10-13T04:44:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11005v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11005v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11004v1",
    "arxivId": "2510.11004v1",
    "title": "Automating Structural Engineering Workflows with Large Language Model Agents",
    "abstract": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows. Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size. Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization -- capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities. We present a proof-of-concept showing that most real-world structural engineering workflows can be fully automated through a training-free LLM-based multi-agent system. MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios.",
    "authors": [
      "Haoran Liang",
      "Yufa Zhou",
      "Mohammad Talebi Kalaleh",
      "Qipei Mei"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T04:38:46.000Z",
    "updatedAt": "2025-10-13T04:38:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11004v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11004v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11003v1",
    "arxivId": "2510.11003v1",
    "title": "FBS Model-based Maintenance Record Accumulation for Failure-Cause Inference in Manufacturing Systems",
    "abstract": "In manufacturing systems, identifying the causes of failures is crucial for maintaining and improving production efficiency. In knowledge-based failure-cause inference, it is important that the knowledge base (1) explicitly structures knowledge about the target system and about failures, and (2) contains sufficiently long causal chains of failures. In this study, we constructed Diagnostic Knowledge Ontology and proposed a Function-Behavior-Structure (FBS) model-based maintenance-record accumulation method based on it. Failure-cause inference using the maintenance records accumulated by the proposed method showed better agreement with the set of candidate causes enumerated by experts, especially in difficult cases where the number of related cases is small and the vocabulary used differs. In the future, it will be necessary to develop inference methods tailored to these maintenance records, build a user interface, and carry out validation on larger and more diverse systems. Additionally, this approach leverages the understanding and knowledge of the target in the design phase to support knowledge accumulation and problem solving during the maintenance phase, and it is expected to become a foundation for knowledge sharing across the entire engineering chain in the future.",
    "authors": [
      "Takuma Fujiu",
      "Sho Okazaki",
      "Kohei Kaminishi",
      "Yuji Nakata",
      "Shota Hamamoto",
      "Kenshin Yokose",
      "Tatsunori Hara",
      "Yasushi Umeda",
      "Jun Ota"
    ],
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T04:37:40.000Z",
    "updatedAt": "2025-10-13T04:37:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11003v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11003v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11001v1",
    "arxivId": "2510.11001v1",
    "title": "DND: Boosting Large Language Models with Dynamic Nested Depth",
    "abstract": "We introduce Dynamic Nested Depth (DND), a novel method that improves performance for off-the-shelf LLMs by selecting critical tokens to reprocess in a nested depth manner. Specifically, at the end of the given transformer layer, DND identifies more critical tokens with a router and feeds them back for an extra round of processing, effectively ``reviewing\" difficult tokens while avoiding redundant computation for easier ones. The dynamic selection mechanism is tailored for precise control via two novel strategies: a router controlling loss to enhance token selection distinguishability, and a threshold control scheme to ensure selection stability. We demonstrate the effectiveness of DND by directly integrating it into pre-trained dense and MoE models during a post-training phase. On diverse benchmarks, this approach boosts the performances of the dense Qwen3-1.7B by 1.88% and the MoE Qwen3-30B-A3B by 0.87%, all with a minimal parameter and computing increase.",
    "authors": [
      "Tieyuan Chen",
      "Xiaodong Chen",
      "Haoxing Chen",
      "Zhenzhong Lan",
      "Weiyao Lin",
      "Jianguo Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T04:22:57.000Z",
    "updatedAt": "2025-10-13T04:22:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11001v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11001v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.11000v1",
    "arxivId": "2510.11000v1",
    "title": "ContextGen: Contextual Layout Anchoring for Identity-Consistent Multi-Instance Generation",
    "abstract": "Multi-instance image generation (MIG) remains a significant challenge for modern diffusion models due to key limitations in achieving precise control over object layout and preserving the identity of multiple distinct subjects. To address these limitations, we introduce ContextGen, a novel Diffusion Transformer framework for multi-instance generation that is guided by both layout and reference images. Our approach integrates two key technical contributions: a Contextual Layout Anchoring (CLA) mechanism that incorporates the composite layout image into the generation context to robustly anchor the objects in their desired positions, and Identity Consistency Attention (ICA), an innovative attention mechanism that leverages contextual reference images to ensure the identity consistency of multiple instances. Recognizing the lack of large-scale, hierarchically-structured datasets for this task, we introduce IMIG-100K, the first dataset with detailed layout and identity annotations. Extensive experiments demonstrate that ContextGen sets a new state-of-the-art, outperforming existing methods in control precision, identity fidelity, and overall visual quality.",
    "authors": [
      "Ruihang Xu",
      "Dewei Zhou",
      "Fan Ma",
      "Yi Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T04:21:19.000Z",
    "updatedAt": "2025-10-13T04:21:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.11000v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.11000v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10998v1",
    "arxivId": "2510.10998v1",
    "title": "ABLEIST: Intersectional Disability Bias in LLM-Generated Hiring Scenarios",
    "abstract": "Large language models (LLMs) are increasingly under scrutiny for perpetuating identity-based discrimination in high-stakes domains such as hiring, particularly against people with disabilities (PwD). However, existing research remains largely Western-centric, overlooking how intersecting forms of marginalization--such as gender and caste--shape experiences of PwD in the Global South. We conduct a comprehensive audit of six LLMs across 2,820 hiring scenarios spanning diverse disability, gender, nationality, and caste profiles. To capture subtle intersectional harms and biases, we introduce ABLEIST (Ableism, Inspiration, Superhumanization, and Tokenism), a set of five ableism-specific and three intersectional harm metrics grounded in disability studies literature. Our results reveal significant increases in ABLEIST harms towards disabled candidates--harms that many state-of-the-art models failed to detect. These harms were further amplified by sharp increases in intersectional harms (e.g., Tokenism) for gender and caste-marginalized disabled candidates, highlighting critical blind spots in current safety tools and the need for intersectional safety evaluations of frontier models in high-stakes domains like hiring.",
    "authors": [
      "Mahika Phutane",
      "Hayoung Jung",
      "Matthew Kim",
      "Tanushree Mitra",
      "Aditya Vashistha"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T04:18:23.000Z",
    "updatedAt": "2025-10-13T04:18:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10998v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10998v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10995v1",
    "arxivId": "2510.10995v1",
    "title": "MSRBench: A Benchmarking Dataset for Music Source Restoration",
    "abstract": "Music Source Restoration (MSR) extends source separation to realistic settings where signals undergo production effects (equalization, compression, reverb) and real-world degradations, with the goal of recovering the original unprocessed sources. Existing benchmarks cannot measure restoration fidelity: synthetic datasets use unprocessed stems but unrealistic mixtures, while real production datasets provide only already-processed stems without clean references. We present MSRBench, the first benchmark explicitly designed for MSR evaluation. MSRBench contains raw stem-mixture pairs across eight instrument classes, where mixtures are produced by professional mixing engineers. These raw-processed pairs enable direct evaluation of both separation accuracy and restoration fidelity. Beyond controlled studio conditions, the mixtures are augmented with twelve real-world degradations spanning analog artifacts, acoustic environments, and lossy codecs. Baseline experiments with U-Net and BSRNN achieve SI-SNR of -37.8 dB and -23.4 dB respectively, with perceptual quality (FAD CLAP) around 0.7-0.8, demonstrating substantial room for improvement and the need for restoration-specific architectures.",
    "authors": [
      "Yongyi Zang",
      "Jiarui Hai",
      "Wanying Ge",
      "Qiuqiang Kong",
      "Zheqi Dai",
      "Helin Wang",
      "Yuki Mitsufuji",
      "Mark D. Plumbley"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-13T04:12:55.000Z",
    "updatedAt": "2025-10-13T04:12:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10995v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10995v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10994v1",
    "arxivId": "2510.10994v1",
    "title": "DeepResearchGuard: Deep Research with Open-Domain Evaluation and Multi-Stage Guardrails for Safety",
    "abstract": "Deep research frameworks have shown promising capabilities in synthesizing comprehensive reports from web sources. While deep research possesses significant potential to address complex issues through planning and research cycles, existing frameworks are deficient in sufficient evaluation procedures and stage-specific protections. They typically treat evaluation as exact match accuracy of question-answering, but overlook crucial aspects of report quality such as credibility, coherence, breadth, depth, and safety. This oversight may result in hazardous or malicious sources being integrated into the final report. To address these issues, we introduce DEEPRESEARCHGUARD, a comprehensive framework featuring four-stage safeguards with open-domain evaluation of references and reports. We assess performance across multiple metrics, e.g., defense success rate and over-refusal rate, and five key report dimensions. In the absence of a suitable safety benchmark, we introduce DRSAFEBENCH, a stage-wise benchmark for deep research safety. Our evaluation spans diverse state-of-the-art LLMs, including GPT-4o, Gemini-2.5-flash, DeepSeek-v3, and o4-mini. DEEPRESEARCHGUARD achieves an average defense success rate improvement of 18.16% while reducing over-refusal rate by 6%. The input guard provides the most substantial early-stage protection by filtering out obvious risks, while the plan and research guards enhance citation discipline and source credibility. Through extensive experiments, we show that DEEPRESEARCHGUARD enables comprehensive open-domain evaluation and stage-aware defenses that effectively block harmful content propagation, while systematically improving report quality without excessive over-refusal rates. The code can be found via https://github.com/Jasonya/DeepResearchGuard.",
    "authors": [
      "Wei-Chieh Huang",
      "Henry Peng Zou",
      "Yaozu Wu",
      "Dongyuan Li",
      "Yankai Chen",
      "Weizhi Zhang",
      "Yangning Li",
      "Angelo Zangari",
      "Jizhou Guo",
      "Chunyu Miao",
      "Liancheng Fang",
      "Langzhou He",
      "Renhe Jiang",
      "Philip S. Yu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T04:11:21.000Z",
    "updatedAt": "2025-10-13T04:11:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10994v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10994v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10993v1",
    "arxivId": "2510.10993v1",
    "title": "Perspective-aware 3D Gaussian Inpainting with Multi-view Consistency",
    "abstract": "3D Gaussian inpainting, a critical technique for numerous applications in virtual reality and multimedia, has made significant progress with pretrained diffusion models. However, ensuring multi-view consistency, an essential requirement for high-quality inpainting, remains a key challenge. In this work, we present PAInpainter, a novel approach designed to advance 3D Gaussian inpainting by leveraging perspective-aware content propagation and consistency verification across multi-view inpainted images. Our method iteratively refines inpainting and optimizes the 3D Gaussian representation with multiple views adaptively sampled from a perspective graph. By propagating inpainted images as prior information and verifying consistency across neighboring views, PAInpainter substantially enhances global consistency and texture fidelity in restored 3D scenes. Extensive experiments demonstrate the superiority of PAInpainter over existing methods. Our approach achieves superior 3D inpainting quality, with PSNR scores of 26.03 dB and 29.51 dB on the SPIn-NeRF and NeRFiller datasets, respectively, highlighting its effectiveness and generalization capability.",
    "authors": [
      "Yuxin Cheng",
      "Binxiao Huang",
      "Taiqiang Wu",
      "Wenyong Zhou",
      "Chenchen Ding",
      "Zhengwu Liu",
      "Graziano Chesi",
      "Ngai Wong"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T04:10:39.000Z",
    "updatedAt": "2025-10-13T04:10:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10993v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10993v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10991v1",
    "arxivId": "2510.10991v1",
    "title": "A Survey on Agentic Multimodal Large Language Models",
    "abstract": "With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at https://github.com/HJYao00/Awesome-Agentic-MLLMs.",
    "authors": [
      "Huanjin Yao",
      "Ruifei Zhang",
      "Jiaxing Huang",
      "Jingyi Zhang",
      "Yibo Wang",
      "Bo Fang",
      "Ruolin Zhu",
      "Yongcheng Jing",
      "Shunyu Liu",
      "Guanbin Li",
      "Dacheng Tao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T04:07:01.000Z",
    "updatedAt": "2025-10-13T04:07:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10991v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10991v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10990v1",
    "arxivId": "2510.10990v1",
    "title": "Secret-Protected Evolution for Differentially Private Synthetic Text Generation",
    "abstract": "Text data has become extremely valuable on large language models (LLMs) and even lead to general artificial intelligence (AGI). A lot of high-quality text in the real world is private and cannot be freely used due to privacy concerns. Therefore, differentially private (DP) synthetic text generation has been proposed, aiming to produce high-utility synthetic data while protecting sensitive information. However, existing DP synthetic text generation imposes uniform guarantees that often overprotect non-sensitive content, resulting in substantial utility loss and computational overhead. Therefore, we propose Secret-Protected Evolution (SecPE), a novel framework that extends private evolution with secret-aware protection. Theoretically, we show that SecPE satisfies $(\\mathrm{p}, \\mathrm{r})$-secret protection, constituting a relaxation of Gaussian DP that enables tighter utility-privacy trade-offs, while also substantially reducing computational complexity relative to baseline methods. Empirically, across the OpenReview, PubMed, and Yelp benchmarks, SecPE consistently achieves lower Fr\\'echet Inception Distance (FID) and higher downstream task accuracy than GDP-based Aug-PE baselines, while requiring less noise to attain the same level of protection. Our results highlight that secret-aware guarantees can unlock more practical and effective privacy-preserving synthetic text generation.",
    "authors": [
      "Tianze Wang",
      "Zhaoyu Chen",
      "Jian Du",
      "Yingtai Xiao",
      "Linjun Zhang",
      "Qiang Yan"
    ],
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.NE"
    ],
    "publishedAt": "2025-10-13T04:05:42.000Z",
    "updatedAt": "2025-10-13T04:05:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10990v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10990v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10989v1",
    "arxivId": "2510.10989v1",
    "title": "Crane Scheduling Problem with Energy Saving",
    "abstract": "During loading and unloading steps, energy is consumed when cranes lift containers, while energy is often wasted when cranes drop containers. By optimizing the scheduling of cranes, it is possible to reduce energy consumption, thereby lowering operational costs and environmental impacts. In this paper, we introduce a single-crane scheduling problem with energy savings, focusing on reusing the energy from containers that have already been lifted and reducing the total energy consumption of the entire scheduling plan. We establish a basic model considering a one-dimensional storage area and provide a systematic complexity analysis of the problem. First, we investigate the connection between our problem and the semi-Eulerization problem and propose an additive approximation algorithm. Then, we present a polynomial-time Dynamic Programming (DP) algorithm for the case of bounded energy buffer and processing lengths. Next, adopting a Hamiltonian perspective, we address the general case with arbitrary energy buffer and processing lengths. We propose an exact DP algorithm and show that the variation of the problem is polynomially solvable when it can be transformed into a path cover problem on acyclic interval digraphs. We introduce a paradigm that integrates both the Eulerian and Hamiltonian perspectives, providing a robust framework for addressing the problem.",
    "authors": [
      "Yixiong Gao",
      "Florian Jaehn",
      "Minming Li",
      "Wenhao Ma",
      "Xinbo Zhang"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-13T03:58:59.000Z",
    "updatedAt": "2025-10-13T03:58:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10989v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10989v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10988v1",
    "arxivId": "2510.10988v1",
    "title": "Adversarial Robustness in One-Stage Learning-to-Defer",
    "abstract": "Learning-to-Defer (L2D) enables hybrid decision-making by routing inputs either to a predictor or to external experts. While promising, L2D is highly vulnerable to adversarial perturbations, which can not only flip predictions but also manipulate deferral decisions. Prior robustness analyses focus solely on two-stage settings, leaving open the end-to-end (one-stage) case where predictor and allocation are trained jointly. We introduce the first framework for adversarial robustness in one-stage L2D, covering both classification and regression. Our approach formalizes attacks, proposes cost-sensitive adversarial surrogate losses, and establishes theoretical guarantees including $\\mathcal{H}$, $(\\mathcal{R }, \\mathcal{F})$, and Bayes consistency. Experiments on benchmark datasets confirm that our methods improve robustness against untargeted and targeted attacks while preserving clean performance.",
    "authors": [
      "Yannis Montreuil",
      "Letian Yu",
      "Axel Carlier",
      "Lai Xing Ng",
      "Wei Tsang Ooi"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T03:55:55.000Z",
    "updatedAt": "2025-10-13T03:55:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10988v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10988v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10987v1",
    "arxivId": "2510.10987v1",
    "title": "DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation",
    "abstract": "The promise of LLM watermarking rests on a core assumption that a specific watermark proves authorship by a specific model. We demonstrate that this assumption is dangerously flawed. We introduce the threat of watermark spoofing, a sophisticated attack that allows a malicious model to generate text containing the authentic-looking watermark of a trusted, victim model. This enables the seamless misattribution of harmful content, such as disinformation, to reputable sources. The key to our attack is repurposing watermark radioactivity, the unintended inheritance of data patterns during fine-tuning, from a discoverable trait into an attack vector. By distilling knowledge from a watermarked teacher model, our framework allows an attacker to steal and replicate the watermarking signal of the victim model. This work reveals a critical security gap in text authorship verification and calls for a paradigm shift towards technologies capable of distinguishing authentic watermarks from expertly imitated ones. Our code is available at https://github.com/hsannn/ditto.git.",
    "authors": [
      "Hyeseon Ahn",
      "Shinwoo Park",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T03:53:40.000Z",
    "updatedAt": "2025-10-13T03:53:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10987v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10987v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10986v1",
    "arxivId": "2510.10986v1",
    "title": "Mixup Helps Understanding Multimodal Video Better",
    "abstract": "Multimodal video understanding plays a crucial role in tasks such as action recognition and emotion classification by combining information from different modalities. However, multimodal models are prone to overfitting strong modalities, which can dominate learning and suppress the contributions of weaker ones. To address this challenge, we first propose Multimodal Mixup (MM), which applies the Mixup strategy at the aggregated multimodal feature level to mitigate overfitting by generating virtual feature-label pairs. While MM effectively improves generalization, it treats all modalities uniformly and does not account for modality imbalance during training. Building on MM, we further introduce Balanced Multimodal Mixup (B-MM), which dynamically adjusts the mixing ratios for each modality based on their relative contributions to the learning objective. Extensive experiments on several datasets demonstrate the effectiveness of our methods in improving generalization and multimodal robustness.",
    "authors": [
      "Xiaoyu Ma",
      "Ding Ding",
      "Hao Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T03:53:25.000Z",
    "updatedAt": "2025-10-13T03:53:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10986v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10986v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10984v1",
    "arxivId": "2510.10984v1",
    "title": "A Constrained Multi-Fidelity Bayesian Optimization Method",
    "abstract": "Recently, multi-fidelity Bayesian optimization (MFBO) has been successfully applied to many engineering design optimization problems, where the cost of high-fidelity simulations and experiments can be prohibitive. However, challenges remain for constrained optimization problems using the MFBO framework, particularly in efficiently identifying the feasible region defined by the constraints. In this paper, we propose a constrained multi-fidelity Bayesian optimization (CMFBO) method with novel acquisition functions. Specifically, we design efficient acquisition functions that 1) have analytically closed-form expressions; 2) are straightforward to implement; and 3) do not require feasible initial samples, an important feature often missing in commonly used acquisition functions such as expected constrained improvement (ECI). We demonstrate the effectiveness of our algorithms on synthetic test problems using different combinations of acquisition functions. Then, we apply the proposed method to a data-driven inertial confinement fusion (ICF) design problem, and a high-current joint design problem using finite element simulations with computational contact mechanics.",
    "authors": [
      "Jingyi Wang",
      "Nai-Yuan Chiang",
      "Tucker Hartland",
      "J. Luc Peterson",
      "Jerome Solberg",
      "Cosmin G. Petra"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T03:45:54.000Z",
    "updatedAt": "2025-10-13T03:45:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10984v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10984v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10982v1",
    "arxivId": "2510.10982v1",
    "title": "Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization",
    "abstract": "Recent AI regulations call for data that remain useful for innovation while resistant to misuse, balancing utility with protection at the model level. Existing approaches either perturb data to make it unlearnable or retrain models to suppress transfer, but neither governs inference by unknown models, and both typically require control over training. We propose non-transferable examples (NEs), a training-free and data-agnostic input-side usage-control mechanism. We recode inputs within a model-specific low-sensitivity subspace, preserving outputs for the authorized model while reducing performance on unauthorized models through subspace misalignment. We establish formal bounds that guarantee utility for the authorized model and quantify deviation for unauthorized ones, with the Hoffman-Wielandt inequality linking degradation to spectral differences. Empirically, NEs retain performance on diverse vision backbones and state-of-the-art vision-language models under common preprocessing, whereas non-target models collapse even with reconstruction attempts. These results establish NEs as a practical means to preserve intended data utility while preventing unauthorized exploitation. Our project is available at https://trusted-system-lab.github.io/model-specificity",
    "authors": [
      "Zihan Wang",
      "Zhiyong Ma",
      "Zhongkui Ma",
      "Shuofeng Liu",
      "Akide Liu",
      "Derui Wang",
      "Minhui Xue",
      "Guangdong Bai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T03:43:11.000Z",
    "updatedAt": "2025-10-13T03:43:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10982v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10982v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10981v1",
    "arxivId": "2510.10981v1",
    "title": "In-Context Learning Is Provably Bayesian Inference: A Generalization Theory for Meta-Learning",
    "abstract": "This paper develops a finite-sample statistical theory for in-context learning (ICL), analyzed within a meta-learning framework that accommodates mixtures of diverse task types. We introduce a principled risk decomposition that separates the total ICL risk into two orthogonal components: Bayes Gap and Posterior Variance. The Bayes Gap quantifies how well the trained model approximates the Bayes-optimal in-context predictor. For a uniform-attention Transformer, we derive a non-asymptotic upper bound on this gap, which explicitly clarifies the dependence on the number of pretraining prompts and their context length. The Posterior Variance is a model-independent risk representing the intrinsic task uncertainty. Our key finding is that this term is determined solely by the difficulty of the true underlying task, while the uncertainty arising from the task mixture vanishes exponentially fast with only a few in-context examples. Together, these results provide a unified view of ICL: the Transformer selects the optimal meta-algorithm during pretraining and rapidly converges to the optimal algorithm for the true task at test time.",
    "authors": [
      "Tomoya Wakayama",
      "Taiji Suzuki"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T03:42:31.000Z",
    "updatedAt": "2025-10-13T03:42:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10981v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10981v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10980v1",
    "arxivId": "2510.10980v1",
    "title": "On the Optimal Representation Efficiency of Barlow Twins: An Information-Geometric Interpretation",
    "abstract": "Self-supervised learning (SSL) has achieved remarkable success by learning meaningful representations without labeled data. However, a unified theoretical framework for understanding and comparing the efficiency of different SSL paradigms remains elusive. In this paper, we introduce a novel information-geometric framework to quantify representation efficiency. We define representation efficiency $\\eta$ as the ratio between the effective intrinsic dimension of the learned representation space and its ambient dimension, where the effective dimension is derived from the spectral properties of the Fisher Information Matrix (FIM) on the statistical manifold induced by the encoder. Within this framework, we present a theoretical analysis of the Barlow Twins method. Under specific but natural assumptions, we prove that Barlow Twins achieves optimal representation efficiency ($\\eta = 1$) by driving the cross-correlation matrix of representations towards the identity matrix, which in turn induces an isotropic FIM. This work provides a rigorous theoretical foundation for understanding the effectiveness of Barlow Twins and offers a new geometric perspective for analyzing SSL algorithms.",
    "authors": [
      "Di Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.IT",
      "math.IT",
      "math.ST",
      "stat.ML",
      "stat.TH",
      "68T07, 62B11, 94A17, 53B12",
      "I.2.6; I.5.1; G.3; H.1.1"
    ],
    "publishedAt": "2025-10-13T03:41:27.000Z",
    "updatedAt": "2025-10-13T03:41:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10980v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10980v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10979v1",
    "arxivId": "2510.10979v1",
    "title": "AMO-HEAD: Adaptive MARG-Only Heading Estimation for UAVs under Magnetic Disturbances",
    "abstract": "Accurate and robust heading estimation is crucial for unmanned aerial vehicles (UAVs) when conducting indoor inspection tasks. However, the cluttered nature of indoor environments often introduces severe magnetic disturbances, which can significantly degrade heading accuracy. To address this challenge, this paper presents an Adaptive MARG-Only Heading (AMO-HEAD) estimation approach for UAVs operating in magnetically disturbed environments. AMO-HEAD is a lightweight and computationally efficient Extended Kalman Filter (EKF) framework that leverages inertial and magnetic sensors to achieve reliable heading estimation. In the proposed approach, gyroscope angular rate measurements are integrated to propagate the quaternion state, which is subsequently corrected using accelerometer and magnetometer data. The corrected quaternion is then used to compute the UAV's heading. An adaptive process noise covariance method is introduced to model and compensate for gyroscope measurement noise, bias drift, and discretization errors arising from the Euler method integration. To mitigate the effects of external magnetic disturbances, a scaling factor is applied based on real-time magnetic deviation detection. A theoretical observability analysis of the proposed AMO-HEAD is performed using the Lie derivative. Extensive experiments were conducted in real world indoor environments with customized UAV platforms. The results demonstrate the effectiveness of the proposed algorithm in providing precise heading estimation under magnetically disturbed conditions.",
    "authors": [
      "Qizhi Guo",
      "Siyuan Yang",
      "Junning Lyu",
      "Jianjun Sun",
      "Defu Lin",
      "Shaoming He"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T03:36:53.000Z",
    "updatedAt": "2025-10-13T03:36:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10979v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10979v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10978v1",
    "arxivId": "2510.10978v1",
    "title": "Does LLM Focus on the Right Words? Diagnosing Language Bias in LLM-based Recommenders",
    "abstract": "Large language models (LLMs), owing to their extensive open-domain knowledge and semantic reasoning capabilities, have been increasingly integrated into recommender systems (RS). However, a substantial gap remains between the pre-training objectives of LLMs and the specific requirements of recommendation tasks. To address this gap, supervised fine-tuning (SFT) is commonly performed on specially curated recommendation datasets to further enhance their predictive ability. Despite its success, SFT exhibits a critical limitation: it induces Language Bias, whereby the model over-relies on auxiliary tokens-such as task descriptions and prefix-generated tokens-while underutilizing core user interaction tokens that encode user-specific preferences. This bias not only undermines recommendation accuracy but also raises unfairness concerns. To address this issue, we propose Group Distributionally Robust Optimization-based Tuning (GDRT), a novel fine-tuning paradigm that enforces consistent model performance across token groups with varying degrees of relevance to auxiliary tokens. By adaptively upweighting underperforming groups, typically those weakly correlated with auxiliary tokens, GDRT shifts the model's attention from superficial auxiliary cues to informative user interaction tokens, thereby mitigating language bias. Extensive experiments conducted on three public datasets demonstrate that GDRT effectively mitigates language bias, yielding substantial improvements in recommendation accuracy (with an average NDCG@10 gain of 24.29%) and significantly enhancing recommendation fairness.",
    "authors": [
      "Bohao Wang",
      "Jiawei Chen",
      "Feng Liu",
      "Changwang Zhang",
      "Jun Wang",
      "Canghong Jin",
      "Chun Chen",
      "Can Wang"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T03:35:26.000Z",
    "updatedAt": "2025-10-13T03:35:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10978v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10978v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10977v1",
    "arxivId": "2510.10977v1",
    "title": "Revisiting Model Interpolation for Efficient Reasoning",
    "abstract": "Model merging, typically on Instruct and Thinking models, has shown remarkable performance for efficient reasoning. In this paper, we systematically revisit the simplest merging method that interpolates two weights directly. Particularly, we observe that model interpolation follows a three-stage evolutionary paradigm with distinct behaviors on the reasoning trajectory. These dynamics provide a principled guide for navigating the performance-cost trade-off. Empirical results demonstrate that a strategically interpolated model surprisingly surpasses sophisticated model merging baselines on both efficiency and effectiveness. We further validate our findings with extensive ablation studies on model layers, modules, and decoding strategies. Ultimately, this work demystifies model interpolation and offers a practical framework for crafting models with precisely targeted reasoning capabilities. Code is available at \\href{https://github.com/wutaiqiang/MI}{Github}.",
    "authors": [
      "Taiqiang Wu",
      "Runming Yang",
      "Tao Liu",
      "Jiahao Wang",
      "Ngai Wong"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T03:30:01.000Z",
    "updatedAt": "2025-10-13T03:30:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10977v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10977v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10976v1",
    "arxivId": "2510.10976v1",
    "title": "Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph",
    "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) has demonstrated strong semantic understanding capabilities, but struggles to perform precise spatio-temporal understanding. Existing spatio-temporal methods primarily focus on the video itself, while overlooking the physical information within the video, such as multi-object layouts and motion. Such limitations restrict the use of MLLMs in downstream applications that demand high precision, including embodied intelligence and VR. To address this issue, we present Video-STR, a novel graph-based reinforcement method for precise Video Spatio-Temporal Reasoning. Building upon the capacity of Reinforcement Learning with Verifiable Reward (RLVR) to improve model abilities, we introduce a reasoning mechanism using graph-based Group Relative Policy Optimization (GRPO) method to guide the model in inferring the underlying spatio-temporal topology of scenarios during the thinking process. To resolve the lack of spatio-temporal training data, we construct the STV-205k dataset with 205k question-answering pairs, covering dynamic multi-object scenes in both indoor and outdoor environments, to support the model training. Experiments show that Video-STR achieves state-of-the-art results on various benchmarks, outperforming the base model by 13% on STI-Bench, and demonstrating the effectiveness of our approach and dataset. Code, model, and data will be released.",
    "authors": [
      "Wentao Wang",
      "Heqing Zou",
      "Tianze Luo",
      "Rui Huang",
      "Yutian Zhao",
      "Zhuochen Wang",
      "Hansheng Zhang",
      "Chengwei Qin",
      "Yan Wang",
      "Lin Zhao",
      "Huaijian Zhang"
    ],
    "categories": [
      "cs.AI",
      "68T05",
      "I.2.10"
    ],
    "publishedAt": "2025-10-13T03:26:56.000Z",
    "updatedAt": "2025-10-13T03:26:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10976v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10976v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10975v1",
    "arxivId": "2510.10975v1",
    "title": "RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model",
    "abstract": "Vision-Language-Action (VLA) models have become a prominent paradigm for embodied intelligence, yet further performance improvements typically rely on scaling up training data and model size -- an approach that is prohibitively expensive for robotics and fundamentally limited by data collection costs.We address this limitation with $\\mathbf{RoVer}$, an embodied test-time scaling framework that uses a $\\mathbf{Ro}$bot Process Reward Model (PRM) as a Test-Time $\\mathbf{Ver}$ifier to enhance the capabilities of existing VLA models without modifying their architectures or weights. Specifically, RoVer (i) assigns scalar-based process rewards to evaluate the reliability of candidate actions, and (ii) predicts an action-space direction for candidate expansion/refinement. During inference, RoVer generates multiple candidate actions concurrently from the base policy, expands them along PRM-predicted directions, and then scores all candidates with PRM to select the optimal action for execution. Notably, by caching shared perception features, it can amortize perception cost and evaluate more candidates under the same test-time computational budget. Essentially, our approach effectively transforms available computing resources into better action decision-making, realizing the benefits of test-time scaling without extra training overhead. Our contributions are threefold: (1) a general, plug-and-play test-time scaling framework for VLAs; (2) a PRM that jointly provides scalar process rewards and an action-space direction to guide exploration; and (3) an efficient direction-guided sampling strategy that leverages a shared perception cache to enable scalable candidate generation and selection during inference.",
    "authors": [
      "Mingtong Dai",
      "Lingbo Liu",
      "Yongjie Bai",
      "Yang Liu",
      "Zhouxia Wang",
      "Rui SU",
      "Chunjie Chen",
      "Liang Lin",
      "Xinyu Wu"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T03:26:14.000Z",
    "updatedAt": "2025-10-13T03:26:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10975v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10975v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10974v1",
    "arxivId": "2510.10974v1",
    "title": "Enhancing Large Language Model Reasoning via Selective Critical Token Fine-Tuning",
    "abstract": "Large language models (LLMs) primarily rely on supervised fine-tuning (SFT) as a key method to adapt pre-trained models to domain-specific tasks such as mathematical reasoning. However, standard SFT uniformly penalizes all tokens, neglecting that only a small subset of critical tokens determines reasoning correctness. This uniform supervision often causes reduced output diversity and limited generalization. We propose Critical Token Fine-tuning (CFT), a simple yet effective approach that updates only tokens identified as functionally indispensable via counterfactual perturbations. By focusing gradient signals on these decisive reasoning steps while preserving the diversity of non-critical tokens, CFT can enhance both generation and diversity. Extensive experiments on five models across three families (Qwen, OLMo, LLaMA) and eleven mathematical reasoning benchmarks show that CFT, despite fine-tuning on less than 12% of tokens, consistently outperforms standard SFT. Moreover, CFT enables test-time scaling through improved sampling diversity and provides a stronger initialization for reinforcement learning, sustaining performance gains in later training stages while maintaining higher entropy for better exploration. These results highlight CFT as a practical and general framework for efficient and robust LLM fine-tuning.",
    "authors": [
      "Zhiwen Ruan",
      "Yixia Li",
      "He Zhu",
      "Yun Chen",
      "Peng Li",
      "Yang Liu",
      "Guanhua Chen"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T03:25:36.000Z",
    "updatedAt": "2025-10-13T03:25:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10974v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10974v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10973v1",
    "arxivId": "2510.10973v1",
    "title": "Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning",
    "abstract": "The capabilities of Large Vision-Language Models (LVLMs) have reached state-of-the-art on many visual reasoning tasks, including chart reasoning, yet they still falter on out-of-distribution (OOD) data, and degrade further when asked to produce their chain-of-thought (CoT) rationales, limiting explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs to be more robust and explainable for chart reasoning by coupling Group Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our framework comprises of three rewards that maximize: (i) correct chart-type classification, (ii) faithful chart table reconstruction, and (iii) process conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently outperforms standard supervised fine-tuning (SFT) on both in-distribution and out-of-distribution datasets, closing the OOD performance gap while improving rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve state-of-the-art results on six chart-reasoning benchmarks spanning in-domain and OOD settings, surpassing all existing models of comparable size. Beyond accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening trust and reliability - showcasing the power of verifiable rewards with GRPO for training reliable, interpretable chart-reasoning models.",
    "authors": [
      "Sanchit Sinha",
      "Oana Frunza",
      "Kashif Rasul",
      "Yuriy Nevmyvaka",
      "Aidong Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T03:25:35.000Z",
    "updatedAt": "2025-10-13T03:25:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10973v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10973v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10971v1",
    "arxivId": "2510.10971v1",
    "title": "RV-HATE: Reinforced Multi-Module Voting for Implicit Hate Speech Detection",
    "abstract": "Hate speech remains prevalent in human society and continues to evolve in its forms and expressions. Modern advancements in internet and online anonymity accelerate its rapid spread and complicate its detection. However, hate speech datasets exhibit diverse characteristics primarily because they are constructed from different sources and platforms, each reflecting different linguistic styles and social contexts. Despite this diversity, prior studies on hate speech detection often rely on fixed methodologies without adapting to data-specific features. We introduce RV-HATE, a detection framework designed to account for the dataset-specific characteristics of each hate speech dataset. RV-HATE consists of multiple specialized modules, where each module focuses on distinct linguistic or contextual features of hate speech. The framework employs reinforcement learning to optimize weights that determine the contribution of each module for a given dataset. A voting mechanism then aggregates the module outputs to produce the final decision. RV-HATE offers two primary advantages: (1)~it improves detection accuracy by tailoring the detection process to dataset-specific attributes, and (2)~it also provides interpretable insights into the distinctive features of each dataset. Consequently, our approach effectively addresses implicit hate speech and achieves superior performance compared to conventional static methods. Our code is available at https://github.com/leeyejin1231/RV-HATE.",
    "authors": [
      "Yejin Lee",
      "Hyeseon Ahn",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "publishedAt": "2025-10-13T03:21:51.000Z",
    "updatedAt": "2025-10-13T03:21:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10971v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10971v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10969v1",
    "arxivId": "2510.10969v1",
    "title": "IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation",
    "abstract": "Existing vision language models (VLMs), including GPT-4 and DALL-E, often struggle to preserve logic, object identity, and style in multimodal image-text generation. This limitation significantly hinders the generalization capability of VLMs in complex image-text input-output scenarios. To address this issue, we propose IUT-Plug, a module grounded in an Image Understanding Tree (IUT), which enhances existing interleaved VLMs through explicit structured reasoning, thereby mitigating context drift in logic, entity identity, and style. The proposed framework operates in two stages. (1) A dynamic IUT-Plug extraction module parses visual scenes into hierarchical symbolic structures. (2) A coordinated narrative-flow and image synthesis mechanism ensures cross-modal consistency. To evaluate our approach, we construct a novel benchmark based on 3,000 real human-generated question-answer pairs over fine-tuned large models, introducing a dynamic evaluation protocol for quantifying context drift in interleaved VLMs. Experimental results demonstrate that IUT-Plug not only improves accuracy on established benchmarks but also effectively alleviates the three critical forms of context drift across diverse multimodal question answering (QA) scenarios.",
    "authors": [
      "Zeteng Lin",
      "Xingxing Li",
      "Wen You",
      "Xiaoyang Li",
      "Zehan Lu",
      "Yujun Cai",
      "Jing Tang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T03:19:45.000Z",
    "updatedAt": "2025-10-13T03:19:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10969v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10969v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10968v1",
    "arxivId": "2510.10968v1",
    "title": "Blade: A Derivative-free Bayesian Inversion Method using Diffusion Priors",
    "abstract": "Derivative-free Bayesian inversion is an important task in many science and engineering applications, particularly when computing the forward model derivative is computationally and practically challenging. In this paper, we introduce Blade, which can produce accurate and well-calibrated posteriors for Bayesian inversion using an ensemble of interacting particles. Blade leverages powerful data-driven priors based on diffusion models, and can handle nonlinear forward models that permit only black-box access (i.e., derivative-free). Theoretically, we establish a non-asymptotic convergence analysis to characterize the effects of forward model and prior estimation errors. Empirically, Blade achieves superior performance compared to existing derivative-free Bayesian inversion methods on various inverse problems, including challenging highly nonlinear fluid dynamics.",
    "authors": [
      "Hongkai Zheng",
      "Austin Wang",
      "Zihui Wu",
      "Zhengyu Huang",
      "Ricardo Baptista",
      "Yisong Yue"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T03:19:44.000Z",
    "updatedAt": "2025-10-13T03:19:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10968v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10968v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10966v1",
    "arxivId": "2510.10966v1",
    "title": "Geoffrion's theorem beyond finiteness and rationality",
    "abstract": "Geoffrion's theorem is a fundamental result from mathematical programming assessing the quality of Lagrangian relaxation, a standard technique to get bounds for integer programs. An often implicit condition is that the set of feasible solutions is finite or described by rational linear constraints. However, we show through concrete examples that the conclusion of Geoffrion's theorem does not necessarily hold when this condition is dropped. We then provide sufficient conditions ensuring the validity of the result even when the feasible set is not finite and cannot be described using finitely-many linear constraints.",
    "authors": [
      "Santanu S. Dey",
      "Frédéric Meunier",
      "Diego Moran Ramirez"
    ],
    "categories": [
      "math.OC",
      "cs.DM"
    ],
    "publishedAt": "2025-10-13T03:19:01.000Z",
    "updatedAt": "2025-10-13T03:19:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10966v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10966v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10965v1",
    "arxivId": "2510.10965v1",
    "title": "Judge Before Answer: Can MLLM Discern the False Premise in Question?",
    "abstract": "Multimodal large language models (MLLMs) have witnessed astonishing advancements in recent years. Despite these successes, MLLMs remain vulnerable to flase premise problems. However, existing benchmarks targeting this issue are limited in scope: they often lack fine-grained categorization, exhibit insufficient coverage, and thus fail to provide a rigorous evaluation of the ability of models to recognize false premises. To bridge this gap, we introduce a fully automated pipeline for constructing a comprehensive benchmark of false premise questions. Our method systematically categorizes the premises into three main types and thirteen subtypes according to the abilities required to identify the premises, resulting in the JBA dataset.Results show current MLLMs still struggle with false premise recognition. Building upon this benchmark, we further propose a recognition enhancement framework tailored to strengthen the robustness of MLLMs to detect false premises. Extensive experiments demonstrate that models trained with our framework achieve significant improvements in false premise recognition.",
    "authors": [
      "Jidong Li",
      "Lingyong Fang",
      "Haodong Zhao",
      "Sufeng Duan",
      "Gongshen Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T03:17:00.000Z",
    "updatedAt": "2025-10-13T03:17:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10965v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10965v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10964v1",
    "arxivId": "2510.10964v1",
    "title": "Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies for Reasoning Models",
    "abstract": "While 4-bit quantization has emerged as a memory-optimal choice for non-reasoning models and zero-shot tasks across scales, we show that this universal prescription fails for reasoning models, where the KV cache rather than model size can dominate memory. Through systematic experiments across 1,700 inference scenarios on AIME25 and GPQA-Diamond, we find a scale-dependent trade-off: models with an effective size below 8-bit 4B parameters achieve better accuracy by allocating memory to more weights rather than longer generation, while larger models achieve better accuracy by allocating memory to longer generations. This scale threshold also determines when parallel scaling becomes memory-efficient and whether KV cache eviction outperforms KV quantization. Our findings show that memory optimization for LLMs cannot be scale-agnostic, while providing principled guidelines: for small reasoning models, prioritize model capacity over test-time compute, while for larger ones, maximize test-time compute. Our results suggest that optimizing reasoning models for deployment requires fundamentally different strategies from those established for non-reasoning models.",
    "authors": [
      "Junhyuck Kim",
      "Ethan Ewer",
      "Taehong Moon",
      "Jongho Park",
      "Dimitris Papailiopoulos"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T03:14:28.000Z",
    "updatedAt": "2025-10-13T03:14:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10964v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10964v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10963v1",
    "arxivId": "2510.10963v1",
    "title": "APLOT: Robust Reward Modeling via Adaptive Preference Learning with Optimal Transport",
    "abstract": "The reward model (RM) plays a crucial role in aligning Large Language Models (LLMs) with human preferences through Reinforcement Learning, where the Bradley-Terry (BT) objective has been recognized as simple yet powerful, specifically for pairwise preference learning. However, BT-based RMs often struggle to effectively distinguish between similar preference responses, leading to insufficient separation between preferred and non-preferred outputs. Consequently, they may easily overfit easy samples and cannot generalize well to Out-Of-Distribution (OOD) samples, resulting in suboptimal performance. To address these challenges, this paper introduces an effective enhancement to BT-based RMs through an adaptive margin mechanism. Specifically, we design to dynamically adjust the RM focus on more challenging samples through margins, based on both semantic similarity and model-predicted reward differences, which is approached from a distributional perspective solvable with Optimal Transport (OT). By incorporating these factors into a principled OT cost matrix design, our adaptive margin enables the RM to better capture distributional differences between chosen and rejected responses, yielding significant improvements in performance, convergence speed, and generalization capabilities. Experimental results across multiple benchmarks demonstrate that our method outperforms several existing RM techniques, showcasing enhanced performance in both In-Distribution (ID) and OOD settings. Moreover, RLHF experiments support our practical effectiveness in better aligning LLMs with human preferences. Our code is available at https://github.com/BIRlz/APLOT",
    "authors": [
      "Zhuo Li",
      "Yuege Feng",
      "Dandan Guo",
      "Jinpeng Hu",
      "Anningzhe Gao",
      "Xiang Wan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T03:13:28.000Z",
    "updatedAt": "2025-10-13T03:13:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10963v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10963v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10962v1",
    "arxivId": "2510.10962v1",
    "title": "MC#: Mixture Compressor for Mixture-of-Experts Large Models",
    "abstract": "Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and vision-language models (VLMs) by increasing capacity through sparse activation. However, preloading all experts into memory and activating multiple experts per input introduces significant computational and memory overhead, making the expert module a major contributor to model size and inference cost. To address this, we propose MC# (Mixture-Compressor-sharp), a framework that combines static quantization and dynamic expert pruning by leveraging the significance of experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce storage and loading costs, we introduce Pre-Loading Mixed-Precision Quantization (PMQ), which optimizes bit allocation via linear programming, balancing expert importance and quantization error for a Pareto-optimal trade-off between size and performance. To reduce runtime computation, Online Top-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a subset of experts per token, enabling fine-grained control over activation. By combining PMQ's static bit-width optimization with OTP's dynamic routing, MC# achieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC# achieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7% accuracy drop across five multimodal benchmarks. Additionally, OTP reduces expert activation over 20% with less than 1% performance degradation, demonstrating strong potential for efficient MoE-based model deployment.",
    "authors": [
      "Wei Huang",
      "Yue Liao",
      "Yukang Chen",
      "Jianhui Liu",
      "Haoru Tan",
      "Si Liu",
      "Shiming Zhang",
      "Shuicheng Yan",
      "Xiaojuan Qi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T03:12:46.000Z",
    "updatedAt": "2025-10-13T03:12:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10962v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10962v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10961v1",
    "arxivId": "2510.10961v1",
    "title": "KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification",
    "abstract": "Toxic content has become an increasingly critical social issue with the rapid expansion of online communication. While numerous studies explored methods for detecting and detoxifying such content, most have focused primarily on English, leaving low-resource language underrepresented. Consequently, Large Language Models~(LLMs) often struggle to identify and neutralize toxic expressions in these languages. This challenge becomes even more pronounced when user employ obfuscation techniques to evade detection systems. Therefore, we propose a \\textbf{KOTOX: Korean Toxic Dataset} for deobfuscation and detoxicification to address this issue. We categorize various obfuscation approaches based on linguistic characteristics of Korean and define a set of transformation rules grounded in real-word examples. Using these rules, we construct three dataset versions (easy, normal, and hard) representing different levels of obfuscation difficulty. This is the first dataset that simultaneously supports deobfuscation and detoxification for the Korean language. We expect it to facilitate better understanding and mitigating of obfuscated toxic content in LLM for low-resource languages. Our code and data are available at https://github.com/leeyejin1231/KOTOX.",
    "authors": [
      "Yejin Lee",
      "Su-Hyeon Kim",
      "Hyundong Jin",
      "Dayoung Kim",
      "Yeonsoo Kim",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "publishedAt": "2025-10-13T03:12:37.000Z",
    "updatedAt": "2025-10-13T03:12:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10961v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10961v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10960v1",
    "arxivId": "2510.10960v1",
    "title": "Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving",
    "abstract": "Ensuring safety in autonomous driving (AD) remains a significant challenge, especially in highly dynamic and complex traffic environments where diverse agents interact and unexpected hazards frequently emerge. Traditional reinforcement learning (RL) methods often struggle to balance safety, efficiency, and adaptability, as they primarily focus on reward maximization without explicitly modeling risk or safety constraints. To address these limitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L) framework for safe AD. GTR2L incorporates a multi-level game-theoretic world model that jointly predicts the interactive behaviors of surrounding vehicles and their associated risks, along with an adaptive rollout horizon that adjusts dynamically based on predictive uncertainty. Furthermore, an uncertainty-aware barrier mechanism enables flexible modulation of safety boundaries. A dedicated risk modeling approach is also proposed, explicitly capturing both epistemic and aleatoric uncertainty to guide constrained policy optimization and enhance decision-making in complex environments. Extensive evaluations across diverse and safety-critical traffic scenarios show that GTR2L significantly outperforms state-of-the-art baselines, including human drivers, in terms of success rate, collision and violation reduction, and driving efficiency. The code is available at https://github.com/DanielHu197/GTR2L.",
    "authors": [
      "Dong Hu",
      "Fenqing Hu",
      "Lidong Yang",
      "Chao Huang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T03:12:30.000Z",
    "updatedAt": "2025-10-13T03:12:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10960v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10960v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10959v1",
    "arxivId": "2510.10959v1",
    "title": "Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning",
    "abstract": "Reasoning ability has become a defining capability of Large Language Models (LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as a key paradigm to enhance it. However, RLVR training often suffers from policy entropy collapse, where the policy becomes overly deterministic, hindering exploration and limiting reasoning performance. While entropy regularization is a common remedy, its effectiveness is highly sensitive to the fixed coefficient, making it unstable across tasks and models. In this work, we revisit entropy regularization in RLVR and argue that its potential has been largely underestimated. Our analysis shows that (i) tasks of varying difficulty demand distinct exploration intensities, and (ii) balanced exploration may require the policy entropy to be maintained within a moderate range below its initial level. Therefore, we propose Adaptive Entropy Regularization (AER)--a framework that dynamically balances exploration and exploitation via three components: difficulty-aware coefficient allocation, initial-anchored target entropy, and dynamic global coefficient adjustment. Experiments on multiple mathematical reasoning benchmarks show that AER consistently outperforms baselines, improving both reasoning accuracy and exploration capability.",
    "authors": [
      "Xiaoyun Zhang",
      "Xiaojian Yuan",
      "Di Huang",
      "Wang You",
      "Chen Hu",
      "Jingqing Ruan",
      "Kejiang Chen",
      "Xing Hu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T03:10:26.000Z",
    "updatedAt": "2025-10-13T03:10:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10959v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10959v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10956v1",
    "arxivId": "2510.10956v1",
    "title": "Project-Level C-to-Rust Translation via Synergistic Integration of Knowledge Graphs and Large Language Models",
    "abstract": "Translating C code into safe Rust is an effective way to ensure its memory safety. Compared to rule-based translation which produces Rust code that remains largely unsafe, LLM-based methods can generate more idiomatic and safer Rust code because LLMs have been trained on vast amount of human-written idiomatic code. Although promising, existing LLM-based methods still struggle with project-level C-to-Rust translation. They typically partition a C project into smaller units (\\eg{} functions) based on call graphs and translate them bottom-up to resolve program dependencies. However, this bottom-up, unit-by-unit paradigm often fails to translate pointers due to the lack of a global perspective on their usage. To address this problem, we propose a novel C-Rust Pointer Knowledge Graph (KG) that enriches a code-dependency graph with two types of pointer semantics: (i) pointer-usage information which record global behaviors such as points-to flows and map lower-level struct usage to higher-level units; and (ii) Rust-oriented annotations which encode ownership, mutability, nullability, and lifetime. Synthesizing the \\kg{} with LLMs, we further propose \\ourtool{}, which implements a project-level C-to-Rust translation technique. In \\ourtool{}, the \\kg{} provides LLMs with comprehensive pointer semantics from a global perspective, thus guiding LLMs towards generating safe and idiomatic Rust code from a given C project. Our experiments show that \\ourtool{} reduces unsafe usages in translated Rust by 99.9\\% compared to both rule-based translation and traditional LLM-based rewriting, while achieving an average 29.3\\% higher functional correctness than those fuzzing-enhanced LLM methods.",
    "authors": [
      "Zhiqiang Yuan",
      "Wenjun Mao",
      "Zhuo Chen",
      "Xiyue Shang",
      "Chong Wang",
      "Yiling Lou",
      "Xin Peng"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T03:09:35.000Z",
    "updatedAt": "2025-10-13T03:09:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10956v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10956v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10955v1",
    "arxivId": "2510.10955v1",
    "title": "HatLLM: Hierarchical Attention Masking for Enhanced Collaborative Modeling in LLM-based Recommendation",
    "abstract": "Recent years have witnessed a surge of research on leveraging large language models (LLMs) for sequential recommendation. LLMs have demonstrated remarkable potential in inferring users' nuanced preferences through fine-grained semantic reasoning. However, they also exhibit a notable limitation in effectively modeling collaborative signals, i.e., behavioral correlations inherent in users' historical interactions. Our empirical analysis further reveals that the attention mechanisms in LLMs tend to disproportionately focus on tokens within the same item, thereby impeding the capture of cross-item correlations. To address this limitation, we propose a novel hierarchical attention masking strategy for LLM-based recommendation, termed HatLLM. Specifically, in shallow layers, HatLLM masks attention between tokens from different items, facilitating intra-item semantic understanding; in contrast, in deep layers, HatLLM masks attention within items, thereby compelling the model to capture cross-item correlations. This progressive, layer-wise approach enables LLMs to jointly model both token-level and item-level dependencies. Extensive experiments on three real-world datasets demonstrate that HatLLM achieves significant performance gains (9.13% on average) over existing LLM-based methods.",
    "authors": [
      "Yu Cui",
      "Feng Liu",
      "Jiawei Chen",
      "Canghong Jin",
      "Xingyu Lou",
      "Changwang Zhang",
      "Jun Wang",
      "Yuegang Sun",
      "Can Wang"
    ],
    "categories": [
      "cs.IR"
    ],
    "publishedAt": "2025-10-13T03:05:03.000Z",
    "updatedAt": "2025-10-13T03:05:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10955v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10955v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10954v1",
    "arxivId": "2510.10954v1",
    "title": "Comparative Evaluation of Neural Network Architectures for Generalizable Human Spatial Preference Prediction in Unseen Built Environments",
    "abstract": "The capacity to predict human spatial preferences within built environments is instrumental for developing Cyber-Physical-Social Infrastructure Systems (CPSIS). A significant challenge in this domain is the generalizability of preference models, particularly their efficacy in predicting preferences within environmental configurations not encountered during training. While deep learning models have shown promise in learning complex spatial and contextual dependencies, it remains unclear which neural network architectures are most effective at generalizing to unseen layouts. To address this, we conduct a comparative study of Graph Neural Networks, Convolutional Neural Networks, and standard feedforward Neural Networks using synthetic data generated from a simplified and synthetic pocket park environment. Beginning with this illustrative case study, allows for controlled analysis of each model's ability to transfer learned preference patterns to unseen spatial scenarios. The models are evaluated based on their capacity to predict preferences influenced by heterogeneous physical, environmental, and social features. Generalizability score is calculated using the area under the precision-recall curve for the seen and unseen layouts. This generalizability score is appropriate for imbalanced data, providing insights into the suitability of each neural network architecture for preference-aware human behavior modeling in unseen built environments.",
    "authors": [
      "Maral Doctorarastoo",
      "Katherine A. Flanigan",
      "Mario Bergés",
      "Christopher McComb"
    ],
    "categories": [
      "cs.CE",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "publishedAt": "2025-10-13T03:04:48.000Z",
    "updatedAt": "2025-10-13T03:04:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10954v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10954v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10952v1",
    "arxivId": "2510.10952v1",
    "title": "Interpretable Machine Learning for Cognitive Aging: Handling Missing Data and Uncovering Social Determinant",
    "abstract": "Early detection of Alzheimer's disease (AD) is crucial because its neurodegenerative effects are irreversible, and neuropathologic and social-behavioral risk factors accumulate years before diagnosis. Identifying higher-risk individuals earlier enables prevention, timely care, and equitable resource allocation. We predict cognitive performance from social determinants of health (SDOH) using the NIH NIA-supported PREPARE Challenge Phase 2 dataset derived from the nationally representative Mex-Cog cohort of the 2003 and 2012 Mexican Health and Aging Study (MHAS). Data: The target is a validated composite cognitive score across seven domains-orientation, memory, attention, language, constructional praxis, and executive function-derived from the 2016 and 2021 MHAS waves. Predictors span demographic, socioeconomic, health, lifestyle, psychosocial, and healthcare access factors. Methodology: Missingness was addressed with a singular value decomposition (SVD)-based imputation pipeline treating continuous and categorical variables separately. This approach leverages latent feature correlations to recover missing values while balancing reliability and scalability. After evaluating multiple methods, XGBoost was chosen for its superior predictive performance. Results and Discussion: The framework outperformed existing methods and the data challenge leaderboard, demonstrating high accuracy, robustness, and interpretability. SHAP-based post hoc analysis identified top contributing SDOH factors and age-specific feature patterns. Notably, flooring material emerged as a strong predictor, reflecting socioeconomic and environmental disparities. Other influential factors, age, SES, lifestyle, social interaction, sleep, stress, and BMI, underscore the multifactorial nature of cognitive aging and the value of interpretable, data-driven SDOH modeling.",
    "authors": [
      "Xi Mao",
      "Zhendong Wang",
      "Jingyu Li",
      "Lingchao Mao",
      "Utibe Essien",
      "Hairong Wang",
      "Xuelei Sherry Ni"
    ],
    "categories": [
      "cs.LG",
      "stat.AP"
    ],
    "publishedAt": "2025-10-13T03:04:10.000Z",
    "updatedAt": "2025-10-13T03:04:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10952v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10952v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10951v1",
    "arxivId": "2510.10951v1",
    "title": "Punctuation-aware treebank tree binarization",
    "abstract": "This article presents a curated resource and evaluation suite for punctuation-aware treebank binarization. Standard binarization pipelines drop punctuation before head selection, which alters constituent shape and harms head-child identification. We release (1) a reproducible pipeline that preserves punctuation as sibling nodes prior to binarization, (2) derived artifacts and metadata (intermediate @X markers, reversibility signatures, alignment indices), and (3) an accompanying evaluation suite covering head-child prediction, round-trip reversibility, and structural compatibility with derivational resources (CCGbank). On the Penn Treebank, punctuation-aware preprocessing improves head prediction accuracy from 73.66\\% (Collins rules) and 86.66\\% (MLP) to 91.85\\% with the same classifier, and achieves competitive alignment against CCGbank derivations. All code, configuration files, and documentation are released to enable replication and extension to other corpora.",
    "authors": [
      "Eitan Klinger",
      "Vivaan Wadhwa",
      "Jungyeul Park"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T03:02:38.000Z",
    "updatedAt": "2025-10-13T03:02:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10951v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10951v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10948v1",
    "arxivId": "2510.10948v1",
    "title": "Unify Variables in Neural Scaling Laws for General Audio Representations via Embedding Effective Rank",
    "abstract": "Scaling laws have profoundly shaped our understanding of model performance in computer vision and natural language processing, yet their application to general audio representation learning remains underexplored. A key challenge lies in the multifactorial nature of general audio representation-representation quality is jointly influenced by variables such as audio length, embedding dimensionality, model depth, model architecture, data volume, etc., many of which are difficult to isolate or express analytically. In this work, we present a systematic study of scaling laws for general audio representations by utilizing embedding effective rank (RankMe) as a unifying metric that encapsulates the impact of diverse variables on representation quality. RankMe enables a label-free, information-theoretic quantification of audio embeddings, allowing us to examine scaling behaviors across a wide hyper-parameter space, including model size, training data volume, computational budget, architectural configurations, etc. Our empirical findings reveal a consistent power-law relationship between RankMe and representation quality, suggesting that embedding effective rank serves as a reliable proxy for assessing and predicting model performance in audio representation learning. This work not only validates the applicability of classical scaling principles to the general audio domain but also offers a theoretically grounded and empirically robust framework for guiding future model scaling strategies in audio foundation models.",
    "authors": [
      "Xuyao Deng",
      "Yanjie Sun",
      "Yong Dou",
      "Kele Xu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "publishedAt": "2025-10-13T02:58:50.000Z",
    "updatedAt": "2025-10-13T02:58:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10948v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10948v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10947v1",
    "arxivId": "2510.10947v1",
    "title": "Towards Distribution-Shift Uncertainty Estimation for Inverse Problems with Generative Priors",
    "abstract": "Generative models have shown strong potential as data-driven priors for solving inverse problems such as reconstructing medical images from undersampled measurements. While these priors improve reconstruction quality with fewer measurements, they risk hallucinating features when test images lie outside the training distribution. Existing uncertainty quantification methods in this setting (i) require an in-distribution calibration dataset, which may not be available, (ii) provide heuristic rather than statistical estimates, or (iii) quantify uncertainty from model capacity or limited measurements rather than distribution shift. We propose an instance-level, calibration-free uncertainty indicator that is sensitive to distribution shift, requires no knowledge of the training distribution, and incurs no retraining cost. Our key hypothesis is that reconstructions of in-distribution images remain stable under random measurement variations, while reconstructions of out-of-distribution (OOD) images exhibit greater instability. We use this stability as a proxy for detecting distribution shift. Our proposed OOD indicator is efficiently computable for any computational imaging inverse problem; we demonstrate it on tomographic reconstruction of MNIST digits, where a learned proximal network trained only on digit \"0\" is evaluated on all ten digits. Reconstructions of OOD digits show higher variability and correspondingly higher reconstruction error, validating this indicator. These results suggest a deployment strategy that pairs generative priors with lightweight guardrails, enabling aggressive measurement reduction for in-distribution cases while automatically warning when priors are applied out of distribution.",
    "authors": [
      "Namhoon Kim",
      "Sara Fridovich-Keil"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T02:58:26.000Z",
    "updatedAt": "2025-10-13T02:58:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10947v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10947v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10944v1",
    "arxivId": "2510.10944v1",
    "title": "Throughput Maximization for Multiuser Communications with Flexible-Sector 6DMA",
    "abstract": "This paper presents a cost-effective and easily-deployable flexible-sector six-dimensional movable antenna (6DMA) architecture for future wireless communication networks, which enables flexible antenna configurations to match users' spatial distribution for capacity enhancement. Different from conventional sectorized base station (BS) with fixed-position antennas (FPAs), the flexible-sector 6DMA-enabled BS employs multiple directional sector antenna arrays that can flexibly move along a common circular track. By properly moving antennas across sectors and rotating all sector antenna arrays synchronously, the flexible-sector BS can adjust the coverage regions of all sectors with flexible antenna allocations over them. In particular, we consider the multiuser downlink communication employing the orthogonal multiple access (OMA) to serve users in each sector. Under this setup, we jointly optimize the sector rotation and the antenna allocation at the flexible-sector BS to maximize the average common throughput achievable for all users based on their spatial distribution. We solve this non-convex optimization problem by deriving closed-form solutions and thereby analyze the effect of users' spatial distribution on the achievable common throughput. It is shown that equal user distribution over sectors is optimal for maximizing the common throughput. Motivated by this result, we further develop a low-complexity suboptimal solution for the sector rotation that minimizes the variance of user numbers across sectors. Finally, we provide simulation results to verify our analytical results and validate the performance of our proposed solutions. It is demonstrated that the flexible-sector BS significantly improves the network throughput as compared to other benchmark schemes.",
    "authors": [
      "Xiaoming Shi",
      "Yunli Li",
      "Xiaodan Shao",
      "Jie Xu",
      "Rui Zhang"
    ],
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-13T02:56:43.000Z",
    "updatedAt": "2025-10-13T02:56:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10944v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10944v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10943v1",
    "arxivId": "2510.10943v1",
    "title": "The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi-Agent Systems",
    "abstract": "Bias in large language models (LLMs) remains a persistent challenge, manifesting in stereotyping and unfair treatment across social groups. While prior research has primarily focused on individual models, the rise of multi-agent systems (MAS), where multiple LLMs collaborate and communicate, introduces new and largely unexplored dynamics in bias emergence and propagation. In this work, we present a comprehensive study of stereotypical bias in MAS, examining how internal specialization, underlying LLMs and inter-agent communication protocols influence bias robustness, propagation, and amplification. We simulate social contexts where agents represent different social groups and evaluate system behavior under various interaction and adversarial scenarios. Experiments on three bias benchmarks reveal that MAS are generally less robust than single-agent systems, with bias often emerging early through in-group favoritism. However, cooperative and debate-based communication can mitigate bias amplification, while more robust underlying LLMs improve overall system stability. Our findings highlight critical factors shaping fairness and resilience in multi-agent LLM systems.",
    "authors": [
      "Thi-Nhung Nguyen",
      "Linhao Luo",
      "Thuy-Trang Vu",
      "Dinh Phung"
    ],
    "categories": [
      "cs.MA",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T02:56:42.000Z",
    "updatedAt": "2025-10-13T02:56:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10943v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10943v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10942v1",
    "arxivId": "2510.10942v1",
    "title": "Scalable and Explainable Enterprise Knowledge Discovery Using Graph-Centric Hybrid Retrieval",
    "abstract": "Modern enterprises manage vast knowledge distributed across heterogeneous systems such as Jira, Git repositories, Confluence, and wikis. Conventional retrieval methods based on keyword search or static embeddings often fail to answer complex queries that require contextual reasoning and multi-hop inference across artifacts. We present a modular hybrid retrieval framework for adaptive enterprise information access that integrates Knowledge Base Language-Augmented Models (KBLam), DeepGraph representations, and embedding-driven semantic search. The framework builds a unified knowledge graph from parsed repositories including code, pull requests, and commit histories, enabling semantic similarity search, structural inference, and multi-hop reasoning. Query analysis dynamically determines the optimal retrieval strategy, supporting both structured and unstructured data sources through independent or fused processing. An interactive interface provides graph visualizations, subgraph exploration, and context-aware query routing to generate concise and explainable answers. Experiments on large-scale Git repositories show that the unified reasoning layer improves answer relevance by up to 80 percent compared with standalone GPT-based retrieval pipelines. By combining graph construction, hybrid reasoning, and interactive visualization, the proposed framework offers a scalable, explainable, and user-centric foundation for intelligent knowledge assistants in enterprise environments.",
    "authors": [
      "Nilima Rao",
      "Jagriti Srivastava",
      "Pradeep Kumar Sharma",
      "Hritvik Shrivastava"
    ],
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "publishedAt": "2025-10-13T02:56:36.000Z",
    "updatedAt": "2025-10-13T02:56:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10942v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10942v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10940v1",
    "arxivId": "2510.10940v1",
    "title": "An efficient iteration method to reconstruct the drift term from the final measurement",
    "abstract": "This work investigates the inverse drift problem in the one-dimensional parabolic equation with the final time data. The authors construct an operator first, whose fixed points are the unknown drift, and then apply it to prove the uniqueness. The proof of uniqueness contains an iteration converging to the drift, which inspires the numerical algorithm. To handle the ill-posedness of the inverse problem, the authors add the mollification on the data first in the iterative algorithm, and then provide some numerical results.",
    "authors": [
      "Dakang Cen",
      "Wenlong Zhang",
      "Zhidong Zhang"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "math.AP",
      "35K10, 35R30, 65M32"
    ],
    "publishedAt": "2025-10-13T02:56:05.000Z",
    "updatedAt": "2025-10-13T02:56:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10940v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10940v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10938v1",
    "arxivId": "2510.10938v1",
    "title": "Redundancy as a Structural Information Principle for Learning and Generalization",
    "abstract": "We present a theoretical framework that extends classical information theory to finite and structured systems by redefining redundancy as a fundamental property of information organization rather than inefficiency. In this framework, redundancy is expressed as a general family of informational divergences that unifies multiple classical measures, such as mutual information, chi-squared dependence, and spectral redundancy, under a single geometric principle. This reveals that these traditional quantities are not isolated heuristics but projections of a shared redundancy geometry. The theory further predicts that redundancy is bounded both above and below, giving rise to an optimal equilibrium that balances over-compression (loss of structure) and over-coupling (collapse). While classical communication theory favors minimal redundancy for transmission efficiency, finite and structured systems, such as those underlying real-world learning, achieve maximal stability and generalization near this equilibrium. Experiments with masked autoencoders are used to illustrate and verify this principle: the model exhibits a stable redundancy level where generalization peaks. Together, these results establish redundancy as a measurable and tunable quantity that bridges the asymptotic world of communication and the finite world of learning.",
    "authors": [
      "Yuda Bi",
      "Ying Zhu",
      "Vince D Calhoun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T02:55:37.000Z",
    "updatedAt": "2025-10-13T02:55:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10938v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10938v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10937v1",
    "arxivId": "2510.10937v1",
    "title": "Neutral Agent-based Adversarial Policy Learning against Deep Reinforcement Learning in Multi-party Open Systems",
    "abstract": "Reinforcement learning (RL) has been an important machine learning paradigm for solving long-horizon sequential decision-making problems under uncertainty. By integrating deep neural networks (DNNs) into the RL framework, deep reinforcement learning (DRL) has emerged, which achieved significant success in various domains. However, the integration of DNNs also makes it vulnerable to adversarial attacks. Existing adversarial attack techniques mainly focus on either directly manipulating the environment with which a victim agent interacts or deploying an adversarial agent that interacts with the victim agent to induce abnormal behaviors. While these techniques achieve promising results, their adoption in multi-party open systems remains limited due to two major reasons: impractical assumption of full control over the environment and dependent on interactions with victim agents. To enable adversarial attacks in multi-party open systems, in this paper, we redesigned an adversarial policy learning approach that can mislead well-trained victim agents without requiring direct interactions with these agents or full control over their environments. Particularly, we propose a neutral agent-based approach across various task scenarios in multi-party open systems. While the neutral agents seemingly are detached from the victim agents, indirectly influence them through the shared environment. We evaluate our proposed method on the SMAC platform based on Starcraft II and the autonomous driving simulation platform Highway-env. The experimental results demonstrate that our method can launch general and effective adversarial attacks in multi-party open systems.",
    "authors": [
      "Qizhou Peng",
      "Yang Zheng",
      "Yu Wen",
      "Yanna Wu",
      "Yingying Du"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T02:53:22.000Z",
    "updatedAt": "2025-10-13T02:53:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10937v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10937v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10936v1",
    "arxivId": "2510.10936v1",
    "title": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF: A Reproducibility Study",
    "abstract": "We present a reproducibility study of the state-of-the-art neural architecture for sequence labeling proposed by Ma and Hovy (2016)\\cite{ma2016end}. The original BiLSTM-CNN-CRF model combines character-level representations via Convolutional Neural Networks (CNNs), word-level context modeling through Bi-directional Long Short-Term Memory networks (BiLSTMs), and structured prediction using Conditional Random Fields (CRFs). This end-to-end approach eliminates the need for hand-crafted features while achieving excellent performance on named entity recognition (NER) and part-of-speech (POS) tagging tasks. Our implementation successfully reproduces the key results, achieving 91.18\\% F1-score on CoNLL-2003 NER and demonstrating the model's effectiveness across sequence labeling tasks. We provide a detailed analysis of the architecture components and release an open-source PyTorch implementation to facilitate further research.",
    "authors": [
      "Anirudh Ganesh",
      "Jayavardhan Reddy"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T02:49:21.000Z",
    "updatedAt": "2025-10-13T02:49:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10936v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10936v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10933v1",
    "arxivId": "2510.10933v1",
    "title": "DKPMV: Dense Keypoints Fusion from Multi-View RGB Frames for 6D Pose Estimation of Textureless Objects",
    "abstract": "6D pose estimation of textureless objects is valuable for industrial robotic applications, yet remains challenging due to the frequent loss of depth information. Current multi-view methods either rely on depth data or insufficiently exploit multi-view geometric cues, limiting their performance. In this paper, we propose DKPMV, a pipeline that achieves dense keypoint-level fusion using only multi-view RGB images as input. We design a three-stage progressive pose optimization strategy that leverages dense multi-view keypoint geometry information. To enable effective dense keypoint fusion, we enhance the keypoint network with attentional aggregation and symmetry-aware training, improving prediction accuracy and resolving ambiguities on symmetric objects. Extensive experiments on the ROBI dataset demonstrate that DKPMV outperforms state-of-the-art multi-view RGB approaches and even surpasses the RGB-D methods in the majority of cases. The code will be available soon.",
    "authors": [
      "Jiahong Chen",
      "Jinghao Wang",
      "Zi Wang",
      "Ziwen Wang",
      "Banglei Guan",
      "Qifeng Yu"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T02:45:55.000Z",
    "updatedAt": "2025-10-13T02:45:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10933v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10933v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10932v1",
    "arxivId": "2510.10932v1",
    "title": "TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models",
    "abstract": "With the growing deployment of Vision-Language-Action (VLA) models in real-world embodied AI systems, their increasing vulnerability to backdoor attacks poses a serious safety threat. A backdoored VLA agent can be covertly triggered by a pre-injected backdoor to execute adversarial actions, potentially causing system failures or even physical harm. Although backdoor attacks on VLA models have been explored, prior work has focused only on untargeted attacks, leaving the more practically threatening scenario of targeted manipulation unexamined. In this paper, we study targeted backdoor attacks on VLA models and introduce TabVLA, a novel framework that enables such attacks via black-box fine-tuning. TabVLA explores two deployment-relevant inference-time threat models: input-stream editing and in-scene triggering. It formulates poisoned data generation as an optimization problem to improve attack effectivess. Experiments with OpenVLA-7B on the LIBERO benchmark reveal that the vision channel is the principal attack surface: targeted backdoors succeed with minimal poisoning, remain robust across variations in trigger design, and are degraded only by positional mismatches between fine-tuning and inference triggers. We also investigate a potential detection-based defense against TabVLA, which reconstructs latent visual triggers from the input stream to flag activation-conditioned backdoor samples. Our work highlights the vulnerability of VLA models to targeted backdoor manipulation and underscores the need for more advanced defenses.",
    "authors": [
      "Zonghuan Xu",
      "Xiang Zheng",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T02:45:48.000Z",
    "updatedAt": "2025-10-13T02:45:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10932v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10932v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10930v1",
    "arxivId": "2510.10930v1",
    "title": "Evaluating Language Models' Evaluations of Games",
    "abstract": "Reasoning is not just about solving problems -- it is also about evaluating which problems are worth solving at all. Evaluations of artificial intelligence (AI) systems primarily focused on problem solving, historically by studying how models play games such as chess and Go. In this paper, we advocate for a new paradigm that assesses AI systems' evaluation of games. First, we introduce a formalism for evaluating such evaluations. We then leverage a large-scale dataset of over $100$ novel board games and over 450 human judgments to compare evaluations produced by modern language and reasoning models against those of people and symbolic computational agents. We consider two kinds of evaluative queries: assessing the payoff (or fairness) and the funness of games. These queries span two dimensions relevant to the design of evaluations of AI evaluations: how complex a query is to compute and how difficult a query is to quantify. Our results show that reasoning models are generally more aligned to people in their evaluations of games than non-reasoning language models. However, we observe a non-monotonic relationship: as models get closer to game-theoretic optimal, their fit to human data weakens. We also observe more \"jaggedness\" across models for assessing funness, in line with the greater difficulty of quantifying this query. Across queries and games, reasoning models show highly variable and unpredictable resource usage when assessing queries, pointing to the importance of imbuing more resource-rational meta-reasoning in language and reasoning models.",
    "authors": [
      "Katherine M. Collins",
      "Cedegao E. Zhang",
      "Graham Todd",
      "Lance Ying",
      "Mauricio Barba da Costa",
      "Ryan Liu",
      "Prafull Sharma",
      "Adrian Weller",
      "Ionatan Kuperwajs",
      "Lionel Wong",
      "Joshua B. Tenenbaum",
      "Thomas L. Griffiths"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T02:45:37.000Z",
    "updatedAt": "2025-10-13T02:45:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10930v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10930v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10931v1",
    "arxivId": "2510.10931v1",
    "title": "PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents",
    "abstract": "Retrieval-augmented generation (RAG) agents, such as recent DeepResearch-style systems, extend large language models (LLMs) with autonomous information-seeking capabilities through external tools. While reinforcement learning (RL) has enabled impressive multi-step reasoning, we identify a previously overlooked failure mode, Tool-Call Hacking, where agents inflate reward signals by issuing superficially correct tool calls without genuinely leveraging the retrieved evidence. This results in (i) mode collapse into repetitive reliance on a single source and (ii) spurious grounding, where answers are only weakly supported by cited content. To address this, we propose Proof-of-Use (PoU), an evidence-grounded RL framework that enforces verifiable causal links between retrieved evidence, reasoning traces, and final answers. PoU operationalizes this through a unified step-wise contract combining syntactic citation validation, perturbation-based sensitivity rewards, and answer-evidence alignment objectives, ensuring that tool usage remains both interpretable and functionally grounded. Across seven QA benchmarks spanning in-domain, out-of-domain, and out-of-tool-distribution settings, PoU consistently outperforms strong DeepResearch baselines in factual accuracy, evidence faithfulness, and tool-routing balance. These findings highlight the necessity of grounding RL-trained agents not merely in task outcomes but in the causal use of retrieved information, offering a principled path toward trustworthy retrieval-augmented reasoning.",
    "authors": [
      "SHengjie Ma",
      "Chenlong Deng",
      "Jiaxin Mao",
      "Jiadeng Huang",
      "Teng Wang",
      "Junjie Wu",
      "Changwang Zhang",
      "Jun wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T02:45:37.000Z",
    "updatedAt": "2025-10-13T02:45:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10931v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10931v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10929v1",
    "arxivId": "2510.10929v1",
    "title": "Achieving Coordination in Non-Cooperative Joint Replenishment Games",
    "abstract": "We analyze an infinite-horizon deterministic joint replenishment model from a non-cooperative game-theoretical approach. In this model, a group of retailers can choose to jointly place an order, which incurs a major setup cost independent of the group, and a minor setup cost for each retailer. Additionally, each retailer is associated with a holding cost. Our objective is to design cost allocation rules that minimize the long-run average system cost while accounting for the fact that each retailer independently selects its replenishment interval to minimize its own cost. We introduce a class of cost allocation rules that distribute the major setup cost among the associated retailers in proportion to their predefined weights. For these rules, we establish a monotonicity property of agent better responses, which enables us to prove the existence of a payoff dominant pure Nash equilibrium that can also be computed efficiently. We then analyze the efficiency of these equilibria by examining the price of stability (PoS), the ratio of the best Nash equilibrium's system cost to the social optimum, across different information settings. In particular, our analysis reveals that one rule, which leverages retailers' own holding cost rates, achieves a near-optimal PoS of 1.25, while another rule that does not require access to retailers' private information also yields a favorable PoS.",
    "authors": [
      "Junjie Luo",
      "Changjun Wang"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-13T02:43:38.000Z",
    "updatedAt": "2025-10-13T02:43:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10929v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10929v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10927v1",
    "arxivId": "2510.10927v1",
    "title": "GapDNER: A Gap-Aware Grid Tagging Model for Discontinuous Named Entity Recognition",
    "abstract": "In biomedical fields, one named entity may consist of a series of non-adjacent tokens and overlap with other entities. Previous methods recognize discontinuous entities by connecting entity fragments or internal tokens, which face challenges of error propagation and decoding ambiguity due to the wide variety of span or word combinations. To address these issues, we deeply explore discontinuous entity structures and propose an effective Gap-aware grid tagging model for Discontinuous Named Entity Recognition, named GapDNER. Our GapDNER innovatively applies representation learning on the context gaps between entity fragments to resolve decoding ambiguity and enhance discontinuous NER performance. Specifically, we treat the context gap as an additional type of span and convert span classification into a token-pair grid tagging task. Subsequently, we design two interactive components to comprehensively model token-pair grid features from both intra- and inter-span perspectives. The intra-span regularity extraction module employs the biaffine mechanism along with linear attention to capture the internal regularity of each span, while the inter-span relation enhancement module utilizes criss-cross attention to obtain semantic relations among different spans. At the inference stage of entity decoding, we assign a directed edge to each entity fragment and context gap, then use the BFS algorithm to search for all valid paths from the head to tail of grids with entity tags. Experimental results on three datasets demonstrate that our GapDNER achieves new state-of-the-art performance on discontinuous NER and exhibits remarkable advantages in recognizing complex entity structures.",
    "authors": [
      "Yawen Yang",
      "Fukun Ma",
      "Shiao Meng",
      "Aiwei Liu",
      "Lijie Wen"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T02:40:14.000Z",
    "updatedAt": "2025-10-13T02:40:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10927v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10927v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10925v1",
    "arxivId": "2510.10925v1",
    "title": "Find Your Optimal Teacher: Personalized Data Synthesis via Router-Guided Multi-Teacher Distillation",
    "abstract": "Training student models on synthetic data generated by strong teacher models is a promising way to distilling the capabilities of teachers. However, recent studies show that stronger models are not always optimal teachers, revealing a mismatch between teacher outputs and student learnability. To address this issue, we propose PerSyn (Personalized data Synthesis), a novel synthesis strategy that operates under a new ``Route then Generate'' paradigm to create data tailored to each student model, enabling it to learn more effectively. Specifically, PerSyn first assigns each prompt to its optimal teacher via a query-level router that jointly considers student learnability and teacher response quality. Each teacher then synthesizes data only for its assigned prompts, making the process more efficient than the conventional ``Generate then Select'' paradigm, where all teachers must generate parallel responses for the entire prompt set before constructing the final dataset. Extensive experiments across different model families and scales demonstrate that PerSyn consistently achieves superior or comparable performance to all baselines in instruct tuning and math reasoning settings. Further analysis verifies the effectiveness of PerSyn and offers extra insights to propel future research.",
    "authors": [
      "Hengyuan Zhang",
      "Shiping Yang",
      "Xiao Liang",
      "Chenming Shang",
      "Yuxuan Jiang",
      "Chaofan Tao",
      "Jing Xiong",
      "Hayden Kwok-Hay So",
      "Ruobing Xie",
      "Angel X. Chang",
      "Ngai Wong"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T02:36:36.000Z",
    "updatedAt": "2025-10-13T02:36:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10925v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10925v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10921v1",
    "arxivId": "2510.10921v1",
    "title": "FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model",
    "abstract": "Fine-grained vision-language understanding requires precise alignment between visual content and linguistic descriptions, a capability that remains limited in current models, particularly in non-English settings. While models like CLIP perform well on global alignment, they often struggle to capture fine-grained details in object attributes, spatial relations, and linguistic expressions, with limited support for bilingual comprehension. To address these challenges, we introduce FG-CLIP 2, a bilingual vision-language model designed to advance fine-grained alignment for both English and Chinese. Our approach leverages rich fine-grained supervision, including region-text matching and long-caption modeling, alongside multiple discriminative objectives. We further introduce the Textual Intra-modal Contrastive (TIC) loss to better distinguish semantically similar captions. Trained on a carefully curated mixture of large-scale English and Chinese data, FG-CLIP 2 achieves powerful bilingual performance. To enable rigorous evaluation, we present a new benchmark for Chinese multimodal understanding, featuring long-caption retrieval and bounding box classification. Extensive experiments on 29 datasets across 8 tasks show that FG-CLIP 2 outperforms existing methods, achieving state-of-the-art results in both languages. We release the model, code, and benchmark to facilitate future research on bilingual fine-grained alignment.",
    "authors": [
      "Chunyu Xie",
      "Bin Wang",
      "Fanjing Kong",
      "Jincheng Li",
      "Dawei Liang",
      "Ji Ao",
      "Dawei Leng",
      "Yuhui Yin"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T02:32:07.000Z",
    "updatedAt": "2025-10-13T02:32:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10921v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10921v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10920v1",
    "arxivId": "2510.10920v1",
    "title": "Comparative Explanations via Counterfactual Reasoning in Recommendations",
    "abstract": "Explainable recommendation through counterfactual reasoning seeks to identify the influential aspects of items in recommendations, which can then be used as explanations. However, state-of-the-art approaches, which aim to minimize changes in product aspects while reversing their recommended decisions according to an aggregated decision boundary score, often lead to factual inaccuracies in explanations. To solve this problem, in this work we propose a novel method of Comparative Counterfactual Explanations for Recommendation (CoCountER). CoCountER creates counterfactual data based on soft swap operations, enabling explanations for recommendations of arbitrary pairs of comparative items. Empirical experiments validate the effectiveness of our approach.",
    "authors": [
      "Yi Yu",
      "Zhenxing Hu"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T02:31:03.000Z",
    "updatedAt": "2025-10-13T02:31:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10920v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10920v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10918v1",
    "arxivId": "2510.10918v1",
    "title": "DreamMakeup: Face Makeup Customization using Latent Diffusion Models",
    "abstract": "The exponential growth of the global makeup market has paralleled advancements in virtual makeup simulation technology. Despite the progress led by GANs, their application still encounters significant challenges, including training instability and limited customization capabilities. Addressing these challenges, we introduce DreamMakup - a novel training-free Diffusion model based Makeup Customization method, leveraging the inherent advantages of diffusion models for superior controllability and precise real-image editing. DreamMakeup employs early-stopped DDIM inversion to preserve the facial structure and identity while enabling extensive customization through various conditioning inputs such as reference images, specific RGB colors, and textual descriptions. Our model demonstrates notable improvements over existing GAN-based and recent diffusion-based frameworks - improved customization, color-matching capabilities, identity preservation and compatibility with textual descriptions or LLMs with affordable computational costs.",
    "authors": [
      "Geon Yeong Park",
      "Inhwa Han",
      "Serin Yang",
      "Yeobin Hong",
      "Seongmin Jeong",
      "Heechan Jeon",
      "Myeongjin Goh",
      "Sung Won Yi",
      "Jin Nam",
      "Jong Chul Ye"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T02:29:23.000Z",
    "updatedAt": "2025-10-13T02:29:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10918v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10918v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10915v1",
    "arxivId": "2510.10915v1",
    "title": "LPCVAE: A Conditional VAE with Long-Term Dependency and Probabilistic Time-Frequency Fusion for Time Series Anomaly Detection",
    "abstract": "Time series anomaly detection(TSAD) is a critical task in signal processing field, ensuring the reliability of complex systems. Reconstruction-based methods dominate in TSAD. Among these methods, VAE-based methods have achieved promising results. Existing VAE-based methods suffer from the limitation of single-window feature and insufficient leveraging of long-term time and frequency information. We propose a Conditional Variational AutoEncoder with Long-term dependency and Probabilistic time-frequency fusion, named LPCVAE. LPCVAE introduces LSTM to capture long-term dependencies beyond windows. It further incorporates a Product-of-Experts (PoE) mechanism for adaptive and distribution-level probabilistic fusion. This design effectively mitigates time-frequency information loss. Extensive experiments on four public datasets demonstrate it outperforms state-of-the-art methods. The results confirm that integrating long-term time and frequency representations with adaptive fusion yields a robust and efficient solution for TSAD.",
    "authors": [
      "Hanchang Cheng",
      "Weimin Mu",
      "Fan Liu",
      "Weilin Zhu",
      "Can Ma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T02:27:04.000Z",
    "updatedAt": "2025-10-13T02:27:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10915v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10915v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10914v1",
    "arxivId": "2510.10914v1",
    "title": "Optimal Multi-Modal Transportation and Electric Power Flow: The Value of Coordinated Dynamic Operation",
    "abstract": "The electrification of transportation represents a critical challenge in the global transition toward net-zero emissions, as the sector often accounts for more than one-quarter of national energy consumption. Achieving this transformation requires not only widespread adoption of electric vehicles (EVs) but also their seamless integration into interdependent infrastructure systems-specifically, the transportation-electricity nexus (TEN). This paper develops an optimal multi-modal transportation and electric power flow (OMTEPF) model to evaluate the benefits of coordinated, dynamic system operation. Building on recent advances in hetero-functional graph theory, the framework enables joint optimization of five key operational decisions in intelligent TEN management: vehicle dispatch, route choice, charging station queuing, coordinated charging, and vehicle-to-grid stabilization. The mesoscopic, dynamic model explicitly represents individual EVs and their state-of-charge trajectories, thereby extending beyond the prevailing literature's focus on static, macroscopic traffic assignment. It further captures the full scope of the TEN as a system-of-systems, incorporating five distinct charging modalities: private residential, private commercial, wired public commercial, inductive public, and discharging. On the power system side, an IV-ACOPF formulation ensures globally optimal solutions to the electrical subproblems. Comparative analysis demonstrates the substantial value of coordinated TEN operation relative to the status quo of siloed, uncoordinated infrastructure management. This work provides both a novel methodological contribution and actionable insights for the co-design and operation of next-generation sustainable mobility-energy systems.",
    "authors": [
      "Jiajie Qiu",
      "Dakota Thompson",
      "Kamal Youcef-Toumi",
      "Amro M. Farid"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T02:19:05.000Z",
    "updatedAt": "2025-10-13T02:19:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10914v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10914v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10913v1",
    "arxivId": "2510.10913v1",
    "title": "ADVICE: Answer-Dependent Verbalized Confidence Estimation",
    "abstract": "Recent progress in large language models (LLMs) has enabled them to express their confidence in natural language, enhancing transparency and reliability. However, their confidence often exhibits overconfidence, the cause of which remains poorly understood. In this work, we conduct a detailed analysis of the dynamics underlying verbalized confidence and identify answer-independence as a key factor, defined as the model's failure to condition confidence on its own answer. To address this, we propose ADVICE (Answer-Dependent Verbalized Confidence Estimation), a fine-tuning framework that facilitates answer-grounded confidence estimation. Extensive experiments show that ADVICE substantially improves confidence calibration while preserving task performance. Further analyses confirm that ADVICE strengthens answer-groundedness, leading to more balanced and well-calibrated confidence distributions. Our findings shed light on the origin of overconfidence and establish a framework for more trustworthy confidence verbalization.",
    "authors": [
      "Ki Jung Seo",
      "Sehun Lim",
      "Taeuk Kim"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T02:18:33.000Z",
    "updatedAt": "2025-10-13T02:18:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10913v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10913v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10912v1",
    "arxivId": "2510.10912v1",
    "title": "More than A Point: Capturing Uncertainty with Adaptive Affordance Heatmaps for Spatial Grounding in Robotic Tasks",
    "abstract": "Many language-guided robotic systems rely on collapsing spatial reasoning into discrete points, making them brittle to perceptual noise and semantic ambiguity. To address this challenge, we propose RoboMAP, a framework that represents spatial targets as continuous, adaptive affordance heatmaps. This dense representation captures the uncertainty in spatial grounding and provides richer information for downstream policies, thereby significantly enhancing task success and interpretability. RoboMAP surpasses the previous state-of-the-art on a majority of grounding benchmarks with up to a 50x speed improvement, and achieves an 82\\% success rate in real-world manipulation. Across extensive simulated and physical experiments, it demonstrates robust performance and shows strong zero-shot generalization to navigation. More details and videos can be found at https://robo-map.github.io.",
    "authors": [
      "Xinyu Shao",
      "Yanzhe Tang",
      "Pengwei Xie",
      "Kaiwen Zhou",
      "Yuzheng Zhuang",
      "Xingyue Quan",
      "Jianye Hao",
      "Long Zeng",
      "Xiu Li"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T02:14:30.000Z",
    "updatedAt": "2025-10-13T02:14:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10912v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10912v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10910v1",
    "arxivId": "2510.10910v1",
    "title": "SceneTextStylizer: A Training-Free Scene Text Style Transfer Framework with Diffusion Model",
    "abstract": "With the rapid development of diffusion models, style transfer has made remarkable progress. However, flexible and localized style editing for scene text remains an unsolved challenge. Although existing scene text editing methods have achieved text region editing, they are typically limited to content replacement and simple styles, which lack the ability of free-style transfer. In this paper, we introduce SceneTextStylizer, a novel training-free diffusion-based framework for flexible and high-fidelity style transfer of text in scene images. Unlike prior approaches that either perform global style transfer or focus solely on textual content modification, our method enables prompt-guided style transformation specifically for text regions, while preserving both text readability and stylistic consistency. To achieve this, we design a feature injection module that leverages diffusion model inversion and self-attention to transfer style features effectively. Additionally, a region control mechanism is introduced by applying a distance-based changing mask at each denoising step, enabling precise spatial control. To further enhance visual quality, we incorporate a style enhancement module based on the Fourier transform to reinforce stylistic richness. Extensive experiments demonstrate that our method achieves superior performance in scene text style transformation, outperforming existing state-of-the-art methods in both visual fidelity and text preservation.",
    "authors": [
      "Honghui Yuan",
      "Keiji Yanai"
    ],
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "publishedAt": "2025-10-13T02:11:57.000Z",
    "updatedAt": "2025-10-13T02:11:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10910v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10910v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10909v1",
    "arxivId": "2510.10909v1",
    "title": "PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature",
    "abstract": "Understanding and reasoning on the web-scale scientific literature is a crucial touchstone for large language model (LLM) based agents designed to support complex knowledge-intensive tasks. However, existing works are mainly restricted to tool-free tasks within isolated papers, largely due to the lack of a benchmark for cross-paper reasoning and multi-tool orchestration in real research scenarios. In this work, we propose PaperArena, an evaluation benchmark for agents to address real-world research questions that typically require integrating information across multiple papers with the assistance of external tools. Given a research question, agents should integrate diverse formats across multiple papers through reasoning and interacting with appropriate tools, thereby producing a well-grounded answer. To support standardized evaluation, we provide a modular and extensible platform for agent execution, offering tools such as multimodal parsing, context retrieval, and programmatic computation. Experimental results reveal that even the most advanced LLM powering a well-established agent system achieves merely 38.78% average accuracy. On the hard subset, accuracy drops to only 18.47%, highlighting great potential for improvement. We also present several empirical findings, including that all agents tested exhibit inefficient tool usage, often invoking more tools than necessary to solve a task. We invite the community to adopt PaperArena to develop and evaluate more capable agents for scientific discovery. Our code and data are available https://github.com/Melmaphother/PaperArena.",
    "authors": [
      "Daoyu Wang",
      "Mingyue Cheng",
      "Qi Liu",
      "Shuo Yu",
      "Zirui Liu",
      "Ze Guo"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T02:10:39.000Z",
    "updatedAt": "2025-10-13T02:10:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10909v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10909v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10903v1",
    "arxivId": "2510.10903v1",
    "title": "Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey",
    "abstract": "Embodied intelligence has witnessed remarkable progress in recent years, driven by advances in computer vision, natural language processing, and the rise of large-scale multimodal models. Among its core challenges, robot manipulation stands out as a fundamental yet intricate problem, requiring the seamless integration of perception, planning, and control to enable interaction within diverse and unstructured environments. This survey presents a comprehensive overview of robotic manipulation, encompassing foundational background, task-organized benchmarks and datasets, and a unified taxonomy of existing methods. We extend the classical division between high-level planning and low-level control by broadening high-level planning to include language, code, motion, affordance, and 3D representations, while introducing a new taxonomy of low-level learning-based control grounded in training paradigms such as input modeling, latent learning, and policy learning. Furthermore, we provide the first dedicated taxonomy of key bottlenecks, focusing on data collection, utilization, and generalization, and conclude with an extensive review of real-world applications. Compared with prior surveys, our work offers both a broader scope and deeper insight, serving as an accessible roadmap for newcomers and a structured reference for experienced researchers. All related resources, including research papers, open-source datasets, and projects, are curated for the community at https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.",
    "authors": [
      "Shuanghao Bai",
      "Wenxuan Song",
      "Jiayi Chen",
      "Yuheng Ji",
      "Zhide Zhong",
      "Jin Yang",
      "Han Zhao",
      "Wanqi Zhou",
      "Wei Zhao",
      "Zhe Li",
      "Pengxiang Ding",
      "Cheng Chi",
      "Haoang Li",
      "Chang Xu",
      "Xiaolong Zheng",
      "Donglin Wang",
      "Shanghang Zhang",
      "Badong Chen"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T01:59:27.000Z",
    "updatedAt": "2025-10-13T01:59:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10903v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10903v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10902v1",
    "arxivId": "2510.10902v1",
    "title": "Quantifying Information Disclosure During Gradient Descent Using Gradient Uniqueness",
    "abstract": "Disclosing private information via publication of a machine learning model is often a concern. Intuitively, publishing a learned model should be less risky than publishing a dataset. But how much risk is there? In this paper, we present a principled disclosure metric called \\emph{gradient uniqueness} that is derived from an upper bound on the amount of information disclosure from publishing a learned model. Gradient uniqueness provides an intuitive way to perform privacy auditing. The mathematical derivation of gradient uniqueness is general, and does not make any assumption on the model architecture, dataset type, or the strategy of an attacker. We examine a simple defense based on monitoring gradient uniqueness, and find that it achieves privacy comparable to classical methods such as DP-SGD, while being substantially better in terms of (utility) testing accuracy.",
    "authors": [
      "Mahmoud Abdelghafar",
      "Maryam Aliakbarpour",
      "Chris Jermaine"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "publishedAt": "2025-10-13T01:57:27.000Z",
    "updatedAt": "2025-10-13T01:57:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10902v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10902v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10901v1",
    "arxivId": "2510.10901v1",
    "title": "A Symmetric-Key Cryptosystem Based on the Burnside Ring of a Compact Lie Group",
    "abstract": "Classical linear ciphers, such as the Hill cipher, operate on fixed, finite-dimensional modules and are therefore vulnerable to straightforward known-plaintext attacks that recover the key as a fully determined linear operator. We propose a symmetric-key cryptosystem whose linear action takes place instead in the Burnside ring $A(G)$ of a compact Lie group $G$, with emphasis on the case $G=O(2)$. The secret key consists of (i) a compact Lie group $G$; (ii) a secret total ordering of the subgroup orbit-basis of $A(G)$; and (iii) a finite set $S$ of indices of irreducible $G$-representations, whose associated basic degrees define an involutory multiplier $k\\in A(G)$. Messages of arbitrary finite length are encoded as finitely supported elements of $A(G)$ and encrypted via the Burnside product with $k$. For $G=O(2)$ we prove that encryption preserves plaintext support among the generators $\\{(D_1),\\dots,(D_L),(SO(2)),(O(2))\\}$, avoiding ciphertext expansion and security leakage. We then analyze security in passive models, showing that any finite set of observations constrains the action only on a finite-rank submodule $W_L\\subset A(O(2))$, and we show information-theoretic non-identifiability of the key from such data. Finally, we prove the scheme is \\emph{not} IND-CPA secure, by presenting a one-query chosen-plaintext distinguisher based on dihedral probes.",
    "authors": [
      "Ziad Ghanem"
    ],
    "categories": [
      "cs.CR",
      "math.RA"
    ],
    "publishedAt": "2025-10-13T01:57:22.000Z",
    "updatedAt": "2025-10-13T01:57:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10901v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10901v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10899v1",
    "arxivId": "2510.10899v1",
    "title": "A Simple and Efficient One-Shot Signature Scheme",
    "abstract": "One-shot signatures (OSS) are a powerful and uniquely quantum cryptographic primitive which allows anyone, given common reference string, to come up with a public verification key $\\mathsf{pk}$ and a secret signing state $|\\mathsf{sk}\\rangle$. With the secret signing state, one can produce the signature of any one message, but no more. In a recent breakthrough work, Shmueli and Zhandry (CRYPTO 2025) constructed one-shot signatures, either unconditionally in a classical oracle model or assuming post-quantum indistinguishability obfuscation and the hardness of Learning with Errors (LWE) in the plain model. In this work, we address the inefficiency of the Shmueli-Zhandry construction which signs messages bit-by-bit, resulting in signing keys of $\\Theta(\\lambda^4)$ qubits and signatures of size $\\Theta(\\lambda^3)$ bits for polynomially long messages, where $\\lambda$ is the security parameter. We construct a new, simple, direct, and efficient one-shot signature scheme which can sign messages of any polynomial length using signing keys of $\\Theta(\\lambda^2)$ qubits and signatures of size $\\Theta(\\lambda^2)$ bits. We achieve corresponding savings in runtimes, in both the oracle model and the plain model. In addition, unlike the Shmueli-Zhandry construction, our scheme achieves perfect correctness. Our scheme also achieves strong signature incompressibility, which implies a public-key quantum fire scheme with perfect correctness among other applications, correcting an error in a recent work of \\c{C}akan, Goyal and Shmueli (QCrypt 2025) and recovering their applications.",
    "authors": [
      "Andrew Huang",
      "Vinod Vaikuntanathan"
    ],
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "publishedAt": "2025-10-13T01:53:00.000Z",
    "updatedAt": "2025-10-13T01:53:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10899v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10899v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10895v1",
    "arxivId": "2510.10895v1",
    "title": "LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach",
    "abstract": "Medium Access Control (MAC) protocols, essential for wireless networks, are typically manually configured. While deep reinforcement learning (DRL)-based protocols enhance task-specified network performance, they suffer from poor generalizability and resilience, demanding costly retraining to adapt to dynamic environments. To overcome this limitation, we introduce a game-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which the uplink transmission between a base station and a varying number of user equipments is modeled as a dynamic multi-follower Stackelberg game (MFSG), capturing the network's natural hierarchical structure. Within this game, LLM-driven agents, coordinated through proximal policy optimization (PPO), synthesize adaptive, semantic MAC protocols in response to network dynamics. Protocol action grammar (PAG) is employed to ensure the reliability and efficiency of this process. Under this system, we further analyze the existence and convergence behavior in terms of a Stackelberg equilibrium by studying the learning dynamics of LLM-empowered unified policies in response to changing followers. Simulations corroborate that our framework achieves a 77.6% greater throughput and a 65.2% fairness improvement over conventional baselines. Besides, our framework generalizes excellently to a fluctuating number of users without requiring retraining or architectural changes.",
    "authors": [
      "Renxuan Tan",
      "Rongpeng Li",
      "Fei Wang",
      "Chenghui Peng",
      "Shaoyun Wu",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T01:47:24.000Z",
    "updatedAt": "2025-10-13T01:47:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10895v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10895v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10894v1",
    "arxivId": "2510.10894v1",
    "title": "Multiscale Graph Reduction for Heterogeneous and Anisotropic Discrete Diffusion Processes",
    "abstract": "We present multiscale graph-based reduction algorithms for upscaling heterogeneous and anisotropic diffusion problems. The proposed coarsening approaches begin by constructing a partitioning of the computational domain into a set of balanced local subdomains, resulting in a standard type of domain decomposition. Given this initial decomposition, general coarsening techniques based on spectral clustering are applied within each subgraph in order to accurately identify the key microscopic features of a given system. The spectral clustering algorithm is based on local generalized eigen-decompositions applied to the signed graph Laplacian. The resulting coarse-fine splittings are combined with two variants of energy-minimizing strategies for constructing coarse bases for diffusion problems. The first is an unconstrained minimization formulation in which local harmonic extensions are applied column-wise to construct multi-vector preserving interpolation in each region, whereas the second approach is a variant of the constrained energy minimization formulations derived in the context of non-local multi-continua upscaling techniques. We apply the resulting upscaling algorithms to a variety of tests coming from the graph Laplacian, including diffusion in the perforated domain, channelized media, highly anisotropic settings, and discrete pore network models to demonstrate the potential and robustness of the proposed coarsening approaches. We show numerically and theoretically that the proposed approaches lead to accurate coarse-scale models.",
    "authors": [
      "Maria Vasilyeva",
      "James Brannick",
      "Ben S. Southworth"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T01:47:02.000Z",
    "updatedAt": "2025-10-13T01:47:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10894v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10894v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10893v1",
    "arxivId": "2510.10893v1",
    "title": "An Adaptive Transition Framework for Game-Theoretic Based Takeover",
    "abstract": "The transition of control from autonomous systems to human drivers is critical in automated driving systems, particularly due to the out-of-the-loop (OOTL) circumstances that reduce driver readiness and increase reaction times. Existing takeover strategies are based on fixed time-based transitions, which fail to account for real-time driver performance variations. This paper proposes an adaptive transition strategy that dynamically adjusts the control authority based on both the time and tracking ability of the driver trajectory. Shared control is modeled as a cooperative differential game, where control authority is modulated through time-varying objective functions instead of blending control torques directly. To ensure a more natural takeover, a driver-specific state-tracking matrix is introduced, allowing the transition to align with individual control preferences. Multiple transition strategies are evaluated using a cumulative trajectory error metric. Human-in-the-loop control scenarios of the standardized ISO lane change maneuvers demonstrate that adaptive transitions reduce trajectory deviations and driver control effort compared to conventional strategies. Experiments also confirm that continuously adjusting control authority based on real-time deviations enhances vehicle stability while reducing driver effort during takeover.",
    "authors": [
      "Dikshant Shehmar",
      "Matthew E. Taylor",
      "Ehsan Hashemi"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T01:46:29.000Z",
    "updatedAt": "2025-10-13T01:46:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10893v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10893v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10892v1",
    "arxivId": "2510.10892v1",
    "title": "Observability and parameter estimation of a generic model for aggregated distributed energy resources",
    "abstract": "We propose a novel framework for estimating the parameters of an aggregated distributed energy resources (der_a) model. First, we introduce a rigorous method to determine whether all model parameters are estimable. When they are not, our approach identifies the subset of parameters that can be estimated. The proposed framework offers new insights into the number and specific parameters that can be reliably estimated based on commonly available measurements. It also highlights the limitations of calibrating such models. Second, we introduce a Kalman filtering method to calibrate the der_a model. Since we account for nonlinear effects such as saturation and deadbands, we develop a specific mechanism to handle smoothing functions within the Kalman filter. Specifically, we consider the extended and the unscented Kalman filter. We demonstrate the effectiveness of the proposed framework on a modified IEEE 34-node distribution feeder with inverter-based resources. Our findings align with the North American Electric Reliability Corporation's parameterization guideline and underscore the importance of model calibration in accurately capturing the collective dynamics of distributed energy resources installed on distribution systems.",
    "authors": [
      "Bukunmi Gabriel Odunlami",
      "Marcos Netto"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-13T01:45:44.000Z",
    "updatedAt": "2025-10-13T01:45:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10892v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10892v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10890v1",
    "arxivId": "2510.10890v1",
    "title": "LLM$\\times$MapReduce-V3: Enabling Interactive In-Depth Survey Generation through a MCP-Driven Hierarchically Modular Agent System",
    "abstract": "We introduce LLM x MapReduce-V3, a hierarchically modular agent system designed for long-form survey generation. Building on the prior work, LLM x MapReduce-V2, this version incorporates a multi-agent architecture where individual functional components, such as skeleton initialization, digest construction, and skeleton refinement, are implemented as independent model-context-protocol (MCP) servers. These atomic servers can be aggregated into higher-level servers, creating a hierarchically structured system. A high-level planner agent dynamically orchestrates the workflow by selecting appropriate modules based on their MCP tool descriptions and the execution history. This modular decomposition facilitates human-in-the-loop intervention, affording users greater control and customization over the research process. Through a multi-turn interaction, the system precisely captures the intended research perspectives to generate a comprehensive skeleton, which is then developed into an in-depth survey. Human evaluations demonstrate that our system surpasses representative baselines in both content depth and length, highlighting the strength of MCP-based modular planning.",
    "authors": [
      "Yu Chao",
      "Siyu Lin",
      "xiaorong wang",
      "Zhu Zhang",
      "Zihan Zhou",
      "Haoyu Wang",
      "Shuo Wang",
      "Jie Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-13T01:38:37.000Z",
    "updatedAt": "2025-10-13T01:38:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10890v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10890v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10889v1",
    "arxivId": "2510.10889v1",
    "title": "Topological Alignment of Shared Vision-Language Embedding Space",
    "abstract": "Contrastive Vision-Language Models (VLMs) have demonstrated strong zero-shot capabilities. However, their cross-modal alignment remains biased toward English due to limited multilingual multimodal data. Recent multilingual extensions have alleviated this gap but enforce instance-level alignment while neglecting the global geometry of the shared embedding space. We address this problem by introducing ToMCLIP (Topological Alignment for Multilingual CLIP), a topology-aware framework aligning embedding spaces with topology-preserving constraints. The proposed method applies persistent homology to define a topological alignment loss and approximates persistence diagram with theoretical error bounds using graph sparsification strategy. This work validates the proposed approach, showing enhanced structural coherence of multilingual representations, higher zero-shot accuracy on the CIFAR-100, and stronger multilingual retrieval performance on the xFlickr&CO. Beyond VLMs, the proposed approach provides a general method for incorporating topological alignment into representation learning.",
    "authors": [
      "Junwon You",
      "Dasol Kang",
      "Jae-Hun Jung"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T01:36:38.000Z",
    "updatedAt": "2025-10-13T01:36:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10889v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10889v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10887v1",
    "arxivId": "2510.10887v1",
    "title": "Generative AI for Software Project Management: Insights from a Review of Software Practitioner Literature",
    "abstract": "Software practitioners are discussing GenAI transformations in software project management openly and widely. To understand the state of affairs, we performed a grey literature review using 47 publicly available practitioner sources including blogs, articles, and industry reports. We found that software project managers primarily perceive GenAI as an \"assistant\", \"copilot\", or \"friend\" rather than as a \"PM replacement\", with support of GenAI in automating routine tasks, predictive analytics, communication and collaboration, and in agile practices leading to project success. Practitioners emphasize responsible GenAI usage given concerns such as hallucinations, ethics and privacy, and lack of emotional intelligence and human judgment. We present upskilling requirements for software project managers in the GenAI era mapped to the Project Management Institute's talent triangle. We share key recommendations for both practitioners and researchers.",
    "authors": [
      "Lakshana Iruni Assalaarachchi",
      "Zainab Masood",
      "Rashina Hoda",
      "John Grundy"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-13T01:35:17.000Z",
    "updatedAt": "2025-10-13T01:35:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10887v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10887v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10886v1",
    "arxivId": "2510.10886v1",
    "title": "QuayPoints: A Reasoning Framework to Bridge the Information Gap Between Global and Local Planning in Autonomous Racing",
    "abstract": "Autonomous racing requires tight integration between perception, planning and control to minimize latency as well as timely decision making. A standard autonomy pipeline comprising a global planner, local planner, and controller loses information as the higher-level racing context is sequentially propagated downstream into specific task-oriented context. In particular, the global planner's understanding of optimality is typically reduced to a sparse set of waypoints, leaving the local planner to make reactive decisions with limited context. This paper investigates whether additional global insights, specifically time-optimality information, can be meaningfully passed to the local planner to improve downstream decisions. We introduce a framework that preserves essential global knowledge and conveys it to the local planner through QuayPoints regions where deviations from the optimal raceline result in significant compromises to optimality. QuayPoints enable local planners to make more informed global decisions when deviating from the raceline, such as during strategic overtaking. To demonstrate this, we integrate QuayPoints into an existing planner and show that it consistently overtakes opponents traveling at up to 75% of the ego vehicle's speed across four distinct race tracks.",
    "authors": [
      "Yashom Dighe",
      "Youngjin Kim",
      "Karthik Dantu"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-13T01:33:57.000Z",
    "updatedAt": "2025-10-13T01:33:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10886v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10886v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10885v1",
    "arxivId": "2510.10885v1",
    "title": "Rethinking Agentic Workflows: Evaluating Inference-Based Test-Time Scaling Strategies in Text2SQL Tasks",
    "abstract": "Large language models (LLMs) are increasingly powering Text-to-SQL (Text2SQL) systems, enabling non-expert users to query industrial databases using natural language. While test-time scaling strategies have shown promise in LLM-based solutions, their effectiveness in real-world applications, especially with the latest reasoning models, remains uncertain. In this work, we benchmark six lightweight, industry-oriented test-time scaling strategies and four LLMs, including two reasoning models, evaluating their performance on the BIRD Mini-Dev benchmark. Beyond standard accuracy metrics, we also report inference latency and token consumption, providing insights relevant for practical system deployment. Our findings reveal that Divide-and-Conquer prompting and few-shot demonstrations consistently enhance performance for both general-purpose and reasoning-focused LLMs. However, introducing additional workflow steps yields mixed results, and base model selection plays a critical role. This work sheds light on the practical trade-offs between accuracy, efficiency, and complexity when deploying Text2SQL systems.",
    "authors": [
      "Jiajing Guo",
      "Kenil Patel",
      "Jorge Piazentin Ono",
      "Wenbin He",
      "Liu Ren"
    ],
    "categories": [
      "cs.CL",
      "cs.DB"
    ],
    "publishedAt": "2025-10-13T01:29:54.000Z",
    "updatedAt": "2025-10-13T01:29:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10885v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10885v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10880v1",
    "arxivId": "2510.10880v1",
    "title": "Where on Earth? A Vision-Language Benchmark for Probing Model Geolocation Skills Across Scales",
    "abstract": "Vision-language models (VLMs) have advanced rapidly, yet their capacity for image-grounded geolocation in open-world conditions, a task that is challenging and of demand in real life, has not been comprehensively evaluated. We present EarthWhere, a comprehensive benchmark for VLM image geolocation that evaluates visual recognition, step-by-step reasoning, and evidence use. EarthWhere comprises 810 globally distributed images across two complementary geolocation scales: WhereCountry (i.e., 500 multiple-choice question-answering, with country-level answer and panoramas) and WhereStreet (i.e., 310 fine-grained street-level identification tasks requiring multi-step reasoning with optional web search). For evaluation, we adopt the final-prediction metrics: location accuracies within k km (Acc@k) for coordinates and hierarchical path scores for textual localization. Beyond this, we propose to explicitly score intermediate reasoning chains using human-verified key visual clues and a Shapley-reweighted thinking score that attributes credit to each clue's marginal contribution. We benchmark 13 state-of-the-art VLMs with web searching tools on our EarthWhere and report different types of final answer accuracies as well as the calibrated model thinking scores. Overall, Gemini-2.5-Pro achieves the best average accuracy at 56.32%, while the strongest open-weight model, GLM-4.5V, reaches 34.71%. We reveal that web search and reasoning do not guarantee improved performance when visual clues are limited, and models exhibit regional biases, achieving up to 42.7% higher scores in certain areas than others. These findings highlight not only the promise but also the persistent challenges of models to mitigate bias and achieve robust, fine-grained localization. We open-source our benchmark at https://github.com/UCSC-VLAA/EarthWhere.",
    "authors": [
      "Zhaofang Qian",
      "Hardy Chen",
      "Zeyu Wang",
      "Li Zhang",
      "Zijun Wang",
      "Xiaoke Huang",
      "Hui Liu",
      "Xianfeng Tang",
      "Zeyu Zheng",
      "Haoqin Tu",
      "Cihang Xie",
      "Yuyin Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T01:12:21.000Z",
    "updatedAt": "2025-10-13T01:12:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10880v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10880v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10879v1",
    "arxivId": "2510.10879v1",
    "title": "Multilevel correction type of adaptive finite element method for Hartree-Fock equation",
    "abstract": "This paper proposes an efficient algorithm for solving the Hartree--Fock equation combining a multilevel correction scheme with an adaptive refinement technique to improve computational efficiency. The algorithm integrates a multilevel correction framework with an optimized implementation strategy. Within this framework, a series of linearized boundary value problems are solved, and their approximate solutions are corrected by solving small-scale Hartree--Fock equations in low-dimensional correction spaces. The correction space comprises a coarse space and the solution to the linearized boundary value problem, enabling high accuracy while preserving low-dimensional characteristics. The proposed algorithm efficiently addresses the inherent computational complexity of the Hartree--Fock equation. Innovative correction strategies eliminate the need for direct computation of large-scale nonlinear eigenvalue systems and dense matrix operations. Furthermore, optimization techniques based on precomputations within the correction space render the total computational workload nearly independent of the number of self-consistent field iterations. This approach significantly accelerates the solution process of the Hartree--Fock equation, effectively mitigating the traditional exponential scaling demands on computational resources while maintaining precision.",
    "authors": [
      "Fei Xu"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T01:09:29.000Z",
    "updatedAt": "2025-10-13T01:09:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10879v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10879v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10878v1",
    "arxivId": "2510.10878v1",
    "title": "Identifying and Quantifying Financial Bubbles with the Hyped Log-Periodic Power Law Model",
    "abstract": "We propose a novel model, the Hyped Log-Periodic Power Law Model (HLPPL), to the problem of quantifying and detecting financial bubbles, an ever-fascinating one for academics and practitioners alike. Bubble labels are generated using a Log-Periodic Power Law (LPPL) model, sentiment scores, and a hype index we introduced in previous research on NLP forecasting of stock return volatility. Using these tools, a dual-stream transformer model is trained with market data and machine learning methods, resulting in a time series of confidence scores as a Bubble Score. A distinctive feature of our framework is that it captures phases of extreme overpricing and underpricing within a unified structure. We achieve an average yield of 34.13 percentage annualized return when backtesting U.S. equities during the period 2018 to 2024, while the approach exhibits a remarkable generalization ability across industry sectors. Its conservative bias in predicting bubble periods minimizes false positives, a feature which is especially beneficial for market signaling and decision-making. Overall, this approach utilizes both theoretical and empirical advances for real-time positive and negative bubble identification and measurement with HLPPL signals.",
    "authors": [
      "Zheng Cao",
      "Xingran Shao",
      "Yuheng Yan",
      "Helyette Geman"
    ],
    "categories": [
      "q-fin.CP",
      "cs.CE",
      "q-fin.MF"
    ],
    "publishedAt": "2025-10-13T01:06:16.000Z",
    "updatedAt": "2025-10-13T01:06:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10878v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10878v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10877v1",
    "arxivId": "2510.10877v1",
    "title": "USA Tariffs Effect: Machine Learning Insights into the Stock Market",
    "abstract": "The imposition of tariffs by President Trump during his second term had far-reaching consequences for global markets, including Australia. This study investigates how both the announcement and subsequent implementation of these tariffs, specifically on 02-Apr-2025, affected the Australian stock market, focusing on the S\\&P/ASX 200 index over the period from 21-Jan-2025 to 25-Jul-2025. To accurately capture the significance and behavior of market fluctuations, the exploratory data analysis (EDA) techniques are applied. Furthermore, the impact of tariffs on stock performance is evaluated using machine learning-based regression models. A comparative assessment of these models is conducted to determine their predictive accuracy and robustness in capturing tariff-related market responses.",
    "authors": [
      "Mridul Patel"
    ],
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "publishedAt": "2025-10-13T01:04:05.000Z",
    "updatedAt": "2025-10-13T01:04:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10877v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10877v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10876v1",
    "arxivId": "2510.10876v1",
    "title": "rareboost3d: a synthetic lidar dataset with enhanced rare classes",
    "abstract": "Real-world point cloud datasets have made significant contributions to the development of LiDAR-based perception technologies, such as object segmentation for autonomous driving. However, due to the limited number of instances in some rare classes, the long-tail problem remains a major challenge in existing datasets. To address this issue, we introduce a novel, synthetic point cloud dataset named RareBoost3D, which complements existing real-world datasets by providing significantly more instances for object classes that are rare in real-world datasets. To effectively leverage both synthetic and real-world data, we further propose a cross-domain semantic alignment method named CSC loss that aligns feature representations of the same class across different domains. Experimental results demonstrate that this alignment significantly enhances the performance of LiDAR point cloud segmentation models over real-world data.",
    "authors": [
      "Shutong Lin",
      "Zhengkang Xiang",
      "Jianzhong Qi",
      "Kourosh Khoshelham"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T01:02:33.000Z",
    "updatedAt": "2025-10-13T01:02:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10876v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10876v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10872v1",
    "arxivId": "2510.10872v1",
    "title": "FeNOMS: Enhancing Open Modification Spectral Library Search with In-Storage Processing on Ferroelectric NAND (FeNAND) Flash",
    "abstract": "The rapid expansion of mass spectrometry (MS) data, now exceeding hundreds of terabytes, poses significant challenges for efficient, large-scale library search - a critical component for drug discovery. Traditional processors struggle to handle this data volume efficiently, making in-storage computing (ISP) a promising alternative. This work introduces an ISP architecture leveraging a 3D Ferroelectric NAND (FeNAND) structure, providing significantly higher density, faster speeds, and lower voltage requirements compared to traditional NAND flash. Despite its superior density, the NAND structure has not been widely utilized in ISP applications due to limited throughput associated with row-by-row reads from serially connected cells. To overcome these limitations, we integrate hyperdimensional computing (HDC), a brain-inspired paradigm that enables highly parallel processing with simple operations and strong error tolerance. By combining HDC with the proposed dual-bound approximate matching (D-BAM) distance metric, tailored to the FeNAND structure, we parallelize vector computations to enable efficient MS spectral library search, achieving 43x speedup and 21x higher energy efficiency over state-of-the-art 3D NAND methods, while maintaining comparable accuracy.",
    "authors": [
      "Sumukh Pinge",
      "Ashkan Moradifirouzabadi",
      "Keming Fan",
      "Prasanna Venkatesan Ravindran",
      "Tanvir H. Pantha",
      "Po-Kai Hsu",
      "Zheyu Li",
      "Weihong Xu",
      "Zihan Xia",
      "Flavio Ponzina",
      "Winston Chern",
      "Taeyoung Song",
      "Priyankka Ravikumar",
      "Mengkun Tian",
      "Lance Fernandes",
      "Huy Tran",
      "Hari Jayasankar",
      "Hang Chen",
      "Chinsung Park",
      "Amrit Garlapati",
      "Kijoon Kim",
      "Jongho Woo",
      "Suhwan Lim",
      "Kwangsoo Kim",
      "Wanki Kim",
      "Daewon Ha",
      "Duygu Kuzum",
      "Shimeng Yu",
      "Sourav Dutta",
      "Asif Khan",
      "Tajana Rosing",
      "Mingu Kang"
    ],
    "categories": [
      "cs.AR"
    ],
    "publishedAt": "2025-10-13T00:40:25.000Z",
    "updatedAt": "2025-10-13T00:40:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10872v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10872v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10870v1",
    "arxivId": "2510.10870v1",
    "title": "Transfer Learning with Distance Covariance for Random Forest: Error Bounds and an EHR Application",
    "abstract": "Random forest is an important method for ML applications due to its broad outperformance over competing methods for structured tabular data. We propose a method for transfer learning in nonparametric regression using a centered random forest (CRF) with distance covariance-based feature weights, assuming the unknown source and target regression functions are different for a few features (sparsely different). Our method first obtains residuals from predicting the response in the target domain using a source domain-trained CRF. Then, we fit another CRF to the residuals, but with feature splitting probabilities proportional to the sample distance covariance between the features and the residuals in an independent sample. We derive an upper bound on the mean square error rate of the procedure as a function of sample sizes and difference dimension, theoretically demonstrating transfer learning benefits in random forests. In simulations, we show that the results obtained for the CRFs also hold numerically for the standard random forest (SRF) method with data-driven feature split selection. Beyond transfer learning, our results also show the benefit of distance-covariance-based weights on the performance of RF in some situations. Our method shows significant gains in predicting the mortality of ICU patients in smaller-bed target hospitals using a large multi-hospital dataset of electronic health records for 200,000 ICU patients.",
    "authors": [
      "Chenze Li",
      "Subhadeep Paul"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "publishedAt": "2025-10-13T00:31:56.000Z",
    "updatedAt": "2025-10-13T00:31:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10870v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10870v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10869v1",
    "arxivId": "2510.10869v1",
    "title": "A note on the distinct distances problem over finite fields",
    "abstract": "We study a finite-field analogue of the Erd\\H{o}s distinct distances problem under the Hamming metric. For a set \\(S\\subseteq \\mathbb{F}_q^n\\) let $\\Delta(S)$ denote the set of Hamming distances determined by \\(S\\). We prove the lower bound \\[ |\\Delta(S)| \\;\\ge\\; \\frac{\\log |S|}{2\\log(2nq)}, \\] and show this bound is tight when \\(|S|=O(\\text{poly}(n))\\), where the constant of proportionality depends only on $q$. We then also study the problem of finding a large \\emph{rainbow set}, that is, a subset \\(S\\subseteq \\mathbb{F}_q^n\\) for which all \\(\\binom{|S|}{2}\\) pairwise Hamming distances spanned by $S$ are distinct. In contrast to the Euclidean setting, we show that a set with many distinct distances does not imply the existence of a large rainbow set, by giving an explicit construction. Nevertheless, we establish the existence of large rainbow sets, and prove that every large set in \\(\\mathbb{F}_q^n\\) necessarily contains a non-trivial rainbow subset.",
    "authors": [
      "Nataly Brukhim",
      "Ariel Bruner",
      "Orit E. Raz"
    ],
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "publishedAt": "2025-10-13T00:28:54.000Z",
    "updatedAt": "2025-10-13T00:28:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10869v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10869v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10868v1",
    "arxivId": "2510.10868v1",
    "title": "FastHMR: Accelerating Human Mesh Recovery via Token and Layer Merging with Diffusion Decoding",
    "abstract": "Recent transformer-based models for 3D Human Mesh Recovery (HMR) have achieved strong performance but often suffer from high computational cost and complexity due to deep transformer architectures and redundant tokens. In this paper, we introduce two HMR-specific merging strategies: Error-Constrained Layer Merging (ECLM) and Mask-guided Token Merging (Mask-ToMe). ECLM selectively merges transformer layers that have minimal impact on the Mean Per Joint Position Error (MPJPE), while Mask-ToMe focuses on merging background tokens that contribute little to the final prediction. To further address the potential performance drop caused by merging, we propose a diffusion-based decoder that incorporates temporal context and leverages pose priors learned from large-scale motion capture datasets. Experiments across multiple benchmarks demonstrate that our method achieves up to 2.3x speed-up while slightly improving performance over the baseline.",
    "authors": [
      "Soroush Mehraban",
      "Andrea Iaboni",
      "Babak Taati"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-13T00:23:17.000Z",
    "updatedAt": "2025-10-13T00:23:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10868v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10868v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10866v1",
    "arxivId": "2510.10866v1",
    "title": "Quantifying Dataset Similarity to Guide Transfer Learning",
    "abstract": "Transfer learning has become a cornerstone of modern machine learning, as it can empower models by leveraging knowledge from related domains to improve learning effectiveness. However, transferring from poorly aligned data can harm rather than help performance, making it crucial to determine whether the transfer will be beneficial before implementation. This work aims to address this challenge by proposing an innovative metric to measure dataset similarity and provide quantitative guidance on transferability. In the literature, existing methods largely focus on feature distributions while overlooking label information and predictive relationships, potentially missing critical transferability insights. In contrast, our proposed metric, the Cross-Learning Score (CLS), measures dataset similarity through bidirectional generalization performance between domains. We provide a theoretical justification for CLS by establishing its connection to the cosine similarity between the decision boundaries for the target and source datasets. Computationally, CLS is efficient and fast to compute as it bypasses the problem of expensive distribution estimation for high-dimensional problems. We further introduce a general framework that categorizes source datasets into positive, ambiguous, or negative transfer zones based on their CLS relative to the baseline error, enabling informed decisions. Additionally, we extend this approach to encoder-head architectures in deep learning to better reflect modern transfer pipelines. Extensive experiments on diverse synthetic and real-world tasks demonstrate that CLS can reliably predict whether transfer will improve or degrade performance, offering a principled tool for guiding data selection in transfer learning.",
    "authors": [
      "Shudong Sun",
      "Hao Helen Zhang"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "publishedAt": "2025-10-13T00:18:35.000Z",
    "updatedAt": "2025-10-13T00:18:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10866v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10866v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10865v1",
    "arxivId": "2510.10865v1",
    "title": "GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments",
    "abstract": "Robots navigating dynamic, cluttered, and semantically complex environments must integrate perception, symbolic reasoning, and spatial planning to generalize across diverse layouts and object categories. Existing methods often rely on static priors or limited memory, constraining adaptability under partial observability and semantic ambiguity. We present GRIP, Grid-based Relay with Intermediate Planning, a unified, modular framework with three scalable variants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic occupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and LLM-based introspection; and GRIP-R (Real-World), enabling physical robot deployment under perceptual uncertainty. GRIP integrates dynamic 2D grid construction, open-vocabulary object grounding, co-occurrence-aware symbolic planning, and hybrid policy execution using behavioral cloning, D* search, and grid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks show that GRIP achieves up to 9.6% higher success rates and over $2\\times$ improvement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative analyses reveal interpretable symbolic plans in ambiguous scenes. Real-world deployment on a Jetbot further validates GRIP's generalization under sensor noise and environmental variation. These results position GRIP as a robust, scalable, and explainable framework bridging simulation and real-world navigation.",
    "authors": [
      "Ahmed Alanazi",
      "Duy Ho",
      "Yugyung Lee"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9; I.2.8"
    ],
    "publishedAt": "2025-10-13T00:13:37.000Z",
    "updatedAt": "2025-10-13T00:13:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10865v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10865v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10864v1",
    "arxivId": "2510.10864v1",
    "title": "HeroFilter: Adaptive Spectral Graph Filter for Varying Heterophilic Relations",
    "abstract": "Graph heterophily, where connected nodes have different labels, has attracted significant interest recently. Most existing works adopt a simplified approach - using low-pass filters for homophilic graphs and high-pass filters for heterophilic graphs. However, we discover that the relationship between graph heterophily and spectral filters is more complex - the optimal filter response varies across frequency components and does not follow a strict monotonic correlation with heterophily degree. This finding challenges conventional fixed filter designs and suggests the need for adaptive filtering to preserve expressiveness in graph embeddings. Formally, natural questions arise: Given a heterophilic graph G, how and to what extent will the varying heterophily degree of G affect the performance of GNNs? How can we design adaptive filters to fit those varying heterophilic connections? Our theoretical analysis reveals that the average frequency response of GNNs and graph heterophily degree do not follow a strict monotonic correlation, necessitating adaptive graph filters to guarantee good generalization performance. Hence, we propose [METHOD NAME], a simple yet powerful GNN, which extracts information across the heterophily spectrum and combines salient representations through adaptive mixing. [METHOD NAME]'s superior performance achieves up to 9.2% accuracy improvement over leading baselines across homophilic and heterophilic graphs.",
    "authors": [
      "Shuaicheng Zhang",
      "Haohui Wang",
      "Junhong Lin",
      "Xiaojie Guo",
      "Yada Zhu",
      "Si Zhang",
      "Dongqi Fu",
      "Dawei Zhou"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "publishedAt": "2025-10-13T00:12:40.000Z",
    "updatedAt": "2025-10-13T00:12:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10864v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10864v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10862v1",
    "arxivId": "2510.10862v1",
    "title": "A Joint Learning Approach to Hardware Caching and Prefetching",
    "abstract": "Several learned policies have been proposed to replace heuristics for scheduling, caching, and other system components in modern systems. By leveraging diverse features, learning from historical trends, and predicting future behaviors, such models promise to keep pace with ever-increasing workload dynamism and continuous hardware evolution. However, policies trained in isolation may still achieve suboptimal performance when placed together. In this paper, we inspect one such instance in the domain of hardware caching -- for the policies of cache replacement and prefetching. We argue that these two policies are bidirectionally interdependent and make the case for training the two jointly. We propose a joint learning approach based on developing shared representations for the features used by the two policies. We present two approaches to develop these shared representations, one based on a joint encoder and another based on contrastive learning of the embeddings, and demonstrate promising preliminary results for both of these. Finally, we lay down an agenda for future research in this direction.",
    "authors": [
      "Samuel Yuan",
      "Divyanshu Saxena",
      "Jiayi Chen",
      "Nihal Sharma",
      "Aditya Akella"
    ],
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "publishedAt": "2025-10-13T00:11:02.000Z",
    "updatedAt": "2025-10-13T00:11:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10862v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10862v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10859v1",
    "arxivId": "2510.10859v1",
    "title": "Evaluating Earth-Observing Satellite Sampling Effectiveness Using Kullback-Leibler Divergence",
    "abstract": "This work presents an objective, repeatable, automatic, and fast methodology for assessing the representativeness of geophysical variables sampled by Earth-observing satellites. The primary goal is to identify and mitigate potential sampling biases attributed to orbit selection during pre-Phase A mission studies. This methodology supports current incubation activities for a future Planetary Boundary Layer observing system by incorporating a sampling effectiveness measure into a broader architectural study. The study evaluates the effectiveness of 20 satellite configurations for observing convective storm activity in the Southwestern U.S. during the North American Monsoon (NAM) season. The primary design variables are the number of satellites, orbit type (sun-synchronous or inclined), and Local Time of Ascending Node (LTAN). Using Kullback-Leibler (KL) divergence to assess observational representativeness and Kernel Density Estimation (KDE) to estimate probability density functions, the study quantifies the discrepancy between observed and ground truth storm features. Results indicate that a two-satellite sun-synchronous system with an 8:00 PM LTAN, achieved the lowest KL divergence, signifying the most representative observation of storm clusters. In contrast, single-satellite configurations, particularly those with late-night LTANs (e.g., 12:00 AM), demonstrated significantly higher KL divergence. The study concludes that dual-satellite configurations in sun-synchronous orbits with evening LTANs outperform single-satellite and inclined configurations in capturing representative convective storm activity. Keywords: Earth-Observing Satellites; Sampling Effectiveness; Kullback-Leibler Divergence; Observational Representativeness; Monsoon",
    "authors": [
      "Negin Esmaeili",
      "Paul T. Grogan"
    ],
    "categories": [
      "cs.CE"
    ],
    "publishedAt": "2025-10-12T23:53:14.000Z",
    "updatedAt": "2025-10-12T23:53:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10859v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10859v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10858v1",
    "arxivId": "2510.10858v1",
    "title": "DriftBench: Defining and Generating Data and Query Workload Drift for Benchmarking",
    "abstract": "Data and workload drift are key to evaluating database components such as caching, cardinality estimation, indexing, and query optimization. Yet, existing benchmarks are static, offering little to no support for modeling drift. This limitation stems from the lack of clear definitions and tools for generating data and workload drift. Motivated by this gap, we propose a unified taxonomy for data and workload drift, grounded in observations from both academia and industry. Building on this foundation, we introduce DriftBench, a lightweight and extensible framework for generating data and workload drift in benchmark inputs. Together, the taxonomy and DriftBench provide a standardized vocabulary and mechanism for modeling and generating drift in benchmarking. We demonstrate their effectiveness through case studies involving data drift, workload drift, and drift-aware cardinality estimation.",
    "authors": [
      "Guanli Liu",
      "Renata Borovica-Gajic"
    ],
    "categories": [
      "cs.DB"
    ],
    "publishedAt": "2025-10-12T23:46:04.000Z",
    "updatedAt": "2025-10-12T23:46:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10858v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10858v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10856v1",
    "arxivId": "2510.10856v1",
    "title": "Storage Participation in Electricity Markets: Arbitrage and Ancillary Services",
    "abstract": "Electricity storage is used for intertemporal price arbitrage and for ancillary services that balance unforeseen supply and demand fluctuations via frequency regulation. We present an optimization model that computes bids for both arbitrage and frequency regulation and ensures that storage operators can honor their market commitments at all times for all fluctuation signals in an uncertainty set inspired by market rules. This requirement, initially expressed by an infinite number of nonconvex functional constraints, is shown to be equivalent to a finite number of deterministic constraints. The resulting formulation is a mixed-integer bilinear program that admits mixed-integer linear relaxations and restrictions. Empirical tests on European electricity markets show a negligible optimality gap between the relaxation and the restriction. The model can account for intraday trading and, with a solution time of under 5 seconds, may serve as a building block for more complex trading strategies. Such strategies become necessary as battery capacity exceeds the demand for ancillary services. In a backtest from 1 July 2020 through 30 June 2024 joint market participation more than doubles profits and almost halves energy storage output compared to arbitrage alone.",
    "authors": [
      "Dirk Lauinger",
      "Luc Coté",
      "Andy Sun"
    ],
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T23:36:32.000Z",
    "updatedAt": "2025-10-12T23:36:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10856v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10856v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10854v1",
    "arxivId": "2510.10854v1",
    "title": "Discrete State Diffusion Models: A Sample Complexity Perspective",
    "abstract": "Diffusion models have demonstrated remarkable performance in generating high-dimensional samples across domains such as vision, language, and the sciences. Although continuous-state diffusion models have been extensively studied both empirically and theoretically, discrete-state diffusion models, essential for applications involving text, sequences, and combinatorial structures, remain significantly less understood from a theoretical standpoint. In particular, all existing analyses of discrete-state models assume score estimation error bounds without studying sample complexity results. In this work, we present a principled theoretical framework for discrete-state diffusion, providing the first sample complexity bound of $\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$. Our structured decomposition of the score estimation error into statistical, approximation, optimization, and clipping components offers critical insights into how discrete-state models can be trained efficiently. This analysis addresses a fundamental gap in the literature and establishes the theoretical tractability and practical relevance of discrete-state diffusion models.",
    "authors": [
      "Aadithya Srikanth",
      "Mudit Gaur",
      "Vaneet Aggarwal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "publishedAt": "2025-10-12T23:33:46.000Z",
    "updatedAt": "2025-10-12T23:33:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10854v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10854v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10851v1",
    "arxivId": "2510.10851v1",
    "title": "Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion",
    "abstract": "Humanoid locomotion requires not only accurate command tracking for navigation but also compliant responses to external forces during human interaction. Despite significant progress, existing RL approaches mainly emphasize robustness, yielding policies that resist external forces but lack compliance-particularly challenging for inherently unstable humanoids. In this work, we address this by formulating humanoid locomotion as a multi-objective optimization problem that balances command tracking and external force compliance. We introduce a preference-conditioned multi-objective RL (MORL) framework that integrates rigid command following and compliant behaviors within a single omnidirectional locomotion policy. External forces are modeled via velocity-resistance factor for consistent reward design, and training leverages an encoder-decoder structure that infers task-relevant privileged features from deployable observations. We validate our approach in both simulation and real-world experiments on a humanoid robot. Experimental results indicate that our framework not only improves adaptability and convergence over standard pipelines, but also realizes deployable preference-conditioned humanoid locomotion.",
    "authors": [
      "Tingxuan Leng",
      "Yushi Wang",
      "Tinglong Zheng",
      "Changsheng Luo",
      "Mingguo Zhao"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T23:29:03.000Z",
    "updatedAt": "2025-10-12T23:29:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10851v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10851v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10849v1",
    "arxivId": "2510.10849v1",
    "title": "Glance for Context: Learning When to Leverage LLMs for Node-Aware GNN-LLM Fusion",
    "abstract": "Learning on text-attributed graphs has motivated the use of Large Language Models (LLMs) for graph learning. However, most fusion strategies are applied uniformly across all nodes and attain only small overall performance gains. We argue this result stems from aggregate metrics that obscure when LLMs provide benefit, inhibiting actionable signals for new strategies. In this work, we reframe LLM-GNN fusion around nodes where GNNs typically falter. We first show that performance can significantly differ between GNNs and LLMs, with each excelling on distinct structural patterns, such as local homophily. To leverage this finding, we propose GLANCE (GNN with LLM Assistance for Neighbor- and Context-aware Embeddings), a framework that invokes an LLM to refine a GNN's prediction. GLANCE employs a lightweight router that, given inexpensive per-node signals, decides whether to query the LLM. Since the LLM calls are non-differentiable, the router is trained with an advantage-based objective that compares the utility of querying the LLM against relying solely on the GNN. Across multiple benchmarks, GLANCE achieves the best performance balance across node subgroups, achieving significant gains on heterophilous nodes (up to $+13\\%$) while simultaneously achieving top overall performance. Our findings highlight the value of adaptive, node-aware GNN-LLM architectures, where selectively invoking the LLM enables scalable deployment on large graphs without incurring high computational costs.",
    "authors": [
      "Donald Loveland",
      "Yao-An Yang",
      "Danai Koutra"
    ],
    "categories": [
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T23:25:16.000Z",
    "updatedAt": "2025-10-12T23:25:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10849v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10849v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10846v1",
    "arxivId": "2510.10846v1",
    "title": "DUAL-Bench: Measuring Over-Refusal and Robustness in Vision-Language Models",
    "abstract": "As vision-language models become increasingly capable, maintaining a balance between safety and usefulness remains a central challenge. Safety mechanisms, while essential, can backfire, causing over-refusal, where models decline benign requests out of excessive caution. Yet, no existing benchmark has systematically addressed over-refusal in the visual modality. This setting introduces unique challenges, such as dual-use cases where an instruction is harmless, but the accompanying image contains harmful content. Models frequently fail in such scenarios, either refusing too conservatively or completing tasks unsafely, which highlights the need for more fine-grained alignment. The ideal behavior is safe completion, i.e., fulfilling the benign parts of a request while explicitly warning about any potentially harmful elements. To address this, we present DUAL-Bench, the first multimodal benchmark focused on over-refusal and safe completion in VLMs. We evaluated 18 VLMs across 12 hazard categories, with focus on their robustness under semantics-preserving visual perturbations. The results reveal substantial room for improvement: GPT-5-Nano achieves 12.9% safe completion, GPT-5 models average 7.9%, and Qwen models only 3.9%. We hope that DUAL-Bench will foster the development of more nuanced alignment strategies that ensure models remain both safe and useful in complex multimodal settings.",
    "authors": [
      "Kaixuan Ren",
      "Preslav Nakov",
      "Usman Naseem"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T23:21:34.000Z",
    "updatedAt": "2025-10-12T23:21:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10846v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10846v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10843v1",
    "arxivId": "2510.10843v1",
    "title": "Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots",
    "abstract": "This paper presents a method for detecting and localizing contact along robot legs using distributed joint torque sensors and a single hip-mounted force-torque (FT) sensor using a generalized momentum-based observer framework. We designed a low-cost strain-gauge-based joint torque sensor that can be installed on every joint to provide direct torque measurements, eliminating the need for complex friction models and providing more accurate torque readings than estimation based on motor current. Simulation studies on a floating-based 2-DoF robot leg verified that the proposed framework accurately recovers contact force and location along the thigh and shin links. Through a calibration procedure, our torque sensor achieved an average 96.4% accuracy relative to ground truth measurements. Building upon the torque sensor, we performed hardware experiments on a 2-DoF manipulator, which showed sub-centimeter contact localization accuracy and force errors below 0.2 N.",
    "authors": [
      "Jared Grinberg",
      "Yanran Ding"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T23:15:03.000Z",
    "updatedAt": "2025-10-12T23:15:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10843v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10843v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10841v1",
    "arxivId": "2510.10841v1",
    "title": "The Fire We Share",
    "abstract": "The Fire We Share proposes a care-centered, consequence-aware visualization framework for engaging with wildfire data not as static metrics, but as living archives of ecological and social entanglement. By combining plants-inspired data forms, event-based mapping, and narrative layering, the project foregrounds fire as a shared temporal condition-one that cuts across natural cycles and human systems. Rather than simplifying wildfire data into digestible visuals, The Fire We Share reimagines it as a textured, wounded archive-embodied, relational, and radically ethical.",
    "authors": [
      "Chen Wang",
      "Mengtan Lin"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-12T23:07:48.000Z",
    "updatedAt": "2025-10-12T23:07:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10841v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10841v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10840v1",
    "arxivId": "2510.10840v1",
    "title": "Software Defect Prediction using Autoencoder Transformer Model",
    "abstract": "An AI-ML-powered quality engineering approach uses AI-ML to enhance software quality assessments by predicting defects. Existing ML models struggle with noisy data types, imbalances, pattern recognition, feature extraction, and generalization. To address these challenges, we develop a new model, Adaptive Differential Evolution (ADE) based Quantum Variational Autoencoder-Transformer (QVAET) Model (ADE-QVAET). ADE combines with QVAET to obtain high-dimensional latent features and maintain sequential dependencies, resulting in enhanced defect prediction accuracy. ADE optimization enhances model convergence and predictive performance. ADE-QVAET integrates AI-ML techniques such as tuning hyperparameters for scalable and accurate software defect prediction, representing an AI-ML-driven technology for quality engineering. During training with a 90% training percentage, ADE-QVAET achieves high accuracy, precision, recall, and F1-score of 98.08%, 92.45%, 94.67%, and 98.12%, respectively, when compared to the Differential Evolution (DE) ML model.",
    "authors": [
      "Seshu Barma",
      "Mohanakrishnan Hariharan",
      "Satish Arvapalli"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T23:03:50.000Z",
    "updatedAt": "2025-10-12T23:03:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10840v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10840v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10834v1",
    "arxivId": "2510.10834v1",
    "title": "The Tribonacci constant and finite automata",
    "abstract": "We show that there is no automaton accepting the Tribonacci representations of $n$ and $x$ in parallel, where $\\psi = 1.839\\cdots$ is the Tribonacci constant, and $x= \\lfloor n \\psi \\rfloor$. Similarly, there is no Tribonacci automaton generating the Sturmian characteristic word with slope $\\psi-1$.",
    "authors": [
      "Jeffrey Shallit"
    ],
    "categories": [
      "cs.FL",
      "cs.DM",
      "math.NT"
    ],
    "publishedAt": "2025-10-12T22:55:49.000Z",
    "updatedAt": "2025-10-12T22:55:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10834v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10834v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10833v1",
    "arxivId": "2510.10833v1",
    "title": "FIDRS: A Novel Framework for Integrated Distributed Reliable Systems",
    "abstract": "In this paper we represent a new framework for integrated distributed and reliable systems. In the proposed framework we have used three parts to increase Satisfaction and Performance of this framework. At first we analyze previous frameworks related to integrated systems, then represent new proposed framework in order to improving previous framework, and we discuss its different phases. Finally we compare the results of simulation of the new framework with previous ones. In FIDRS framework, the technique of heterogeneous distributed data base is used to improve Performance and speed in responding to users and in this way we can improve dependability and reliability of framework simultaneously. In extraction phase of the new framework we have used RMSD algorithm that decreases responding time in big database. Finally by using FDIRS framework we succeeded to increase Efficiency, Performance and reliability of integrated systems and remove some of previous frameworks problems.",
    "authors": [
      "Mehdi Zekriyapanah Gashti"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-12T22:50:05.000Z",
    "updatedAt": "2025-10-12T22:50:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10833v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10833v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10830v1",
    "arxivId": "2510.10830v1",
    "title": "Fast and the Furious: Hot Starts in Pursuit-Evasion Games",
    "abstract": "Effectively positioning pursuers in pursuit-evasion games without prior knowledge of evader locations remains a significant challenge. A novel approach that combines game-theoretic control theory with Graph Neural Networks is introduced in this work. By conceptualizing pursuer configurations as strategic arrangements and representing them as graphs, a Graph Characteristic Space is constructed via multi-objective optimization to identify Pareto-optimal configurations. A Graph Convolutional Network (GCN) is trained on these Pareto-optimal graphs to generate strategically effective initial configurations, termed \"hot starts\". Empirical evaluations demonstrate that the GCN-generated hot starts provide a significant advantage over random configurations. In scenarios considering multiple pursuers and evaders, this method hastens the decline in evader survival rates, reduces pursuer travel distances, and enhances containment, showcasing clear strategic benefits.",
    "authors": [
      "Gabriel Smithline",
      "Scott Nivison"
    ],
    "categories": [
      "cs.MA",
      "cs.GT",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T22:46:50.000Z",
    "updatedAt": "2025-10-12T22:46:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10830v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10830v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10829v1",
    "arxivId": "2510.10829v1",
    "title": "Existence and numerical approximation of a one-dimensional Boussinesq system with variable coefficients on a finite interval",
    "abstract": "In this paper, we investigate the well-posedness of a nonlinear dispersive model with variable coefficients that describes the evolution of surface waves propagating through a one-dimensional shallow water channel of finite length with irregular bottom topography. To complement the theoretical analysis, we utilize the numerical solver developed by the authors in \\cite{PizoMunoz} to approximate solutions of the model on a finite spatial interval, considering various parameter values and forms of the variable coefficients in the Boussinesq system under study. Additionally, we present preliminary numerical experiments addressing an inverse problem: the reconstruction of the initial wave elevation and fluid velocity from measurements taken at a final time. This is achieved by formulating an optimization problem in which the initial conditions are estimated as minimizers of a functional that quantifies the discrepancy between the observed final state and the numerical solution evolved from a trial initial state.",
    "authors": [
      "Juan Carlos Muñoz Grajales",
      "Deissy Marcela Pizo"
    ],
    "categories": [
      "math.NA",
      "cs.NA",
      "math.AP"
    ],
    "publishedAt": "2025-10-12T22:45:26.000Z",
    "updatedAt": "2025-10-12T22:45:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10829v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10829v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10828v1",
    "arxivId": "2510.10828v1",
    "title": "VeritasFi: An Adaptable, Multi-tiered RAG Framework for Multi-modal Financial Question Answering",
    "abstract": "Retrieval-Augmented Generation (RAG) is becoming increasingly essential for Question Answering (QA) in the financial sector, where accurate and contextually grounded insights from complex public disclosures are crucial. However, existing financial RAG systems face two significant challenges: (1) they struggle to process heterogeneous data formats, such as text, tables, and figures; and (2) they encounter difficulties in balancing general-domain applicability with company-specific adaptation. To overcome these challenges, we present VeritasFi, an innovative hybrid RAG framework that incorporates a multi-modal preprocessing pipeline alongside a cutting-edge two-stage training strategy for its re-ranking component. VeritasFi enhances financial QA through three key innovations: (1) A multi-modal preprocessing pipeline that seamlessly transforms heterogeneous data into a coherent, machine-readable format. (2) A tripartite hybrid retrieval engine that operates in parallel, combining deep multi-path retrieval over a semantically indexed document corpus, real-time data acquisition through tool utilization, and an expert-curated memory bank for high-frequency questions, ensuring comprehensive scope, accuracy, and efficiency. (3) A two-stage training strategy for the document re-ranker, which initially constructs a general, domain-specific model using anonymized data, followed by rapid fine-tuning on company-specific data for targeted applications. By integrating our proposed designs, VeritasFi presents a groundbreaking framework that greatly enhances the adaptability and robustness of financial RAG systems, providing a scalable solution for both general-domain and company-specific QA tasks. Code accompanying this work is available at https://github.com/simplew4y/VeritasFi.git.",
    "authors": [
      "Zhenghan Tai",
      "Hanwei Wu",
      "Qingchen Hu",
      "Jijun Chi",
      "Hailin He",
      "Lei Ding",
      "Tung Sum Thomas Kwok",
      "Bohuai Xiao",
      "Yuchen Hua",
      "Suyuchen Wang",
      "Peng Lu",
      "Muzhi Li",
      "Yihong Wu",
      "Liheng Ma",
      "Jerry Huang",
      "Jiayi Zhang",
      "Gonghao Zhang",
      "Chaolong Jiang",
      "Jingrui Tian",
      "Sicheng Lyu",
      "Zeyu Li",
      "Boyu Han",
      "Fengran Mo",
      "Xinyue Yu",
      "Yufei Cui",
      "Ling Zhou",
      "Xinyu Wang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T22:45:24.000Z",
    "updatedAt": "2025-10-12T22:45:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10828v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10828v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10827v1",
    "arxivId": "2510.10827v1",
    "title": "Happiness is Sharing a Vocabulary: A Study of Transliteration Methods",
    "abstract": "Transliteration has emerged as a promising means to bridge the gap between various languages in multilingual NLP, showing promising results especially for languages using non-Latin scripts. We investigate the degree to which shared script, overlapping token vocabularies, and shared phonology contribute to performance of multilingual models. To this end, we conduct controlled experiments using three kinds of transliteration (romanization, phonemic transcription, and substitution ciphers) as well as orthography. We evaluate each model on two downstream tasks -- named entity recognition (NER) and natural language inference (NLI) -- and find that romanization significantly outperforms other input types in 7 out of 8 evaluation settings, largely consistent with our hypothesis that it is the most effective approach. We further analyze how each factor contributed to the success, and suggest that having longer (subword) tokens shared with pre-trained languages leads to better utilization of the model.",
    "authors": [
      "Haeji Jung",
      "Jinju Kim",
      "Kyungjin Kim",
      "Youjeong Roh",
      "David R. Mortensen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T22:34:40.000Z",
    "updatedAt": "2025-10-12T22:34:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10827v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10827v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10824v1",
    "arxivId": "2510.10824v1",
    "title": "Agentic RAG for Software Testing with Hybrid Vector-Graph and Multi-Agent Orchestration",
    "abstract": "We present an approach to software testing automation using Agentic Retrieval-Augmented Generation (RAG) systems for Quality Engineering (QE) artifact creation. We combine autonomous AI agents with hybrid vector-graph knowledge systems to automate test plan, case, and QE metric generation. Our approach addresses traditional software testing limitations by leveraging LLMs such as Gemini and Mistral, multi-agent orchestration, and enhanced contextualization. The system achieves remarkable accuracy improvements from 65% to 94.8% while ensuring comprehensive document traceability throughout the quality engineering lifecycle. Experimental validation of enterprise Corporate Systems Engineering and SAP migration projects demonstrates an 85% reduction in testing timeline, an 85% improvement in test suite efficiency, and projected 35% cost savings, resulting in a 2-month acceleration of go-live.",
    "authors": [
      "Mohanakrishnan Hariharan",
      "Satish Arvapalli",
      "Seshu Barma",
      "Evangeline Sheela"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T22:25:15.000Z",
    "updatedAt": "2025-10-12T22:25:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10824v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10824v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10823v1",
    "arxivId": "2510.10823v1",
    "title": "The Irrational Machine: Neurosis and the Limits of Algorithmic Safety",
    "abstract": "We present a framework for characterizing neurosis in embodied AI: behaviors that are internally coherent yet misaligned with reality, arising from interactions among planning, uncertainty handling, and aversive memory. In a grid navigation stack we catalogue recurrent modalities including flip-flop, plan churn, perseveration loops, paralysis and hypervigilance, futile search, belief incoherence, tie break thrashing, corridor thrashing, optimality compulsion, metric mismatch, policy oscillation, and limited-visibility variants. For each we give lightweight online detectors and reusable escape policies (short commitments, a margin to switch, smoothing, principled arbitration). We then show that durable phobic avoidance can persist even under full visibility when learned aversive costs dominate local choice, producing long detours despite globally safe routes. Using First/Second/Third Law as engineering shorthand for safety latency, command compliance, and resource efficiency, we argue that local fixes are insufficient; global failures can remain. To surface them, we propose genetic-programming based destructive testing that evolves worlds and perturbations to maximize law pressure and neurosis scores, yielding adversarial curricula and counterfactual traces that expose where architectural revision, not merely symptom-level patches, is required.",
    "authors": [
      "Daniel Howard"
    ],
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T22:22:17.000Z",
    "updatedAt": "2025-10-12T22:22:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10823v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10823v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10822v1",
    "arxivId": "2510.10822v1",
    "title": "From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis",
    "abstract": "Deep learning models have shown promise in improving diagnostic accuracy from chest X-rays, but they also risk perpetuating healthcare disparities when performance varies across demographic groups. In this work, we present a comprehensive bias detection and mitigation framework targeting sex, age, and race-based disparities when performing diagnostic tasks with chest X-rays. We extend a recent CNN-XGBoost pipeline to support multi-label classification and evaluate its performance across four medical conditions. We show that replacing the final layer of CNN with an eXtreme Gradient Boosting classifier improves the fairness of the subgroup while maintaining or improving the overall predictive performance. To validate its generalizability, we apply the method to different backbones, namely DenseNet-121 and ResNet-50, and achieve similarly strong performance and fairness outcomes, confirming its model-agnostic design. We further compare this lightweight adapter training method with traditional full-model training bias mitigation techniques, including adversarial training, reweighting, data augmentation, and active learning, and find that our approach offers competitive or superior bias reduction at a fraction of the computational cost. Finally, we show that combining eXtreme Gradient Boosting retraining with active learning yields the largest reduction in bias across all demographic subgroups, both in and out of distribution on the CheXpert and MIMIC datasets, establishing a practical and effective path toward equitable deep learning deployment in clinical radiology.",
    "authors": [
      "Clemence Mottez",
      "Louisa Fay",
      "Maya Varma",
      "Sophie Ostmeier",
      "Curtis Langlotz"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T22:20:08.000Z",
    "updatedAt": "2025-10-12T22:20:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10822v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10822v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10820v1",
    "arxivId": "2510.10820v1",
    "title": "Structured identification of multivariable modal systems",
    "abstract": "Physically interpretable models are essential for next-generation industrial systems, as these representations enable effective control, support design validation, and provide a foundation for monitoring strategies. The aim of this paper is to develop a system identification framework for estimating modal models of complex multivariable mechanical systems from frequency response data. To achieve this, a two-step structured identification algorithm is presented, where an additive model is first estimated using a refined instrumental variable method and subsequently projected onto a modal form. The developed identification method provides accurate, physically-relevant, minimal-order models, for both generally-damped and proportionally damped modal systems. The effectiveness of the proposed method is demonstrated through experimental validation on a prototype wafer-stage system, which features a large number of spatially distributed actuators and sensors and exhibits complex flexible dynamics.",
    "authors": [
      "Maarten van der Hulst",
      "Rodrigo A. González",
      "Koen Classens",
      "Paul Tacx",
      "Nick Dirkx",
      "Jeroen van de Wijdeven",
      "Tom Oomen"
    ],
    "categories": [
      "eess.SY",
      "cs.SY",
      "eess.SP"
    ],
    "publishedAt": "2025-10-12T22:06:16.000Z",
    "updatedAt": "2025-10-12T22:06:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10820v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10820v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10819v1",
    "arxivId": "2510.10819v1",
    "title": "Generative AI and the Transformation of Software Development Practices",
    "abstract": "Generative AI is reshaping how software is designed, written, and maintained. Advances in large language models (LLMs) are enabling new development styles - from chat-oriented programming and 'vibe coding' to agentic programming - that can accelerate productivity and broaden access. This paper examines how AI-assisted techniques are changing software engineering practice, and the related issues of trust, accountability, and shifting skills. We survey iterative chat-based development, multi-agent systems, dynamic prompt orchestration, and integration via the Model Context Protocol (MCP). Using case studies and industry data, we outline both the opportunities (faster cycles, democratized coding) and the challenges (model reliability and cost) of applying generative AI to coding. We describe new roles, skills, and best practices for using AI in a responsible and effective way.",
    "authors": [
      "Vivek Acharya"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "68N01, 68T05, 68T07, 68T50",
      "D.2.2; D.2.5; D.2.6; D.2.8; I.2.6; I.2.7; I.2.11"
    ],
    "publishedAt": "2025-10-12T22:02:10.000Z",
    "updatedAt": "2025-10-12T22:02:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10819v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10819v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10818v1",
    "arxivId": "2510.10818v1",
    "title": "Fair Kernel-Lock-Free Claim/Release Protocol for Shared Object Access in Cooperatively Scheduled Runtimes",
    "abstract": "We present the first spin-free, kernel-lock-free mutex that cooperates with user-mode schedulers and is formally proven FIFO-fair and linearizable using CSP/FDR. Our fairness oracle and stability-based proof method are reusable across coroutine runtime designs. We designed the claim/release protocol for a process-oriented language -- ProcessJ -- to manage the race for claiming shared inter-process communication channels. Internally, we use a lock-free queue to park waiting processes for gaining access to a shared object, such as exclusive access to a shared channel to read from or write to. The queue ensures control and fairness for processes wishing to access a shared resource, as the protocol handles claim requests in the order they are inserted into the queue. We produce CSP models of our protocol and a mutex specification, demonstrating with FDR that our protocol behaves as a locking mutex.",
    "authors": [
      "Kevin Chalmers",
      "Jan Bækgaard Pedersen"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-12T21:58:52.000Z",
    "updatedAt": "2025-10-12T21:58:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10818v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10818v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10815v1",
    "arxivId": "2510.10815v1",
    "title": "DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems",
    "abstract": "Automating the formalization of mathematical statements for theorem proving remains a major challenge for Large Language Models (LLMs). LLMs struggle to identify and utilize the prerequisite mathematical knowledge and its corresponding formal representation in languages like Lean. Current retrieval-augmented autoformalization methods query external libraries using the informal statement directly, but overlook a fundamental limitation: informal mathematical statements are often complex and offer limited context on the underlying math concepts. To address this, we introduce DRIFT, a novel framework that enables LLMs to decompose informal mathematical statements into smaller, more tractable ''sub-components''. This facilitates targeted retrieval of premises from mathematical libraries such as Mathlib. Additionally, DRIFT retrieves illustrative theorems to help models use premises more effectively in formalization tasks. We evaluate DRIFT across diverse benchmarks (ProofNet, ConNF, and MiniF2F-test) and find that it consistently improves premise retrieval, nearly doubling the F1 score compared to the DPR baseline on ProofNet. Notably, DRIFT demonstrates strong performance on the out-of-distribution ConNF benchmark, with BEq+@10 improvements of 37.14% and 42.25% using GPT-4.1 and DeepSeek-V3.1, respectively. Our analysis shows that retrieval effectiveness in mathematical autoformalization depends heavily on model-specific knowledge boundaries, highlighting the need for adaptive retrieval strategies aligned with each model's capabilities.",
    "authors": [
      "Meiru Zhang",
      "Philipp Borchert",
      "Milan Gritta",
      "Gerasimos Lampouras"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.SC"
    ],
    "publishedAt": "2025-10-12T21:42:04.000Z",
    "updatedAt": "2025-10-12T21:42:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10815v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10815v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10813v1",
    "arxivId": "2510.10813v1",
    "title": "LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent Heuristics",
    "abstract": "Large Language Models (LLMs) are increasingly applied to domains that require reasoning about other agents' behavior, such as negotiation, policy design, and market simulation, yet existing research has mostly evaluated their adherence to equilibrium play or their exhibited depth of reasoning. Whether they display genuine strategic thinking, understood as the coherent formation of beliefs about other agents, evaluation of possible actions, and choice based on those beliefs, remains unexplored. We develop a framework to identify this ability by disentangling beliefs, evaluation, and choice in static, complete-information games, and apply it across a series of non-cooperative environments. By jointly analyzing models' revealed choices and reasoning traces, and introducing a new context-free game to rule out imitation from memorization, we show that current frontier models exhibit belief-coherent best-response behavior at targeted reasoning depths. When unconstrained, they self-limit their depth of reasoning and form differentiated conjectures about human and synthetic opponents, revealing an emergent form of meta-reasoning. Under increasing complexity, explicit recursion gives way to internally generated heuristic rules of choice that are stable, model-specific, and distinct from known human biases. These findings indicate that belief coherence, meta-reasoning, and novel heuristic formation can emerge jointly from language modeling objectives, providing a structured basis for the study of strategic cognition in artificial agents.",
    "authors": [
      "Enric Junque de Fortuny",
      "Veronica Roberta Cappelli"
    ],
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "publishedAt": "2025-10-12T21:40:29.000Z",
    "updatedAt": "2025-10-12T21:40:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10813v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10813v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10810v1",
    "arxivId": "2510.10810v1",
    "title": "Aegis: A Correlation-Based Data Masking Advisor for Data Sharing Ecosystems",
    "abstract": "Data-sharing ecosystems enable entities -- such as providers, consumers, and intermediaries -- to access, exchange, and utilize data for various downstream tasks and applications. Due to privacy concerns, data providers typically anonymize datasets before sharing them; however, the existence of multiple masking configurations results in masked datasets with varying utility. Consequently, a key challenge lies in efficiently determining the optimal masking configuration that maximizes a dataset's utility. This paper presents AEGIS, a middleware framework for identifying the optimal masking configuration for machine learning datasets that consist of features and a class label. We introduce a utility optimizer that minimizes predictive utility deviation -- a metric based on the changes in feature-label correlations before and after masking. Our framework leverages limited data summaries (such as 1D histograms) or none to estimate the feature-label joint distribution, making it suitable for scenarios where raw data is inaccessible due to privacy restrictions. To achieve this, we propose a joint distribution estimator based on iterative proportional fitting, which allows supporting various feature-label correlation quantification methods such as g3, mutual information, or chi-square. Our experimental evaluation on real-world datasets shows that AEGIS identifies optimal masking configurations over an order of magnitude faster, while the resulting masked datasets achieve predictive performance on downstream ML tasks that is on par with baseline approaches.",
    "authors": [
      "Omar Islam Laskar",
      "Fatemeh Ramezani Khozestani",
      "Ishika Nankani",
      "Sohrab Namazi Nia",
      "Senjuti Basu Roy",
      "Kaustubh Beedkar"
    ],
    "categories": [
      "cs.LG",
      "cs.DB"
    ],
    "publishedAt": "2025-10-12T21:16:43.000Z",
    "updatedAt": "2025-10-12T21:16:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10810v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10810v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10806v1",
    "arxivId": "2510.10806v1",
    "title": "Is Implicit Knowledge Enough for LLMs? A RAG Approach for Tree-based Structures",
    "abstract": "Large Language Models (LLMs) are adept at generating responses based on information within their context. While this ability is useful for interacting with structured data like code files, another popular method, Retrieval-Augmented Generation (RAG), retrieves relevant documents to augment the model's in-context learning. However, it is not well-explored how to best represent this retrieved knowledge for generating responses on structured data, particularly hierarchical structures like trees. In this work, we propose a novel bottom-up method to linearize knowledge from tree-like structures (like a GitHub repository) by generating implicit, aggregated summaries at each hierarchical level. This approach enables the knowledge to be stored in a knowledge base and used directly with RAG. We then compare our method to using RAG on raw, unstructured code, evaluating the accuracy and quality of the generated responses. Our results show that while response quality is comparable across both methods, our approach generates over 68% fewer documents in the retriever, a significant gain in efficiency. This finding suggests that leveraging implicit, linearized knowledge may be a highly effective and scalable strategy for handling complex, hierarchical data structures.",
    "authors": [
      "Mihir Gupte",
      "Paolo Giusto",
      "Ramesh S"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T20:52:43.000Z",
    "updatedAt": "2025-10-12T20:52:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10806v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10806v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10805v1",
    "arxivId": "2510.10805v1",
    "title": "Therapeutic AI and the Hidden Risks of Over-Disclosure: An Embedded AI-Literacy Framework for Mental Health Privacy",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in mental health contexts, from structured therapeutic support tools to informal chat-based well-being assistants. While these systems increase accessibility, scalability, and personalization, their integration into mental health care brings privacy and safety challenges that have not been well-examined. Unlike traditional clinical interactions, LLM-mediated therapy often lacks a clear structure for what information is collected, how it is processed, and how it is stored or reused. Users without clinical guidance may over-disclose personal information, which is sometimes irrelevant to their presenting concern, due to misplaced trust, lack of awareness of data risks, or the conversational design of the system. This overexposure raises privacy concerns and also increases the potential for LLM bias, misinterpretation, and long-term data misuse. We propose a framework embedding Artificial Intelligence (AI) literacy interventions directly into mental health conversational systems, and outline a study plan to evaluate their impact on disclosure safety, trust, and user experience.",
    "authors": [
      "Soraya S. Anvari",
      "Rina R. Wehbe"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T20:50:06.000Z",
    "updatedAt": "2025-10-12T20:50:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10805v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10805v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10804v1",
    "arxivId": "2510.10804v1",
    "title": "Representing Data in Robotic Tactile Perception -- A Review",
    "abstract": "Robotic tactile perception is a complex process involving several computational steps performed at different levels. Tactile information is shaped by the interplay of robot actions, the mechanical properties of its body, and the software that processes the data. In this respect, high-level computation, required to process and extract information, is commonly performed by adapting existing techniques from other domains, such as computer vision, which expects input data to be properly structured. Therefore, it is necessary to transform tactile sensor data to match a specific data structure. This operation directly affects the tactile information encoded and, as a consequence, the task execution. This survey aims to address this specific aspect of the tactile perception pipeline, namely Data Representation. The paper first clearly defines its contributions to the perception pipeline and then reviews how previous studies have dealt with the problem of representing tactile information, investigating the relationships among hardware, representations, and high-level computation methods. The analysis has led to the identification of six structures commonly used in the literature to represent data. The manuscript provides discussions and guidelines for properly selecting a representation depending on operating conditions, including the available hardware, the tactile information required to be encoded, and the task at hand.",
    "authors": [
      "Alessandro Albini",
      "Mohsen Kaboli",
      "Giorgio Cannata",
      "Perla Maiolino"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T20:48:35.000Z",
    "updatedAt": "2025-10-12T20:48:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10804v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10804v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10802v1",
    "arxivId": "2510.10802v1",
    "title": "MSCloudCAM: Cross-Attention with Multi-Scale Context for Multispectral Cloud Segmentation",
    "abstract": "Clouds remain a critical challenge in optical satellite imagery, hindering reliable analysis for environmental monitoring, land cover mapping, and climate research. To overcome this, we propose MSCloudCAM, a Cross-Attention with Multi-Scale Context Network tailored for multispectral and multi-sensor cloud segmentation. Our framework exploits the spectral richness of Sentinel-2 (CloudSEN12) and Landsat-8 (L8Biome) data to classify four semantic categories: clear sky, thin cloud, thick cloud, and cloud shadow. MSCloudCAM combines a Swin Transformer backbone for hierarchical feature extraction with multi-scale context modules ASPP and PSP for enhanced scale-aware learning. A Cross-Attention block enables effective multisensor and multispectral feature fusion, while the integration of an Efficient Channel Attention Block (ECAB) and a Spatial Attention Module adaptively refine feature representations. Comprehensive experiments on CloudSEN12 and L8Biome demonstrate that MSCloudCAM delivers state-of-the-art segmentation accuracy, surpassing leading baseline architectures while maintaining competitive parameter efficiency and FLOPs. These results underscore the model's effectiveness and practicality, making it well-suited for large-scale Earth observation tasks and real-world applications.",
    "authors": [
      "Md Abdullah Al Mazid",
      "Liangdong Deng",
      "Naphtali Rishe"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "F.2.2, I.2.7"
    ],
    "publishedAt": "2025-10-12T20:40:22.000Z",
    "updatedAt": "2025-10-12T20:40:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10802v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10802v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10803v1",
    "arxivId": "2510.10803v1",
    "title": "PruneGCRN: Minimizing and explaining spatio-temporal problems through node pruning",
    "abstract": "This work addresses the challenge of using a deep learning model to prune graphs and the ability of this method to integrate explainability into spatio-temporal problems through a new approach. Instead of applying explainability to the model's behavior, we seek to gain a better understanding of the problem itself. To this end, we propose a novel model that integrates an optimized pruning mechanism capable of removing nodes from the graph during the training process, rather than doing so as a separate procedure. This integration allows the architecture to learn how to minimize prediction error while selecting the most relevant nodes. Thus, during training, the model searches for the most relevant subset of nodes, obtaining the most important elements of the problem, facilitating its analysis. To evaluate the proposed approach, we used several widely used traffic datasets, comparing the accuracy obtained by pruning with the model and with other methods. The experiments demonstrate that our method is capable of retaining a greater amount of information as the graph reduces in size compared to the other methods used. These results highlight the potential of pruning as a tool for developing models capable of simplifying spatio-temporal problems, thereby obtaining their most important elements.",
    "authors": [
      "Javier García-Sigüenza",
      "Mirco Nanni",
      "Faraón Llorens-Largo",
      "José F. Vicent"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T20:40:22.000Z",
    "updatedAt": "2025-10-12T20:40:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10803v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10803v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10801v1",
    "arxivId": "2510.10801v1",
    "title": "Toward Human-Centered Readability Evaluation",
    "abstract": "Text simplification is essential for making public health information accessible to diverse populations, including those with limited health literacy. However, commonly used evaluation metrics in Natural Language Processing (NLP), such as BLEU, FKGL, and SARI, mainly capture surface-level features and fail to account for human-centered qualities like clarity, trustworthiness, tone, cultural relevance, and actionability. This limitation is particularly critical in high-stakes health contexts, where communication must be not only simple but also usable, respectful, and trustworthy. To address this gap, we propose the Human-Centered Readability Score (HCRS), a five-dimensional evaluation framework grounded in Human-Computer Interaction (HCI) and health communication research. HCRS integrates automatic measures with structured human feedback to capture the relational and contextual aspects of readability. We outline the framework, discuss its integration into participatory evaluation workflows, and present a protocol for empirical validation. This work aims to advance the evaluation of health text simplification beyond surface metrics, enabling NLP systems that align more closely with diverse users' needs, expectations, and lived experiences.",
    "authors": [
      "Bahar İlgen",
      "Georges Hattab"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T20:38:32.000Z",
    "updatedAt": "2025-10-12T20:38:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10801v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10801v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10797v1",
    "arxivId": "2510.10797v1",
    "title": "Full segmentation annotations of 3D time-lapse microscopy images of MDA231 cells",
    "abstract": "High-quality, publicly available segmentation annotations of image and video datasets are critical for advancing the field of image processing. In particular, annotations of volumetric images of a large number of targets are time-consuming and challenging. In (Melnikova, A., & Matula, P., 2025), we presented the first publicly available full 3D time-lapse segmentation annotations of migrating cells with complex dynamic shapes. Concretely, three distinct humans annotated two sequences of MDA231 human breast carcinoma cells (Fluo-C3DL-MDA231) from the Cell Tracking Challenge (CTC). This paper aims to provide a comprehensive description of the dataset and accompanying experiments that were not included in (Melnikova, A., & Matula, P., 2025) due to limitations in publication space. Namely, we show that the created annotations are consistent with the previously published tracking markers provided by the CTC organizers and the segmentation accuracy measured based on the 2D gold truth of CTC is within the inter-annotator variability margins. We compared the created 3D annotations with automatically created silver truth provided by CTC. We have found the proposed annotations better represent the complexity of the input images. The presented annotations can be used for testing and training cell segmentation, or analyzing 3D shapes of highly dynamic objects.",
    "authors": [
      "Aleksandra Melnikova",
      "Petr Matula"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T20:31:40.000Z",
    "updatedAt": "2025-10-12T20:31:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10797v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10797v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10793v1",
    "arxivId": "2510.10793v1",
    "title": "ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling",
    "abstract": "Over the last years, 3D morphable models (3DMMs) have emerged as a state-of-the-art methodology for modeling and generating expressive 3D avatars. However, given their reliance on a strict topology, along with their linear nature, they struggle to represent complex full-head shapes. Following the advent of deep implicit functions, we propose imHead, a novel implicit 3DMM that not only models expressive 3D head avatars but also facilitates localized editing of the facial features. Previous methods directly divided the latent space into local components accompanied by an identity encoding to capture the global shape variations, leading to expensive latent sizes. In contrast, we retain a single compact identity space and introduce an intermediate region-specific latent representation to enable local edits. To train imHead, we curate a large-scale dataset of 4K distinct identities, making a step-towards large scale 3D head modeling. Under a series of experiments we demonstrate the expressive power of the proposed model to represent diverse identities and expressions outperforming previous approaches. Additionally, the proposed approach provides an interpretable solution for 3D face manipulation, allowing the user to make localized edits.",
    "authors": [
      "Rolandos Alexandros Potamias",
      "Stathis Galanakis",
      "Jiankang Deng",
      "Athanasios Papaioannou",
      "Stefanos Zafeiriou"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T20:17:34.000Z",
    "updatedAt": "2025-10-12T20:17:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10793v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10793v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10790v1",
    "arxivId": "2510.10790v1",
    "title": "BioOSS: A Bio-Inspired Oscillatory State System with Spatio-Temporal Dynamics",
    "abstract": "Today's deep learning architectures are primarily based on perceptron models, which do not capture the oscillatory dynamics characteristic of biological neurons. Although oscillatory systems have recently gained attention for their closer resemblance to neural behavior, they still fall short of modeling the intricate spatio-temporal interactions observed in natural neural circuits. In this paper, we propose a bio-inspired oscillatory state system (BioOSS) designed to emulate the wave-like propagation dynamics critical to neural processing, particularly in the prefrontal cortex (PFC), where complex activity patterns emerge. BioOSS comprises two interacting populations of neurons: p neurons, which represent simplified membrane-potential-like units inspired by pyramidal cells in cortical columns, and o neurons, which govern propagation velocities and modulate the lateral spread of activity. Through local interactions, these neurons produce wave-like propagation patterns. The model incorporates trainable parameters for damping and propagation speed, enabling flexible adaptation to task-specific spatio-temporal structures. We evaluate BioOSS on both synthetic and real-world tasks, demonstrating superior performance and enhanced interpretability compared to alternative architectures.",
    "authors": [
      "Zhongju Yuan",
      "Geraint Wiggins",
      "Dick Botteldooren"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T20:12:33.000Z",
    "updatedAt": "2025-10-12T20:12:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10790v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10790v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10787v1",
    "arxivId": "2510.10787v1",
    "title": "Review of Inference-Time Scaling Strategies: Reasoning, Search and RAG",
    "abstract": "The performance gains of LLMs have historically been driven by scaling up model size and training data. However, the rapidly diminishing availability of high-quality training data is introducing a fundamental bottleneck, shifting the focus of research toward inference-time scaling. This paradigm uses additional computation at the time of deployment to substantially improve LLM performance on downstream tasks without costly model re-training. This review systematically surveys the diverse techniques contributing to this new era of inference-time scaling, organizing the rapidly evolving field into two comprehensive perspectives: Output-focused and Input-focused methods. Output-focused techniques encompass complex, multi-step generation strategies, including reasoning (e.g., CoT, ToT, ReAct), various search and decoding methods (e.g., MCTS, beam search), training for long CoT (e.g., RLVR, GRPO), and model ensemble methods. Input-focused techniques are primarily categorized by few-shot and RAG, with RAG as the central focus. The RAG section is further detailed through a structured examination of query expansion, data, retrieval and reranker, LLM generation methods, and multi-modal RAG.",
    "authors": [
      "Zhichao Wang",
      "Cheng Wan",
      "Dong Nie"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T20:09:07.000Z",
    "updatedAt": "2025-10-12T20:09:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10787v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10787v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10785v1",
    "arxivId": "2510.10785v1",
    "title": "FAC-FACodec: Controllable Zero-Shot Foreign Accent Conversion with Factorized Speech Codec",
    "abstract": "Previous accent conversion (AC) methods, including foreign accent conversion (FAC), lack explicit control over the degree of modification. Because accent modification can alter the perceived speaker identity, balancing conversion strength and identity preservation is crucial. We present an AC framework that provides an explicit, user-controllable parameter for accent modification. The method targets pronunciation while preserving suprasegmental cues such as intonation and phoneme durations. Results show performance comparable to recent AC systems, stronger preservation of speaker identity, and unique support for controllable accent conversion.",
    "authors": [
      "Yurii Halychanskyi",
      "Cameron Churchwell",
      "Yutong Wen",
      "Volodymyr Kindratenko"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-12T20:02:14.000Z",
    "updatedAt": "2025-10-12T20:02:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10785v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10785v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10782v1",
    "arxivId": "2510.10782v1",
    "title": "DISC-GAN: Disentangling Style and Content for Cluster-Specific Synthetic Underwater Image Generation",
    "abstract": "In this paper, we propose a novel framework, Disentangled Style-Content GAN (DISC-GAN), which integrates style-content disentanglement with a cluster-specific training strategy towards photorealistic underwater image synthesis. The quality of synthetic underwater images is challenged by optical due to phenomena such as color attenuation and turbidity. These phenomena are represented by distinct stylistic variations across different waterbodies, such as changes in tint and haze. While generative models are well-suited to capture complex patterns, they often lack the ability to model the non-uniform conditions of diverse underwater environments. To address these challenges, we employ K-means clustering to partition a dataset into style-specific domains. We use separate encoders to get latent spaces for style and content; we further integrate these latent representations via Adaptive Instance Normalization (AdaIN) and decode the result to produce the final synthetic image. The model is trained independently on each style cluster to preserve domain-specific characteristics. Our framework demonstrates state-of-the-art performance, obtaining a Structural Similarity Index (SSIM) of 0.9012, an average Peak Signal-to-Noise Ratio (PSNR) of 32.5118 dB, and a Frechet Inception Distance (FID) of 13.3728.",
    "authors": [
      "Sneha Varur",
      "Anirudh R Hanchinamani",
      "Tarun S Bagewadi",
      "Uma Mudenagudi",
      "Chaitra D Desai",
      "Sujata C",
      "Padmashree Desai",
      "Sumit Meharwade"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T19:56:20.000Z",
    "updatedAt": "2025-10-12T19:56:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10782v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10782v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10781v1",
    "arxivId": "2510.10781v1",
    "title": "Two-Layer Voronoi Coverage Control for Hybrid Aerial-Ground Robot Teams in Emergency Response: Implementation and Analysis",
    "abstract": "We present a comprehensive two-layer Voronoi coverage control approach for coordinating hybrid aerial-ground robot teams in hazardous material emergency response scenarios. Traditional Voronoi coverage control methods face three critical limitations in emergency contexts: heterogeneous agent capabilities with vastly different velocities, clustered initial deployment configurations, and urgent time constraints requiring rapid response rather than eventual convergence. Our method addresses these challenges through a decoupled two-layer architecture that separately optimizes aerial and ground robot positioning, with aerial agents delivering ground sensors via airdrop to high-priority locations. We provide detailed implementation of bounded Voronoi cell computation, efficient numerical integration techniques for importance-weighted centroids, and robust control strategies that prevent agent trapping. Simulation results demonstrate an 88% reduction in response time, achieving target sensor coverage (18.5% of initial sensor loss) in 25 seconds compared to 220 seconds for ground-only deployment. Complete implementation code is available at https://github.com/dHutchings/ME292B.",
    "authors": [
      "Douglas Hutchings",
      "Luai Abuelsamen",
      "Karthik Rajgopal"
    ],
    "categories": [
      "cs.RO",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "I.2.9; I.2.11"
    ],
    "publishedAt": "2025-10-12T19:53:40.000Z",
    "updatedAt": "2025-10-12T19:53:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10781v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10781v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10779v1",
    "arxivId": "2510.10779v1",
    "title": "Structured Spectral Graph Learning for Multi-label Abnormality Classification in 3D Chest CT Scans",
    "abstract": "With the growing volume of CT examinations, there is an increasing demand for automated tools such as organ segmentation, abnormality detection, and report generation to support radiologists in managing their clinical workload. Multi-label classification of 3D Chest CT scans remains a critical yet challenging problem due to the complex spatial relationships inherent in volumetric data and the wide variability of abnormalities. Existing methods based on 3D convolutional neural networks struggle to capture long-range dependencies, while Vision Transformers often require extensive pre-training on large-scale, domain-specific datasets to perform competitively. In this work, we propose a 2.5D alternative by introducing a new graph-based framework that represents 3D CT volumes as structured graphs, where axial slice triplets serve as nodes processed through spectral graph convolution, enabling the model to reason over inter-slice dependencies while maintaining complexity compatible with clinical deployment. Our method, trained and evaluated on 3 datasets from independent institutions, achieves strong cross-dataset generalization, and shows competitive performance compared to state-of-the-art visual encoders. We further conduct comprehensive ablation studies to evaluate the impact of various aggregation strategies, edge-weighting schemes, and graph connectivity patterns. Additionally, we demonstrate the broader applicability of our approach through transfer experiments on automated radiology report generation and abdominal CT data.\\\\ This work extends our previous contribution presented at the MICCAI 2025 EMERGE Workshop.",
    "authors": [
      "Theo Di Piazza",
      "Carole Lazarus",
      "Olivier Nempont",
      "Loic Boussel"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T19:49:51.000Z",
    "updatedAt": "2025-10-12T19:49:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10779v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10779v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10778v1",
    "arxivId": "2510.10778v1",
    "title": "Real2USD: Scene Representations in Universal Scene Description Language",
    "abstract": "Large Language Models (LLMs) can help robots reason about abstract task specifications. This requires augmenting classical representations of the environment used by robots with natural language-based priors. There are a number of existing approaches to doing so, but they are tailored to specific tasks, e.g., visual-language models for navigation, language-guided neural radiance fields for mapping, etc. This paper argues that the Universal Scene Description (USD) language is an effective and general representation of geometric, photometric and semantic information in the environment for LLM-based robotics tasks. Our argument is simple: a USD is an XML-based scene graph, readable by LLMs and humans alike, and rich enough to support essentially any task -- Pixar developed this language to store assets, scenes and even movies. We demonstrate a ``Real to USD'' system using a Unitree Go2 quadruped robot carrying LiDAR and a RGB camera that (i) builds an explicit USD representation of indoor environments with diverse objects and challenging settings with lots of glass, and (ii) parses the USD using Google's Gemini to demonstrate scene understanding, complex inferences, and planning. We also study different aspects of this system in simulated warehouse and hospital settings using Nvidia's Issac Sim. Code is available at https://github.com/grasp-lyrl/Real2USD .",
    "authors": [
      "Christopher D. Hsu",
      "Pratik Chaudhari"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T19:43:10.000Z",
    "updatedAt": "2025-10-12T19:43:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10778v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10778v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10776v1",
    "arxivId": "2510.10776v1",
    "title": "HiligayNER: A Baseline Named Entity Recognition Model for Hiligaynon",
    "abstract": "The language of Hiligaynon, spoken predominantly by the people of Panay Island, Negros Occidental, and Soccsksargen in the Philippines, remains underrepresented in language processing research due to the absence of annotated corpora and baseline models. This study introduces HiligayNER, the first publicly available baseline model for the task of Named Entity Recognition (NER) in Hiligaynon. The dataset used to build HiligayNER contains over 8,000 annotated sentences collected from publicly available news articles, social media posts, and literary texts. Two Transformer-based models, mBERT and XLM-RoBERTa, were fine-tuned on this collected corpus to build versions of HiligayNER. Evaluation results show strong performance, with both models achieving over 80% in precision, recall, and F1-score across entity types. Furthermore, cross-lingual evaluation with Cebuano and Tagalog demonstrates promising transferability, suggesting the broader applicability of HiligayNER for multilingual NLP in low-resource settings. This work aims to contribute to language technology development for underrepresented Philippine languages, specifically for Hiligaynon, and support future research in regional language processing.",
    "authors": [
      "James Ald Teves",
      "Ray Daniel Cal",
      "Josh Magdiel Villaluz",
      "Jean Malolos",
      "Mico Magtira",
      "Ramon Rodriguez",
      "Mideth Abisado",
      "Joseph Marvin Imperial"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T19:34:22.000Z",
    "updatedAt": "2025-10-12T19:34:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10776v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10776v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10774v1",
    "arxivId": "2510.10774v1",
    "title": "ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis",
    "abstract": "Persian Language, despite being spoken by over 100 million people worldwide, remains severely underrepresented in high-quality speech corpora, particularly for text-to-speech (TTS) synthesis applications. Existing Persian speech datasets are typically smaller than their English counterparts, which creates a key limitation for developing Persian speech technologies. We address this gap by introducing ParsVoice, the largest Persian speech corpus designed specifically for TTS applications. We created an automated pipeline that transforms raw audiobook content into TTS-ready data, incorporating components such as a BERT-based sentence completion detector, a binary search boundary optimization method for precise audio-text alignment, and multi-dimensional quality assessment frameworks tailored to Persian. The pipeline processes 2,000 audiobooks, yielding 3,526 hours of clean speech, which was further filtered into a 1,804-hour high-quality subset suitable for TTS, featuring more than 470 speakers. ParsVoice is the largest high-quality Persian speech dataset, offering speaker diversity and audio quality comparable to major English corpora. The complete dataset has been made publicly available to accelerate the development of Persian speech technologies and to serve as a template for other low-resource languages. The ParsVoice dataset is publicly available at ParsVoice (https://huggingface.co/datasets/MohammadJRanjbar/ParsVoice).",
    "authors": [
      "Mohammad Javad Ranjbar Kalahroodi",
      "Heshaam Faili",
      "Azadeh Shakery"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T19:33:11.000Z",
    "updatedAt": "2025-10-12T19:33:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10774v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10774v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10767v1",
    "arxivId": "2510.10767v1",
    "title": "Understanding Sampler Stochasticity in Training Diffusion Models for RLHF",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is increasingly used to fine-tune diffusion models, but a key challenge arises from the mismatch between stochastic samplers used during training and deterministic samplers used during inference. In practice, models are fine-tuned using stochastic SDE samplers to encourage exploration, while inference typically relies on deterministic ODE samplers for efficiency and stability. This discrepancy induces a reward gap, raising concerns about whether high-quality outputs can be expected during inference. In this paper, we theoretically characterize this reward gap and provide non-vacuous bounds for general diffusion models, along with sharper convergence rates for Variance Exploding (VE) and Variance Preserving (VP) Gaussian models. Methodologically, we adopt the generalized denoising diffusion implicit models (gDDIM) framework to support arbitrarily high levels of stochasticity, preserving data marginals throughout. Empirically, our findings through large-scale experiments on text-to-image models using denoising diffusion policy optimization (DDPO) and mixed group relative policy optimization (MixGRPO) validate that reward gaps consistently narrow over training, and ODE sampling quality improves when models are updated using higher-stochasticity SDE training.",
    "authors": [
      "Jiayuan Sheng",
      "Hanyang Zhao",
      "Haoxian Chen",
      "David D. Yao",
      "Wenpin Tang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "publishedAt": "2025-10-12T19:08:38.000Z",
    "updatedAt": "2025-10-12T19:08:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10767v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10767v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10766v1",
    "arxivId": "2510.10766v1",
    "title": "GPS Spoofing Attack Detection in Autonomous Vehicles Using Adaptive DBSCAN",
    "abstract": "As autonomous vehicles become an essential component of modern transportation, they are increasingly vulnerable to threats such as GPS spoofing attacks. This study presents an adaptive detection approach utilizing a dynamically tuned Density Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm, designed to adjust the detection threshold ({\\epsilon}) in real-time. The threshold is updated based on the recursive mean and standard deviation of displacement errors between GPS and in-vehicle sensors data, but only at instances classified as non-anomalous. Furthermore, an initial threshold, determined from 120,000 clean data samples, ensures the capability to identify even subtle and gradual GPS spoofing attempts from the beginning. To assess the performance of the proposed method, five different subsets from the real-world Honda Research Institute Driving Dataset (HDD) are selected to simulate both large and small magnitude GPS spoofing attacks. The modified algorithm effectively identifies turn-by-turn, stop, overshoot, and multiple small biased spoofing attacks, achieving detection accuracies of 98.621%, 99.960.1%, 99.880.1%, and 98.380.1%, respectively. This work provides a substantial advancement in enhancing the security and safety of AVs against GPS spoofing threats.",
    "authors": [
      "Ahmad Mohammadi",
      "Reza Ahmari",
      "Vahid Hemmati",
      "Frederick Owusu-Ambrose",
      "Mahmoud Nabil Mahmoud",
      "Parham Kebria",
      "Abdollah Homaifar",
      "Mehrdad Saif"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T19:06:44.000Z",
    "updatedAt": "2025-10-12T19:06:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10766v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10766v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10765v1",
    "arxivId": "2510.10765v1",
    "title": "EGD-YOLO: A Lightweight Multimodal Framework for Robust Drone-Bird Discrimination via Ghost-Enhanced YOLOv8n and EMA Attention under Adverse Condition",
    "abstract": "Identifying drones and birds correctly is essential for keeping the skies safe and improving security systems. Using the VIP CUP 2025 dataset, which provides both RGB and infrared (IR) images, this study presents EGD-YOLOv8n, a new lightweight yet powerful model for object detection. The model improves how image features are captured and understood, making detection more accurate and efficient. It uses smart design changes and attention layers to focus on important details while reducing the amount of computation needed. A special detection head helps the model adapt to objects of different shapes and sizes. We trained three versions: one using RGB images, one using IR images, and one combining both. The combined model achieved the best accuracy and reliability while running fast enough for real-time use on common GPUs.",
    "authors": [
      "Sudipto Sarkar",
      "Mohammad Asif Hasan",
      "Khondokar Ashik Shahriar",
      "Fablia Labiba",
      "Nahian Tasnim",
      "Sheikh Anawarul Haq Fattah"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T19:05:16.000Z",
    "updatedAt": "2025-10-12T19:05:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10765v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10765v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10764v1",
    "arxivId": "2510.10764v1",
    "title": "Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency",
    "abstract": "Deep neural networks (DNNs) have provided brilliant performance across various tasks. However, this success often comes at the cost of unnecessarily large model sizes, high computational demands, and substantial memory footprints. Typically, powerful architectures are trained at full depths but not all datasets or tasks require such high model capacity. Training very deep architectures on relatively low-complexity datasets frequently leads to wasted computation, unnecessary energy consumption, and excessive memory usage, which in turn makes deployment of models on resource-constrained devices impractical. To address this problem, we introduce Optimally Deep Networks (ODNs), which provide a balance between model depth and task complexity. Specifically, we propose a NAS like training strategy called progressive depth expansion, which begins by training deep networks at shallower depths and incrementally increases their depth as the earlier blocks converge, continuing this process until the target accuracy is reached. ODNs use only the optimal depth for the given datasets, removing redundant layers. This cuts down future training and inference costs, lowers the memory footprint, enhances computational efficiency, and facilitates deployment on edge devices. Empirical results show that the optimal depths of ResNet-18 and ResNet-34 for MNIST and SVHN, achieve up to 98.64 % and 96.44 % reduction in memory footprint, while maintaining a competitive accuracy of 99.31 % and 96.08 %, respectively.",
    "authors": [
      "Shaharyar Ahmed Khan Tareen",
      "Filza Khan Tareen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T19:05:04.000Z",
    "updatedAt": "2025-10-12T19:05:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10764v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10764v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10763v1",
    "arxivId": "2510.10763v1",
    "title": "Influence of coronary plaque morphology on local mechanical states and associated in-stent restenosis",
    "abstract": "In-stent restenosis after percutaneous coronary intervention is a multifactorial process. Specific morphological lesion characteristics were observed to contribute to the occurrence of in-stent restenosis. Local mechanical factors, such as stresses and strains, are known to influence tissue adaptation after stent implantation. However, the influence of morphological features on those local mechanical states and, hence, on the occurrence of in-stent restenosis remains understudied. This work investigates the correlation between local mechanical quantities and in-stent restenosis by evaluating the stress distributions in the artery wall during and after stent implantation for informative lesion morphologies. We perform computational simulations of the stenting procedure with physics-based patient-specific coronary artery models. Different morphologies are assessed using the spatial plaque composition information from high-resolution coronary computed tomography angiography data. We quantify the correlation between in-stent restenosis and local tensional stresses. We found that specific morphological characteristics like circumferential or asymmetric block calcifications result in higher stresses in the surrounding tissue. This study concludes that local stresses are critical for assessing the individual in-stent restenosis risk.",
    "authors": [
      "Janina C. Datz",
      "Ivo Steinbrecher",
      "Johannes Krefting",
      "Leif-Christopher Engel",
      "Alexander Popp",
      "Martin R. Pfaller",
      "Heribert Schunkert",
      "Wolfgang A. Wall"
    ],
    "categories": [
      "cs.CE"
    ],
    "publishedAt": "2025-10-12T19:04:25.000Z",
    "updatedAt": "2025-10-12T19:04:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10763v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10763v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10762v1",
    "arxivId": "2510.10762v1",
    "title": "Large Language Models for Full-Text Methods Assessment: A Case Study on Mediation Analysis",
    "abstract": "Systematic reviews are crucial for synthesizing scientific evidence but remain labor-intensive, especially when extracting detailed methodological information. Large language models (LLMs) offer potential for automating methodological assessments, promising to transform evidence synthesis. Here, using causal mediation analysis as a representative methodological domain, we benchmarked state-of-the-art LLMs against expert human reviewers across 180 full-text scientific articles. Model performance closely correlated with human judgments (accuracy correlation 0.71; F1 correlation 0.97), achieving near-human accuracy on straightforward, explicitly stated methodological criteria. However, accuracy sharply declined on complex, inference-intensive assessments, lagging expert reviewers by up to 15%. Errors commonly resulted from superficial linguistic cues -- for instance, models frequently misinterpreted keywords like \"longitudinal\" or \"sensitivity\" as automatic evidence of rigorous methodological approache, leading to systematic misclassifications. Longer documents yielded lower model accuracy, whereas publication year showed no significant effect. Our findings highlight an important pattern for practitioners using LLMs for methods review and synthesis from full texts: current LLMs excel at identifying explicit methodological features but require human oversight for nuanced interpretations. Integrating automated information extraction with targeted expert review thus provides a promising approach to enhance efficiency and methodological rigor in evidence synthesis across diverse scientific fields.",
    "authors": [
      "Wenqing Zhang",
      "Trang Nguyen",
      "Elizabeth A. Stuart",
      "Yiqun T. Chen"
    ],
    "categories": [
      "cs.CL",
      "stat.AP"
    ],
    "publishedAt": "2025-10-12T19:04:22.000Z",
    "updatedAt": "2025-10-12T19:04:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10762v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10762v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10761v1",
    "arxivId": "2510.10761v1",
    "title": "Toxic Ink on Immutable Paper: Content Moderation for Ethereum Input Data Messages (IDMs)",
    "abstract": "Decentralized communication is becoming an important use case within Web3. On Ethereum, users can repurpose the transaction input data field to embed natural-language messages, commonly known as Input Data Messages (IDMs). However, as IDMs gain wider adoption, there has been a growing volume of toxic content on-chain. This trend is concerning, as Ethereum provides no protocol-level support for content moderation. We propose two moderation frameworks for Ethereum IDMs: (i) BUILDERMOD, where builders perform semantic checks during block construction; and (ii) USERMOD, where users proactively obtain moderation proofs from external classifiers and embed them in transactions. Our evaluation reveals that BUILDERMOD incurs high block-time overhead, which limits its practicality. In contrast, USERMOD enables lower-latency validation and scales more effectively, making it a more practical approach in moderation-aware Ethereum environments. Our study lays the groundwork for protocol-level content governance in decentralized systems, and we hope it contributes to the development of a decentralized communication environment that is safe, trustworthy, and socially responsible.",
    "authors": [
      "Xihan Xiong",
      "Zhipeng Wang",
      "Qin Wang",
      "William Knottenbelt"
    ],
    "categories": [
      "cs.CR"
    ],
    "publishedAt": "2025-10-12T19:02:57.000Z",
    "updatedAt": "2025-10-12T19:02:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10761v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10761v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10759v1",
    "arxivId": "2510.10759v1",
    "title": "Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning",
    "abstract": "Existing robot locomotion learning techniques rely heavily on the offline selection of proper reward weighting gains and cannot guarantee constraint satisfaction (i.e., constraint violation) during training. Thus, this work aims to address both issues by proposing Reward-Oriented Gains via Embodied Regulation (ROGER), which adapts reward-weighting gains online based on penalties received throughout the embodied interaction process. The ratio between the positive reward (primary reward) and negative reward (penalty) gains is automatically reduced as the learning approaches the constraint thresholds to avoid violation. Conversely, the ratio is increased when learning is in safe states to prioritize performance. With a 60-kg quadruped robot, ROGER achieved near-zero constraint violation throughout multiple learning trials. It also achieved up to 50% more primary reward than the equivalent state-of-the-art techniques. In MuJoCo continuous locomotion benchmarks, including a single-leg hopper, ROGER exhibited comparable or up to 100% higher performance and 60% less torque usage and orientation deviation compared to those trained with the default reward function. Finally, real-world locomotion learning of a physical quadruped robot was achieved from scratch within one hour without any falls. Therefore, this work contributes to constraint-satisfying real-world continual robot locomotion learning and simplifies reward weighting gain tuning, potentially facilitating the development of physical robots and those that learn in the real world.",
    "authors": [
      "Arthicha Srisuchinnawong",
      "Poramate Manoonpong"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T18:58:59.000Z",
    "updatedAt": "2025-10-12T18:58:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10759v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10759v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10753v1",
    "arxivId": "2510.10753v1",
    "title": "Restricted Receptive Fields for Face Verification",
    "abstract": "Understanding how deep neural networks make decisions is crucial for analyzing their behavior and diagnosing failure cases. In computer vision, a common approach to improve interpretability is to assign importance to individual pixels using post-hoc methods. Although they are widely used to explain black-box models, their fidelity to the model's actual reasoning is uncertain due to the lack of reliable evaluation metrics. This limitation motivates an alternative approach, which is to design models whose decision processes are inherently interpretable. To this end, we propose a face similarity metric that breaks down global similarity into contributions from restricted receptive fields. Our method defines the similarity between two face images as the sum of patch-level similarity scores, providing a locally additive explanation without relying on post-hoc analysis. We show that the proposed approach achieves competitive verification performance even with patches as small as 28x28 within 112x112 face images, and surpasses state-of-the-art methods when using 56x56 patches.",
    "authors": [
      "Kagan Ozturk",
      "Aman Bhatta",
      "Haiyu Wu",
      "Patrick Flynn",
      "Kevin W. Bowyer"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T18:46:56.000Z",
    "updatedAt": "2025-10-12T18:46:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10753v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10753v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10751v1",
    "arxivId": "2510.10751v1",
    "title": "MATStruct: High-Quality Medial Mesh Computation via Structure-aware Variational Optimization",
    "abstract": "We propose a novel optimization framework for computing the medial axis transform that simultaneously preserves the medial structure and ensures high medial mesh quality. The medial structure, consisting of interconnected sheets, seams, and junctions, provides a natural volumetric decomposition of a 3D shape. Our method introduces a structure-aware, particle-based optimization pipeline guided by the restricted power diagram (RPD), which partitions the input volume into convex cells whose dual encodes the connectivity of the medial mesh. Structure-awareness is enforced through a spherical quadratic error metric (SQEM) projection that constrains the movement of medial spheres, while a Gaussian kernel energy encourages an even spatial distribution. Compared to feature-preserving methods such as MATFP and MATTopo, our approach produces cleaner and more accurate medial structures with significantly improved mesh quality. In contrast to voxel-based, point-cloud-based, and variational methods, our framework is the first to integrate structural awareness into the optimization process, yielding medial meshes with superior geometric fidelity, topological correctness, and explicit structural decomposition.",
    "authors": [
      "Ningna Wang",
      "Rui Xu",
      "Yibo Yin",
      "Zichun Zhong",
      "Taku Komura",
      "Wenping Wang",
      "Xiaohu Guo"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-12T18:39:36.000Z",
    "updatedAt": "2025-10-12T18:39:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10751v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10751v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10750v1",
    "arxivId": "2510.10750v1",
    "title": "Uncovering Anomalous Events for Marine Environmental Monitoring via Visual Anomaly Detection",
    "abstract": "Underwater video monitoring is a promising strategy for assessing marine biodiversity, but the vast volume of uneventful footage makes manual inspection highly impractical. In this work, we explore the use of visual anomaly detection (VAD) based on deep neural networks to automatically identify interesting or anomalous events. We introduce AURA, the first multi-annotator benchmark dataset for underwater VAD, and evaluate four VAD models across two marine scenes. We demonstrate the importance of robust frame selection strategies to extract meaningful video segments. Our comparison against multiple annotators reveals that VAD performance of current models varies dramatically and is highly sensitive to both the amount of training data and the variability in visual content that defines \"normal\" scenes. Our results highlight the value of soft and consensus labels and offer a practical approach for supporting scientific exploration and scalable biodiversity monitoring.",
    "authors": [
      "Laura Weihl",
      "Nejc Novak",
      "Stefan H. Bengtson",
      "Malte Pedersen"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T18:39:34.000Z",
    "updatedAt": "2025-10-12T18:39:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10750v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10750v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10747v1",
    "arxivId": "2510.10747v1",
    "title": "CPU-Limits kill Performance: Time to rethink Resource Control",
    "abstract": "Research in compute resource management for cloud-native applications is dominated by the problem of setting optimal CPU limits -- a fundamental OS mechanism that strictly restricts a container's CPU usage to its specified CPU-limits . Rightsizing and autoscaling works have innovated on allocation/scaling policies assuming the ubiquity and necessity of CPU-limits . We question this. Practical experiences of cloud users indicate that CPU-limits harms application performance and costs more than it helps. These observations are in contradiction to the conventional wisdom presented in both academic research and industry best practices. We argue that this indiscriminate adoption of CPU-limits is driven by erroneous beliefs that CPU-limits is essential for operational and safety purposes. We provide empirical evidence making a case for eschewing CPU-limits completely from latency-sensitive applications. This prompts a fundamental rethinking of auto-scaling and billing paradigms and opens new research avenues. Finally, we highlight specific scenarios where CPU-limits can be beneficial if used in a well-reasoned way (e.g. background jobs).",
    "authors": [
      "Chirag Shetty",
      "Sarthak Chakraborty",
      "Hubertus Franke",
      "Larisa Shwartz",
      "Chandra Narayanaswami",
      "Indranil Gupta",
      "Saurabh Jha"
    ],
    "categories": [
      "cs.DC",
      "cs.OS",
      "cs.PF"
    ],
    "publishedAt": "2025-10-12T18:37:11.000Z",
    "updatedAt": "2025-10-12T18:37:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10747v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10747v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10742v1",
    "arxivId": "2510.10742v1",
    "title": "Seeing My Future: Predicting Situated Interaction Behavior in Virtual Reality",
    "abstract": "Virtual and augmented reality systems increasingly demand intelligent adaptation to user behaviors for enhanced interaction experiences. Achieving this requires accurately understanding human intentions and predicting future situated behaviors - such as gaze direction and object interactions - which is vital for creating responsive VR/AR environments and applications like personalized assistants. However, accurate behavioral prediction demands modeling the underlying cognitive processes that drive human-environment interactions. In this work, we introduce a hierarchical, intention-aware framework that models human intentions and predicts detailed situated behaviors by leveraging cognitive mechanisms. Given historical human dynamics and the observation of scene contexts, our framework first identifies potential interaction targets and forecasts fine-grained future behaviors. We propose a dynamic Graph Convolutional Network (GCN) to effectively capture human-environment relationships. Extensive experiments on challenging real-world benchmarks and live VR environment demonstrate the effectiveness of our approach, achieving superior performance across all metrics and enabling practical applications for proactive VR systems that anticipate user behaviors and adapt virtual environments accordingly.",
    "authors": [
      "Yuan Xu",
      "Zimu Zhang",
      "Xiaoxuan Ma",
      "Wentao Zhu",
      "Yu Qiao",
      "Yizhou Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T18:29:01.000Z",
    "updatedAt": "2025-10-12T18:29:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10742v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10742v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10740v1",
    "arxivId": "2510.10740v1",
    "title": "Dual Data Scaling for Robust Two-Stage User-Defined Keyword Spotting",
    "abstract": "In this paper, we propose DS-KWS, a two-stage framework for robust user-defined keyword spotting. It combines a CTC-based method with a streaming phoneme search module to locate candidate segments, followed by a QbyT-based method with a phoneme matcher module for verification at both the phoneme and utterance levels. To further improve performance, we introduce a dual data scaling strategy: (1) expanding the ASR corpus from 460 to 1,460 hours to strengthen the acoustic model; and (2) leveraging over 155k anchor classes to train the phoneme matcher, significantly enhancing the distinction of confusable words. Experiments on LibriPhrase show that DS-KWS significantly outperforms existing methods, achieving 6.13\\% EER and 97.85\\% AUC on the Hard subset. On Hey-Snips, it achieves zero-shot performance comparable to full-shot trained models, reaching 99.13\\% recall at one false alarm per hour.",
    "authors": [
      "Zhiqi Ai",
      "Han Cheng",
      "Yuxin Wang",
      "Shiyi Mu",
      "Shugong Xu",
      "Yongjin Zhou"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-12T18:25:55.000Z",
    "updatedAt": "2025-10-12T18:25:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10740v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10740v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10739v1",
    "arxivId": "2510.10739v1",
    "title": "A Stochastic Differential Equation Framework for Multi-Objective LLM Interactions: Dynamical Systems Analysis with Code Generation Applications",
    "abstract": "We introduce a general stochastic differential equation framework for modelling multiobjective optimization dynamics in iterative Large Language Model (LLM) interactions. Our framework captures the inherent stochasticity of LLM responses through explicit diffusion terms and reveals systematic interference patterns between competing objectives via an interference matrix formulation. We validate our theoretical framework using iterative code generation as a proof-of-concept application, analyzing 400 sessions across security, efficiency, and functionality objectives. Our results demonstrate strategy-dependent convergence behaviors with rates ranging from 0.33 to 1.29, and predictive accuracy achieving R2 = 0.74 for balanced approaches. This work proposes the feasibility of dynamical systems analysis for multi-objective LLM interactions, with code generation serving as an initial validation domain.",
    "authors": [
      "Shivani Shukla",
      "Himanshu Joshi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "publishedAt": "2025-10-12T18:25:12.000Z",
    "updatedAt": "2025-10-12T18:25:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10739v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10739v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10738v1",
    "arxivId": "2510.10738v1",
    "title": "Proficiency-Aware Adaptation and Data Augmentation for Robust L2 ASR",
    "abstract": "General-purpose ASR underperforms for atypical speakers, such as L2 learners, reinforcing bias and limiting use in education and accessibility. Using the CEFR-graded Speak and Improve corpus, we show that naive fine-tuning of Whisper reduces average WER but simultaneously widens disparities and disproportionately harms lower-level learners. To address this, we propose two strategies: (i) proficiency-aware multitask learning, jointly optimizing ASR with proficiency classification, and (ii) targeted augmentation, applying spectrogram masking to low-proficiency speech to counter imbalance. These approaches reduce WER by up to 29.4 percent (relative) and insertion/deletion errors by as much as 58.6 percent (relative). Crucially, despite the severe imbalance of the dataset reflecting real-world distributions, both strategies consistently narrow proficiency gaps, advancing equitable ASR for L2 learners.",
    "authors": [
      "Ling Sun",
      "Charlotte Zhu",
      "Shuju Shi"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "68T07 (Primary), 94A12, 68T05 (Secondary)",
      "I.5.4; I.2.7"
    ],
    "publishedAt": "2025-10-12T18:20:58.000Z",
    "updatedAt": "2025-10-12T18:20:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10738v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10738v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10732v1",
    "arxivId": "2510.10732v1",
    "title": "When Openness Fails: Lessons from System Safety for Assessing Openness in AI",
    "abstract": "Most frameworks for assessing the openness of AI systems use narrow criteria such as availability of data, model, code, documentation, and licensing terms. However, to evaluate whether the intended effects of openness - such as democratization and autonomy - are realized, we need a more holistic approach that considers the context of release: who will reuse the system, for what purposes, and under what conditions. To this end, we adapt five lessons from system safety that offer guidance on how openness can be evaluated at the system level.",
    "authors": [
      "Tamara Paris",
      "Shalaleh Rismani"
    ],
    "categories": [
      "cs.CY"
    ],
    "publishedAt": "2025-10-12T18:08:00.000Z",
    "updatedAt": "2025-10-12T18:08:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10732v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10732v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10731v1",
    "arxivId": "2510.10731v1",
    "title": "Controllable Generative Trajectory Prediction via Weak Preference Alignment",
    "abstract": "Deep generative models such as conditional variational autoencoders (CVAEs) have shown great promise for predicting trajectories of surrounding agents in autonomous vehicle planning. State-of-the-art models have achieved remarkable accuracy in such prediction tasks. Besides accuracy, diversity is also crucial for safe planning because human behaviors are inherently uncertain and multimodal. However, existing methods generally lack a scheme to generate controllably diverse trajectories, which is arguably more useful than randomly diversified trajectories, to the end of safe planning. To address this, we propose PrefCVAE, an augmented CVAE framework that uses weakly labeled preference pairs to imbue latent variables with semantic attributes. Using average velocity as an example attribute, we demonstrate that PrefCVAE enables controllable, semantically meaningful predictions without degrading baseline accuracy. Our results show the effectiveness of preference supervision as a cost-effective way to enhance sampling-based generative models.",
    "authors": [
      "Yongxi Cao",
      "Julian F. Schumann",
      "Jens Kober",
      "Joni Pajarinen",
      "Arkady Zgonnikov"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T18:06:39.000Z",
    "updatedAt": "2025-10-12T18:06:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10731v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10731v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10730v1",
    "arxivId": "2510.10730v1",
    "title": "Provable Anytime Ensemble Sampling Algorithms in Nonlinear Contextual Bandits",
    "abstract": "We provide a unified algorithmic framework for ensemble sampling in nonlinear contextual bandits and develop corresponding regret bounds for two most common nonlinear contextual bandit settings: Generalized Linear Ensemble Sampling (\\texttt{GLM-ES}) for generalized linear bandits and Neural Ensemble Sampling (\\texttt{Neural-ES}) for neural contextual bandits. Both methods maintain multiple estimators for the reward model parameters via maximum likelihood estimation on randomly perturbed data. We prove high-probability frequentist regret bounds of $\\mathcal{O}(d^{3/2} \\sqrt{T} + d^{9/2})$ for \\texttt{GLM-ES} and $\\mathcal{O}(\\widetilde{d} \\sqrt{T})$ for \\texttt{Neural-ES}, where $d$ is the dimension of feature vectors, $\\widetilde{d}$ is the effective dimension of a neural tangent kernel matrix, and $T$ is the number of rounds. These regret bounds match the state-of-the-art results of randomized exploration algorithms in nonlinear contextual bandit settings. In the theoretical analysis, we introduce techniques that address challenges specific to nonlinear models. Practically, we remove fixed-time horizon assumptions by developing anytime versions of our algorithms, suitable when $T$ is unknown. Finally, we empirically evaluate \\texttt{GLM-ES}, \\texttt{Neural-ES}, and their anytime variants, demonstrating strong performance. Overall, our results establish ensemble sampling as a provable and practical randomized exploration approach for nonlinear contextual bandits.",
    "authors": [
      "Jiazheng Sun",
      "Weixin Wang",
      "Pan Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "publishedAt": "2025-10-12T18:05:53.000Z",
    "updatedAt": "2025-10-12T18:05:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10730v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10730v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10729v1",
    "arxivId": "2510.10729v1",
    "title": "Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning Framework",
    "abstract": "Sarcasm is a nuanced and often misinterpreted form of communication, especially in text, where tone and body language are absent. This paper proposes a modular deep learning framework for sarcasm detection, leveraging Deep Convolutional Neural Networks (DCNNs) and contextual models such as BERT to analyze linguistic, emotional, and contextual cues. The system integrates sentiment analysis, contextual embeddings, linguistic feature extraction, and emotion detection through a multi-layer architecture. While the model is in the conceptual stage, it demonstrates feasibility for real-world applications such as chatbots and social media analysis.",
    "authors": [
      "Manas Zambre",
      "Sarika Bobade"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T18:02:50.000Z",
    "updatedAt": "2025-10-12T18:02:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10729v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10729v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10726v1",
    "arxivId": "2510.10726v1",
    "title": "WorldMirror: Universal 3D World Reconstruction with Any-Prior Prompting",
    "abstract": "We present WorldMirror, an all-in-one, feed-forward model for versatile 3D geometric prediction tasks. Unlike existing methods constrained to image-only inputs or customized for a specific task, our framework flexibly integrates diverse geometric priors, including camera poses, intrinsics, and depth maps, while simultaneously generating multiple 3D representations: dense point clouds, multi-view depth maps, camera parameters, surface normals, and 3D Gaussians. This elegant and unified architecture leverages available prior information to resolve structural ambiguities and delivers geometrically consistent 3D outputs in a single forward pass. WorldMirror achieves state-of-the-art performance across diverse benchmarks from camera, point map, depth, and surface normal estimation to novel view synthesis, while maintaining the efficiency of feed-forward inference. Code and models will be publicly available soon.",
    "authors": [
      "Yifan Liu",
      "Zhiyuan Min",
      "Zhenwei Wang",
      "Junta Wu",
      "Tengfei Wang",
      "Yixuan Yuan",
      "Yawei Luo",
      "Chunchao Guo"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T17:59:09.000Z",
    "updatedAt": "2025-10-12T17:59:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10726v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10726v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10719v1",
    "arxivId": "2510.10719v1",
    "title": "SS-DPPN: A self-supervised dual-path foundation model for the generalizable cardiac audio representation",
    "abstract": "The automated analysis of phonocardiograms is vital for the early diagnosis of cardiovascular disease, yet supervised deep learning is often constrained by the scarcity of expert-annotated data. In this paper, we propose the Self-Supervised Dual-Path Prototypical Network (SS-DPPN), a foundation model for cardiac audio representation and classification from unlabeled data. The framework introduces a dual-path contrastive learning based architecture that simultaneously processes 1D waveforms and 2D spectrograms using a novel hybrid loss. For the downstream task, a metric-learning approach using a Prototypical Network was used that enhances sensitivity and produces well-calibrated and trustworthy predictions. SS-DPPN achieves state-of-the-art performance on four cardiac audio benchmarks. The framework demonstrates exceptional data efficiency with a fully supervised model on three-fold reduction in labeled data. Finally, the learned representations generalize successfully across lung sound classification and heart rate estimation. Our experiments and findings validate SS-DPPN as a robust, reliable, and scalable foundation model for physiological signals.",
    "authors": [
      "Ummy Maria Muna",
      "Md Mehedi Hasan Shawon",
      "Md Jobayer",
      "Sumaiya Akter",
      "Md Rakibul Hasan",
      "Md. Golam Rabiul Alam"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T17:43:57.000Z",
    "updatedAt": "2025-10-12T17:43:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10719v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10719v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10718v1",
    "arxivId": "2510.10718v1",
    "title": "HYPERDOA: Robust and Efficient DoA Estimation using Hyperdimensional Computing",
    "abstract": "Direction of Arrival (DoA) estimation techniques face a critical trade-off, as classical methods often lack accuracy in challenging, low signal-to-noise ratio (SNR) conditions, while modern deep learning approaches are too energy-intensive and opaque for resource-constrained, safety-critical systems. We introduce HYPERDOA, a novel estimator leveraging Hyperdimensional Computing (HDC). The framework introduces two distinct feature extraction strategies -- Mean Spatial-Lag Autocorrelation and Spatial Smoothing -- for its HDC pipeline, and then reframes DoA estimation as a pattern recognition problem. This approach leverages HDC's inherent robustness to noise and its transparent algebraic operations to bypass the expensive matrix decompositions and ``black-box'' nature of classical and deep learning methods, respectively. Our evaluation demonstrates that HYPERDOA achieves ~35.39% higher accuracy than state-of-the-art methods in low-SNR, coherent-source scenarios. Crucially, it also consumes ~93% less energy than competing neural baselines on an embedded NVIDIA Jetson Xavier NX platform. This dual advantage in accuracy and efficiency establishes HYPERDOA as a robust and viable solution for mission-critical applications on edge devices.",
    "authors": [
      "Rajat Bhattacharjya",
      "Woohyeok Park",
      "Arnab Sarkar",
      "Hyunwoo Oh",
      "Mohsen Imani",
      "Nikil Dutt"
    ],
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.AR",
      "cs.SC"
    ],
    "publishedAt": "2025-10-12T17:42:01.000Z",
    "updatedAt": "2025-10-12T17:42:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10718v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10718v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10716v1",
    "arxivId": "2510.10716v1",
    "title": "Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy",
    "abstract": "A new AUV mission planning and execution software has been tested on AUV Sentry. Dubbed DINOS-R, it draws inspiration from cognitive architectures and AUV control systems to replace the legacy MC architecture. Unlike these existing architectures, however, DINOS-R is built from the ground-up to unify symbolic decision making (for understandable, repeatable, provable behavior) with machine learning techniques and reactive behaviors, for field-readiness across oceanographic platforms. Implemented primarily in Python3, DINOS-R is extensible, modular, and reusable, with an emphasis on non-expert use as well as growth for future research in oceanography and robot algorithms. Mission specification is flexible, and can be specified declaratively. Behavior specification is similarly flexible, supporting simultaneous use of real-time task planning and hard-coded user specified plans. These features were demonstrated in the field on Sentry, in addition to a variety of simulated cases. These results are discussed, and future work is outlined.",
    "authors": [
      "Christopher Thierauf"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T17:37:32.000Z",
    "updatedAt": "2025-10-12T17:37:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10716v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10716v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10715v1",
    "arxivId": "2510.10715v1",
    "title": "VLM-Guided Adaptive Negative Prompting for Creative Generation",
    "abstract": "Creative generation is the synthesis of new, surprising, and valuable samples that reflect user intent yet cannot be envisioned in advance. This task aims to extend human imagination, enabling the discovery of visual concepts that exist in the unexplored spaces between familiar domains. While text-to-image diffusion models excel at rendering photorealistic scenes that faithfully match user prompts, they still struggle to generate genuinely novel content. Existing approaches to enhance generative creativity either rely on interpolation of image features, which restricts exploration to predefined categories, or require time-intensive procedures such as embedding optimization or model fine-tuning. We propose VLM-Guided Adaptive Negative-Prompting, a training-free, inference-time method that promotes creative image generation while preserving the validity of the generated object. Our approach utilizes a vision-language model (VLM) that analyzes intermediate outputs of the generation process and adaptively steers it away from conventional visual concepts, encouraging the emergence of novel and surprising outputs. We evaluate creativity through both novelty and validity, using statistical metrics in the CLIP embedding space. Through extensive experiments, we show consistent gains in creative novelty with negligible computational overhead. Moreover, unlike existing methods that primarily generate single objects, our approach extends to complex scenarios, such as generating coherent sets of creative objects and preserving creativity within elaborate compositional prompts. Our method integrates seamlessly into existing diffusion pipelines, offering a practical route to producing creative outputs that venture beyond the constraints of textual descriptions.",
    "authors": [
      "Shelly Golan",
      "Yotam Nitzan",
      "Zongze Wu",
      "Or Patashnik"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T17:34:59.000Z",
    "updatedAt": "2025-10-12T17:34:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10715v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10715v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10714v1",
    "arxivId": "2510.10714v1",
    "title": "Nine lower bound conjectures on streaming approximation algorithms for CSPs",
    "abstract": "In this column, we overview recent progress by many authors on understanding the approximability of constraint satisfaction problems (CSPs) in low-space streaming models. Inspired by this recent progress, we collate nine conjectural lower bounds against streaming algorithms for CSPs, some of which appear here for the first time.",
    "authors": [
      "Noah G. Singer"
    ],
    "categories": [
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-12T17:34:20.000Z",
    "updatedAt": "2025-10-12T17:34:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10714v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10714v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10713v1",
    "arxivId": "2510.10713v1",
    "title": "Deep Learning in Astrophysics",
    "abstract": "Deep learning has generated diverse perspectives in astronomy, with ongoing discussions between proponents and skeptics motivating this review. We examine how neural networks complement classical statistics, extending our data analytical toolkit for modern surveys. Astronomy offers unique opportunities through encoding physical symmetries, conservation laws, and differential equations directly into architectures, creating models that generalize beyond training data. Yet challenges persist as unlabeled observations number in billions while confirmed examples with known properties remain scarce and expensive. This review demonstrates how deep learning incorporates domain knowledge through architectural design, with built-in assumptions guiding models toward physically meaningful solutions. We evaluate where these methods offer genuine advances versus claims requiring careful scrutiny. - Neural architectures overcome trade-offs between scalability, expressivity, and data efficiency by encoding physical symmetries and conservation laws into network structure, enabling learning from limited labeled data. - Simulation-based inference and anomaly detection extract information from complex, non-Gaussian distributions where analytical likelihoods fail, enabling field-level cosmological analysis and systematic discovery of rare phenomena. - Multi-scale neural modeling bridges resolution gaps in astronomical simulations, learning effective subgrid physics from expensive high-fidelity runs to enhance large-volume calculations where direct computation remains prohibitive. - Emerging paradigms-reinforcement learning for telescope operations, foundation models learning from minimal examples, and large language model agents for research automation-show promise though are still developing in astronomical applications.",
    "authors": [
      "Yuan-Sen Ting"
    ],
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.HE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T17:31:46.000Z",
    "updatedAt": "2025-10-12T17:31:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10713v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10713v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10710v1",
    "arxivId": "2510.10710v1",
    "title": "Informative Keyboard and its Application to Raise Awareness of Smartphone Use",
    "abstract": "Excessive smartphone use is now widely considered a personal and societal problem. It is recognized by application and smartphone makers, who provide tools to track the amount of use, set limits, or block certain services at predefined times. These tools, while powerful, may require significant cognitive effort to operate: configuration parameters need to be set, and captured statistics need to be analyzed. To offer a complementary solution, we propose a radically different approach. We employ the keyboard of a smartphone as an output device. With each press of a key, the user is given a high-level, qualitative, color-encoded estimate of the amount of recent smartphone use. The technique, dubbed the informative keyboard, is a case of implicit interaction: the user's intention is to enter text but, while typing, they receive the feedback. In the paper, we elaborate the concept, identify design decisions, describe our implementation, present the outcome of a questionnaire-based evaluation, and point to some other applications of the informative keyboard.",
    "authors": [
      "Jaroslaw Domaszewicz",
      "Damian Sienicki",
      "Michal Obirek"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-12T17:17:57.000Z",
    "updatedAt": "2025-10-12T17:17:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10710v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10710v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10709v1",
    "arxivId": "2510.10709v1",
    "title": "Missing Data Multiple Imputation for Tabular Q-Learning in Online RL",
    "abstract": "Missing data in online reinforcement learning (RL) poses challenges compared to missing data in standard tabular data or in offline policy learning. The need to impute and act at each time step means that imputation cannot be put off until enough data exist to produce stable imputation models. It also means future data collection and learning depend on previous imputations. This paper proposes fully online imputation ensembles. We find that maintaining multiple imputation pathways may help balance the need to capture uncertainty under missingness and the need for efficiency in online settings. We consider multiple approaches for incorporating these pathways into learning and action selection. Using a Grid World experiment with various types of missingness, we provide preliminary evidence that multiple imputation pathways may be a useful framework for constructing simple and efficient online missing data RL methods.",
    "authors": [
      "Kyla Chasalow",
      "Skyler Wu",
      "Susan Murphy"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T17:16:36.000Z",
    "updatedAt": "2025-10-12T17:16:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10709v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10709v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10706v1",
    "arxivId": "2510.10706v1",
    "title": "Designing ReLU Generative Networks to Enumerate Trees with a Given Tree Edit Distance",
    "abstract": "The generation of trees with a specified tree edit distance has significant applications across various fields, including computational biology, structured data analysis, and image processing. Recently, generative networks have been increasingly employed to synthesize new data that closely resembles the original datasets. However, the appropriate size and depth of generative networks required to generate data with a specified tree edit distance remain unclear. In this paper, we theoretically establish the existence and construction of generative networks capable of producing trees similar to a given tree with respect to the tree edit distance. Specifically, for a given rooted, ordered, and vertex-labeled tree T of size n + 1 with labels from an alphabet \\Sigma, and a non-negative integer d, we prove that all rooted, ordered, and vertex-labeled trees over \\Sigma with tree edit distance at most d from T can be generated using a ReLU-based generative network with size O(n^3 ) and constant depth. The proposed networks were implemented and evaluated for generating trees with up to 21 nodes. Due to their deterministic architecture, the networks successfully generated all valid trees within the specified tree edit distance. In contrast, state-of-the-art graph generative models GraphRNN and GraphGDP, which rely on non-deterministic mechanisms, produced significantly fewer valid trees, achieving validation rates of only up to 35% and 48%, respectively. These findings provide a theoretical foundation towards construction of compact generative models and open new directions for exact and valid tree-structured data generation. An implementation of the proposed networks is available at https://github.com/MGANN-KU/TreeGen_ReLUNetworks.",
    "authors": [
      "Mamoona Ghafoor",
      "Tatsuya Akutsu"
    ],
    "categories": [
      "cs.LG",
      "cs.DM"
    ],
    "publishedAt": "2025-10-12T17:07:49.000Z",
    "updatedAt": "2025-10-12T17:07:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10706v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10706v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10705v1",
    "arxivId": "2510.10705v1",
    "title": "Learning-Augmented Streaming Algorithms for Correlation Clustering",
    "abstract": "We study streaming algorithms for Correlation Clustering. Given a graph as an arbitrary-order stream of edges, with each edge labeled as positive or negative, the goal is to partition the vertices into disjoint clusters, such that the number of disagreements is minimized. In this paper, we give the first learning-augmented streaming algorithms for the problem on both complete and general graphs, improving the best-known space-approximation tradeoffs. Based on the works of Cambus et al. (SODA'24) and Ahn et al. (ICML'15), our algorithms use the predictions of pairwise distances between vertices provided by a predictor. For complete graphs, our algorithm achieves a better-than-$3$ approximation under good prediction quality, while using $\\tilde{O}(n)$ total space. For general graphs, our algorithm achieves an $O(\\log |E^-|)$ approximation under good prediction quality using $\\tilde{O}(n)$ total space, improving the best-known non-learning algorithm in terms of space efficiency. Experimental results on synthetic and real-world datasets demonstrate the superiority of our proposed algorithms over their non-learning counterparts.",
    "authors": [
      "Yinhao Dong",
      "Shan Jiang",
      "Shi Li",
      "Pan Peng"
    ],
    "categories": [
      "cs.DS",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T17:04:40.000Z",
    "updatedAt": "2025-10-12T17:04:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10705v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10705v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10703v1",
    "arxivId": "2510.10703v1",
    "title": "Adaptive Selection of Symbolic Languages for Improving LLM Logical Reasoning",
    "abstract": "Large Language Models (LLMs) still struggle with complex logical reasoning. While previous works achieve remarkable improvements, their performance is highly dependent on the correctness of translating natural language (NL) problems into a symbolic language (SL). Though numerous works focusing on improving this translation accuracy, they only consider the similarity between the meaning of SL and NL, overlooking another crucial influencing factor, the selection of the target SL type itself. For example, first-order logic language specializes in logical reasoning with categorical syllogisms and complex quantifiers, while Boolean satisfiability formalism excels at representing constraint satisfaction like partial problems. To our knowledge, this is the first paper to claim and verify that different NL logical reasoning problem corresponds to different optimal SL formalization for translation. Based on this, we propose a methods to improve the logical reasoning performance of LLMs by adaptively selecting the most suitable SL for each problem prior to translation. Specifically, we leverage LLMs to select the target SL among first-order logic, logic programming and Boolean satisfiability and then translate the problem in NL to target SL expressions as well as employ the corresponding logical solver to derive the final answer. Experimental results on benchmarks show that our adaptive selection method significantly outperforms translating all into single SL and randomly selecting the SL. On a mixed dataset of these benchmarks, our approach achieves 96% accuracy, which improving performance by 25% compared to the second highest accuracy from the first-order logic translation.",
    "authors": [
      "Xiangyu Wang",
      "Haocheng Yang",
      "Fengxiang Cheng",
      "Fenrong Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T17:04:01.000Z",
    "updatedAt": "2025-10-12T17:04:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10703v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10703v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10702v1",
    "arxivId": "2510.10702v1",
    "title": "Attention-Enhanced LSTM Modeling for Improved Temperature and Rainfall Forecasting in Bangladesh",
    "abstract": "Accurate climate forecasting is vital for Bangladesh, a region highly susceptible to climate change impacts on temperature and rainfall. Existing models often struggle to capture long-range dependencies and complex temporal patterns in climate data. This study introduces an advanced Long Short-Term Memory (LSTM) model integrated with an attention mechanism to enhance the prediction of temperature and rainfall dynamics. Utilizing comprehensive datasets from 1901-2023, sourced from NASA's POWER Project for temperature and the Humanitarian Data Exchange for rainfall, the model effectively captures seasonal and long-term trends. It outperforms baseline models, including XGBoost, Simple LSTM, and GRU, achieving a test MSE of 0.2411 (normalized units), MAE of 0.3860 degrees C, R^2 of 0.9834, and NRMSE of 0.0370 for temperature, and MSE of 1283.67 mm^2, MAE of 22.91 mm, R^2 of 0.9639, and NRMSE of 0.0354 for rainfall on monthly forecasts. The model demonstrates improved robustness with only a 20 percent increase in MSE under simulated climate trends (compared to an approximately 2.2-fold increase in baseline models without trend features) and a 50 percent degradation under regional variations (compared to an approximately 4.8-fold increase in baseline models without enhancements). These results highlight the model's ability to improve forecasting precision and offer potential insights into the physical processes governing climate variability in Bangladesh, supporting applications in climate-sensitive sectors.",
    "authors": [
      "Usman Gani Joy",
      "Shahadat kabir",
      "Tasnim Niger"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T17:03:45.000Z",
    "updatedAt": "2025-10-12T17:03:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10702v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10702v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10701v1",
    "arxivId": "2510.10701v1",
    "title": "Extended Triangular Method: A Generalized Algorithm for Contradiction Separation Based Automated Deduction",
    "abstract": "Automated deduction lies at the core of Artificial Intelligence (AI), underpinning theorem proving, formal verification, and logical reasoning. Despite decades of progress, reconciling deductive completeness with computational efficiency remains an enduring challenge. Traditional reasoning calculi, grounded in binary resolution, restrict inference to pairwise clause interactions and thereby limit deductive synergy among multiple clauses. The Contradiction Separation Extension (CSE) framework, introduced in 2018, proposed a dynamic multi-clause reasoning theory that redefined logical inference as a process of contradiction separation rather than sequential resolution. While that work established the theoretical foundation, its algorithmic realization remained unformalized and unpublished. This work presents the Extended Triangular Method (ETM), a generalized contradiction-construction algorithm that formalizes and extends the internal mechanisms of contradiction separation. The ETM unifies multiple contradiction-building strategies, including the earlier Standard Extension method, within a triangular geometric framework that supports flexible clause interaction and dynamic synergy. ETM serves as the algorithmic core of several high-performance theorem provers, CSE, CSE-E, CSI-E, and CSI-Enig, whose competitive results in standard first-order benchmarks (TPTP problem sets and CASC 2018-2015) empirically validate the effectiveness and generality of the proposed approach. By bridging theoretical abstraction and operational implementation, ETM advances the contradiction separation paradigm into a generalized, scalable, and practically competitive model for automated reasoning, offering new directions for future research in logical inference and theorem proving.",
    "authors": [
      "Yang Xu",
      "Shuwei Chen",
      "Jun Liu",
      "Feng Cao",
      "Xingxing He"
    ],
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "publishedAt": "2025-10-12T17:03:33.000Z",
    "updatedAt": "2025-10-12T17:03:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10701v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10701v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10698v1",
    "arxivId": "2510.10698v1",
    "title": "Fair Assignment of Indivisible Chores to Asymmetric Agents",
    "abstract": "We consider the problem of assigning indivisible chores to agents with different entitlements in the maximin share value (\\MMS) context. While constant-\\MMS\\ allocations/assignments are guaranteed to exist for both goods and chores in the symmetric setting, the situation becomes much more complex when agents have different entitlements. For the allocation of indivisible goods, it has been proven that an $n$-\\WMMS\\ (weighted \\MMS) guarantee is the best one can hope for. For indivisible chores, however, it was recently discovered that an $O(\\log n)$-\\WMMS\\ assignment is guaranteed to exist. In this work, we improve this upper bound to a constant-\\WMMS\\ guarantee.\\footnote{We prove the existence of a 20-\\WMMS\\ assignment, but we did not attempt to optimize the constant factor. We believe our methods already yield a slightly better bound with a tighter analysis.}",
    "authors": [
      "Masoud Seddighin",
      "Saeed Seddighin"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-12T16:54:59.000Z",
    "updatedAt": "2025-10-12T16:54:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10698v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10698v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10693v1",
    "arxivId": "2510.10693v1",
    "title": "High-Dimensional Learning Dynamics of Quantized Models with Straight-Through Estimator",
    "abstract": "Quantized neural network training optimizes a discrete, non-differentiable objective. The straight-through estimator (STE) enables backpropagation through surrogate gradients and is widely used. While previous studies have primarily focused on the properties of surrogate gradients and their convergence, the influence of quantization hyperparameters, such as bit width and quantization range, on learning dynamics remains largely unexplored. We theoretically show that in the high-dimensional limit, STE dynamics converge to a deterministic ordinary differential equation. This reveals that STE training exhibits a plateau followed by a sharp drop in generalization error, with plateau length depending on the quantization range. A fixed-point analysis quantifies the asymptotic deviation from the unquantized linear model. We also extend analytical techniques for stochastic gradient descent to nonlinear transformations of weights and inputs.",
    "authors": [
      "Yuma Ichikawa",
      "Shuhei Kashiwamura",
      "Ayaka Sakata"
    ],
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "publishedAt": "2025-10-12T16:43:46.000Z",
    "updatedAt": "2025-10-12T16:43:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10693v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10693v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10691v1",
    "arxivId": "2510.10691v1",
    "title": "Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos",
    "abstract": "This paper presents a unified framework that allows high-quality dynamic Gaussian Splatting from both defocused and motion-blurred monocular videos. Due to the significant difference between the formation processes of defocus blur and motion blur, existing methods are tailored for either one of them, lacking the ability to simultaneously deal with both of them. Although the two can be jointly modeled as blur kernel-based convolution, the inherent difficulty in estimating accurate blur kernels greatly limits the progress in this direction. In this work, we go a step further towards this direction. Particularly, we propose to estimate per-pixel reliable blur kernels using a blur prediction network that exploits blur-related scene and camera information and is subject to a blur-aware sparsity constraint. Besides, we introduce a dynamic Gaussian densification strategy to mitigate the lack of Gaussians for incomplete regions, and boost the performance of novel view synthesis by incorporating unseen view information to constrain scene optimization. Extensive experiments show that our method outperforms the state-of-the-art methods in generating photorealistic novel view synthesis from defocused and motion-blurred monocular videos. Our code and trained model will be made publicly available.",
    "authors": [
      "Xuankai Zhang",
      "Junjin Xiao",
      "Qing Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T16:38:54.000Z",
    "updatedAt": "2025-10-12T16:38:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10691v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10691v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10689v1",
    "arxivId": "2510.10689v1",
    "title": "OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs",
    "abstract": "Recent advances in multimodal large language models (MLLMs) have demonstrated substantial potential in video understanding. However, existing benchmarks fail to comprehensively evaluate synergistic reasoning capabilities across audio and visual modalities, often neglecting either one of the modalities or integrating them in a logically inconsistent manner. To bridge this gap, we introduce OmniVideoBench, a large-scale and rigorously designed benchmark dedicated to assessing synergistic audio-visual understanding, with a strong emphasis on modality complementarity and logical consistency. Specifically, OmniVideoBench comprises 1000 high-quality question-answer(QA) pairs, each annotated with step-by-step reasoning traces, derived from 628 diverse videos ranging from several seconds to 30 minutes, and manually verified to guarantee complete correctness and uniqueness. Moreover, OmniVideoBench encompasses 13 carefully designed question types, covering temporal reasoning, spatial localization, counting, causal inference, summarization, and beyond, thereby capturing the essential challenges of video understanding. Evaluation of multiple MLLMs on OmniVideoBench reveals a pronounced gap between model performance and human reasoning, with open-source models lagging significantly behind their closed-source counterparts, underscoring the inherent difficulty of genuine audio-visual reasoning. We will release OmniVideoBench to foster the development of MLLMs with stronger and more generalizable reasoning capabilities.",
    "authors": [
      "Caorui Li",
      "Yu Chen",
      "Yiyan Ji",
      "Jin Xu",
      "Zhenyu Cui",
      "Shihao Li",
      "Yuanxing Zhang",
      "Jiafu Tang",
      "Zhenghao Song",
      "Dingling Zhang",
      "Ying He",
      "Haoxiang Liu",
      "Yuxuan Wang",
      "Qiufeng Wang",
      "Zhenhe Wu",
      "Jiehui Luo",
      "Zhiyu Pan",
      "Weihao Xie",
      "Chenchen Zhang",
      "Zhaohui Wang",
      "Jiayi Tian",
      "Yanghai Wang",
      "Zhe Cao",
      "Minxin Dai",
      "Ke Wang",
      "Runzhe Wen",
      "Yinghao Ma",
      "Yaning Pan",
      "Sungkyun Chang",
      "Termeh Taheri",
      "Haiwen Xia",
      "Christos Plachouras",
      "Emmanouil Benetos",
      "Yizhi Li",
      "Ge Zhang",
      "Jian Yang",
      "Tianhao Peng",
      "Zili Wang",
      "Minghao Liu",
      "Junran Peng",
      "Zhaoxiang Zhang",
      "Jiaheng Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T16:34:00.000Z",
    "updatedAt": "2025-10-12T16:34:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10689v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10689v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10687v1",
    "arxivId": "2510.10687v1",
    "title": "LSZone: A Lightweight Spatial Information Modeling Architecture for Real-time In-car Multi-zone Speech Separation",
    "abstract": "In-car multi-zone speech separation, which captures voices from different speech zones, plays a crucial role in human-vehicle interaction. Although previous SpatialNet has achieved notable results, its high computational cost still hinders real-time applications in vehicles. To this end, this paper proposes LSZone, a lightweight spatial information modeling architecture for real-time in-car multi-zone speech separation. We design a spatial information extraction-compression (SpaIEC) module that combines Mel spectrogram and Interaural Phase Difference (IPD) to reduce computational burden while maintaining performance. Additionally, to efficiently model spatial information, we introduce an extremely lightweight Conv-GRU crossband-narrowband processing (CNP) module. Experimental results demonstrate that LSZone, with a complexity of 0.56G MACs and a real-time factor (RTF) of 0.37, delivers impressive performance in complex noise and multi-speaker scenarios.",
    "authors": [
      "Jun Chen",
      "Shichao Hu",
      "Jiuxin Lin",
      "Wenjie Li",
      "Zihan Zhang",
      "Xingchen Li",
      "JinJiang Liu",
      "Longshuai Xiao",
      "Chao Weng",
      "Lei Xie",
      "Zhiyong Wu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T16:31:05.000Z",
    "updatedAt": "2025-10-12T16:31:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10687v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10687v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10682v1",
    "arxivId": "2510.10682v1",
    "title": "Action-Dynamics Modeling and Cross-Temporal Interaction for Online Action Understanding",
    "abstract": "Action understanding, encompassing action detection and anticipation, plays a crucial role in numerous practical applications. However, untrimmed videos are often characterized by substantial redundant information and noise. Moreover, in modeling action understanding, the influence of the agent's intention on the action is often overlooked. Motivated by these issues, we propose a novel framework called the State-Specific Model (SSM), designed to unify and enhance both action detection and anticipation tasks. In the proposed framework, the Critical State-Based Memory Compression module compresses frame sequences into critical states, reducing information redundancy. The Action Pattern Learning module constructs a state-transition graph with multi-dimensional edges to model action dynamics in complex scenarios, on the basis of which potential future cues can be generated to represent intention. Furthermore, our Cross-Temporal Interaction module models the mutual influence between intentions and past as well as current information through cross-temporal interactions, thereby refining present and future features and ultimately realizing simultaneous action detection and anticipation. Extensive experiments on multiple benchmark datasets -- including EPIC-Kitchens-100, THUMOS'14, TVSeries, and the introduced Parkinson's Disease Mouse Behaviour (PDMB) dataset -- demonstrate the superior performance of our proposed framework compared to other state-of-the-art approaches. These results highlight the importance of action dynamics learning and cross-temporal interactions, laying a foundation for future action understanding research.",
    "authors": [
      "Xinyu Yang",
      "Zheheng Jiang",
      "Feixiang Zhou",
      "Yihang Zhu",
      "Na Lv",
      "Nan Xing",
      "Huiyu Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T16:10:40.000Z",
    "updatedAt": "2025-10-12T16:10:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10682v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10682v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10681v1",
    "arxivId": "2510.10681v1",
    "title": "RePro: Training Language Models to Faithfully Recycle the Web for Pretraining",
    "abstract": "High-quality pretraining data is the fossil fuel of large language models (LLMs), yet its reserves are running low for frontier models. In this paper, we introduce RePro, a novel web recycling method that trains a relatively small LM with reinforcement learning to generate effective and faithful rephrasings of pretraining data. Specifically, we design one quality reward and three faithfulness rewards, optimizing the LM rephraser to convert organic data into high-quality rephrasings while maintaining its core semantics and structure. In our experiment, we train a 4B rephraser to recycle 72B tokens sampled from DCLM-RefinedWeb. Pretraining results on 400M and 1.4B models demonstrate that RePro delivers 4.7%-14.0% relative accuracy gains over organic-only baseline on 22 downstream tasks. RePro also outperforms ReWire, the state-of-the-art web recycling method that prompts a 70B rephraser, as well as the organic baseline with a 4x larger data pool. Experiments with different amounts of recycled data highlight that RePro improves organic data efficiency by 2-3x. Individual and distributional analyses validate that RePro preserves more critical information and faithfully reflects the characteristics of organic data compared to prompting-based methods. Together, these results show that RePro provides an efficient and controllable path to effectively harness the fossil fuel of LLM pretraining. We open-source our code, rephraser, and recycled data at https://github.com/cxcscmu/RePro.",
    "authors": [
      "Zichun Yu",
      "Chenyan Xiong"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T16:08:38.000Z",
    "updatedAt": "2025-10-12T16:08:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10681v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10681v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10679v1",
    "arxivId": "2510.10679v1",
    "title": "MSM-Seg: A Modality-and-Slice Memory Framework with Category-Agnostic Prompting for Multi-Modal Brain Tumor Segmentation",
    "abstract": "Multi-modal brain tumor segmentation is critical for clinical diagnosis, and it requires accurate identification of distinct internal anatomical subregions. While the recent prompt-based segmentation paradigms enable interactive experiences for clinicians, existing methods ignore cross-modal correlations and rely on labor-intensive category-specific prompts, limiting their applicability in real-world scenarios. To address these issues, we propose a MSM-Seg framework for multi-modal brain tumor segmentation. The MSM-Seg introduces a novel dual-memory segmentation paradigm that synergistically integrates multi-modal and inter-slice information with the efficient category-agnostic prompt for brain tumor understanding. To this end, we first devise a modality-and-slice memory attention (MSMA) to exploit the cross-modal and inter-slice relationships among the input scans. Then, we propose a multi-scale category-agnostic prompt encoder (MCP-Encoder) to provide tumor region guidance for decoding. Moreover, we devise a modality-adaptive fusion decoder (MF-Decoder) that leverages the complementary decoding information across different modalities to improve segmentation accuracy. Extensive experiments on different MRI datasets demonstrate that our MSM-Seg framework outperforms state-of-the-art methods in multi-modal metastases and glioma tumor segmentation. The code is available at https://github.com/xq141839/MSM-Seg.",
    "authors": [
      "Yuxiang Luo",
      "Qing Xu",
      "Hai Huang",
      "Yuqi Ouyang",
      "Zhen Chen",
      "Wenting Duan"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T16:08:16.000Z",
    "updatedAt": "2025-10-12T16:08:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10679v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10679v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10677v1",
    "arxivId": "2510.10677v1",
    "title": "Unlocking LLM Safeguards for Low-Resource Languages via Reasoning and Alignment with Minimal Training Data",
    "abstract": "Recent advances in LLMs have enhanced AI capabilities, but also increased the risk posed by malicious requests, highlighting the need for effective LLM safeguards to detect such queries. Existing approaches largely rely on classifier-based methods that lack interpretability and perform poorly on low-resource languages. To address these limitations, we propose ConsistentGuard, a novel reasoning-based multilingual safeguard, which enhances explainability via reasoning and boosts knowledge transfer between languages through alignment. With only 1,000 training samples, our method demonstrates superior performance on three datasets across six languages, outperforming larger models trained with significantly more data, and exhibits strong interpretability and generalization ability. We also contribute a multilingual benchmark extension and release our codes to support future research.",
    "authors": [
      "Zhuowei Chen",
      "Bowei Zhang",
      "Nankai Lin",
      "Tian Hou",
      "Lianxi Wang"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T16:05:56.000Z",
    "updatedAt": "2025-10-12T16:05:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10677v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10677v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10676v1",
    "arxivId": "2510.10676v1",
    "title": "Bhasha-Rupantarika: Algorithm-Hardware Co-design approach for Multilingual Neural Machine Translation",
    "abstract": "This paper introduces Bhasha-Rupantarika, a light and efficient multilingual translation system tailored through algorithm-hardware codesign for resource-limited settings. The method investigates model deployment at sub-octet precision levels (FP8, INT8, INT4, and FP4), with experimental results indicating a 4.1x reduction in model size (FP4) and a 4.2x speedup in inference speed, which correlates with an increased throughput of 66 tokens/s (improvement by 4.8x). This underscores the importance of ultra-low precision quantization for real-time deployment in IoT devices using FPGA accelerators, achieving performance on par with expectations. Our evaluation covers bidirectional translation between Indian and international languages, showcasing its adaptability in low-resource linguistic contexts. The FPGA deployment demonstrated a 1.96x reduction in LUTs and a 1.65x decrease in FFs, resulting in a 2.2x enhancement in throughput compared to OPU and a 4.6x enhancement compared to HPTA. Overall, the evaluation provides a viable solution based on quantisation-aware translation along with hardware efficiency suitable for deployable multilingual AI systems. The entire codes [https://github.com/mukullokhande99/Bhasha-Rupantarika/] and dataset for reproducibility are publicly available, facilitating rapid integration and further development by researchers.",
    "authors": [
      "Mukul Lokhande",
      "Tanushree Dewangan",
      "Mohd Sharik Mansoori",
      "Tejas Chaudhari",
      "Akarsh J.",
      "Damayanti Lokhande",
      "Adam Teman",
      "Santosh Kumar Vishvakarma"
    ],
    "categories": [
      "cs.AR",
      "cs.CL",
      "cs.RO",
      "eess.AS"
    ],
    "publishedAt": "2025-10-12T16:04:11.000Z",
    "updatedAt": "2025-10-12T16:04:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10676v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10676v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10675v1",
    "arxivId": "2510.10675v1",
    "title": "Simpliflow: A Lightweight Open-Source Framework for Rapid Creation and Deployment of Generative Agentic AI Workflows",
    "abstract": "Generative Agentic AI systems are emerging as a powerful paradigm for automating complex, multi-step tasks. However, many existing frameworks for building these systems introduce significant complexity, a steep learning curve, and substantial boilerplate code, hindering rapid prototyping and deployment. This paper introduces simpliflow, a lightweight, open-source Python framework designed to address these challenges. simpliflow enables the rapid development and orchestration of linear, deterministic agentic workflows through a declarative, JSON-based configuration. Its modular architecture decouples agent management, workflow execution, and post-processing, promoting ease of use and extensibility. By integrating with LiteLLM, it supports over 100 Large Language Models (LLMs) out-of-the-box. We present the architecture, operational flow, and core features of simpliflow, demonstrating its utility through diverse use cases ranging from software development simulation to real-time system interaction. A comparative analysis with prominent frameworks like LangChain and AutoGen highlights simpliflow's unique position as a tool optimized for simplicity, control, and speed in deterministic workflow environments.",
    "authors": [
      "Deven Panchal"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T16:02:50.000Z",
    "updatedAt": "2025-10-12T16:02:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10675v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10675v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10671v1",
    "arxivId": "2510.10671v1",
    "title": "Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey",
    "abstract": "Image-Language Foundation Models (ILFM) have demonstrated remarkable success in image-text understanding/generation tasks, providing transferable multimodal representations that generalize across diverse downstream image-based tasks. The advancement of video-text research has spurred growing interest in extending image-based models to the video domain. This paradigm, known as image-to-video transfer learning, succeeds in alleviating the substantial data and computational requirements associated with training video-language foundation models from scratch for video-text learning. This survey provides the first comprehensive review of this emerging field, which begins by summarizing the widely used ILFM and their capabilities. We then systematically classify existing image-to-video transfer learning strategies into two categories: frozen features and modified features, depending on whether the original representations from ILFM are preserved or undergo modifications. Building upon the task-specific nature of image-to-video transfer, this survey methodically elaborates these strategies and details their applications across a spectrum of video-text learning tasks, ranging from fine-grained (e.g., spatio-temporal video grounding) to coarse-grained (e.g., video question answering). We further present a detailed experimental analysis to investigate the efficacy of different image-to-video transfer learning paradigms on a range of downstream video understanding tasks. Finally, we identify prevailing challenges and highlight promising directions for future research. By offering a comprehensive and structured overview, this survey aims to establish a structured roadmap for advancing video-text learning based on existing ILFM, and to inspire future research directions in this rapidly evolving domain.",
    "authors": [
      "Jinxuan Li",
      "Chaolei Tan",
      "Haoxuan Chen",
      "Jianxin Ma",
      "Jian-Fang Hu",
      "Wei-Shi Zheng",
      "Jianhuang Lai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T15:56:02.000Z",
    "updatedAt": "2025-10-12T15:56:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10671v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10671v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10670v1",
    "arxivId": "2510.10670v1",
    "title": "AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes",
    "abstract": "Recent Text-to-Video (T2V) models have demonstrated powerful capability in visual simulation of real-world geometry and physical laws, indicating its potential as implicit world models. Inspired by this, we explore the feasibility of leveraging the video generation prior for viewpoint planning from given 4D scenes, since videos internally accompany dynamic scenes with natural viewpoints. To this end, we propose a two-stage paradigm to adapt pre-trained T2V models for viewpoint prediction, in a compatible manner. First, we inject the 4D scene representation into the pre-trained T2V model via an adaptive learning branch, where the 4D scene is viewpoint-agnostic and the conditional generated video embeds the viewpoints visually. Then, we formulate viewpoint extraction as a hybrid-condition guided camera extrinsic denoising process. Specifically, a camera extrinsic diffusion branch is further introduced onto the pre-trained T2V model, by taking the generated video and 4D scene as input. Experimental results show the superiority of our proposed method over existing competitors, and ablation studies validate the effectiveness of our key technical designs. To some extent, this work proves the potential of video generation models toward 4D interaction in real world.",
    "authors": [
      "Yu Li",
      "Menghan Xia",
      "Gongye Liu",
      "Jianhong Bai",
      "Xintao Wang",
      "Conglang Zhang",
      "Yuxuan Lin",
      "Ruihang Chu",
      "Pengfei Wan",
      "Yujiu Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T15:55:44.000Z",
    "updatedAt": "2025-10-12T15:55:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10670v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10670v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10666v1",
    "arxivId": "2510.10666v1",
    "title": "BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions",
    "abstract": "Efficiently solving real-world problems with LLMs increasingly hinges on their ability to interact with dynamic web environments and autonomously acquire external information. While recent research like Search-R1 and WebDancer demonstrates strong performance in solving web tasks, they heavily rely on additional tools to convert the interactive web environment into static text content. This is in contrast to human browsing behaviors, which involve diverse interactions with the browser, such as scrolling, clicking, and typing. In this paper, we propose BrowserAgent, a more interactive agent that solves complex tasks through human-inspired browser actions. BrowserAgent operates directly on raw web pages via Playwright through a set of predefined browser actions. We adopt a two-stage training (Supervised Fine-Tuning (SFT) and Rejection Fine-Tuning (RFT)) to improve the model's generalization abilities. Despite using significantly less training data than Search-R1, BrowserAgent achieves more competitive results across different Open-QA tasks. Additionally, we introduce an explicit memory mechanism to store key conclusions across steps, further enhancing the model's reasoning capabilities for long-horizon tasks. Notably, BrowserAgent-7B can achieve around 20\\% improvement over Search-R1 on multi-hop QA tasks like HotpotQA, 2Wiki, and Bamboogle. These results indicate that BrowserAgent can serve as a more advanced framework for more interactive and scalable web agents.",
    "authors": [
      "Zhengbo Zhang",
      "Zhiheng Lyu",
      "Junhao Gong",
      "Hongzhu Yi",
      "Xinming Wang",
      "Yuxuan Zhou",
      "Jiabing Yang",
      "Ping Nie",
      "Yan Huang",
      "Wenhu Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T15:43:37.000Z",
    "updatedAt": "2025-10-12T15:43:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10666v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10666v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10665v1",
    "arxivId": "2510.10665v1",
    "title": "Information-Computation Tradeoffs for Noiseless Linear Regression with Oblivious Contamination",
    "abstract": "We study the task of noiseless linear regression under Gaussian covariates in the presence of additive oblivious contamination. Specifically, we are given i.i.d.\\ samples from a distribution $(x, y)$ on $\\mathbb{R}^d \\times \\mathbb{R}$ with $x \\sim \\mathcal{N}(0,\\mathbf{I}_d)$ and $y = x^\\top \\beta + z$, where $z$ is drawn independently of $x$ from an unknown distribution $E$. Moreover, $z$ satisfies $\\mathbb{P}_E[z = 0] = \\alpha>0$. The goal is to accurately recover the regressor $\\beta$ to small $\\ell_2$-error. Ignoring computational considerations, this problem is known to be solvable using $O(d/\\alpha)$ samples. On the other hand, the best known polynomial-time algorithms require $\\Omega(d/\\alpha^2)$ samples. Here we provide formal evidence that the quadratic dependence in $1/\\alpha$ is inherent for efficient algorithms. Specifically, we show that any efficient Statistical Query algorithm for this task requires VSTAT complexity at least $\\tilde{\\Omega}(d^{1/2}/\\alpha^2)$.",
    "authors": [
      "Ilias Diakonikolas",
      "Chao Gao",
      "Daniel M. Kane",
      "John Lafferty",
      "Ankit Pensia"
    ],
    "categories": [
      "cs.DS",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "publishedAt": "2025-10-12T15:42:44.000Z",
    "updatedAt": "2025-10-12T15:42:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10665v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10665v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10663v1",
    "arxivId": "2510.10663v1",
    "title": "Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection",
    "abstract": "With abundant, unlabeled real faces, how can we learn robust and transferable facial representations to boost generalization across various face security tasks? We make the first attempt and propose FS-VFM, a scalable self-supervised pre-training framework, to learn fundamental representations of real face images. We introduce three learning objectives, namely 3C, that synergize masked image modeling (MIM) and instance discrimination (ID), empowering FS-VFM to encode both local patterns and global semantics of real faces. Specifically, we formulate various facial masking strategies for MIM and devise a simple yet effective CRFR-P masking, which explicitly prompts the model to pursue meaningful intra-region Consistency and challenging inter-region Coherency. We present a reliable self-distillation mechanism that seamlessly couples MIM with ID to establish underlying local-to-global Correspondence. After pre-training, vanilla vision transformers (ViTs) serve as universal Vision Foundation Models for downstream Face Security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forensics. To efficiently transfer the pre-trained FS-VFM, we further propose FS-Adapter, a lightweight plug-and-play bottleneck atop the frozen backbone with a novel real-anchor contrastive objective. Extensive experiments on 11 public benchmarks demonstrate that our FS-VFM consistently generalizes better than diverse VFMs, spanning natural and facial domains, fully, weakly, and self-supervised paradigms, small, base, and large ViT scales, and even outperforms SOTA task-specific methods, while FS-Adapter offers an excellent efficiency-performance trade-off. The code and models are available on https://fsfm-3c.github.io/fsvfm.html.",
    "authors": [
      "Gaojian Wang",
      "Feng Lin",
      "Tong Wu",
      "Zhisheng Yan",
      "Kui Ren"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.10; I.2.10; I.5.0"
    ],
    "publishedAt": "2025-10-12T15:38:03.000Z",
    "updatedAt": "2025-10-12T15:38:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10663v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10663v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10661v1",
    "arxivId": "2510.10661v1",
    "title": "AGENTIQL: An Agent-Inspired Multi-Expert Framework for Text-to-SQL Generation",
    "abstract": "LLMs have advanced text-to-SQL generation, yet monolithic architectures struggle with complex reasoning and schema diversity. We propose AGENTIQL, an agent-inspired multi-expert framework that combines a reasoning agent for question decomposition, a coding agent for sub-query generation, and a refinement step for column selection. An adaptive router further balances efficiency and accuracy by selecting between our modular pipeline and a baseline parser. Several steps in the pipeline can be executed in parallel, making the framework scalable to larger workloads. Evaluated on the Spider benchmark, AGENTIQL improves execution accuracy and interpretability and achieves up to 86.07\\% EX with 14B models using the Planner&Executor merging strategy. The attained performance is contingent upon the efficacy of the routing mechanism, thereby narrowing the gap to GPT-4-based SOTA (89.65% EX) while using much smaller open-source LLMs. Beyond accuracy, AGENTIQL enhances transparency by exposing intermediate reasoning steps, offering a robust, scalable, and interpretable approach to semantic parsing.",
    "authors": [
      "Omid Reza Heidari",
      "Siobhan Reid",
      "Yassine Yaakoubi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T15:35:05.000Z",
    "updatedAt": "2025-10-12T15:35:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10661v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10661v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10660v1",
    "arxivId": "2510.10660v1",
    "title": "Stability Under Scrutiny: Benchmarking Representation Paradigms for Online HD Mapping",
    "abstract": "As one of the fundamental modules in autonomous driving, online high-definition (HD) maps have attracted significant attention due to their cost-effectiveness and real-time capabilities. Since vehicles always cruise in highly dynamic environments, spatial displacement of onboard sensors inevitably causes shifts in real-time HD mapping results, and such instability poses fundamental challenges for downstream tasks. However, existing online map construction models tend to prioritize improving each frame's mapping accuracy, while the mapping stability has not yet been systematically studied. To fill this gap, this paper presents the first comprehensive benchmark for evaluating the temporal stability of online HD mapping models. We propose a multi-dimensional stability evaluation framework with novel metrics for Presence, Localization, and Shape Stability, integrated into a unified mean Average Stability (mAS) score. Extensive experiments on 42 models and variants show that accuracy (mAP) and stability (mAS) represent largely independent performance dimensions. We further analyze the impact of key model design choices on both criteria, identifying architectural and training factors that contribute to high accuracy, high stability, or both. To encourage broader focus on stability, we will release a public benchmark. Our work highlights the importance of treating temporal stability as a core evaluation criterion alongside accuracy, advancing the development of more reliable autonomous driving systems. The benchmark toolkit, code, and models will be available at https://stablehdmap.github.io/.",
    "authors": [
      "Hao Shan",
      "Ruikai Li",
      "Han Jiang",
      "Yizhe Fan",
      "Ziyang Yan",
      "Bohan Li",
      "Xiaoshuai Hao",
      "Hao Zhao",
      "Zhiyong Cui",
      "Yilong Ren",
      "Haiyang Yu"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T15:33:45.000Z",
    "updatedAt": "2025-10-12T15:33:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10660v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10660v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10658v1",
    "arxivId": "2510.10658v1",
    "title": "You're Not Gonna Believe This: A Computational Analysis of Factual Appeals and Sourcing in Partisan News",
    "abstract": "While media bias is widely studied, the epistemic strategies behind factual reporting remain computationally underexplored. This paper analyzes these strategies through a large-scale comparison of CNN and Fox News. To isolate reporting style from topic selection, we employ an article matching strategy to compare reports on the same events and apply the FactAppeal framework to a corpus of over 470K articles covering two highly politicized periods: the COVID-19 pandemic and the Israel-Hamas war. We find that CNN's reporting contains more factual statements and is more likely to ground them in external sources. The outlets also exhibit sharply divergent sourcing patterns: CNN builds credibility by citing Experts} and Expert Documents, constructing an appeal to formal authority, whereas Fox News favors News Reports and direct quotations. This work quantifies how partisan outlets use systematically different epistemic strategies to construct reality, adding a new dimension to the study of media bias.",
    "authors": [
      "Guy Mor-Lan",
      "Tamir Sheafer",
      "Shaul R. Shenhav"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T15:30:39.000Z",
    "updatedAt": "2025-10-12T15:30:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10658v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10658v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10653v1",
    "arxivId": "2510.10653v1",
    "title": "A Machine Learning Perspective on Automated Driving Corner Cases",
    "abstract": "For high-stakes applications, like autonomous driving, a safe operation is necessary to prevent harm, accidents, and failures. Traditionally, difficult scenarios have been categorized into corner cases and addressed individually. However, this example-based categorization is not scalable and lacks a data coverage perspective, neglecting the generalization to training data of machine learning models. In our work, we propose a novel machine learning approach that takes the underlying data distribution into account. Based on our novel perspective, we present a framework for effective corner case recognition for perception on individual samples. In our evaluation, we show that our approach (i) unifies existing scenario-based corner case taxonomies under a distributional perspective, (ii) achieves strong performance on corner case detection tasks across standard benchmarks for which we extend established out-of-distribution detection benchmarks, and (iii) enables analysis of combined corner cases via a newly introduced fog-augmented Lost & Found dataset. These results provide a principled basis for corner case recognition, underlining our manual specification-free definition.",
    "authors": [
      "Sebastian Schmidt",
      "Julius Körner",
      "Stephan Günnemann"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T15:18:12.000Z",
    "updatedAt": "2025-10-12T15:18:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10653v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10653v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10651v1",
    "arxivId": "2510.10651v1",
    "title": "Aggregate Modeling of Air-Conditioner Loads Under Packet-based Control with Both On and Off Grid Access Requests",
    "abstract": "Coordination of distributed energy resources (DERs) can engender flexibility necessary to improve grid reliability. Packetized Energy Management (PEM) is a method for coordinating DERs, such as thermostatically controlled loads (TCLs) and electric vehicles, within customer quality-of-service (QoS) limits. In PEM, a DER uses local information to offer flexibility by sending a request to the DER coordinator to turn-ON or turn-OFF. Much work has focused on modeling and analyzing aggregations of DERs under PEM with fixed packet durations and only turn-ON requests. Different recent efforts to enable variable packet lengths have shown an increase in available flexibility and ramping capability, but have not been modeled in aggregate, which limits systematic analyses. To address this issue, this paper presents a new aggregate bin-based (macro) model of PEM loads that incorporates both turn-ON and turn-OFF request features, enabling the model to accurately characterize the capability of the fleet of DERs to track a power reference signal, population temperature dynamics, aggregate request rates, and variable packet lengths. Simulation-based validation is performed against an agent-based (micro) model to evaluate robustness and quantify model accuracy. Finally, the distribution of variable packet lengths from macro-model simulations are applied to inform past work on PEM with randomized packet lengths",
    "authors": [
      "Mohammad Hassan",
      "Mads R. Almassalkhi"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-12T15:11:07.000Z",
    "updatedAt": "2025-10-12T15:11:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10651v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10651v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10650v1",
    "arxivId": "2510.10650v1",
    "title": "DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis",
    "abstract": "Audio-driven talking-head generation has advanced rapidly with diffusion-based generative models, yet producing temporally coherent videos with fine-grained motion control remains challenging. We propose DEMO, a flow-matching generative framework for audio-driven talking-portrait video synthesis that delivers disentangled, high-fidelity control of lip motion, head pose, and eye gaze. The core contribution is a motion auto-encoder that builds a structured latent space in which motion factors are independently represented and approximately orthogonalized. On this disentangled motion space, we apply optimal-transport-based flow matching with a transformer predictor to generate temporally smooth motion trajectories conditioned on audio. Extensive experiments across multiple benchmarks show that DEMO outperforms prior methods in video realism, lip-audio synchronization, and motion fidelity. These results demonstrate that combining fine-grained motion disentanglement with flow-based generative modeling provides a powerful new paradigm for controllable talking-head video synthesis.",
    "authors": [
      "Peiyin Chen",
      "Zhuowei Yang",
      "Hui Feng",
      "Sheng Jiang",
      "Rui Yan"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T15:10:33.000Z",
    "updatedAt": "2025-10-12T15:10:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10650v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10650v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10649v1",
    "arxivId": "2510.10649v1",
    "title": "Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has shown significant promise for enhancing the reasoning capabilities of large language models (LLMs). However, prevailing algorithms like GRPO broadcast a uniform advantage signal across all tokens in a sequence. This coarse-grained approach overlooks the pivotal role of uncertain, high-stakes decisions during reasoning, leading to inefficient exploration and the well-documented problem of entropy collapse. To address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), a model-free method that refines credit assignment by leveraging the model's internal uncertainty signals. UCAS operates in two stages: it first modulates the response-level advantage using the model's overall self-confidence, and then applies a token-level penalty based on raw logit certainty. This dual mechanism encourages exploration of high-uncertainty paths that yield correct answers while penalizing overconfident yet erroneous reasoning, effectively balancing the exploration-exploitation trade-off. Extensive experiments on five mathematical reasoning benchmarks show that UCAS significantly outperforms strong RLVR baselines across multiple model scales, including 1.5B and 7B. Our analysis confirms that UCAS not only achieves higher rewards but also promotes greater reasoning diversity and successfully mitigates entropy collapse.",
    "authors": [
      "Can Xie",
      "Ruotong Pan",
      "Xiangyu Wu",
      "Yunfei Zhang",
      "Jiayi Fu",
      "Tingting Gao",
      "Guorui Zhou"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T15:06:53.000Z",
    "updatedAt": "2025-10-12T15:06:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10649v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10649v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10648v1",
    "arxivId": "2510.10648v1",
    "title": "JND-Guided Light-Weight Neural Pre-Filter for Perceptual Image Coding",
    "abstract": "Just Noticeable Distortion (JND)-guided pre-filter is a promising technique for improving the perceptual compression efficiency of image coding. However, existing methods are often computationally expensive, and the field lacks standardized benchmarks for fair comparison. To address these challenges, this paper introduces a twofold contribution. First, we develop and open-source FJNDF-Pytorch, a unified benchmark for frequency-domain JND-Guided pre-filters. Second, leveraging this platform, we propose a complete learning framework for a novel, lightweight Convolutional Neural Network (CNN). Experimental results demonstrate that our proposed method achieves state-of-the-art compression efficiency, consistently outperforming competitors across multiple datasets and encoders. In terms of computational cost, our model is exceptionally lightweight, requiring only 7.15 GFLOPs to process a 1080p image, which is merely 14.1% of the cost of recent lightweight network. Our work presents a robust, state-of-the-art solution that excels in both performance and efficiency, supported by a reproducible research platform. The open-source implementation is available at https://github.com/viplab-fudan/FJNDF-Pytorch.",
    "authors": [
      "Chenlong He",
      "Zijing Dong",
      "Min Li",
      "Zhijian Hao",
      "Leilei Huang",
      "Xiaoyang Zeng",
      "Yibo Fan"
    ],
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "publishedAt": "2025-10-12T15:05:05.000Z",
    "updatedAt": "2025-10-12T15:05:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10648v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10648v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10645v1",
    "arxivId": "2510.10645v1",
    "title": "Trustworthy Retrosynthesis: Eliminating Hallucinations with a Diverse Ensemble of Reaction Scorers",
    "abstract": "Retrosynthesis is one of the domains transformed by the rise of generative models, and it is one where the problem of nonsensical or erroneous outputs (hallucinations) is particularly insidious: reliable assessment of synthetic plans is time-consuming, with automatic methods lacking. In this work, we present RetroTrim, a retrosynthesis system that successfully avoids nonsensical plans on a set of challenging drug-like targets. Compared to common baselines in the field, our system is not only the sole method that succeeds in filtering out hallucinated reactions, but it also results in the highest number of high-quality paths overall. The key insight behind RetroTrim is the combination of diverse reaction scoring strategies, based on machine learning models and existing chemical databases. We show that our scoring strategies capture different classes of hallucinations by analyzing them on a dataset of labeled retrosynthetic intermediates. To measure the performance of retrosynthesis systems, we propose a novel evaluation protocol for reactions and synthetic paths based on a structured review by expert chemists. Using this protocol, we compare systems on a set of 32 novel targets, curated to reflect recent trends in drug structures. While the insights behind our methodology are broadly applicable to retrosynthesis, our focus is on targets in the drug-like domain. By releasing our benchmark targets and the details of our evaluation protocol, we hope to inspire further research into reliable retrosynthesis.",
    "authors": [
      "Michal Sadowski",
      "Maria Wyrzykowska",
      "Lukasz Sztukiewicz",
      "Tadija Radusinović",
      "Jan Rzymkowski",
      "Paweł Włodarczyk-Pruszyński",
      "Mikołaj Sacha",
      "Piotr Kozakowski",
      "Ruard van Workum",
      "Stanislaw Kamil Jastrzebski"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T14:56:34.000Z",
    "updatedAt": "2025-10-12T14:56:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10645v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10645v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10644v1",
    "arxivId": "2510.10644v1",
    "title": "Hierarchical Optimization via LLM-Guided Objective Evolution for Mobility-on-Demand Systems",
    "abstract": "Online ride-hailing platforms aim to deliver efficient mobility-on-demand services, often facing challenges in balancing dynamic and spatially heterogeneous supply and demand. Existing methods typically fall into two categories: reinforcement learning (RL) approaches, which suffer from data inefficiency, oversimplified modeling of real-world dynamics, and difficulty enforcing operational constraints; or decomposed online optimization methods, which rely on manually designed high-level objectives that lack awareness of low-level routing dynamics. To address this issue, we propose a novel hybrid framework that integrates large language model (LLM) with mathematical optimization in a dynamic hierarchical system: (1) it is training-free, removing the need for large-scale interaction data as in RL, and (2) it leverages LLM to bridge cognitive limitations caused by problem decomposition by adaptively generating high-level objectives. Within this framework, LLM serves as a meta-optimizer, producing semantic heuristics that guide a low-level optimizer responsible for constraint enforcement and real-time decision execution. These heuristics are refined through a closed-loop evolutionary process, driven by harmony search, which iteratively adapts the LLM prompts based on feasibility and performance feedback from the optimization layer. Extensive experiments based on scenarios derived from both the New York and Chicago taxi datasets demonstrate the effectiveness of our approach, achieving an average improvement of 16% compared to state-of-the-art baselines.",
    "authors": [
      "Yi Zhang",
      "Yushen Long",
      "Yun Ni",
      "Liping Huang",
      "Xiaohong Wang",
      "Jun Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T14:56:19.000Z",
    "updatedAt": "2025-10-12T14:56:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10644v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10644v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10642v1",
    "arxivId": "2510.10642v1",
    "title": "UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning",
    "abstract": "Building generalist robot policies that can handle diverse tasks in open-ended environments is a central challenge in robotics. To leverage knowledge from large-scale pretraining, prior work has typically built generalist policies either on top of vision-language understanding models (VLMs) or generative models. However, both semantic understanding from vision-language pretraining and visual dynamics modeling from visual-generation pretraining are crucial for embodied robots. Recent unified models of generation and understanding have demonstrated strong capabilities in both comprehension and generation through large-scale pretraining. We posit that robotic policy learning can likewise benefit from the combined strengths of understanding, planning and continuous future representation learning. Building on this insight, we introduce UniCoD, which acquires the ability to dynamically model high-dimensional visual features through pretraining on over 1M internet-scale instructional manipulation videos. Subsequently, UniCoD is fine-tuned on data collected from the robot embodiment, enabling the learning of mappings from predictive representations to action tokens. Extensive experiments show our approach consistently outperforms baseline methods in terms of 9\\% and 12\\% across simulation environments and real-world out-of-distribution tasks.",
    "authors": [
      "Jianke Zhang",
      "Yucheng Hu",
      "Yanjiang Guo",
      "Xiaoyu Chen",
      "Yichen Liu",
      "Wenna Chen",
      "Chaochao Lu",
      "Jianyu Chen"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T14:54:19.000Z",
    "updatedAt": "2025-10-12T14:54:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10642v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10642v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10640v1",
    "arxivId": "2510.10640v1",
    "title": "Equity-Aware Geospatial AI for Forecasting Demand-Driven Hospital Locations in Germany",
    "abstract": "This paper presents EA-GeoAI, an integrated framework for demand forecasting and equitable hospital planning in Germany through 2030. We combine district-level demographic shifts, aging population density, and infrastructure balances into a unified Equity Index. An interpretable Agentic AI optimizer then allocates beds and identifies new facility sites to minimize unmet need under budget and travel-time constraints. This approach bridges GeoAI, long-term forecasting, and equity measurement to deliver actionable recommendations for policymakers.",
    "authors": [
      "Piyush Pant",
      "Marcellius William Suntoro",
      "Ayesha Siddiqua",
      "Muhammad Shehryaar Sharif",
      "Daniyal Ahmed"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T14:51:28.000Z",
    "updatedAt": "2025-10-12T14:51:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10640v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10640v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10639v1",
    "arxivId": "2510.10639v1",
    "title": "Automatic Piecewise Linear Regression for Predicting Student Learning Satisfaction",
    "abstract": "Although student learning satisfaction has been widely studied, modern techniques such as interpretable machine learning and neural networks have not been sufficiently explored. This study demonstrates that a recent model that combines boosting with interpretability, automatic piecewise linear regression(APLR), offers the best fit for predicting learning satisfaction among several state-of-the-art approaches. Through the analysis of APLR's numerical and visual interpretations, students' time management and concentration abilities, perceived helpfulness to classmates, and participation in offline courses have the most significant positive impact on learning satisfaction. Surprisingly, involvement in creative activities did not positively affect learning satisfaction. Moreover, the contributing factors can be interpreted on an individual level, allowing educators to customize instructions according to student profiles.",
    "authors": [
      "Haemin Choi",
      "Gayathri Nadarajan"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T14:48:50.000Z",
    "updatedAt": "2025-10-12T14:48:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10639v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10639v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10637v1",
    "arxivId": "2510.10637v1",
    "title": "High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting",
    "abstract": "The scalability of robotic learning is fundamentally bottlenecked by the significant cost and labor of real-world data collection. While simulated data offers a scalable alternative, it often fails to generalize to the real world due to significant gaps in visual appearance, physical properties, and object interactions. To address this, we propose RoboSimGS, a novel Real2Sim2Real framework that converts multi-view real-world images into scalable, high-fidelity, and physically interactive simulation environments for robotic manipulation. Our approach reconstructs scenes using a hybrid representation: 3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the environment, while mesh primitives for interactive objects ensure accurate physics simulation. Crucially, we pioneer the use of a Multi-modal Large Language Model (MLLM) to automate the creation of physically plausible, articulated assets. The MLLM analyzes visual data to infer not only physical properties (e.g., density, stiffness) but also complex kinematic structures (e.g., hinges, sliding rails) of objects. We demonstrate that policies trained entirely on data generated by RoboSimGS achieve successful zero-shot sim-to-real transfer across a diverse set of real-world manipulation tasks. Furthermore, data from RoboSimGS significantly enhances the performance and generalization capabilities of SOTA methods. Our results validate RoboSimGS as a powerful and scalable solution for bridging the sim-to-real gap.",
    "authors": [
      "Haoyu Zhao",
      "Cheng Zeng",
      "Linghao Zhuang",
      "Yaxi Zhao",
      "Shengke Xue",
      "Hao Wang",
      "Xingyue Zhao",
      "Zhongyu Li",
      "Kehan Li",
      "Siteng Huang",
      "Mingxiu Chen",
      "Xin Li",
      "Deli Zhao",
      "Hua Zou"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T14:42:07.000Z",
    "updatedAt": "2025-10-12T14:42:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10637v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10637v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10633v1",
    "arxivId": "2510.10633v1",
    "title": "Collaborative Text-to-Image Generation via Multi-Agent Reinforcement Learning and Semantic Fusion",
    "abstract": "Multimodal text-to-image generation remains constrained by the difficulty of maintaining semantic alignment and professional-level detail across diverse visual domains. We propose a multi-agent reinforcement learning framework that coordinates domain-specialized agents (e.g., focused on architecture, portraiture, and landscape imagery) within two coupled subsystems: a text enhancement module and an image generation module, each augmented with multimodal integration components. Agents are trained using Proximal Policy Optimization (PPO) under a composite reward function that balances semantic similarity, linguistic visual quality, and content diversity. Cross-modal alignment is enforced through contrastive learning, bidirectional attention, and iterative feedback between text and image. Across six experimental settings, our system significantly enriches generated content (word count increased by 1614%) while reducing ROUGE-1 scores by 69.7%. Among fusion methods, Transformer-based strategies achieve the highest composite score (0.521), despite occasional stability issues. Multimodal ensembles yield moderate consistency (ranging from 0.444 to 0.481), reflecting the persistent challenges of cross-modal semantic grounding. These findings underscore the promise of collaborative, specialization-driven architectures for advancing reliable multimodal generative systems.",
    "authors": [
      "Jiabao Shi",
      "Minfeng Qi",
      "Lefeng Zhang",
      "Di Wang",
      "Yingjie Zhao",
      "Ziying Li",
      "Yalong Xing",
      "Ningran Li"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T14:29:32.000Z",
    "updatedAt": "2025-10-12T14:29:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10633v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10633v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10631v1",
    "arxivId": "2510.10631v1",
    "title": "GraphTARIF: Linear Graph Transformer with Augmented Rank and Improved Focus",
    "abstract": "Linear attention mechanisms have emerged as efficient alternatives to full self-attention in Graph Transformers, offering linear time complexity. However, existing linear attention models often suffer from a significant drop in expressiveness due to low-rank projection structures and overly uniform attention distributions. We theoretically prove that these properties reduce the class separability of node representations, limiting the model's classification ability. To address this, we propose a novel hybrid framework that enhances both the rank and focus of attention. Specifically, we enhance linear attention by attaching a gated local graph network branch to the value matrix, thereby increasing the rank of the resulting attention map. Furthermore, to alleviate the excessive smoothing effect inherent in linear attention, we introduce a learnable log-power function into the attention scores to reduce entropy and sharpen focus. We theoretically show that this function decreases entropy in the attention distribution, enhancing the separability of learned embeddings. Extensive experiments on both homophilic and heterophilic graph benchmarks demonstrate that our method achieves competitive performance while preserving the scalability of linear attention.",
    "authors": [
      "Zhaolin Hu",
      "Kun Li",
      "Hehe Fan",
      "Yi Yang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T14:22:32.000Z",
    "updatedAt": "2025-10-12T14:22:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10631v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10631v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10627v1",
    "arxivId": "2510.10627v1",
    "title": "FactAppeal: Identifying Epistemic Factual Appeals in News Media",
    "abstract": "How is a factual claim made credible? We propose the novel task of Epistemic Appeal Identification, which identifies whether and how factual statements have been anchored by external sources or evidence. To advance research on this task, we present FactAppeal, a manually annotated dataset of 3,226 English-language news sentences. Unlike prior resources that focus solely on claim detection and verification, FactAppeal identifies the nuanced epistemic structures and evidentiary basis underlying these claims and used to support them. FactAppeal contains span-level annotations which identify factual statements and mentions of sources on which they rely. Moreover, the annotations include fine-grained characteristics of factual appeals such as the type of source (e.g. Active Participant, Witness, Expert, Direct Evidence), whether it is mentioned by name, mentions of the source's role and epistemic credentials, attribution to the source via direct or indirect quotation, and other features. We model the task with a range of encoder models and generative decoder models in the 2B-9B parameter range. Our best performing model, based on Gemma 2 9B, achieves a macro-F1 score of 0.73.",
    "authors": [
      "Guy Mor-Lan",
      "Tamir Sheafer",
      "Shaul R. Shenhav"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T14:14:54.000Z",
    "updatedAt": "2025-10-12T14:14:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10627v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10627v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10625v1",
    "arxivId": "2510.10625v1",
    "title": "ImpMIA: Leveraging Implicit Bias for Membership Inference Attack under Realistic Scenarios",
    "abstract": "Determining which data samples were used to train a model-known as Membership Inference Attack (MIA)-is a well-studied and important problem with implications for data privacy. Black-box methods presume access only to the model's outputs and often rely on training auxiliary reference models. While they have shown strong empirical performance, they rely on assumptions that rarely hold in real-world settings: (i) the attacker knows the training hyperparameters; (ii) all available non-training samples come from the same distribution as the training data; and (iii) the fraction of training data in the evaluation set is known. In this paper, we demonstrate that removing these assumptions leads to a significant drop in the performance of black-box attacks. We introduce ImpMIA, a Membership Inference Attack that exploits the Implicit Bias of neural networks, hence removes the need to rely on any reference models and their assumptions. ImpMIA is a white-box attack -- a setting which assumes access to model weights and is becoming increasingly realistic given that many models are publicly available (e.g., via Hugging Face). Building on maximum-margin implicit bias theory, ImpMIA uses the Karush-Kuhn-Tucker (KKT) optimality conditions to identify training samples. This is done by finding the samples whose gradients most strongly reconstruct the trained model's parameters. As a result, ImpMIA achieves state-of-the-art performance compared to both black and white box attacks in realistic settings where only the model weights and a superset of the training data are available.",
    "authors": [
      "Yuval Golbari",
      "Navve Wasserman",
      "Gal Vardi",
      "Michal Irani"
    ],
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T14:12:28.000Z",
    "updatedAt": "2025-10-12T14:12:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10625v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10625v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10624v1",
    "arxivId": "2510.10624v1",
    "title": "Parameterized crack modelling based on a localized non-intrusive reduced basis method",
    "abstract": "This contribution presents a model order reduction strategy for fast parametric modelling of problems with cracks formulated on spline discretizations. In the context of damage detection, parametric reduced order models (ROMs) are well suited for fast computations by establishing an efficient offline/online split of the simulation process. The problems of interest focus on geometric parameters that describe the crack configuration and may pose challenges to constructing efficient ROMs. This work proposes a framework based on non-intrusive reduced basis methods and a localization strategy tailored to parametric problems with moving discontinuities. The combined benefits of non-intrusive ROMs and localization enable accurate and efficient reduction with low online cost. We demonstrate the applicability of the ROM approach with benchmark tests on linear elastic problems discretized with splines and the extended isogeometric method (XIGA) for crack modelling. The results we obtain show the accuracy and real-time efficiency of the constructed reduced order models.",
    "authors": [
      "Margarita Chasapi"
    ],
    "categories": [
      "cs.CE"
    ],
    "publishedAt": "2025-10-12T14:06:04.000Z",
    "updatedAt": "2025-10-12T14:06:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10624v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10624v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10623v1",
    "arxivId": "2510.10623v1",
    "title": "ADiP: Adaptive Precision Systolic Array for Matrix Multiplication Acceleration",
    "abstract": "Transformers are at the core of modern AI nowadays. They rely heavily on matrix multiplication and require efficient acceleration due to their substantial memory and computational requirements. Quantization plays a vital role in reducing memory usage, and can be exploited for computations by designing reconfigurable architectures that enhance matrix multiplication by dynamically adjusting the precision. This paper proposes ADiP, a novel adaptive-precision systolic array architecture designed for efficient matrix multiplication acceleration.The proposed architecture consists of NxN adaptive-precision processing elements (PEs) and shared accumulators. ADiP supports multiple computation modes, including symmetric single-matrix multiplication as well as asymmetric multi-matrix multiplication with a shared input matrix, thereby improving data-reuse and PE utilization. In addition, ADiP maximizes the computational density by adapting to different precisions, such as 8bitx8bit, 8bitx4bit, and 8bitx2bit. Analytical models are developed for ADiP architecture, including latency and throughput for versatile architecture configurations. A comprehensive hardware design space exploration is demonstrated using 22nm commercial technology, achieving up to a 4x higher computational throughput. Furthermore, ADiP is evaluated on different transformer workloads from GPT-2 Medium, BERT Large, and BitNet-1.58B models, delivering latency improvement up to 53.6%, and energy improvement up to 24.4% for BitNet-1.58B MHA workloads. At a 64x64 size with 4096 PEs, ADiP achieves a peak throughput of 8.192 TOPS, 16.384 TOPS, and 32.768 TOPS for 8bitx8bit, 8bitx4bit, and 8bitx2bit operations, respectively.",
    "authors": [
      "Ahmed J. Abdelmaksoud",
      "Cristian Sestito",
      "Shiwei Wang",
      "Themis Prodromakis"
    ],
    "categories": [
      "cs.AR"
    ],
    "publishedAt": "2025-10-12T14:03:22.000Z",
    "updatedAt": "2025-10-12T14:03:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10623v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10623v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10620v1",
    "arxivId": "2510.10620v1",
    "title": "DCP: Addressing Input Dynamism In Long-Context Training via Dynamic Context Parallelism",
    "abstract": "Context parallelism has emerged as a key technique to support long-context training, a growing trend in generative AI for modern large models. However, existing context parallel methods rely on static parallelization configurations that overlook the dynamic nature of training data, specifically, the variability in sequence lengths and token relationships (i.e., attention patterns) across samples. As a result, these methods often suffer from unnecessary communication overhead and imbalanced computation. In this paper, we present DCP, a dynamic context parallel training framework that introduces fine-grained blockwise partitioning of both data and computation. By enabling flexible mapping of data and computation blocks to devices, DCP can adapt to varying sequence characteristics, effectively reducing communication and improving memory and computation balance. Micro-benchmarks demonstrate that DCP accelerates attention by 1.19x~2.45x under causal masks and 2.15x~3.77x under sparse attention patterns. Additionally, we observe up to 0.94x~1.16x end-to-end training speed-up for causal masks, and 1.00x~1.46x for sparse masks.",
    "authors": [
      "Chenyu Jiang",
      "Zhenkun Cai",
      "Ye Tian",
      "Zhen Jia",
      "Yida Wang",
      "Chuan Wu"
    ],
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T14:01:32.000Z",
    "updatedAt": "2025-10-12T14:01:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10620v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10620v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10619v1",
    "arxivId": "2510.10619v1",
    "title": "A Machine Learning Approach for MIDI to Guitar Tablature Conversion",
    "abstract": "Guitar tablature transcription consists in deducing the string and the fret number on which each note should be played to reproduce the actual musical part. This assignment should lead to playable string-fret combinations throughout the entire track and, in general, preserve parsimonious motion between successive combinations. Throughout the history of guitar playing, specific chord fingerings have been developed across different musical styles that facilitate common idiomatic voicing combinations and motion between them. This paper presents a method for assigning guitar tablature notation to a given MIDI-based musical part (possibly consisting of multiple polyphonic tracks), i.e. no information about guitar-idiomatic expressional characteristics is involved (e.g. bending etc.) The current strategy is based on machine learning and requires a basic assumption about how much fingers can stretch on a fretboard; only standard 6-string guitar tuning is examined. The proposed method also examines the transcription of music pieces that was not meant to be played or could not possibly be played by a guitar (e.g. potentially a symphonic orchestra part), employing a rudimentary method for augmenting musical information and training/testing the system with artificial data. The results present interesting aspects about what the system can achieve when trained on the initial and augmented dataset, showing that the training with augmented data improves the performance even in simple, e.g. monophonic, cases. Results also indicate weaknesses and lead to useful conclusions about possible improvements.",
    "authors": [
      "Maximos Kaliakatsos-Papakostas",
      "Gregoris Bastas",
      "Dimos Makris",
      "Dorien Herremans",
      "Vassilis Katsouros",
      "Petros Maragos"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T14:01:01.000Z",
    "updatedAt": "2025-10-12T14:01:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10619v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10619v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10618v1",
    "arxivId": "2510.10618v1",
    "title": "Preserving LLM Capabilities through Calibration Data Curation: From Analysis to Optimization",
    "abstract": "Post-training compression has been a widely employed approach to scale down large language model (LLM) and facilitate efficient inference. In various proposed compression methods, including pruning and quantization, calibration data plays a vital role by informing the weight importance and activation dynamic ranges. However, how calibration data impacts the LLM capability after compression is less explored. Few of the existing works, though recognizing the significance of this study, only investigate the language modeling or commonsense reasoning performance degradation from limited angles, like the data sources or sample amounts. More systematic research is still needed to examine the impacts on different LLM capabilities in terms of compositional properties and domain correspondence of calibration data. In this work, we aim at bridging this gap and further analyze underlying influencing mechanisms from the activation pattern perspective. Especially, we explore the calibration data's impacts on high-level complex reasoning capabilities, like math problem solving and code generation. Delving into the underlying mechanism, we find that the representativeness and diversity in activation space more fundamentally determine the quality of calibration data. Finally, we propose a calibration data curation framework based on such observations and analysis, enhancing the performance of existing post-training compression methods on preserving critical LLM capabilities. Our code is provided in \\href{https://github.com/BokwaiHo/COLA.git}{Link}.",
    "authors": [
      "Bowei He",
      "Lihao Yin",
      "Huiling Zhen",
      "Shuqi Liu",
      "Han Wu",
      "Xiaokun Zhang",
      "Mingxuan Yuan",
      "Chen Ma"
    ],
    "categories": [
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T14:00:23.000Z",
    "updatedAt": "2025-10-12T14:00:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10618v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10618v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10616v1",
    "arxivId": "2510.10616v1",
    "title": "Assessing Policy Updates: Toward Trust-Preserving Intelligent User Interfaces",
    "abstract": "Reinforcement learning agents are often updated with human feedback, yet such updates can be unreliable: reward misspecification, preference conflicts, or limited data may leave policies unchanged or even worse. Because policies are difficult to interpret directly, users face the challenge of deciding whether an update has truly helped. We propose that assessing model updates -- not just a single model -- is a critical design challenge for intelligent user interfaces. In a controlled study, participants provided feedback to an agent in a gridworld and then compared its original and updated policies. We evaluated four strategies for communicating updates: no demonstration, same-context, random-context, and salient-contrast demonstrations designed to highlight informative differences. Salient-contrast demonstrations significantly improved participants' ability to detect when updates helped or harmed performance, mitigating participants' bias towards assuming that feedback is always beneficial, and supported better trust calibration across contexts.",
    "authors": [
      "Matan Solomon",
      "Ofra Amir",
      "Omer Ben-Porat"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-12T13:57:33.000Z",
    "updatedAt": "2025-10-12T13:57:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10616v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10616v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10613v1",
    "arxivId": "2510.10613v1",
    "title": "Dynamic Topic Evolution with Temporal Decay and Attention in Large Language Models",
    "abstract": "This paper proposes a modeling framework for dynamic topic evolution based on temporal large language models. The method first uses a large language model to obtain contextual embeddings of text and then introduces a temporal decay function and an attention mechanism. These components allow the model to adjust the importance of semantic units according to time intervals and capture topic variations across different periods. The temporal representations are then mapped into a latent topic space, where a state transition matrix is applied to describe the dynamic evolution of topics. A joint optimization objective constrains both semantic modeling and temporal consistency, ensuring diversity and smoothness in topic generation. The design emphasizes the unified modeling of semantic representation and temporal evolution, which improves topic coherence and diversity while enhancing stability and interpretability over time. Experiments on real-world corpora show that the framework effectively captures the generation, expansion, and decline of topics and outperforms existing models across multiple metrics. Overall, the proposed method provides a systematic solution for understanding dynamic semantic patterns in large-scale text, enriches the research paradigm of topic modeling, and supports complex text analysis tasks in multiple domains.",
    "authors": [
      "Di Wu abd Shuaidong Pan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T13:50:41.000Z",
    "updatedAt": "2025-10-12T13:50:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10613v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10613v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10612v1",
    "arxivId": "2510.10612v1",
    "title": "UltraScatter: Ray-Based Simulation of Ultrasound Scattering",
    "abstract": "Traditional ultrasound simulation methods solve wave equations numerically, achieving high accuracy but at substantial computational cost. Faster alternatives based on convolution with precomputed impulse responses remain relatively slow, often requiring several minutes to generate a full B-mode image. We introduce UltraScatter, a probabilistic ray tracing framework that models ultrasound scattering efficiently and realistically. Tissue is represented as a volumetric field of scattering probability and scattering amplitude, and ray interactions are simulated via free-flight delta tracking. Scattered rays are traced to the transducer, with phase information incorporated through a linear time-of-flight model. Integrated with plane-wave imaging and beamforming, our parallelized ray tracing architecture produces B-mode images within seconds. Validation with phantom data shows realistic speckle and inclusion patterns, positioning UltraScatter as a scalable alternative to wave-based methods.",
    "authors": [
      "Felix Duelmer",
      "Mohammad Farid Azampour",
      "Nassir Navab"
    ],
    "categories": [
      "physics.med-ph",
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T13:48:46.000Z",
    "updatedAt": "2025-10-12T13:48:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10612v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10612v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10611v1",
    "arxivId": "2510.10611v1",
    "title": "HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication",
    "abstract": "Recent advances in large language model-powered multi-agent systems have demonstrated remarkable collective intelligence through effective communication. However, existing approaches face two primary challenges: (i) \\textit{Ineffective group collaboration modeling}, as they rely on pairwise edge representations in graph structures, limiting their ability to capture relationships among multiple agents; and (ii) \\textit{Limited task-adaptiveness in communication topology design}, leading to excessive communication cost for simple tasks and insufficient coordination for complex scenarios. These issues restrict the scalability and practical deployment of adaptive collaboration frameworks. To address these challenges, we propose \\textbf{HyperAgent}, a hypergraph-based framework that optimizes communication topologies and effectively captures group collaboration patterns using direct hyperedge representations. Unlike edge-based approaches, HyperAgent uses hyperedges to link multiple agents within the same subtask and employs hypergraph convolutional layers to achieve one-step information aggregation in collaboration groups. Additionally, it incorporates a variational autoencoder framework with sparsity regularization to dynamically adjust hypergraph topologies based on task complexity. Experiments highlight the superiority of HyperAgent in both performance and efficiency. For instance, on GSM8K, HyperAgent achieves 95.07\\% accuracy while reducing token consumption by 25.33\\%, demonstrating the potential of hypergraph-based optimization for multi-agent communication.",
    "authors": [
      "Heng Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Zijian Zhang",
      "Haochen You",
      "Lubin Gan",
      "Yilei Yuan",
      "Jin Huang"
    ],
    "categories": [
      "cs.MA",
      "cs.GR"
    ],
    "publishedAt": "2025-10-12T13:47:42.000Z",
    "updatedAt": "2025-10-12T13:47:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10611v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10611v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10609v1",
    "arxivId": "2510.10609v1",
    "title": "OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment",
    "abstract": "Current visual evaluation approaches are typically constrained to a single task. To address this, we propose OmniQuality-R, a unified reward modeling framework that transforms multi-task quality reasoning into continuous and interpretable reward signals for policy optimization. Inspired by subjective experiments, where participants are given task-specific instructions outlining distinct assessment principles prior to evaluation, we propose OmniQuality-R, a structured reward modeling framework that transforms multi-dimensional reasoning into continuous and interpretable reward signals. To enable this, we construct a reasoning-enhanced reward modeling dataset by sampling informative plan-reason trajectories via rejection sampling, forming a reliable chain-of-thought (CoT) dataset for supervised fine-tuning (SFT). Building on this, we apply Group Relative Policy Optimization (GRPO) for post-training, using a Gaussian-based reward to support continuous score prediction. To further stabilize the training and improve downstream generalization, we incorporate standard deviation (STD) filtering and entropy gating mechanisms during reinforcement learning. These techniques suppress unstable updates and reduce variance in policy optimization. We evaluate OmniQuality-R on three key IQA tasks: aesthetic quality assessment, technical quality evaluation, and text-image alignment.",
    "authors": [
      "Yiting Lu",
      "Fengbin Guan",
      "Yixin Gao",
      "Yan Zhong",
      "Xinge Peng",
      "Jiakang Yuan",
      "Yihao Liu",
      "Bo Zhang",
      "Xin Li",
      "Zhibo Chen",
      "Weisi Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T13:46:28.000Z",
    "updatedAt": "2025-10-12T13:46:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10609v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10609v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10606v1",
    "arxivId": "2510.10606v1",
    "title": "ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models",
    "abstract": "Typical post-training paradigms for Large Vision-and-Language Models (LVLMs) include Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR). SFT leverages external guidance to inject new knowledge, whereas RLVR utilizes internal reinforcement to enhance reasoning capabilities and overall performance. However, our analysis reveals that SFT often leads to sub-optimal performance, while RLVR struggles with tasks that exceed the model's internal knowledge base. To address these limitations, we propose ViSurf (\\textbf{Vi}sual \\textbf{Su}pervised-and-\\textbf{R}einforcement \\textbf{F}ine-Tuning), a unified post-training paradigm that integrates the strengths of both SFT and RLVR within a single stage. We analyze the derivation of the SFT and RLVR objectives to establish the ViSurf objective, providing a unified perspective on these two paradigms. The core of ViSurf involves injecting ground-truth labels into the RLVR rollouts, thereby providing simultaneous external supervision and internal reinforcement. Furthermore, we introduce three novel reward control strategies to stabilize and optimize the training process. Extensive experiments across several diverse benchmarks demonstrate the effectiveness of ViSurf, outperforming both individual SFT, RLVR, and two-stage SFT \\textrightarrow RLVR. In-depth analysis corroborates these findings, validating the derivation and design principles of ViSurf.",
    "authors": [
      "Yuqi Liu",
      "Liangyu Chen",
      "Jiazhen Liu",
      "Mingkang Zhu",
      "Zhisheng Zhong",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T13:42:55.000Z",
    "updatedAt": "2025-10-12T13:42:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10606v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10606v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10603v1",
    "arxivId": "2510.10603v1",
    "title": "EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms",
    "abstract": "In recent years, large language models (LLMs) have made remarkable progress, with model optimization primarily relying on gradient-based optimizers such as Adam. However, these gradient-based methods impose stringent hardware requirements, demanding high-concurrency, high-memory GPUs. Moreover, they require all neural network operations to be differentiable, thereby excluding many promising non-differentiable architectures from practical use. To address these limitations, we propose a method for optimizing LLMs using evolutionary algorithms (EA4LLM) and, for the first time, successfully demonstrate its capability to train a 1-billion-parameter LLM from the pre-trained stage. We conduct extensive experiments and provide key insights into how evolutionary algorithms can effectively optimize neural networks. Our work challenges the prevailing assumption that gradient-based optimization is the only viable approach for training neural networks. It also holds significant potential to reduce the computational cost of training large language models, thereby enabling groups with limited computational resources to participate in deep learning research.",
    "authors": [
      "WenTao Liu",
      "Siyu Song",
      "Hao Hao",
      "Aimin Zhou"
    ],
    "categories": [
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T13:38:28.000Z",
    "updatedAt": "2025-10-12T13:38:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10603v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10603v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10602v1",
    "arxivId": "2510.10602v1",
    "title": "SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams",
    "abstract": "Most robotic grasping systems rely on converting sensor data into explicit 3D point clouds, which is a computational step not found in biological intelligence. This paper explores a fundamentally different, neuro-inspired paradigm for 6-DoF grasp detection. We introduce SpikeGrasp, a framework that mimics the biological visuomotor pathway, processing raw, asynchronous events from stereo spike cameras, similarly to retinas, to directly infer grasp poses. Our model fuses these stereo spike streams and uses a recurrent spiking neural network, analogous to high-level visual processing, to iteratively refine grasp hypotheses without ever reconstructing a point cloud. To validate this approach, we built a large-scale synthetic benchmark dataset. Experiments show that SpikeGrasp surpasses traditional point-cloud-based baselines, especially in cluttered and textureless scenes, and demonstrates remarkable data efficiency. By establishing the viability of this end-to-end, neuro-inspired approach, SpikeGrasp paves the way for future systems capable of the fluid and efficient manipulation seen in nature, particularly for dynamic objects.",
    "authors": [
      "Zhuoheng Gao",
      "Jiyao Zhang",
      "Zhiyong Xie",
      "Hao Dong",
      "Zhaofei Yu",
      "Rongmei Chen",
      "Guozhang Chen",
      "Tiejun Huang"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T13:36:40.000Z",
    "updatedAt": "2025-10-12T13:36:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10602v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10602v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10597v1",
    "arxivId": "2510.10597v1",
    "title": "Fast Vision in the Dark: A Case for Single-Photon Imaging in Planetary Navigation",
    "abstract": "Improving robotic navigation is critical for extending exploration range and enhancing operational efficiency. Vision-based navigation relying on traditional CCD or CMOS cameras faces major challenges when complex illumination conditions are paired with motion, limiting the range and accessibility of mobile planetary robots. In this study, we propose a novel approach to planetary navigation that leverages the unique imaging capabilities of Single-Photon Avalanche Diode (SPAD) cameras. We present the first comprehensive evaluation of single-photon imaging as an alternative passive sensing technology for robotic exploration missions targeting perceptually challenging locations, with a special emphasis on high-latitude lunar regions. We detail the operating principles and performance characteristics of SPAD cameras, assess their advantages and limitations in addressing key perception challenges of upcoming exploration missions to the Moon, and benchmark their performance under representative illumination conditions.",
    "authors": [
      "David Rodríguez-Martínez",
      "C. J. Pérez del Pulgar"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T13:29:57.000Z",
    "updatedAt": "2025-10-12T13:29:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10597v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10597v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10596v1",
    "arxivId": "2510.10596v1",
    "title": "A Distance Measure for Random Permutation Set: From the Layer-2 Belief Structure Perspective",
    "abstract": "Random permutation set (RPS) is a recently proposed framework designed to represent order-structured uncertain information. Measuring the distance between permutation mass functions is a key research topic in RPS theory (RPST). This paper conducts an in-depth analysis of distances between RPSs from two different perspectives: random finite set (RFS) and transferable belief model (TBM). Adopting the layer-2 belief structure interpretation of RPS, we regard RPST as a refinement of TBM, where the order in the ordered focus set represents qualitative propensity. Starting from the permutation, we introduce a new definition of the cumulative Jaccard index to quantify the similarity between two permutations and further propose a distance measure method for RPSs based on the cumulative Jaccard index matrix. The metric and structural properties of the proposed distance measure are investigated, including the positive definiteness analysis of the cumulative Jaccard index matrix, and a correction scheme is provided. The proposed method has a natural top-weightiness property: inconsistencies between higher-ranked elements tend to result in greater distance values. Two parameters are provided to the decision-maker to adjust the weight and truncation depth. Several numerical examples are used to compare the proposed method with the existing method. The experimental results show that the proposed method not only overcomes the shortcomings of the existing method and is compatible with the Jousselme distance, but also has higher sensitivity and flexibility.",
    "authors": [
      "Ruolan Cheng",
      "Yong Deng",
      "Serafín Moral",
      "José Ramón Trillo"
    ],
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-12T13:29:23.000Z",
    "updatedAt": "2025-10-12T13:29:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10596v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10596v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10592v1",
    "arxivId": "2510.10592v1",
    "title": "A Layered Intuition -- Method Model with Scope Extension for LLM Reasoning",
    "abstract": "Existing studies have introduced method-based reasoning and scope extension as approaches to enhance Large Language Model (LLM) performance beyond direct matrix mappings. Building on these foundations, this paper summarizes and integrates these ideas into a unified Intuition-Method Layered Model with Scope Extension, designed to address indirected (unseen) issues more systematically. In this framework, intuition-based thinking provides rapid first-reaction answers, while method-based thinking decouples questions and solutions into transferable reasoning units. Scope extension is then applied to broaden applicability, including vertical (cause analysis), horizontal (parallel and generalized issues), and for the first time, temporal and spatial extensions, which expand reasoning across time and contextual dimensions. These extensions are organized into systematic knowledge trees that interconnect into a knowledge network, thereby increasing adaptability. To quantitatively evaluate this process, we propose the entropy of method extension, which measures the independence and diversity of extensions as an indicator of the system's capacity to solve unseen questions. By logically connecting existing approaches with new extensions and introducing an entropy-based evaluation framework, this work advances toward a more robust and extensible reasoning paradigm for LLMs in real-world problem-solving.",
    "authors": [
      "Hong Su"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-12T13:14:23.000Z",
    "updatedAt": "2025-10-12T13:14:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10592v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10592v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10588v1",
    "arxivId": "2510.10588v1",
    "title": "Making Power Explicable in AI: Analyzing, Understanding, and Redirecting Power to Operationalize Ethics in AI Technical Practice",
    "abstract": "The operationalization of ethics in the technical practices of artificial intelligence (AI) is facing significant challenges. To address the problem of ineffective implementation of AI ethics, we present our diagnosis, analysis, and interventional recommendations from a unique perspective of the real-world implementation of AI ethics through explainable AI (XAI) techniques. We first describe the phenomenon (i.e., the \"symptoms\") of ineffective implementation of AI ethics in explainable AI using four empirical cases. From the \"symptoms\", we diagnose the root cause (i.e., the \"disease\") being the dysfunction and imbalance of power structures in the sociotechnical system of AI. The power structures are dominated by unjust and unchecked power that does not represent the benefits and interests of the public and the most impacted communities, and cannot be countervailed by ethical power. Based on the understanding of power mechanisms, we propose three interventional recommendations to tackle the root cause, including: 1) Making power explicable and checked, 2) Reframing the narratives and assumptions of AI and AI ethics to check unjust power and reflect the values and benefits of the public, and 3) Uniting the efforts of ethical and scientific conduct of AI to encode ethical values as technical standards, norms, and methods, including conducting critical examinations and limitation analyses of AI technical practices. We hope that our diagnosis and interventional recommendations can be a useful input to the AI community and civil society's ongoing discussion and implementation of ethics in AI for ethical and responsible AI practice.",
    "authors": [
      "Weina Jin",
      "Elise Li Zheng",
      "Ghassan Hamarneh"
    ],
    "categories": [
      "cs.CY"
    ],
    "publishedAt": "2025-10-12T13:09:22.000Z",
    "updatedAt": "2025-10-12T13:09:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10588v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10588v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10587v1",
    "arxivId": "2510.10587v1",
    "title": "A Simple and Better Baseline for Visual Grounding",
    "abstract": "Visual grounding aims to predict the locations of target objects specified by textual descriptions. For this task with linguistic and visual modalities, there is a latest research line that focuses on only selecting the linguistic-relevant visual regions for object localization to reduce the computational overhead. Albeit achieving impressive performance, it is iteratively performed on different image scales, and at every iteration, linguistic features and visual features need to be stored in a cache, incurring extra overhead. To facilitate the implementation, in this paper, we propose a feature selection-based simple yet effective baseline for visual grounding, called FSVG. Specifically, we directly encapsulate the linguistic and visual modalities into an overall network architecture without complicated iterative procedures, and utilize the language in parallel as guidance to facilitate the interaction between linguistic modal and visual modal for extracting effective visual features. Furthermore, to reduce the computational cost, during the visual feature learning, we introduce a similarity-based feature selection mechanism to only exploit language-related visual features for faster prediction. Extensive experiments conducted on several benchmark datasets comprehensively substantiate that the proposed FSVG achieves a better balance between accuracy and efficiency beyond the current state-of-the-art methods. Code is available at https://github.com/jcwang0602/FSVG.",
    "authors": [
      "Jingchao Wang",
      "Wenlong Zhang",
      "Dingjiang Huang",
      "Hong Wang",
      "Yefeng Zheng"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T13:06:59.000Z",
    "updatedAt": "2025-10-12T13:06:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10587v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10587v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10586v1",
    "arxivId": "2510.10586v1",
    "title": "Compositional Symmetry as Compression: Lie Pseudogroup Structure in Algorithmic Agents",
    "abstract": "In the algorithmic (Kolmogorov) view, agents are programs that track and compress sensory streams using generative programs. We propose a framework where the relevant structural prior is simplicity (Solomonoff) understood as \\emph{compositional symmetry}: natural streams are well described by (local) actions of finite-parameter Lie pseudogroups on geometrically and topologically complex low-dimensional configuration manifolds (latent spaces). Modeling the agent as a generic neural dynamical system coupled to such streams, we show that accurate world-tracking imposes (i) \\emph{structural constraints} -- equivariance of the agent's constitutive equations and readouts -- and (ii) \\emph{dynamical constraints}: under static inputs, symmetry induces conserved quantities (Noether-style labels) in the agent dynamics and confines trajectories to reduced invariant manifolds; under slow drift, these manifolds move but remain low-dimensional. This yields a hierarchy of reduced manifolds aligned with the compositional factorization of the pseudogroup, providing a geometric account of the ``blessing of compositionality'' in deep models. We connect these ideas to the Spencer formalism for Lie pseudogroups and formulate a symmetry-based, self-contained version of predictive coding in which higher layers receive only \\emph{coarse-grained residual transformations} (prediction-error coordinates) along symmetry directions unresolved at lower layers.",
    "authors": [
      "Giulio Ruffini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "q-bio.NC"
    ],
    "publishedAt": "2025-10-12T13:06:37.000Z",
    "updatedAt": "2025-10-12T13:06:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10586v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10586v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10585v1",
    "arxivId": "2510.10585v1",
    "title": "D3MAS: Decompose, Deduce, and Distribute for Enhanced Knowledge Sharing in Multi-Agent Systems",
    "abstract": "Multi-agent systems powered by large language models exhibit strong capabilities in collaborative problem-solving. However, these systems suffer from substantial knowledge redundancy. Agents duplicate efforts in retrieval and reasoning processes. This inefficiency stems from a deeper issue: current architectures lack mechanisms to ensure agents share minimal sufficient information at each operational stage. Empirical analysis reveals an average knowledge duplication rate of 47.3\\% across agent communications. We propose D3MAS (Decompose, Deduce, and Distribute), a hierarchical coordination framework addressing redundancy through structural design rather than explicit optimization. The framework organizes collaboration across three coordinated layers. Task decomposition filters irrelevant sub-problems early. Collaborative reasoning captures complementary inference paths across agents. Distributed memory provides access to non-redundant knowledge. These layers coordinate through structured message passing in a unified heterogeneous graph. This cross-layer alignment ensures information remains aligned with actual task needs. Experiments on four challenging datasets show that D3MAS consistently improves reasoning accuracy by 8.7\\% to 15.6\\% and reduces knowledge redundancy by 46\\% on average.",
    "authors": [
      "Heng Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Yilei Yuan",
      "Jin Huang"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-12T13:01:41.000Z",
    "updatedAt": "2025-10-12T13:01:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10585v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10585v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10584v1",
    "arxivId": "2510.10584v1",
    "title": "Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection",
    "abstract": "Pre-trained vision foundation models have transformed many computer vision tasks. Despite their strong ability to learn discriminative and generalizable features crucial for out-of-distribution (OOD) detection, their impact on this task remains underexplored. Motivated by this gap, we systematically investigate representative vision foundation models for OOD detection. Our findings reveal that a pre-trained DINOv2 model, even without fine-tuning on in-domain (ID) data, naturally provides a highly discriminative feature space for OOD detection, achieving performance comparable to existing state-of-the-art methods without requiring complex designs. Beyond this, we explore how fine-tuning foundation models on in-domain (ID) data can enhance OOD detection. However, we observe that the performance of vision foundation models remains unsatisfactory in scenarios with a large semantic space. This is due to the increased complexity of decision boundaries as the number of categories grows, which complicates the optimization process. To mitigate this, we propose the Mixture of Feature Experts (MoFE) module, which partitions features into subspaces, effectively capturing complex data distributions and refining decision boundaries. Further, we introduce a Dynamic-$\\beta$ Mixup strategy, which samples interpolation weights from a dynamic beta distribution. This adapts to varying levels of learning difficulty across categories, improving feature learning for more challenging categories. Extensive experiments demonstrate the effectiveness of our approach, significantly outperforming baseline methods.",
    "authors": [
      "Shizhen Zhao",
      "Jiahui Liu",
      "Xin Wen",
      "Haoru Tan",
      "Xiaojuan Qi"
    ],
    "categories": [
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T13:00:53.000Z",
    "updatedAt": "2025-10-12T13:00:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10584v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10584v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10581v1",
    "arxivId": "2510.10581v1",
    "title": "GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search",
    "abstract": "Multi-agent systems powered by Large Language Models excel at complex tasks through coordinated collaboration, yet they face high failure rates in multi-turn deep search scenarios. Existing temporal attribution methods struggle to accurately diagnose root causes, particularly when errors propagate across multiple agents. Attempts to automate failure attribution by analyzing action sequences remain ineffective due to their inability to account for information dependencies that span agents. This paper identifies two core challenges: \\textit{(i) distinguishing symptoms from root causes in multi-agent error propagation}, and \\textit{(ii) tracing information dependencies beyond temporal order}. To address these issues, we introduce \\textbf{GraphTracer}, a framework that redefines failure attribution through information flow analysis. GraphTracer constructs Information Dependency Graphs (IDGs) to explicitly capture how agents reference and build on prior outputs. It localizes root causes by tracing through these dependency structures instead of relying on temporal sequences. GraphTracer also uses graph-aware synthetic data generation to target critical nodes, creating realistic failure scenarios. Evaluations on the Who\\&When benchmark and integration into production systems demonstrate that GraphTracer-8B achieves up to 18.18\\% higher attribution accuracy compared to state-of-the-art models and enables 4.8\\% to 14.2\\% performance improvements in deployed multi-agent frameworks, establishing a robust solution for multi-agent system debugging.",
    "authors": [
      "Heng Zhang",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Yilei Yuan",
      "Jin Huang"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-12T12:55:42.000Z",
    "updatedAt": "2025-10-12T12:55:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10581v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10581v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10570v1",
    "arxivId": "2510.10570v1",
    "title": "Multitask Learning with Learned Task Relationships",
    "abstract": "Classical consensus-based strategies for federated and decentralized learning are statistically suboptimal in the presence of heterogeneous local data or task distributions. As a result, in recent years, there has been growing interest in multitask or personalized strategies, which allow individual agents to benefit from one another in pursuing locally optimal models without enforcing consensus. Existing strategies require either precise prior knowledge of the underlying task relationships or are fully non-parametric and instead rely on meta-learning or proximal constructions. In this work, we introduce an algorithmic framework that strikes a balance between these extremes. By modeling task relationships through a Gaussian Markov Random Field with an unknown precision matrix, we develop a strategy that jointly learns both the task relationships and the local models, allowing agents to self-organize in a way consistent with their individual data distributions. Our theoretical analysis quantifies the quality of the learned relationship, and our numerical experiments demonstrate its practical effectiveness.",
    "authors": [
      "Zirui Wan",
      "Stefan Vlaski"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.MA"
    ],
    "publishedAt": "2025-10-12T12:42:19.000Z",
    "updatedAt": "2025-10-12T12:42:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10570v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10570v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10567v1",
    "arxivId": "2510.10567v1",
    "title": "Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving",
    "abstract": "Sampling-based trajectory planners are widely used for agile autonomous driving due to their ability to generate fast, smooth, and kinodynamically feasible trajectories. However, their behavior is often governed by a cost function with manually tuned, static weights, which forces a tactical compromise that is suboptimal across the wide range of scenarios encountered in a race. To address this shortcoming, we propose using a Reinforcement Learning (RL) agent as a high-level behavioral selector that dynamically switches the cost function parameters of an analytical, low-level trajectory planner during runtime. We show the effectiveness of our approach in simulation in an autonomous racing environment where our RL-based planner achieved 0% collision rate while reducing overtaking time by up to 60% compared to state-of-the-art static planners. Our new agent now dynamically switches between aggressive and conservative behaviors, enabling interactive maneuvers unattainable with static configurations. These results demonstrate that integrating reinforcement learning as a high-level selector resolves the inherent trade-off between safety and competitiveness in autonomous racing planners. The proposed methodology offers a pathway toward adaptive yet interpretable motion planning for broader autonomous driving applications.",
    "authors": [
      "Alexander Langmann",
      "Yevhenii Tokarev",
      "Mattia Piccinini",
      "Korbinian Moller",
      "Johannes Betz"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T12:30:12.000Z",
    "updatedAt": "2025-10-12T12:30:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10567v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10567v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10552v1",
    "arxivId": "2510.10552v1",
    "title": "Transforming Tarlac State University (TSU) Gymnasium to a Nearly Zero-Energy Building through Integration of a Solar Photovoltaic (PV) System",
    "abstract": "The study is anchored to the principles of Nearly-Zero Energy Building (NZEB). It aimed to transform the Tarlac State University Gymnasium into a facility with energy-efficient equipment to contribute to reducing carbon footprints by integrating a solar PV system as its renewable energy source. The researchers found out that the electrical infrastructure of the Gym was outdated, and the lighting was not energy efficient, and there were too few convenience or power outlets. There was also insufficient cooling equipment to maintain a comfortable temperature. Analysis shows that the payback period is within the average range, making it a cost-effective investment for the University. Aside from the cost of the PV System, adherence to engineering design standards will mean additional costs to replace the metal halides with LED high bay lamps, installation of additional air conditioning units, and provision of additional convenience outlets. These additional costs should be considered when evaluating the feasibility of the project. It is recommended that the integrity of the existing roof system of the Gymnasium be considered. The total cost of putting up the whole electrical system, including new lighting, cooling, and convenience loads, must be calculated to determine the total cost of implementing the whole NZEB project. Other factors in the economic evaluation may be considered to determine a more stringent result.",
    "authors": [
      "Rafael R. Yumul",
      "Enalyn T. Domingo"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-12T11:35:36.000Z",
    "updatedAt": "2025-10-12T11:35:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10552v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10552v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10551v1",
    "arxivId": "2510.10551v1",
    "title": "How Students Use Generative AI for Software Testing: An Observational Study",
    "abstract": "The integration of generative AI tools like ChatGPT into software engineering workflows opens up new opportunities to boost productivity in tasks such as unit test engineering. However, these AI-assisted workflows can also significantly alter the developer's role, raising concerns about control, output quality, and learning, particularly for novice developers. This study investigates how novice software developers with foundational knowledge in software testing interact with generative AI for engineering unit tests. Our goal is to examine the strategies they use, how heavily they rely on generative AI, and the benefits and challenges they perceive when using generative AI-assisted approaches for test engineering. We conducted an observational study involving 12 undergraduate students who worked with generative AI for unit testing tasks. We identified four interaction strategies, defined by whether the test idea or the test implementation originated from generative AI or the participant. Additionally, we singled out prompting styles that focused on one-shot or iterative test generation, which often aligned with the broader interaction strategy. Students reported benefits including time-saving, reduced cognitive load, and support for test ideation, but also noted drawbacks such as diminished trust, test quality concerns, and lack of ownership. While strategy and prompting styles influenced workflow dynamics, they did not significantly affect test effectiveness or test code quality as measured by mutation score or test smells.",
    "authors": [
      "Baris Ardic",
      "Quentin Le Dilavrec",
      "Andy Zaidman"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-12T11:31:41.000Z",
    "updatedAt": "2025-10-12T11:31:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10551v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10551v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10545v1",
    "arxivId": "2510.10545v1",
    "title": "Decoupled Scaling 4ch Bilateral Control on the Cartesian coordinate by 6-DoF Manipulator using Rotation Matrix",
    "abstract": "Four-channel bilateral control is a method for achieving remote control with force feedback and adjustment operability by synchronizing the positions and forces of two manipulators. This is expected to significantly improve the operability of the remote control in contact-rich tasks. Among these, 4-channel bilateral control on the Cartesian coordinate system is advantageous owing to its suitability for manipulators with different structures and because it allows the dynamics in the Cartesian coordinate system to be adjusted by adjusting the control parameters, thus achieving intuitive operability for humans. This paper proposes a 4-channel bilateral control method that achieves the desired dynamics by decoupling each dimension in the Cartesian coordinate system regardless of the scaling factor.",
    "authors": [
      "Koki Yamane",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T11:03:37.000Z",
    "updatedAt": "2025-10-12T11:03:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10545v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10545v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10531v1",
    "arxivId": "2510.10531v1",
    "title": "A Verified High-Performance Composable Object Library for Remote Direct Memory Access (Extended Version)",
    "abstract": "Remote Direct Memory Access (RDMA) is a memory technology that allows remote devices to directly write to and read from each other's memory, bypassing components such as the CPU and operating system. This enables low-latency high-throughput networking, as required for many modern data centres, HPC applications and AI/ML workloads. However, baseline RDMA comprises a highly permissive weak memory model that is difficult to use in practice and has only recently been formalised. In this paper, we introduce the Library of Composable Objects (LOCO), a formally verified library for building multi-node objects on RDMA, filling the gap between shared memory and distributed system programming. LOCO objects are well-encapsulated and take advantage of the strong locality and the weak consistency characteristics of RDMA. They have performance comparable to custom RDMA systems (e.g. distributed maps), but with a far simpler programming model amenable to formal proofs of correctness. To support verification, we develop a novel modular declarative verification framework, called Mowgli, that is flexible enough to model multinode objects and is independent of a memory consistency model. We instantiate Mowgli with the RDMA memory model, and use it to verify correctness of LOCO libraries.",
    "authors": [
      "Guillaume Ambal",
      "George Hodgkins",
      "Mark Madler",
      "Gregory Chockler",
      "Brijesh Dongol",
      "Joseph Izraelevitz",
      "Azalea Raad",
      "Viktor Vafeiadis"
    ],
    "categories": [
      "cs.PL",
      "cs.DC",
      "cs.LO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T10:12:16.000Z",
    "updatedAt": "2025-10-12T10:12:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10531v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10531v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10520v1",
    "arxivId": "2510.10520v1",
    "title": "AI-Agents for Culturally Diverse Online Higher Education Environments",
    "abstract": "As the global reach of online higher education continues to grow, universities are increasingly accommodating students from diverse cultural backgrounds \\parencite{tereshko2024culturally}. This can present a number of challenges including linguistic barriers \\parencite{ullah2021linguistic}, cultural differences in learning style \\parencite{omidvar2012cultural}, cultural sensitivity in course design \\parencite{nguyen2022cultural} and perceived isolation when students feel their perspectives or experiences are not reflected or valued in the learning environment \\parencite{hansen2022belonging}. Ensuring active engagement and reasonable learning outcomes in such a environments requires distance educational systems that are not only adaptive but also culturally resonant \\parencite{dalle2024cultural}. Both embodied and virtual AI-Agents have great potential in this regard as they can facilitate personalized learning and adapt their interactions and content delivery to align with students' cultural context. In addition Generative AI (GAI), such as, Large Language Models (LLMs) can amplify the potential for these culturally aware AI agents to address educational challenges due to their advanced capacity for understanding and generating contextually relevant content \\parencite{wang2024large}. This chapter reviews existing research and suggests the usage of culturally aware AI-Agents, powered by GAI, to foster engagement and improve learning outcomes in culturally diverse online higher education environments.",
    "authors": [
      "Fuze Sun",
      "Paul Craig",
      "Lingyu Li",
      "Shixiangyue Meng",
      "Chuxi Nan"
    ],
    "categories": [
      "cs.CY",
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T09:42:09.000Z",
    "updatedAt": "2025-10-12T09:42:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10520v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10520v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10517v1",
    "arxivId": "2510.10517v1",
    "title": "ECO: Enhanced Code Optimization via Performance-Aware Prompting for Code-LLMs",
    "abstract": "Code runtime optimization-the task of rewriting a given code to a faster one-remains challenging, as it requires reasoning about performance trade-offs involving algorithmic and structural choices. Recent approaches employ code-LLMs with slow-fast code pairs provided as optimization guidance, but such pair-based methods obscure the causal factors of performance gains and often lead to superficial pattern imitation rather than genuine performance reasoning. We introduce ECO, a performance-aware prompting framework for code optimization. ECO first distills runtime optimization instructions (ROIs) from reference slow-fast code pairs; Each ROI describes root causes of inefficiency and the rationales that drive performance improvements. For a given input code, ECO in parallel employs (i) a symbolic advisor to produce a bottleneck diagnosis tailored to the code, and (ii) an ROI retriever to return related ROIs. These two outputs are then composed into a performance-aware prompt, providing actionable guidance for code-LLMs. ECO's prompts are model-agnostic, require no fine-tuning, and can be easily prepended to any code-LLM prompt. Our empirical studies highlight that ECO prompting significantly improves code-LLMs' ability to generate efficient code, achieving speedups of up to 7.81x while minimizing correctness loss.",
    "authors": [
      "Su-Hyeon Kim",
      "Joonghyuk Hahn",
      "Sooyoung Cha",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.SE"
    ],
    "publishedAt": "2025-10-12T09:29:24.000Z",
    "updatedAt": "2025-10-12T09:29:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10517v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10517v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10516v1",
    "arxivId": "2510.10516v1",
    "title": "Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control",
    "abstract": "Energy-efficient and high-performance motor control remains a critical challenge in robotics, particularly for high-dimensional continuous control tasks with limited onboard resources. While Deep Reinforcement Learning (DRL) has achieved remarkable results, its computational demands and energy consumption limit deployment in resource-constrained environments. This paper introduces a novel framework combining population-coded Spiking Neural Networks (SNNs) with DRL to address these challenges. Our approach leverages the event-driven, asynchronous computation of SNNs alongside the robust policy optimization capabilities of DRL, achieving a balance between energy efficiency and control performance. Central to this framework is the Population-coded Spiking Actor Network (PopSAN), which encodes high-dimensional observations into neuronal population activities and enables optimal policy learning through gradient-based updates. We evaluate our method on the Isaac Gym platform using the PixMC benchmark with complex robotic manipulation tasks. Experimental results on the Franka robotic arm demonstrate that our approach achieves energy savings of up to 96.10% compared to traditional Artificial Neural Networks (ANNs) while maintaining comparable control performance. The trained SNN policies exhibit robust finger position tracking with minimal deviation from commanded trajectories and stable target height maintenance during pick-and-place operations. These results position population-coded SNNs as a promising solution for energy-efficient, high-performance robotic control in resource-constrained applications, paving the way for scalable deployment in real-world robotics systems.",
    "authors": [
      "Kanishkha Jaisankar",
      "Xiaoyang Jiang",
      "Feifan Liao",
      "Jeethu Sreenivas Amuthan"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T09:27:25.000Z",
    "updatedAt": "2025-10-12T09:27:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10516v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10516v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10509v1",
    "arxivId": "2510.10509v1",
    "title": "MARS-Sep: Multimodal-Aligned Reinforced Sound Separation",
    "abstract": "Universal sound separation faces a fundamental misalignment: models optimized for low-level signal metrics often produce semantically contaminated outputs, failing to suppress perceptually salient interference from acoustically similar sources. To bridge this gap, we introduce MARS-Sep, a reinforcement learning framework that reformulates separation as decision making. Instead of simply regressing ground-truth masks, MARS-Sep learns a factorized Beta mask policy that is optimized by a clipped trust-region surrogate with entropy regularization and group-relative advantage normalization. Concretely, we sample masks from a frozen old policy, reconstruct waveforms, and update the current policy using clipped importance ratios-yielding substantially more stable and sample-efficient learning. Multimodal rewards, derived from an audio-text-vision encoder, directly incentivize semantic consistency with query prompts. We further propose a progressive alignment scheme to fine-tune this encoder, boosting its cross-modal discriminability and improving reward faithfulness. Extensive experiments on multiple benchmarks demonstrate consistent gains in Text-, Audio-, and Image-Queried separation, with notable improvements in signal metrics and semantic quality. Our code is available at https://anonymous.4open.science/r/MARS-Sep. Sound separation samples are available at https://mars-sep.github.io/.",
    "authors": [
      "Zihan Zhang",
      "Xize Cheng",
      "Zhennan Jiang",
      "Dongjie Fu",
      "Jingyuan Chen",
      "Zhou Zhao",
      "Tao Jin"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T09:05:28.000Z",
    "updatedAt": "2025-10-12T09:05:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10509v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10509v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10506v1",
    "arxivId": "2510.10506v1",
    "title": "SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception",
    "abstract": "Efficient exploration and mapping in unknown indoor environments is a fundamental challenge, with high stakes in time-critical settings. In current systems, robot perception remains confined to line-of-sight; occluded regions remain unknown until physically traversed, leading to inefficient exploration when layouts deviate from prior assumptions. In this work, we bring non-line-of-sight (NLOS) sensing to robotic exploration. We leverage single-photon LiDARs, which capture time-of-flight histograms that encode the presence of hidden objects - allowing robots to look around blind corners. Recent single-photon LiDARs have become practical and portable, enabling deployment beyond controlled lab settings. Prior NLOS works target 3D reconstruction in static, lab-based scenarios, and initial efforts toward NLOS-aided navigation consider simplified geometries. We introduce SuperEx, a framework that integrates NLOS sensing directly into the mapping-exploration loop. SuperEx augments global map prediction with beyond-line-of-sight cues by (i) carving empty NLOS regions from timing histograms and (ii) reconstructing occupied structure via a two-step physics-based and data-driven approach that leverages structural regularities. Evaluations on complex simulated maps and the real-world KTH Floorplan dataset show a 12% gain in mapping accuracy under < 30% coverage and improved exploration efficiency compared to line-of-sight baselines, opening a path to reliable mapping beyond direct visibility.",
    "authors": [
      "Kush Garg",
      "Akshat Dave"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-12T08:52:20.000Z",
    "updatedAt": "2025-10-12T08:52:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10506v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10506v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10503v1",
    "arxivId": "2510.10503v1",
    "title": "Align2Act: Instruction-Tuned Models for Human-Aligned Autonomous Driving",
    "abstract": "Motion planning in complex scenarios is a core challenge in autonomous driving. Conventional methods apply predefined rules or learn from driving data to generate trajectories, while recent approaches leverage large language models (LLMs) for decision-making. However, it remains unclear whether LLMs truly capture human driving logic. We propose Align2Act, a motion planning framework that transforms instruction-tuned LLMs into interpretable planners aligned with human behavior. We derive structured driving instructions based on human reasoning patterns (e.g., anticipate hazards, yield at intersections) and traffic rules (e.g., stop at red lights, maintain lane boundaries). Our Align2ActChain module guides step-by-step reasoning to produce both an interpretable rationale and a safe trajectory. By fine-tuning LLaMA-2-7B with LoRA on one million scenarios from the nuPlan dataset, our method achieves an open-loop score of 85.17 and closed-loop scores of 70.31 (non-reactive) and 66.96 (reactive) on Test14-random. Unlike prior work focused on synthetic or open-loop settings, we demonstrate improved planning quality and human-likeness on the real-world nuPlan closed-loop benchmark. Ablation studies confirm that structured reasoning significantly improves performance over baseline LLM planners.",
    "authors": [
      "Kanishkha Jaisankar",
      "Sunidhi Tandel"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T08:50:34.000Z",
    "updatedAt": "2025-10-12T08:50:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10503v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10503v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10499v1",
    "arxivId": "2510.10499v1",
    "title": "Preserving Core Structures of Social Networks via Information Guided Multi-Step Graph Pruning",
    "abstract": "Social networks often contain dense and overlapping connections that obscure their essential interaction patterns, making analysis and interpretation challenging. Identifying the structural backbone of such networks is crucial for understanding community organization, information flow, and functional relationships. This study introduces a multi-step network pruning framework that leverages principles from information theory to balance structural complexity and task-relevant information. The framework iteratively evaluates and removes edges from the graph based on their contribution to task-relevant mutual information, producing a trajectory of network simplification that preserves most of the inherent semantics. Motivated by gradient boosting, we propose IGPrune, which enables efficient, differentiable optimization to progressively uncover semantically meaningful connections. Extensive experiments on social and biological networks show that IGPrune retains critical structural and functional patterns. Beyond quantitative performance, the pruned networks reveal interpretable backbones, highlighting the method's potential to support scientific discovery and actionable insights in real-world networks.",
    "authors": [
      "Yutong Hu",
      "Bingxin Zhou",
      "Jing Wang",
      "Weishu Zhao",
      "Liang Hong"
    ],
    "categories": [
      "cs.SI",
      "cs.IT",
      "math.IT"
    ],
    "publishedAt": "2025-10-12T08:38:36.000Z",
    "updatedAt": "2025-10-12T08:38:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10499v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10499v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10496v1",
    "arxivId": "2510.10496v1",
    "title": "Personalized Motion Guidance Framework for Athlete-Centric Coaching",
    "abstract": "A critical challenge in contemporary sports science lies in filling the gap between group-level insights derived from controlled hypothesis-driven experiments and the real-world need for personalized coaching tailored to individual athletes' unique movement patterns. This study developed a Personalized Motion Guidance Framework (PMGF) to enhance athletic performance by generating individualized motion-refinement guides using generative artificial intelligence techniques. PMGF leverages a vertical autoencoder to encode motion sequences into athlete-specific latent representations, which can then be directly manipulated to generate meaningful guidance motions. Two manipulation strategies were explored: (1) smooth interpolation between the learner's motion and a target (e.g., expert) motion to facilitate observational learning, and (2) shifting the motion pattern in an optimal direction in the latent space using a local optimization technique. The results of the validation experiment with data from 51 baseball pitchers revealed that (1) PMGF successfully generated smooth transitions in motion patterns between individuals across all 1,275 pitcher pairs, and (2) the features significantly altered through PMGF manipulations reflected known performance-enhancing characteristics, such as increased stride length and knee extension associated with higher ball velocity, indicating that PMGF induces biomechanically plausible improvements. We propose a future extension called general-PMGF to enhance the applicability of this framework. This extension incorporates bodily, environmental, and task constraints into the generation process, aiming to provide more realistic and versatile guidance across diverse sports contexts.",
    "authors": [
      "Ryota Takamidoa",
      "Chiharu Suzukia",
      "Hiroki Nakamoto"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "68T99",
      "J.3; H.4"
    ],
    "publishedAt": "2025-10-12T08:21:19.000Z",
    "updatedAt": "2025-10-12T08:21:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10496v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10496v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10484v1",
    "arxivId": "2510.10484v1",
    "title": "CAPSim: A Fast CPU Performance Simulator Using Attention-based Predictor",
    "abstract": "CPU simulators are vital for computer architecture research, primarily for estimating performance under different programs. This poses challenges for fast and accurate simulation of modern CPUs, especially in multi-core systems. Modern CPU peformance simulators such as GEM5 adopt the cycle-accurate and event-driven approach, which is timeconsuming to simulate the extensive microarchitectural behavior of a real benchmark running on out-of-order CPUs. Recently, machine leaning based approach has been proposed to improve simulation speed, but they are currently limited to estimating the cycles of basic blocks rather than the complete benchmark program. This paper introduces a novel ML-based CPU simulator named CAPSim, which uses an attention-based neural network performance predictor and instruction trace sampling method annotated with context. The attention mechanism effectively captures long-range influence within the instruction trace, emphasizing critical context information. This allows the model to improve performance prediction accuracy by focusing on important code instruction. CAPSim can predict the execution time of unseen benchmarks at a significantly fast speed compared with an accurate O3 simulator built with gem5. Our evaluation on a commercial Intel Xeon CPU demonstrates that CAPSim achieves a 2.2 - 8.3x speedup compared to using gem5 built simulator, which is superior to the cutting-edge deep learning approach",
    "authors": [
      "Buqing Xu",
      "Jianfeng Zhu",
      "Yichi Zhang",
      "Qinyi Cai",
      "Guanhua Li",
      "Shaojun Wei",
      "Leibo Liu"
    ],
    "categories": [
      "cs.PF"
    ],
    "publishedAt": "2025-10-12T07:32:07.000Z",
    "updatedAt": "2025-10-12T07:32:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10484v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10484v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10468v1",
    "arxivId": "2510.10468v1",
    "title": "Galilean Symmetry in Robotics",
    "abstract": "Galilean symmetry is the natural symmetry of inertial motion that underpins Newtonian physics. Although rigid-body symmetry is one of the most established and fundamental tools in robotics, there appears to be no comparable treatment of Galilean symmetry for a robotics audience. In this paper, we present a robotics-tailored exposition of Galilean symmetry that leverages the community's familiarity with and understanding of rigid-body transformations and pose representations. Our approach contrasts with common treatments in the physics literature that introduce Galilean symmetry as a stepping stone to Einstein's relativity. A key insight is that the Galilean matrix Lie group can be used to describe two different pose representations, Galilean frames, that use inertial velocity in the state definition, and extended poses, that use coordinate velocity. We provide three examples where applying the Galilean matrix Lie-group algebra to robotics problems is straightforward and yields significant insights: inertial navigation above the rotating Earth, manipulator kinematics, and sensor data fusion under temporal uncertainty. We believe that the time is right for the robotics community to benefit from rediscovering and extending this classical material and applying it to modern problems.",
    "authors": [
      "Robert Mahony",
      "Jonathan Kelly",
      "Stephan Weiss"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T06:24:03.000Z",
    "updatedAt": "2025-10-12T06:24:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10468v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10468v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10460v1",
    "arxivId": "2510.10460v1",
    "title": "Testing and Enhancing Multi-Agent Systems for Robust Code Generation",
    "abstract": "Multi-agent systems (MASs) have emerged as a promising paradigm for automated code generation, demonstrating impressive performance on established benchmarks by decomposing complex coding tasks across specialized agents with different roles. Despite their prosperous development and adoption, their robustness remains pressingly under-explored, raising critical concerns for real-world deployment. This paper presents the first comprehensive study examining the robustness of MASs for code generation through a fuzzing-based testing approach. By designing a fuzzing pipeline incorporating semantic-preserving mutation operators and a novel fitness function, we assess mainstream MASs across multiple datasets and LLMs. Our findings reveal substantial robustness flaws of various popular MASs: they fail to solve 7.9%-83.3% of problems they initially resolved successfully after applying the semantic-preserving mutations. Through comprehensive failure analysis, we identify a common yet largely overlooked cause of the robustness issue: miscommunications between planning and coding agents, where plans lack sufficient detail and coding agents misinterpret intricate logic, aligning with the challenges inherent in a multi-stage information transformation process. Accordingly, we also propose a repairing method that encompasses multi-prompt generation and introduces a new monitor agent to address this issue. Evaluation shows that our repairing method effectively enhances the robustness of MASs by solving 40.0%-88.9% of identified failures. Our work uncovers critical robustness flaws in MASs and provides effective mitigation strategies, contributing essential insights for developing more reliable MASs for code generation.",
    "authors": [
      "Zongyi Lyu",
      "Songqiang Chen",
      "Zhenlan Ji",
      "Liwen Wang",
      "Shuai Wang",
      "Daoyuan Wu",
      "Wenxuan Wang",
      "Shing-Chi Cheung"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-12T05:45:04.000Z",
    "updatedAt": "2025-10-12T05:45:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10460v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10460v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10455v1",
    "arxivId": "2510.10455v1",
    "title": "Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds",
    "abstract": "Quadrupedal robots exhibit a wide range of viable gaits, but generating specific footfall sequences often requires laborious expert tuning of numerous variables, such as touch-down and lift-off events and holonomic constraints for each leg. This paper presents a unified reinforcement learning framework for generating versatile quadrupedal gaits by leveraging the intrinsic symmetries and velocity-period relationship of dynamic legged systems. We propose a symmetry-guided reward function design that incorporates temporal, morphological, and time-reversal symmetries. By focusing on preserved symmetries and natural dynamics, our approach eliminates the need for predefined trajectories, enabling smooth transitions between diverse locomotion patterns such as trotting, bounding, half-bounding, and galloping. Implemented on the Unitree Go2 robot, our method demonstrates robust performance across a range of speeds in both simulations and hardware tests, significantly improving gait adaptability without extensive reward tuning or explicit foot placement control. This work provides insights into dynamic locomotion strategies and underscores the crucial role of symmetries in robotic gait design.",
    "authors": [
      "Jiayu Ding",
      "Xulin Chen",
      "Garrett E. Katz",
      "Zhenyu Gan"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T05:25:49.000Z",
    "updatedAt": "2025-10-12T05:25:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10455v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10455v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10450v1",
    "arxivId": "2510.10450v1",
    "title": "Controller for Incremental Input-to-State Practical Stabilization of Partially Unknown systems with Invariance Guarantees",
    "abstract": "Incremental stability is a property of dynamical systems that ensures the convergence of trajectories with respect to each other rather than a fixed equilibrium point or a fixed trajectory. In this paper, we introduce a related stability notion called incremental input-to-state practical stability ({\\delta}-ISpS), ensuring safety guarantees. We also present a feedback linearization based control design scheme that renders a partially unknown system incrementally input-to-state practically stable and safe with formal guarantees. To deal with the unknown dynamics, we utilize Gaussian process regression to approximate the model. Finally, we implement the controller synthesized by the proposed scheme on a manipulator example",
    "authors": [
      "P Sangeerth",
      "David Smith Sundarsingh",
      "Bhabani Shankar Dey",
      "Pushpak Jagtap"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-12T05:06:33.000Z",
    "updatedAt": "2025-10-12T05:06:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10450v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10450v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10442v1",
    "arxivId": "2510.10442v1",
    "title": "Risk-Budgeted Control Framework for Balanced Performance and Safety in Autonomous Vehicles",
    "abstract": "This paper presents a risk-budgeted monitor with a control framework that certifies safety for autonomous driving. In this process, a sliding window is proposed to monitor for insufficient barrier residuals or nonzero tail risk, ensuring system safety. When the safety margin deteriorates, it triggers switching the safety constraint from a performance-based relaxed-control barrier function (R-CBF) to a conservative conditional value at risk (CVaR-CBF) to address the safety concern. This switching is governed by two real-time triggers: Feasibility-Triggered (FT) and Quality-Triggered (QT) conditions. In the FT condition, if the R-CBF constraint becomes infeasible or yields a suboptimal solution, the risk monitor triggers the use of the CVaR constraints for the controller. In the QT condition, the risk monitor observes the safety margin of the R-CBF solution at every step, regardless of feasibility. If it falls below the safety margin, the safety filter switches to the CVaR-CBF constraints. The proposed framework is evaluated using a model predictive controller (MPC) for autonomous driving in the presence of autonomous vehicle (AV) localization noise and obstacle position uncertainties. Multiple AV-pedestrian interaction scenarios are considered, with 1,500 Monte Carlo runs conducted for all scenarios. In the most challenging setting with pedestrian detection uncertainty of 5 m, the proposed framework achieves a 94-96% success rate of not colliding with the pedestrians over 300 trials while maintaining the lowest mean cross-track error (CTE = 3.2-3.6 m) to the reference path. The reduced CTE indicates faster trajectory recovery after obstacle avoidance, demonstrating a balance between safety and performance.",
    "authors": [
      "Pei Yu Chang",
      "Vishnu Renganathan",
      "Qadeer Ahmed"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-12T04:24:23.000Z",
    "updatedAt": "2025-10-12T04:24:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10442v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10442v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10434v1",
    "arxivId": "2510.10434v1",
    "title": "MonoSE(3)-Diffusion: A Monocular SE(3) Diffusion Framework for Robust Camera-to-Robot Pose Estimation",
    "abstract": "We propose MonoSE(3)-Diffusion, a monocular SE(3) diffusion framework that formulates markerless, image-based robot pose estimation as a conditional denoising diffusion process. The framework consists of two processes: a visibility-constrained diffusion process for diverse pose augmentation and a timestep-aware reverse process for progressive pose refinement. The diffusion process progressively perturbs ground-truth poses to noisy transformations for training a pose denoising network. Importantly, we integrate visibility constraints into the process, ensuring the transformations remain within the camera field of view. Compared to the fixed-scale perturbations used in current methods, the diffusion process generates in-view and diverse training poses, thereby improving the network generalization capability. Furthermore, the reverse process iteratively predicts the poses by the denoising network and refines pose estimates by sampling from the diffusion posterior of current timestep, following a scheduled coarse-to-fine procedure. Moreover, the timestep indicates the transformation scales, which guide the denoising network to achieve more accurate pose predictions. The reverse process demonstrates higher robustness than direct prediction, benefiting from its timestep-aware refinement scheme. Our approach demonstrates improvements across two benchmarks (DREAM and RoboKeyGen), achieving a notable AUC of 66.75 on the most challenging dataset, representing a 32.3% gain over the state-of-the-art.",
    "authors": [
      "Kangjian Zhu",
      "Haobo Jiang",
      "Yigong Zhang",
      "Jianjun Qian",
      "Jian Yang",
      "Jin Xie"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T03:57:30.000Z",
    "updatedAt": "2025-10-12T03:57:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10434v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10434v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10431v1",
    "arxivId": "2510.10431v1",
    "title": "Explicit Min-wise Hash Families with Optimal Size",
    "abstract": "We study explicit constructions of min-wise hash families and their extension to $k$-min-wise hash families. Informally, a min-wise hash family guarantees that for any fixed subset $X\\subseteq[N]$, every element in $X$ has an equal chance to have the smallest value among all elements in $X$; a $k$-min-wise hash family guarantees this for every subset of size $k$ in $X$. Min-wise hash is widely used in many areas of computer science such as sketching, web page detection, and $\\ell_0$ sampling. The classical works by Indyk and P\\u{a}tra\\c{s}cu and Thorup have shown $\\Theta(\\log(1/\\delta))$-wise independent families give min-wise hash of multiplicative (relative) error $\\delta$, resulting in a construction with $\\Theta(\\log(1/\\delta)\\log N)$ random bits. Based on a reduction from pseudorandom generators for combinatorial rectangles by Saks, Srinivasan, Zhou and Zuckerman, Gopolan and Yehudayoff improved the number of bits to $O(\\log N\\log\\log N)$ for polynomially small errors $\\delta$. However, no construction with $O(\\log N)$ bits (polynomial size family) and sub-constant error was known before. In this work, we continue and extend the study of constructing ($k$-)min-wise hash families from pseudorandomness for combinatorial rectangles and read-once branching programs. Our main result gives the first explicit min-wise hash families that use an optimal (up to constant) number of random bits and achieve a sub-constant (in fact, almost polynomially small) error, specifically, an explicit family of $k$-min-wise hash with $O(k\\log N)$ bits and $2^{-O(\\log N/\\log\\log N)}$ error. This improves all previous results for any $k=\\log^{O(1)}N$ under $O(k \\log N)$ bits. Our main techniques involve several new ideas to adapt the classical Nisan-Zuckerman pseudorandom generator to fool min-wise hashing with a multiplicative error.",
    "authors": [
      "Xue Chen",
      "Shengtang Huang",
      "Xin Li"
    ],
    "categories": [
      "cs.DS",
      "cs.DM"
    ],
    "publishedAt": "2025-10-12T03:47:48.000Z",
    "updatedAt": "2025-10-12T03:47:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10431v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10431v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10423v1",
    "arxivId": "2510.10423v1",
    "title": "Improved Maximin Share Guarantee for Additive Valuations",
    "abstract": "The maximin share ($\\textsf{MMS}$) is the most prominent share-based fairness notion in the fair allocation of indivisible goods. Recent years have seen significant efforts to improve the approximation guarantees for $\\textsf{MMS}$ for different valuation classes, particularly for additive valuations. For the additive setting, it has been shown that for some instances, no allocation can guarantee a factor better than $1-\\tfrac{1}{n^4}$ of maximin share value to all agents. However, the best currently known algorithm achieves an approximation guarantee of $\\tfrac{3}{4} + \\tfrac{3}{3836}$ for $\\textsf{MMS}$. In this work, we narrow this gap and improve the best-known approximation guarantee for $\\textsf{MMS}$ to $\\tfrac{10}{13}$.",
    "authors": [
      "Ehsan Heidari",
      "Alireza Kaviani",
      "Masoud Seddighin",
      "AmirMohammad Shahrezaei"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-12T03:14:32.000Z",
    "updatedAt": "2025-10-12T03:14:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10423v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10423v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10421v1",
    "arxivId": "2510.10421v1",
    "title": "Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty",
    "abstract": "Achieving persistent tracking of multiple dynamic targets over a large spatial area poses significant challenges for a single-robot system with constrained sensing capabilities. As the robot moves to track different targets, the ones outside the field of view accumulate uncertainty, making them progressively harder to track. An effective path planning algorithm must manage uncertainty over a long horizon and account for the risk of permanently losing track of targets that remain unseen for too long. However, most existing approaches rely on short planning horizons and assume small, bounded environments, resulting in poor tracking performance and target loss in large-scale scenarios. In this paper, we present a hierarchical planner for tracking multiple moving targets with an aerial vehicle. To address the challenge of tracking non-static targets, our method incorporates motion models and uncertainty propagation during path execution, allowing for more informed decision-making. We decompose the multi-target tracking task into sub-tasks of single target search and detection, and our proposed pipeline consists a novel low-level coverage planner that enables searching for a target in an evolving belief area, and an estimation method to assess the likelihood of success for each sub-task, making it possible to convert the active target tracking task to a Markov decision process (MDP) that we solve with a tree-based algorithm to determine the sequence of sub-tasks. We validate our approach in simulation, demonstrating its effectiveness compared to existing planners for active target tracking tasks, and our proposed planner outperforms existing approaches, achieving a reduction of 11-70% in final uncertainty across different environments.",
    "authors": [
      "Junbin Yuan",
      "Brady Moon",
      "Muqing Cao",
      "Sebastian Scherer"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-12T03:08:00.000Z",
    "updatedAt": "2025-10-12T03:08:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10421v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10421v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10411v1",
    "arxivId": "2510.10411v1",
    "title": "Discovering interpretable piecewise nonlinear model predictive control laws via symbolic decision trees",
    "abstract": "In this paper, we propose symbolic decision trees as surrogate models for approximating model predictive control laws. The proposed approach learns simultaneously the partition of the input domain (splitting logic) as well as local nonlinear expressions for predicting the control action leading to interpretable piecewise nonlinear control laws. The local nonlinear expressions are determined by the learning problem and are modeled using a set of basis functions. The learning task is posed as a mixed integer optimization, which is solved to global optimality with state-of-the-art global optimization solvers. We apply the proposed approach to a case study regarding the control of an isothermal reactor. The results show that the proposed approach can learn the control law accurately, leading to closed-loop performance comparable to that of a standard model predictive controller. Finally, comparison with existing interpretable models shows that the symbolic trees achieve both lower prediction error and superior closed-loop performance.",
    "authors": [
      "Ilias Mitrai"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-12T02:11:39.000Z",
    "updatedAt": "2025-10-12T02:11:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10411v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10411v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10410v1",
    "arxivId": "2510.10410v1",
    "title": "A Trace-based Approach for Code Safety Analysis",
    "abstract": "Rust is a memory-safe programming language that disallows undefined behavior. Its safety guarantees have been extensively examined by the community through empirical studies, which has led to its remarkable success. However, unsafe code remains a critical concern in Rust. By reviewing the safety design of Rust and analyzing real-world Rust projects, this paper establishes a systematic framework for understanding unsafe code and undefined behavior, and summarizes the soundness criteria for Rust code. It further derives actionable guidance for achieving sound encapsulation.",
    "authors": [
      "Hui Xu"
    ],
    "categories": [
      "cs.PL",
      "cs.SE"
    ],
    "publishedAt": "2025-10-12T02:11:38.000Z",
    "updatedAt": "2025-10-12T02:11:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10410v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10410v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10407v1",
    "arxivId": "2510.10407v1",
    "title": "PrediQL: Automated Testing of GraphQL APIs with LLMs",
    "abstract": "GraphQL's flexible query model and nested data dependencies expose APIs to complex, context-dependent vulnerabilities that are difficult to uncover using conventional testing tools. Existing fuzzers either rely on random payload generation or rigid mutation heuristics, failing to adapt to the dynamic structures of GraphQL schemas and responses. We present PrediQL, the first retrieval-augmented, LLM-guided fuzzer for GraphQL APIs. PrediQL combines large language model reasoning with adaptive feedback loops to generate semantically valid and diverse queries. It models the choice of fuzzing strategy as a multi-armed bandit problem, balancing exploration of new query structures with exploitation of past successes. To enhance efficiency, PrediQL retrieves and reuses execution traces, schema fragments, and prior errors, enabling self-correction and progressive learning across test iterations. Beyond input generation, PrediQL integrates a context-aware vulnerability detector that uses LLM reasoning to analyze responses, interpreting data values, error messages, and status codes to identify issues such as injection flaws, access-control bypasses, and information disclosure. Our evaluation across open-source and benchmark GraphQL APIs shows that PrediQL achieves significantly higher coverage and vulnerability discovery rates compared to state-of-the-art baselines. These results demonstrate that combining retrieval-augmented reasoning with adaptive fuzzing can transform API security testing from reactive enumeration to intelligent exploration.",
    "authors": [
      "Shaolun Liu",
      "Sina Marefat",
      "Omar Tsai",
      "Yu Chen",
      "Zecheng Deng",
      "Jia Wang",
      "Mohammad A. Tayebi"
    ],
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "publishedAt": "2025-10-12T01:49:45.000Z",
    "updatedAt": "2025-10-12T01:49:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10407v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10407v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10404v1",
    "arxivId": "2510.10404v1",
    "title": "Expanding detection bandwidth via a photonic reservoir for ultrafast optical sensing",
    "abstract": "The detection of ultrafast optical and radio-frequency (RF) signals is crucial for applications ranging from high-speed communications to advanced sensing. However, conventional detectors are fundamentally constrained by their intrinsic bandwidth, limiting accurate broadband signal measurement. Here, we show that a neuromorphic photonic processing approach can overcome this limitation, enabling accurate broadband signal detection beyond the detector bandwidth. The key idea lies in the spatiotemporal encoding of input waveforms within a photonic reservoir network, which reconstructs high-frequency components otherwise inaccessible to individual detectors. We experimentally demonstrate the detection of high-speed optical phase signals with more than an eightfold effective bandwidth expansion using an on-chip silicon photonic reservoir. This approach provides a scalable and integrable platform for high-speed optical and RF signal processing, opening new opportunities in ultrafast photonics and next-generation communication systems.",
    "authors": [
      "Yuito Ito",
      "Tomoaki Niiyama",
      "Tetsuya Asai",
      "Gouhei Tanaka",
      "Atsushi Uchida",
      "Satoshi Sunada"
    ],
    "categories": [
      "physics.optics",
      "cs.ET"
    ],
    "publishedAt": "2025-10-12T01:45:11.000Z",
    "updatedAt": "2025-10-12T01:45:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10404v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10404v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10401v1",
    "arxivId": "2510.10401v1",
    "title": "Knowledge-Decoupled Functionally Invariant Path with Synthetic Personal Data for Personalized ASR",
    "abstract": "Fine-tuning generic ASR models with large-scale synthetic personal data can enhance the personalization of ASR models, but it introduces challenges in adapting to synthetic personal data without forgetting real knowledge, and in adapting to personal data without forgetting generic knowledge. Considering that the functionally invariant path (FIP) framework enables model adaptation while preserving prior knowledge, in this letter, we introduce FIP into synthetic-data-augmented personalized ASR models. However, the model still struggles to balance the learning of synthetic, personalized, and generic knowledge when applying FIP to train the model on all three types of data simultaneously. To decouple this learning process and further address the above two challenges, we integrate a gated parameter-isolation strategy into FIP and propose a knowledge-decoupled functionally invariant path (KDFIP) framework, which stores generic and personalized knowledge in separate modules and applies FIP to them sequentially. Specifically, KDFIP adapts the personalized module to synthetic and real personal data and the generic module to generic data. Both modules are updated along personalization-invariant paths, and their outputs are dynamically fused through a gating mechanism. With augmented synthetic data, KDFIP achieves a 29.38% relative character error rate reduction on target speakers and maintains comparable generalization performance to the unadapted ASR baseline.",
    "authors": [
      "Yue Gu",
      "Zhihao Du",
      "Ying Shi",
      "Jiqing Han",
      "Yongjun He"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-12T01:39:29.000Z",
    "updatedAt": "2025-10-12T01:39:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10401v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10401v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10396v1",
    "arxivId": "2510.10396v1",
    "title": "MRSAudio: A Large-Scale Multimodal Recorded Spatial Audio Dataset with Refined Annotations",
    "abstract": "Humans rely on multisensory integration to perceive spatial environments, where auditory cues enable sound source localization in three-dimensional space. Despite the critical role of spatial audio in immersive technologies such as VR/AR, most existing multimodal datasets provide only monaural audio, which limits the development of spatial audio generation and understanding. To address these challenges, we introduce MRSAudio, a large-scale multimodal spatial audio dataset designed to advance research in spatial audio understanding and generation. MRSAudio spans four distinct components: MRSLife, MRSSpeech, MRSMusic, and MRSSing, covering diverse real-world scenarios. The dataset includes synchronized binaural and ambisonic audio, exocentric and egocentric video, motion trajectories, and fine-grained annotations such as transcripts, phoneme boundaries, lyrics, scores, and prompts. To demonstrate the utility and versatility of MRSAudio, we establish five foundational tasks: audio spatialization, and spatial text to speech, spatial singing voice synthesis, spatial music generation and sound event localization and detection. Results show that MRSAudio enables high-quality spatial modeling and supports a broad range of spatial audio research. Demos and dataset access are available at https://mrsaudio.github.io.",
    "authors": [
      "Wenxiang Guo",
      "Changhao Pan",
      "Zhiyuan Zhu",
      "Xintong Hu",
      "Yu Zhang",
      "Li Tang",
      "Rui Yang",
      "Han Wang",
      "Zongbao Zhang",
      "Yuhan Wang",
      "Yixuan Chen",
      "Hankun Xu",
      "Ke Xu",
      "Pengfei Fan",
      "Zhetao Chen",
      "Yanhao Yu",
      "Qiange Huang",
      "Fei Wu",
      "Zhou Zhao"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-12T01:20:23.000Z",
    "updatedAt": "2025-10-12T01:20:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10396v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10396v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10392v1",
    "arxivId": "2510.10392v1",
    "title": "MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation",
    "abstract": "This paper presents MicroRoboScope, a portable, compact, and versatile microrobotic experimentation platform designed for real-time, closed-loop control of both magnetic and acoustic microrobots. The system integrates an embedded computer, microscope, power supplies, and control circuitry into a single, low-cost and fully integrated apparatus. Custom control software developed in Python and Arduino C++ handles live video acquisition, microrobot tracking, and generation of control signals for electromagnetic coils and acoustic transducers. The platform's multi-modal actuation, accessibility, and portability make it suitable not only for specialized research laboratories but also for educational and outreach settings. By lowering the barrier to entry for microrobotic experimentation, this system enables new opportunities for research, education, and translational applications in biomedicine, tissue engineering, and robotics.",
    "authors": [
      "Max Sokolich",
      "Yanda Yang",
      "Subrahmanyam Cherukumilli",
      "Fatma Ceren Kirmizitas",
      "Sambeeta Das"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-12T01:04:19.000Z",
    "updatedAt": "2025-10-12T01:04:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10392v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10392v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10380v1",
    "arxivId": "2510.10380v1",
    "title": "FLAMMABLE: A Multi-Model Federated Learning Framework with Multi-Model Engagement and Adaptive Batch Sizes",
    "abstract": "Multi-Model Federated Learning (MMFL) is an emerging direction in Federated Learning (FL) where multiple models are trained in parallel, generally on various datasets. Optimizing the models' accuracies and training times in the MMFL setting requires adapting to data and system heterogeneity across clients as in single-model FL; these challenges are amplified in the MMFL setting due to additional heterogeneity across models. Neither existing solutions nor na\\\"ive extensions of single-model FL frameworks efficiently address these challenges. To bridge this gap, we propose FLAMMABLE, a comprehensive MMFL training framework. FLAMMABLE optimizes model training by intelligently adapting client batch sizes while engaging them to train multiple carefully chosen models, depending on their system capabilities, in each training round. To evaluate FLAMMABLE, we develop the first benchmark platform for the MMFL setting, which may enable future reproducible MMFL research. Extensive evaluations on multiple datasets and models show that FLAMMABLE boosts the MMFL time-to-accuracy performance by 1.1$\\sim$10.0$\\times$ while improving the final model accuracy by 1.3$\\sim$5.4\\% compared to several known baselines.",
    "authors": [
      "Shouxu Lin",
      "Zimeng Pan",
      "Yuhang Yao",
      "Haeyoung Noh",
      "Pei Zhang",
      "Carlee Joe-Wong"
    ],
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-12T00:38:10.000Z",
    "updatedAt": "2025-10-12T00:38:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10380v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10380v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10379v1",
    "arxivId": "2510.10379v1",
    "title": "RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning",
    "abstract": "Coordinating heterogeneous robot fleets to achieve multiple goals is challenging in multi-robot systems. We introduce an open-source and extensible framework for centralized multi-robot task planning and scheduling that leverages LLMs to enable fleets of heterogeneous robots to accomplish multiple tasks. RobotFleet provides abstractions for planning, scheduling, and execution across robots deployed as containerized services to simplify fleet scaling and management. The framework maintains a shared declarative world state and two-way communication for task execution and replanning. By modularizing each layer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet lowers the barrier to building scalable multi-robot systems. The code can be found here: https://github.com/therohangupta/robot-fleet.",
    "authors": [
      "Rohan Gupta",
      "Trevor Asbery",
      "Zain Merchant",
      "Abrar Anwar",
      "Jesse Thomason"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "publishedAt": "2025-10-12T00:32:37.000Z",
    "updatedAt": "2025-10-12T00:32:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10379v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10379v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10357v1",
    "arxivId": "2510.10357v1",
    "title": "Learning to Throw-Flip",
    "abstract": "Dynamic manipulation, such as robot tossing or throwing objects, has recently gained attention as a novel paradigm to speed up logistic operations. However, the focus has predominantly been on the object's landing location, irrespective of its final orientation. In this work, we present a method enabling a robot to accurately \"throw-flip\" objects to a desired landing pose (position and orientation). Conventionally, objects thrown by revolute robots suffer from parasitic rotation, resulting in highly restricted and uncontrollable landing poses. Our approach is based on two key design choices: first, leveraging the impulse-momentum principle, we design a family of throwing motions that effectively decouple the parasitic rotation, significantly expanding the feasible set of landing poses. Second, we combine a physics-based model of free flight with regression-based learning methods to account for unmodeled effects. Real robot experiments demonstrate that our framework can learn to throw-flip objects to a pose target within ($\\pm$5 cm, $\\pm$45 degrees) threshold in dozens of trials. Thanks to data assimilation, incorporating projectile dynamics reduces sample complexity by an average of 40% when throw-flipping to unseen poses compared to end-to-end learning methods. Additionally, we show that past knowledge on in-hand object spinning can be effectively reused, accelerating learning by 70% when throwing a new object with a Center of Mass (CoM) shift. A video summarizing the proposed method and the hardware experiments is available at https://youtu.be/txYc9b1oflU.",
    "authors": [
      "Yang Liu",
      "Bruno Da Costa",
      "Aude Billard"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-11T22:18:09.000Z",
    "updatedAt": "2025-10-11T22:18:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10357v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10357v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10346v1",
    "arxivId": "2510.10346v1",
    "title": "sqrtVINS: Robust and Ultrafast Square-Root Filter-based 3D Motion Tracking",
    "abstract": "In this paper, we develop and open-source, for the first time, a square-root filter (SRF)-based visual-inertial navigation system (VINS), termed sqrtVINS, which is ultra-fast, numerically stable, and capable of dynamic initialization even under extreme conditions (i.e., extremely small time window). Despite recent advancements in VINS, resource constraints and numerical instability on embedded (robotic) systems with limited precision remain critical challenges. A square-root covariance-based filter offers a promising solution by providing numerical stability, efficient memory usage, and guaranteed positive semi-definiteness. However, canonical SRFs suffer from inefficiencies caused by disruptions in the triangular structure of the covariance matrix during updates. The proposed method significantly improves VINS efficiency with a novel Cholesky decomposition (LLT)-based SRF update, by fully exploiting the system structure to preserve the structure. Moreover, we design a fast, robust, dynamic initialization method, which first recovers the minimal states without triangulating 3D features and then efficiently performs iterative SRF update to refine the full states, enabling seamless VINS operation. The proposed LLT-based SRF is extensively verified through numerical studies, demonstrating superior numerical stability and achieving robust efficient performance on 32-bit single-precision floats, operating at twice the speed of state-of-the-art (SOTA) methods. Our initialization method, tested on both mobile workstations and Jetson Nano computers, achieving a high success rate of initialization even within a 100 ms window under minimal conditions. Finally, the proposed sqrtVINS is extensively validated across diverse scenarios, demonstrating strong efficiency, robustness, and reliability. The full open-source implementation is released to support future research and applications.",
    "authors": [
      "Yuxiang Peng",
      "Chuchu Chen",
      "Kejian Wu",
      "Guoquan Huang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T21:41:03.000Z",
    "updatedAt": "2025-10-11T21:41:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10346v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10346v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10339v1",
    "arxivId": "2510.10339v1",
    "title": "Measuring What Matters: Connecting AI Ethics Evaluations to System Attributes, Hazards, and Harms",
    "abstract": "Over the past decade, an ecosystem of measures has emerged to evaluate the social and ethical implications of AI systems, largely shaped by high-level ethics principles. These measures are developed and used in fragmented ways, without adequate attention to how they are situated in AI systems. In this paper, we examine how existing measures used in the computing literature map to AI system components, attributes, hazards, and harms. Our analysis draws on a scoping review resulting in nearly 800 measures corresponding to 11 AI ethics principles. We find that most measures focus on four principles - fairness, transparency, privacy, and trust - and primarily assess model or output system components. Few measures account for interactions across system elements, and only a narrow set of hazards is typically considered for each harm type. Many measures are disconnected from where harm is experienced and lack guidance for setting meaningful thresholds. These patterns reveal how current evaluation practices remain fragmented, measuring in pieces rather than capturing how harms emerge across systems. Framing measures with respect to system attributes, hazards, and harms can strengthen regulatory oversight, support actionable practices in industry, and ground future research in systems-level understanding.",
    "authors": [
      "Shalaleh Rismani",
      "Renee Shelby",
      "Leah Davis",
      "Negar Rostamzadeh",
      "AJung Moon"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-11T20:52:21.000Z",
    "updatedAt": "2025-10-11T20:52:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10339v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10339v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10337v1",
    "arxivId": "2510.10337v1",
    "title": "Rise of the Robochemist",
    "abstract": "Chemistry, a long-standing discipline, has historically relied on manual and often time-consuming processes. While some automation exists, the field is now on the cusp of a significant evolution driven by the integration of robotics and artificial intelligence (AI), giving rise to the concept of the robochemist: a new paradigm where autonomous systems assist in designing, executing, and analyzing experiments. Robochemists integrate mobile manipulators, advanced perception, teleoperation, and data-driven protocols to execute experiments with greater adaptability, reproducibility, and safety. Rather than a fully automated replacement for human chemists, we envisioned the robochemist as a complementary partner that works collaboratively to enhance discovery, enabling a more efficient exploration of chemical space and accelerating innovation in pharmaceuticals, materials science, and sustainable manufacturing. This article traces the technologies, applications, and challenges that define this transformation, highlighting both the opportunities and the responsibilities that accompany the emergence of the robochemist. Ultimately, the future of chemistry is argued to lie in a symbiotic partnership where human intuition and expertise is amplified by robotic precision and AI-driven insight.",
    "authors": [
      "Jihong Zhu",
      "Kefeng Huang",
      "Jonathon Pipe",
      "Chris Horbaczewsky",
      "Andy Tyrrell",
      "Ian J. S. Fairlamb"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T20:51:57.000Z",
    "updatedAt": "2025-10-11T20:51:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10337v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10337v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10336v1",
    "arxivId": "2510.10336v1",
    "title": "From Funding to Findings (FIND): An Open Database of NSF Awards and Research Outputs",
    "abstract": "Public funding plays a central role in driving scientific discovery. To better understand the link between research inputs and outputs, we introduce FIND (Funding-Impact NSF Database), an open-access dataset that systematically links NSF grant proposals to their downstream research outputs, including publication metadata and abstracts. The primary contribution of this project is the creation of a large-scale, structured dataset that enables transparency, impact evaluation, and metascience research on the returns to public funding. To illustrate the potential of FIND, we present two proof-of-concept NLP applications. First, we analyze whether the language of grant proposals can predict the subsequent citation impact of funded research. Second, we leverage large language models to extract scientific claims from both proposals and resulting publications, allowing us to measure the extent to which funded projects deliver on their stated goals. Together, these applications highlight the utility of FIND for advancing metascience, informing funding policy, and enabling novel AI-driven analyses of the scientific process.",
    "authors": [
      "Kazimier Smith",
      "Yucheng Lu",
      "Qiaochu Fan"
    ],
    "categories": [
      "cs.DL"
    ],
    "publishedAt": "2025-10-11T20:45:42.000Z",
    "updatedAt": "2025-10-11T20:45:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10336v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10336v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10335v1",
    "arxivId": "2510.10335v1",
    "title": "Proportional and Pareto-Optimal Allocation of Chores with Subsidy",
    "abstract": "We consider the problem of allocating $m$ indivisible chores among $n$ agents with possibly different weights, aiming for a solution that is both fair and efficient. Specifically, we focus on the classic fairness notion of proportionality and efficiency notion of Pareto-optimality. Since proportional allocations may not always exist in this setting, we allow the use of subsidies (monetary compensation to agents) to ensure agents are proportionally-satisfied, and aim to minimize the total subsidy required. Wu and Zhou (WINE 2024) showed that when each chore has disutility at most 1, a total subsidy of at most $n/3 - 1/6$ is sufficient to guarantee proportionality. However, their approach is based on a complex technique, which does not guarantee economic efficiency - a key desideratum in fair division. In this work, we give a polynomial-time algorithm that achieves the same subsidy bound while also ensuring Pareto-optimality. Moreover, both our algorithm and its analysis are significantly simpler than those of Wu and Zhou (WINE 2024). Our approach first computes a proportionally-fair competitive equilibrium, and then applies a rounding procedure guided by minimum-pain-per-buck edges.",
    "authors": [
      "Jugal Garg",
      "Eklavya Sharma",
      "Xiaowei Wu"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-11T20:42:37.000Z",
    "updatedAt": "2025-10-11T20:42:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10335v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10335v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10332v1",
    "arxivId": "2510.10332v1",
    "title": "Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework",
    "abstract": "We present a deep reinforcement learning framework based on Soft Actor-Critic (SAC) for safe and precise maneuvering of double-Ackermann-steering mobile robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as differential-drive robots, DASMRs face strong kinematic constraints that make classical planners brittle in cluttered environments. Our framework leverages the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage maneuvering efficiency while avoiding obstacles. Simulation results with a heavy four-wheel-steering rover show that the learned policy can robustly reach up to 97% of target positions while avoiding obstacles. Our framework does not rely on handcrafted trajectories or expert demonstrations.",
    "authors": [
      "Kohio Deflesselle",
      "Mélodie Daniel",
      "Aly Magassouba",
      "Miguel Aranda",
      "Olivier Ly"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T20:30:37.000Z",
    "updatedAt": "2025-10-11T20:30:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10332v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10332v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10325v1",
    "arxivId": "2510.10325v1",
    "title": "KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments",
    "abstract": "The seamless integration of physical and digital environments in Cyber-Physical Systems(CPS), particularly within Industry 4.0, presents significant challenges stemming from system heterogeneity and complexity. Traditional approaches often rely on rigid, data-centric solutions like co-simulation frameworks or brittle point-to-point middleware bridges, which lack the semantic richness and flexibility required for intelligent, autonomous coordination. This report introduces the Knowledge Graph-Enhanced Multi-Agent Infrastructure(KG-MAS), as resolution in addressing such limitations. KG-MAS leverages a centralized Knowledge Graph (KG) as a dynamic, shared world model, providing a common semantic foundation for a Multi-Agent System(MAS). Autonomous agents, representing both physical and digital components, query this KG for decision-making and update it with real-time state information. The infrastructure features a model-driven architecture which facilitates the automatic generation of agents from semantic descriptions, thereby simplifying system extension and maintenance. By abstracting away underlying communication protocols and providing a unified, intelligent coordination mechanism, KG-MAS offers a robust, scalable, and flexible solution for coupling heterogeneous physical and digital robotic environments.",
    "authors": [
      "Walid Abdela"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T19:41:47.000Z",
    "updatedAt": "2025-10-11T19:41:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10325v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10325v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10321v1",
    "arxivId": "2510.10321v1",
    "title": "Bridging Semantics & Structure for Software Vulnerability Detection using Hybrid Network Models",
    "abstract": "Software vulnerabilities remain a persistent risk, yet static and dynamic analyses often overlook structural dependencies that shape insecure behaviors. Viewing programs as heterogeneous graphs, we capture control- and data-flow relations as complex interaction networks. Our hybrid framework combines these graph representations with light-weight (<4B) local LLMs, uniting topological features with semantic reasoning while avoiding the cost and privacy concerns of large cloud models. Evaluated on Java vulnerability detection (binary classification), our method achieves 93.57% accuracy-an 8.36% gain over Graph Attention Network-based embeddings and 17.81% over pretrained LLM baselines such as Qwen2.5 Coder 3B. Beyond accuracy, the approach extracts salient subgraphs and generates natural language explanations, improving interpretability for developers. These results pave the way for scalable, explainable, and locally deployable tools that can shift vulnerability analysis from purely syntactic checks to deeper structural and semantic insights, facilitating broader adoption in real-world secure software development.",
    "authors": [
      "Jugal Gajjar",
      "Kaustik Ranaware",
      "Kamalasankari Subramaniakuppusamy"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "publishedAt": "2025-10-11T19:32:00.000Z",
    "updatedAt": "2025-10-11T19:32:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10321v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10321v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10320v1",
    "arxivId": "2510.10320v1",
    "title": "Prepared for the Unknown: Adapting AIOps Capacity Forecasting Models to Data Changes",
    "abstract": "Capacity management is critical for software organizations to allocate resources effectively and meet operational demands. An important step in capacity management is predicting future resource needs often relies on data-driven analytics and machine learning (ML) forecasting models, which require frequent retraining to stay relevant as data evolves. Continuously retraining the forecasting models can be expensive and difficult to scale, posing a challenge for engineering teams tasked with balancing accuracy and efficiency. Retraining only when the data changes appears to be a more computationally efficient alternative, but its impact on accuracy requires further investigation. In this work, we investigate the effects of retraining capacity forecasting models for time series based on detected changes in the data compared to periodic retraining. Our results show that drift-based retraining achieves comparable forecasting accuracy to periodic retraining in most cases, making it a cost-effective strategy. However, in cases where data is changing rapidly, periodic retraining is still preferred to maximize the forecasting accuracy. These findings offer actionable insights for software teams to enhance forecasting systems, reducing retraining overhead while maintaining robust performance.",
    "authors": [
      "Lorena Poenaru-Olaru",
      "Wouter van 't Hof",
      "Adrian Stando",
      "Arkadiusz P. Trawinski",
      "Eileen Kapel",
      "Jan S. Rellermeyer",
      "Luis Cruz",
      "Arie van Deursen"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T19:21:20.000Z",
    "updatedAt": "2025-10-11T19:21:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10320v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10320v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10313v1",
    "arxivId": "2510.10313v1",
    "title": "Low-cost Pyranometer-Based ANN Approach for MPPT in Solar PV Systems",
    "abstract": "This article presents a study on the application of artificial neural networks (ANNs) for maximum power point tracking (MPPT) in photovoltaic (PV) systems using low-cost pyranometer sensors. The proposed approach integrates pyranometers, temperature sensors, and an ANN to estimate the duty cycle of a DC/DC converter, enabling the system to consistently operate at its maximum power point. The strategy was implemented in the local control of a Cuk converter and experimentally validated against the conventional Perturb and Observe (P&O) method. Results demonstrate that the ANN-based technique, leveraging affordable sensor technology, achieves accurate MPPT performance with reduced fluctuations, enhancing the responsiveness and efficiency of PV tracking systems.",
    "authors": [
      "Luiz Fernando M. Arruda",
      "Moises Ferber",
      "Diego Greff"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-11T18:40:10.000Z",
    "updatedAt": "2025-10-11T18:40:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10313v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10313v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10307v1",
    "arxivId": "2510.10307v1",
    "title": "On the Relationship between Space-Time Accessibility and Leisure Activity Participation",
    "abstract": "Understanding how accessibility shapes participation in leisure activities is central to promoting inclusive and vibrant urban life. Conventional accessibility measures often focus on potential access from fixed home locations, overlooking the constraints and opportunities embedded in daily routines. In this study, we introduce a space-time accessibility (SPA) metric rooted in the capability approach, capturing feasible leisure opportunities between home and work given a certain time budget, individual transport modes, and urban infrastructure. Using high-resolution GPS data from 2,415 residents in the Paris region, we assess how SPA influences total travel time and leisure participation, measured as the diversity of leisure activity locations. Spatial patterns show that most individuals-especially active transport users-choose destinations aligned with their SPA-defined opportunity sets, underscoring the metric's validity in capturing capability sets. Structural equation modeling reveals that SPA directly fosters leisure diversity but also reduces travel time, which in turn is associated with lower diversity. These findings highlight the value of person-centered, capability-informed accessibility metrics for understanding inequalities in urban mobility and informing transport planning strategies that expand real freedoms to participate in social life across diverse population groups.",
    "authors": [
      "Yuan Liao",
      "Rafael H. M. Pereira",
      "Jorge Gil",
      "Silvia De Sojo Caso",
      "Laura Alessandretti"
    ],
    "categories": [
      "cs.SI",
      "cs.CE"
    ],
    "publishedAt": "2025-10-11T18:21:32.000Z",
    "updatedAt": "2025-10-11T18:21:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10307v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10307v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10302v1",
    "arxivId": "2510.10302v1",
    "title": "SP-MoE: Speculative Decoding and Prefetching for Accelerating MoE-based Model Inference",
    "abstract": "The Mixture-of-Experts (MoE) architecture has been widely adopted in large language models (LLMs) to reduce computation cost through model sparsity. Employing speculative decoding (SD) can further accelerate MoE inference by drafting multiple tokens per step and verifying them in parallel. However, combining MoE with SD inflates GPU memory and aggravates CPU-GPU bandwidth contention during multi-token verification. Existing MoE offloading systems are SD-agnostic and do not address this bottleneck. We present SP-MoE, the first SD-aware expert-offloading and compute-communication pipelining framework. SP-MoE introduces: (1) speculative expert prefetching that exploits structural correspondence between the draft and target models to prefetch likely experts ahead of verification; (2) a cutoff-layer policy that bounds per-layer prefetch depth based on empirical profiles and an analytical latency model, guaranteeing just-in-time availability without overfetch; and (3) a pipelined runtime with asynchronous prefetch threads and batched I/O to hide loading latency. Extensive experiments demonstrate that SP-MoE achieves a 1.07-3.5 times TPOT speedup over state-of-the-art methods across diverse datasets, environments, and MoE-based models.",
    "authors": [
      "Liangkun Chen",
      "Zijian Wen",
      "Tian Wu",
      "Xiaoxi Zhang",
      "Chuan Wu"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-11T17:59:00.000Z",
    "updatedAt": "2025-10-11T17:59:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10302v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10302v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10300v1",
    "arxivId": "2510.10300v1",
    "title": "The algorithmic regulator",
    "abstract": "The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \\emph{good algorithmic regulator} if it \\emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\\varnothing$, i.e., \\[ \\Delta = K\\big(O_{W,\\varnothing}\\big) - K\\big(O_{W,R}\\big) > 0. \\] We then prove that the larger $\\Delta$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $\\Delta > 0$ yields \\[ \\Pr\\big((W,R)\\mid x\\big) \\le C\\,2^{\\,M(W{:}R)}\\,2^{-\\Delta}, \\] making low $M(W{:}R)$ exponentially unlikely as $\\Delta$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \\emph{canonical scalar objective} and implicates a \\emph{planner}. On the realized episode, a regulator behaves \\emph{as if} it minimized the conditional description length of the readout.",
    "authors": [
      "Giulio Ruffini"
    ],
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.IT",
      "cs.SY",
      "eess.SY",
      "math.IT",
      "q-bio.NC"
    ],
    "publishedAt": "2025-10-11T17:54:08.000Z",
    "updatedAt": "2025-10-11T17:54:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10300v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10300v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10290v1",
    "arxivId": "2510.10290v1",
    "title": "Grounded AI for Code Review: Resource-Efficient Large-Model Serving in Enterprise Pipelines",
    "abstract": "Automated code review adoption lags in compliance-heavy settings, where static analyzers produce high-volume, low-rationale outputs, and naive LLM use risks hallucination and incurring cost overhead. We present a production system for grounded, PR-native review that pairs static-analysis findings with AST-guided context extraction and a single-GPU, on-demand serving stack (quantized open-weight model, multi-tier caching) to deliver concise explanations and remediation guidance. Evaluated on safety-oriented C/C++ standards, the approach achieves sub-minute median first-feedback (offline p50 build+LLM 59.8s) while maintaining competitive violation reduction and lower violation rates versus larger proprietary models. The architecture is decoupled: teams can adopt the grounding/prompting layer or the serving layer independently. A small internal survey (n=8) provides directional signals of reduced triage effort and moderate perceived grounding, with participants reporting fewer human review iterations. We outline operational lessons and limitations, emphasizing reproducibility, auditability, and pathways to broader standards and assisted patching.",
    "authors": [
      "Sayan Mandal",
      "Hua Jiang"
    ],
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "publishedAt": "2025-10-11T17:08:45.000Z",
    "updatedAt": "2025-10-11T17:08:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10290v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10290v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10289v1",
    "arxivId": "2510.10289v1",
    "title": "Optimal monophasic, asymmetric electric field pulses for selective transcranial magnetic stimulation (TMS) with minimised power and coil heating",
    "abstract": "Transcranial magnetic stimulation (TMS) with asymmetric electric field pulses, such as monophasic, offers directional selectivity for neural activation but requires excessive energy. Previous pulse shape optimisation has been limited to symmetric pulses or heavily constrained variations of conventional waveforms without achieving general optimality in energy efficiency or neural selectivity. We implemented an optimisation framework that incorporates neuron model activation constraints and flexible control of pulse asymmetry. The optimised electric field waveforms achieved up to 92 % and 88 % reduction in energy loss and thus coil heating respectively compared to conventional monophasic pulses and previously improved monophasic-equivalent pulses. In the human experiments, OUR pulses showed similar motor thresholds to monophasic pulses in both AP and PA directions with significantly lower energy loss, particularly in the AP direction. Moreover, there was a significant MEP latency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR pulses, which suggests directional selectivity. Our framework successfully identified highly energy-efficient asymmetric pulses for directionally-selective neural engagement. These pulses can enable selective rapid-rate repetitive TMS protocols with reduced power consumption and coil heating, with potential benefits for precision and potency of neuro-modulation.",
    "authors": [
      "Ke Ma",
      "Andrey Vlasov",
      "Zeynep B. Simsek",
      "Jinshui Zhang",
      "Yiru Li",
      "Boshuo Wang",
      "David L. K. Murphy",
      "Jessica Y. Choi",
      "Maya E. Clinton",
      "Noreen Bukhari-Parlakturk",
      "Angel V. Peterchev",
      "Stephan M. Goetz"
    ],
    "categories": [
      "eess.SY",
      "cs.SY",
      "q-bio.NC"
    ],
    "publishedAt": "2025-10-11T17:08:15.000Z",
    "updatedAt": "2025-10-11T17:08:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10289v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10289v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10287v1",
    "arxivId": "2510.10287v1",
    "title": "Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking",
    "abstract": "Camera-based 3D object detection and tracking are essential for perception in autonomous driving. Current state-of-the-art approaches often rely exclusively on either perspective-view (PV) or bird's-eye-view (BEV) features, limiting their ability to leverage both fine-grained object details and spatially structured scene representations. In this work, we propose DualViewDistill, a hybrid detection and tracking framework that incorporates both PV and BEV camera image features to leverage their complementary strengths. Our approach introduces BEV maps guided by foundation models, leveraging descriptive DINOv2 features that are distilled into BEV representations through a novel distillation process. By integrating PV features with BEV maps enriched with semantic and geometric features from DINOv2, our model leverages this hybrid representation via deformable aggregation to enhance 3D object detection and tracking. Extensive experiments on the nuScenes and Argoverse 2 benchmarks demonstrate that DualViewDistill achieves state-of-the-art performance. The results showcase the potential of foundation model BEV maps to enable more reliable perception for autonomous driving. We make the code and pre-trained models available at https://dualviewdistill.cs.uni-freiburg.de .",
    "authors": [
      "Markus Käppeler",
      "Özgün Çiçek",
      "Daniele Cattaneo",
      "Claudius Gläser",
      "Yakov Miron",
      "Abhinav Valada"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T17:01:42.000Z",
    "updatedAt": "2025-10-11T17:01:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10287v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10287v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10274v1",
    "arxivId": "2510.10274v1",
    "title": "X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model",
    "abstract": "Successful generalist Vision-Language-Action (VLA) models rely on effective training across diverse robotic platforms with large-scale, cross-embodiment, heterogeneous datasets. To facilitate and leverage the heterogeneity in rich, diverse robotic data sources, we propose a novel Soft Prompt approach with minimally added parameters, by infusing prompt learning concepts into cross-embodiment robot learning and introducing separate sets of learnable embeddings for each distinct data source. These embeddings serve as embodiment-specific prompts, which in unity empower VLA models with effective exploitation of varying cross-embodiment features. Our new X-VLA, a neat flow-matching-based VLA architecture, relies exclusively on soft-prompted standard Transformer encoders, enjoying both scalability and simplicity. Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep of benchmarks, demonstrating superior results on a wide axes of capabilities, from flexible dexterity to quick adaptation across embodiments, environments, and tasks. Website: https://thu-air-dream.github.io/X-VLA/",
    "authors": [
      "Jinliang Zheng",
      "Jianxiong Li",
      "Zhihao Wang",
      "Dongxiu Liu",
      "Xirui Kang",
      "Yuchun Feng",
      "Yinan Zheng",
      "Jiayin Zou",
      "Yilun Chen",
      "Jia Zeng",
      "Ya-Qin Zhang",
      "Jiangmiao Pang",
      "Jingjing Liu",
      "Tai Wang",
      "Xianyuan Zhan"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-11T16:20:17.000Z",
    "updatedAt": "2025-10-11T16:20:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10274v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10274v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10273v1",
    "arxivId": "2510.10273v1",
    "title": "Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles",
    "abstract": "Efficient physics simulation has significantly accelerated research progress in robotics applications such as grasping and assembly. The advent of GPU-accelerated simulation frameworks like Isaac Sim has particularly empowered learning-based methods, enabling them to tackle increasingly complex tasks. The PAL Robotics TIAGo++ Omni is a versatile mobile manipulator equipped with a mecanum-wheeled base, allowing omnidirectional movement and a wide range of task capabilities. However, until now, no model of the robot has been available in Isaac Sim. In this paper, we introduce such a model, calibrated to approximate the behavior of the real robot, with a focus on its omnidirectional drive dynamics. We present two control models for the omnidirectional drive: a physically accurate model that replicates real-world wheel dynamics and a lightweight velocity-based model optimized for learning-based applications. With these models, we introduce a learning-based calibration approach to approximate the real robot's S-shaped velocity profile using minimal trajectory data recordings. This simulation should allow researchers to experiment with the robot and perform efficient learning-based control in diverse environments. We provide the integration publicly at https://github.com/AIS-Bonn/tiago_isaac.",
    "authors": [
      "Vincent Schoenbach",
      "Marvin Wiedemann",
      "Raphael Memmesheimer",
      "Malte Mosbach",
      "Sven Behnke"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T16:18:44.000Z",
    "updatedAt": "2025-10-11T16:18:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10273v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10273v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10263v1",
    "arxivId": "2510.10263v1",
    "title": "Unveiling Gamer Archetypes through Multi modal feature Correlations and Unsupervised Learning",
    "abstract": "Profiling gamers provides critical insights for adaptive game design, behavioral understanding, and digital well-being. This study proposes an integrated, data-driven framework that combines psychological measures, behavioral analytics, and machine learning to reveal underlying gamer personas. A structured survey of 250 participants, including 113 active gamers, captured multidimensional behavioral, motivational, and social data. The analysis pipeline integrated feature engineering, association-network, knowledge-graph analysis, and unsupervised clustering to extract meaningful patterns. Correlation statistics uses Cramers V, Tschuprows T, Theils U, and Spearmans quantified feature associations, and network centrality guided feature selection. Dimensionality-reduction techniques such as PCA, SVD, t-SNE are coupled with clustering algorithms like K-Means, Agglomerative, Spectral, DBSCAN, evaluated using Silhouette, Calinski Harabasz, and Davies Bouldin indices. The PCA with K-Means with k = 4 model achieved optimal cluster quality with Silhouette = 0.4, identifying four archetypes as Immersive Social Story-Seekers, Disciplined Optimizers, Strategic Systems Navigators, and Competitive Team-Builders. This research contributes a reproducible pipeline that links correlation-driven network insights with unsupervised learning. The integration of behavioral correlation networks with clustering not only enhances classification accuracy but also offers a holistic lens to connect gameplay motivations with psychological and wellness outcomes.",
    "authors": [
      "Moona Kanwal",
      "Muhammad Sami Siddiqui",
      "Syed Anael Ali"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "publishedAt": "2025-10-11T15:46:44.000Z",
    "updatedAt": "2025-10-11T15:46:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10263v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10263v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10258v1",
    "arxivId": "2510.10258v1",
    "title": "Exploration of Embodied Space Experience through Umbilical Interaction: A Grounded Theory Approach",
    "abstract": "This paper critiques the limits of human-centered design in HCI, proposing a shift toward Interface-Centered Design. Drawing on Hookway's philosophy of interfaces, phenomenology, and embodied interaction, we created Umbilink, an umbilical interaction device simulating a uterine environment with tactile sensors and rhythmic feedback to induce a pre-subjectivized state of sensory reduction. Participants' experiences were captured through semi-structured interviews and analyzed with grounded theory. Our contributions are: (1) introducing the novel interface type of Umbilical Interaction; (2) demonstrating the cognitive value of materialized interfaces in a human-interface-environment relation; (3) highlighting the design role of wearing rituals as liminal experiences. As a pilot study, this design suggests imaginative applications in healing, meditation, and sleep, while offering a speculative tool for future interface research.",
    "authors": [
      "Shuai Guo",
      "Dawei Liu",
      "Tiantian Zheng"
    ],
    "categories": [
      "cs.HC",
      "cs.ET",
      "cs.MM",
      "H.5.2; H.5.1; H.5.m"
    ],
    "publishedAt": "2025-10-11T15:35:03.000Z",
    "updatedAt": "2025-10-11T15:35:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10258v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10258v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10256v1",
    "arxivId": "2510.10256v1",
    "title": "Unlocking Thickness Modeling for Codimensional Contact Simulation",
    "abstract": "In this work we analyze and address a fundamental restriction that blocks the reliable application of codimensional yarn-level and shell models with thickness, to simulate real-world woven and knit fabrics. As discretizations refine toward practical and accurate physical modeling, such models can generate non-physical contact forces with stencil-neighboring elements in the simulation mesh, leading to severe locking artifacts. While not well-documented in the literature, this restriction has so far been addressed with two alternatives with undesirable tradeoffs. One option is to restrict the mesh to coarse resolutions, however, this eliminates the possibility of accurate (and consistent) resolution simulations across real-world material variations. A second alternative instead seeks to cull contact pairs that can create such locking forces in the first place. This relaxes resolution restrictions but compromise robustness. Culling can and will generate unacceptable and unpredictable geometric intersections and tunneling that destroys weaving and knitting structures and cause unrecoverable pull-throughs. We address these challenges to simulating real-world materials with a new and practical contact-processing model for thickened codimensional simulation, that removes resolution restrictions, while guaranteeing contact-locking-free, non-intersecting simulations. We demonstrate the application of our model across a wide range of previously unavailable simulation scenarios, with real-world material yarn and fabric parameters and patterns, challenging simulation conditions and mesh resolutions, and both rod and shell models, integrated with the IPC barrier.",
    "authors": [
      "Gonzalo Gomez-Nogales",
      "Zhen Chen",
      "Rosalie Martin",
      "Elena Garces",
      "Danny M. Kaufman"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-11T15:25:05.000Z",
    "updatedAt": "2025-10-11T15:25:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10256v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10256v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10249v1",
    "arxivId": "2510.10249v1",
    "title": "ProGress: Structured Music Generation via Graph Diffusion and Hierarchical Music Analysis",
    "abstract": "Artificial Intelligence (AI) for music generation is undergoing rapid developments, with recent symbolic models leveraging sophisticated deep learning and diffusion model algorithms. One drawback with existing models is that they lack structural cohesion, particularly on harmonic-melodic structure. Furthermore, such existing models are largely \"black-box\" in nature and are not musically interpretable. This paper addresses these limitations via a novel generative music framework that incorporates concepts of Schenkerian analysis (SchA) in concert with a diffusion modeling framework. This framework, which we call ProGress (Prolongation-enhanced DiGress), adapts state-of-the-art deep models for discrete diffusion (in particular, the DiGress model of Vignac et al., 2023) for interpretable and structured music generation. Concretely, our contributions include 1) novel adaptations of the DiGress model for music generation, 2) a novel SchA-inspired phrase fusion methodology, and 3) a framework allowing users to control various aspects of the generation process to create coherent musical compositions. Results from human experiments suggest superior performance to existing state-of-the-art methods.",
    "authors": [
      "Stephen Ni-Hahn",
      "Chao Péter Yang",
      "Mingchen Ma",
      "Cynthia Rudin",
      "Simon Mak",
      "Yue Jiang"
    ],
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "publishedAt": "2025-10-11T15:06:56.000Z",
    "updatedAt": "2025-10-11T15:06:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10249v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10249v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10236v1",
    "arxivId": "2510.10236v1",
    "title": "Hybrid MAC Protocol with Integrated Multi-Layered Security for Resource-Constrained UAV Swarm Communications",
    "abstract": "Flying Ad Hoc Networks (FANETs) present unique challenges due to high node mobility, dynamic topologies, and strict resource constraints. Existing routing protocols often optimize for a single metric, such as path length or energy, while neglecting the complex dependencies between network performance, security, and MAC layer efficiency. This paper introduces a novel hardware software co design framework for secure and adaptive UAV swarm communications, featuring an energy aware protocol stack. The architecture employs a multicast, clustered organization where routing decisions integrate dynamic trust scores, historical link quality, and internodal distance. A hybrid MAC protocol combines contention based and scheduled channel access for optimized throughput. Security is ensured through a zero trust model that fuses cryptographic authentication with a behavioral reputation system, alongside hardware accelerated AES GCM encryption. Comparative analysis in an NS 3 simulation environment demonstrates the framework's superiority in packet delivery ratio, latency, resilience, and overhead, providing a scalable foundation for high performance swarm operations.",
    "authors": [
      "Dhrumil Bhatt",
      "Siddharth Penumatsa",
      "Vidushi Kumar"
    ],
    "categories": [
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-11T14:27:48.000Z",
    "updatedAt": "2025-10-11T14:27:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10236v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10236v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10227v1",
    "arxivId": "2510.10227v1",
    "title": "Simple Length-Constrained Expander Decompositions",
    "abstract": "Length-constrained expander decompositions are a new graph decomposition that has led to several recent breakthroughs in fast graph algorithms. Roughly, an $(h, s)$-length $\\phi$-expander decomposition is a small collection of length increases to a graph so that nodes within distance $h$ can route flow over paths of length $hs$ while using each edge to an extent at most $1/\\phi$. Prior work showed that every $n$-node and $m$-edge graph admits an $(h, s)$-length $\\phi$-expander decomposition of size $\\log n \\cdot s n^{O(1/s)} \\cdot \\phi m$. In this work, we give a simple proof of the existence of $(h, s)$-length $\\phi$-expander decompositions with an improved size of $s n^{O(1/s)}\\cdot \\phi m$. Our proof is a straightforward application of the fact that the union of sparse length-constrained cuts is itself a sparse length-constrained cut. In deriving our result, we improve the loss in sparsity when taking the union of sparse length-constrained cuts from $\\log ^3 n\\cdot s^3 n^{O(1/s)}$ to $s\\cdot n^{O(1/s)}$.",
    "authors": [
      "Greg Bodwin",
      "Bernhard Haeupler",
      "D Ellis Hershkowitz",
      "Zihan Tan"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-11T14:04:15.000Z",
    "updatedAt": "2025-10-11T14:04:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10227v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10227v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10221v1",
    "arxivId": "2510.10221v1",
    "title": "A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots",
    "abstract": "This study investigates the developmental interaction between top-down (TD) and bottom-up (BU) visual attention in robotic learning. Our goal is to understand how structured, human-like attentional behavior emerges through the mutual adaptation of TD and BU mechanisms over time. To this end, we propose a novel attention model $A^3 RNN$ that integrates predictive TD signals and saliency-based BU cues through a bi-directional attention architecture. We evaluate our model in robotic manipulation tasks using imitation learning. Experimental results show that attention behaviors evolve throughout training, from saliency-driven exploration to prediction-driven direction. Initially, BU attention highlights visually salient regions, which guide TD processes, while as learning progresses, TD attention stabilizes and begins to reshape what is perceived as salient. This trajectory reflects principles from cognitive science and the free-energy framework, suggesting the importance of self-organizing attention through interaction between perception and internal prediction. Although not explicitly optimized for stability, our model exhibits more coherent and interpretable attention patterns than baselines, supporting the idea that developmental mechanisms contribute to robust attention formation.",
    "authors": [
      "Hyogo Hiruma",
      "Hiroshi Ito",
      "Hiroki Mori",
      "Tetsuya Ogata"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T13:58:08.000Z",
    "updatedAt": "2025-10-11T13:58:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10221v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10221v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10219v1",
    "arxivId": "2510.10219v1",
    "title": "Old is Gold: Optimizing Single-threaded Applications with Exgen-Malloc",
    "abstract": "Memory allocators hide beneath nearly every application stack, yet their performance footprint extends far beyond their code size. Even small inefficiencies in the allocators ripple through caches and the rest of the memory hierarchy, collectively imposing what operators often call a \"datacenter tax\". At hyperscale, even a 1% improvement in allocator efficiency can unlock millions of dollars in savings and measurable reductions in datacenter energy consumption. Modern memory allocators are designed to optimize allocation speed and memory fragmentation in multi-threaded environments, relying on complex metadata and control logic to achieve high performance. However, the overhead introduced by this complexity prompts a reevaluation of allocator design. Notably, such overhead can be avoided in single-threaded scenarios, which continue to be widely used across diverse application domains. In this paper, we introduce Exgen-Malloc, a memory allocator purpose-built for single-threaded applications. By specializing for single-threaded execution, Exgen-Malloc eliminates unnecessary metadata, simplifies the control flow, thereby reducing overhead and improving allocation efficiency. Its core design features include a centralized heap, a single free-block list, and a balanced strategy for memory commitment and relocation. Additionally, Exgen-Malloc incorporates design principles in modern multi-threaded allocators, which do not exist in legacy single-threaded allocators such as dlmalloc. We evaluate Exgen-Malloc on two Intel Xeon platforms. Across both systems, Exgen-Malloc achieves a speedup of 1.17x, 1.10x, and 1.93x over dlmalloc on SPEC CPU2017, redis-benchmark, and mimalloc-bench, respectively. In addition to performance, Exgen-Malloc achieves 6.2%, 0.1%, and 25.2% memory savings over mimalloc on SPEC CPU2017, redis-benchmark, and mimalloc-bench, respectively.",
    "authors": [
      "Ruihao Li",
      "Lizy K. John",
      "Neeraja J. Yadwadkar"
    ],
    "categories": [
      "cs.PL"
    ],
    "publishedAt": "2025-10-11T13:52:48.000Z",
    "updatedAt": "2025-10-11T13:52:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10219v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10219v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10218v1",
    "arxivId": "2510.10218v1",
    "title": "Sketch Animation: State-of-the-art Report",
    "abstract": "Sketch animation has emerged as a transformative technology, bridging art and science to create dynamic visual narratives across various fields such as entertainment, education, healthcare, and virtual reality. This survey explores recent trends and innovations in sketch animation, with a focus on methods that have advanced the state of the art. The paper categorizes and evaluates key methodologies, including keyframe interpolation, physics-based animation, data-driven, motion capture, and deep learning approaches. We examine the integration of artificial intelligence, real-time rendering, and cloud-based solutions, highlighting their impact on enhancing realism, scalability, and interactivity. Additionally, the survey delves into the challenges of computational complexity, scalability, and user-friendly interfaces, as well as emerging opportunities within metaverse applications and human-machine interaction. By synthesizing insights from a wide array of research, this survey aims to provide a comprehensive understanding of the current landscape and future directions of sketch animation, serving as a resource for both academics and industry professionals seeking to innovate in this dynamic field.",
    "authors": [
      "Gaurav Rai",
      "Ojaswa Sharma"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-11T13:48:27.000Z",
    "updatedAt": "2025-10-11T13:48:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10218v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10218v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10217v1",
    "arxivId": "2510.10217v1",
    "title": "UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction",
    "abstract": "Training robots to operate effectively in environments with uncertain states, such as ambiguous object properties or unpredictable interactions, remains a longstanding challenge in robotics. Imitation learning methods typically rely on successful examples and often neglect failure scenarios where uncertainty is most pronounced. To address this limitation, we propose the Uncertainty-driven Foresight Recurrent Neural Network (UF-RNN), a model that combines standard time-series prediction with an active \"Foresight\" module. This module performs internal simulations of multiple future trajectories and refines the hidden state to minimize predicted variance, enabling the model to selectively explore actions under high uncertainty. We evaluate UF-RNN on a door-opening task in both simulation and a real-robot setting, demonstrating that, despite the absence of explicit failure demonstrations, the model exhibits robust adaptation by leveraging self-induced chaotic dynamics in its latent space. When guided by the Foresight module, these chaotic properties stimulate exploratory behaviors precisely when the environment is ambiguous, yielding improved success rates compared to conventional stochastic RNN baselines. These findings suggest that integrating uncertainty-driven foresight into imitation learning pipelines can significantly enhance a robot's ability to handle unpredictable real-world conditions.",
    "authors": [
      "Hyogo Hiruma",
      "Hiroshi Ito",
      "Tetsuya Ogata"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T13:44:20.000Z",
    "updatedAt": "2025-10-11T13:44:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10217v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10217v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10216v1",
    "arxivId": "2510.10216v1",
    "title": "Learning to Guarantee Type Correctness in Code Generation through Type-Guided Program Synthesis",
    "abstract": "Language models have shown remarkable proficiency in code generation; nevertheless, ensuring type correctness remains a challenge. Although traditional methods, such as constrained decoding, alleviate this problem by externally rejecting untypable code, the model itself does not effectively learn type reasoning internally, which ultimately limits its overall performance. This paper introduces TyFlow, a novel system that internalizes type reasoning within code generation to guide the model to learn the type system. The core of our approach is a novel type-guided program synthesis system that maintains an isomorphism between type derivation trees and synthesis derivation trees, enabling a new code representation based on synthesis decision sequences rather than traditional text-based token sequences. By offloading the complexity of type system learning to the representation itself, models can redirect their computational resources toward higher-level program semantics. Our evaluation shows that TyFlow not only eliminates type errors but also significantly improves functional correctness, highlighting the importance of aligning LMs with type systems internally.",
    "authors": [
      "Zhechong Huang",
      "Zhao Zhang",
      "Ruyi Ji",
      "Tingxuan Xia",
      "Qihao Zhu",
      "Qinxiang Cao",
      "Zeyu Sun",
      "Yingfei Xiong"
    ],
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.SE"
    ],
    "publishedAt": "2025-10-11T13:43:36.000Z",
    "updatedAt": "2025-10-11T13:43:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10216v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10216v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10215v1",
    "arxivId": "2510.10215v1",
    "title": "Bounds of Validity for Bifurcations of Equilibria in a Class of Networked Dynamical Systems",
    "abstract": "Local bifurcation analysis plays a central role in understanding qualitative transitions in networked nonlinear dynamical systems, including dynamic neural network and opinion dynamics models. In this article we establish explicit bounds of validity for the classification of bifurcation diagrams in two classes of continuous-time networked dynamical systems, analogous in structure to the Hopfield and the Firing Rate dynamic neural network models. Our approach leverages recent advances in computing the bounds for the validity of Lyapunov-Schmidt reduction, a reduction method widely employed in nonlinear systems analysis. Using these bounds we rigorously characterize neighborhoods around bifurcation points where predictions from reduced-order models remain reliable. We further demonstrate how these bounds can be applied to an illustrative family of nonlinear opinion dynamics on k-regular graphs, which emerges as a special case of the general framework. These results provide new analytical tools for quantifying the robustness of bifurcation phenomena in dynamics over networked systems and highlight the interplay between network structure and nonlinear dynamical behavior.",
    "authors": [
      "Pranav Gupta",
      "Ravi Banavar",
      "Anastasia Bizyaeva"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-11T13:40:55.000Z",
    "updatedAt": "2025-10-11T13:40:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10215v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10215v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10214v1",
    "arxivId": "2510.10214v1",
    "title": "Distributionally Robust Control with End-to-End Statistically Guaranteed Metric Learning",
    "abstract": "Wasserstein distributionally robust control (DRC) recently emerges as a principled paradigm for handling uncertainty in stochastic dynamical systems. However, it constructs data-driven ambiguity sets via uniform distribution shifts before sequentially incorporating them into downstream control synthesis. This segregation between ambiguity set construction and control objectives inherently introduces a structural misalignment, which undesirably leads to conservative control policies with sub-optimal performance. To address this limitation, we propose a novel end-to-end finite-horizon Wasserstein DRC framework that integrates the learning of anisotropic Wasserstein metrics with downstream control tasks in a closed-loop manner, thus enabling ambiguity sets to be systematically adjusted along performance-critical directions and yielding more effective control policies. This framework is formulated as a bilevel program: the inner level characterizes dynamical system evolution under DRC, while the outer level refines the anisotropic metric leveraging control-performance feedback across a range of initial conditions. To solve this program efficiently, we develop a stochastic augmented Lagrangian algorithm tailored to the bilevel structure. Theoretically, we prove that the learned ambiguity sets preserve statistical finite-sample guarantees under a novel radius adjustment mechanism, and we establish the well-posedness of the bilevel formulation by demonstrating its continuity with respect to the learnable metric. Furthermore, we show that the algorithm converges to stationary points of the outer level problem, which are statistically consistent with the optimal metric at a non-asymptotic convergence rate. Experiments on both numerical and inventory control tasks verify that the proposed framework achieves superior closed-loop performance and robustness compared against state-of-the-art methods.",
    "authors": [
      "Jingyi Wu",
      "Chao Ning",
      "Yang Shi"
    ],
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-11T13:40:49.000Z",
    "updatedAt": "2025-10-11T13:40:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10214v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10214v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10209v1",
    "arxivId": "2510.10209v1",
    "title": "LOOPerSet: A Large-Scale Dataset for Data-Driven Polyhedral Compiler Optimization",
    "abstract": "The advancement of machine learning for compiler optimization, particularly within the polyhedral model, is constrained by the scarcity of large-scale, public performance datasets. This data bottleneck forces researchers to undertake costly data generation campaigns, slowing down innovation and hindering reproducible research learned code optimization. To address this gap, we introduce LOOPerSet, a new public dataset containing 28 million labeled data points derived from 220,000 unique, synthetically generated polyhedral programs. Each data point maps a program and a complex sequence of semantics-preserving transformations (such as fusion, skewing, tiling, and parallelism)to a ground truth performance measurement (execution time). The scale and diversity of LOOPerSet make it a valuable resource for training and evaluating learned cost models, benchmarking new model architectures, and exploring the frontiers of automated polyhedral scheduling. The dataset is released under a permissive license to foster reproducible research and lower the barrier to entry for data-driven compiler optimization.",
    "authors": [
      "Massinissa Merouani",
      "Afif Boudaoud",
      "Riyadh Baghdadi"
    ],
    "categories": [
      "cs.PL",
      "cs.LG",
      "cs.PF"
    ],
    "publishedAt": "2025-10-11T13:27:02.000Z",
    "updatedAt": "2025-10-11T13:27:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10209v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10209v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10206v1",
    "arxivId": "2510.10206v1",
    "title": "It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots",
    "abstract": "The true promise of humanoid robotics lies beyond single-agent autonomy: two or more humanoids must engage in physically grounded, socially meaningful whole-body interactions that echo the richness of human social interaction. However, single-humanoid methods suffer from the isolation issue, ignoring inter-agent dynamics and causing misaligned contacts, interpenetrations, and unrealistic motions. To address this, we present Harmanoid , a dual-humanoid motion imitation framework that transfers interacting human motions to two robots while preserving both kinematic fidelity and physical realism. Harmanoid comprises two key components: (i) contact-aware motion retargeting, which restores inter-body coordination by aligning SMPL contacts with robot vertices, and (ii) interaction-driven motion controller, which leverages interaction-specific rewards to enforce coordinated keypoints and physically plausible contacts. By explicitly modeling inter-agent contacts and interaction-aware dynamics, Harmanoid captures the coupled behaviors between humanoids that single-humanoid frameworks inherently overlook. Experiments demonstrate that Harmanoid significantly improves interactive motion imitation, surpassing existing single-humanoid frameworks that largely fail in such scenarios.",
    "authors": [
      "Zuhong Liu",
      "Junhao Ge",
      "Minhao Xiong",
      "Jiahao Gu",
      "Bowei Tang",
      "Wei Jing",
      "Siheng Chen"
    ],
    "categories": [
      "cs.RO",
      "cs.MA"
    ],
    "publishedAt": "2025-10-11T13:14:13.000Z",
    "updatedAt": "2025-10-11T13:14:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10206v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10206v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10202v1",
    "arxivId": "2510.10202v1",
    "title": "Performance Index Shaping for Closed-loop Optimal Control",
    "abstract": "The design of the performance index, also referred to as cost or reward shaping, is central to both optimal control and reinforcement learning, as it directly determines the behaviors, trade-offs, and objectives that the resulting control laws seek to achieve. A commonly used approach for this inference task in recent years is differentiable trajectory optimization, which allows gradients to be computed with respect to cost parameters by differentiating through an optimal control solver. However, this method often requires repeated solving of the underlying optimal control problem at every iteration, making the method computationally expensive. In this work, assuming known dynamics, we propose a novel framework that analytically links the performance index to the resulting closed-loop optimal control law, thereby transforming a typically bi-level inverse problem into a tractable single-level formulation. Our approach is motivated by the question: given a closed-loop control law that solves an infinite-horizon optimal control problem, how does this law change when the performance index is modified with additional terms? This formulation yields closed-form characterizations for broad classes of systems and performance indices, which not only facilitate interpretation and stability analysis, but also provide insight into the robust stability and input-to-state stable behavior of the resulting nonlinear closed-loop system. Moreover, this analytical perspective enables the generalization of our approach to diverse design objectives, yielding a unifying framework for performance index shaping. Given specific design objectives, we propose a systematic methodology to guide the shaping of the performance index and thereby design the resulting optimal control law.",
    "authors": [
      "Ayush Rai",
      "Shaoshuai Mou",
      "Brian D. O. Anderson"
    ],
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ],
    "publishedAt": "2025-10-11T13:05:46.000Z",
    "updatedAt": "2025-10-11T13:05:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10202v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10202v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10199v1",
    "arxivId": "2510.10199v1",
    "title": "Revisiting Trust in the Era of Generative AI: Factorial Structure and Latent Profiles",
    "abstract": "Trust is one of the most important factors shaping whether and how people adopt and rely on artificial intelligence (AI). Yet most existing studies measure trust in terms of functionality, focusing on whether a system is reliable, accurate, or easy to use, while giving less attention to the social and emotional dimensions that are increasingly relevant for today's generative AI (GenAI) systems. These systems do not just process information; they converse, respond, and collaborate with users, blurring the line between tool and partner. In this study, we introduce and validate the Human-AI Trust Scale (HAITS), a new measure designed to capture both the rational and relational aspects of trust in GenAI. Drawing on prior trust theories, qualitative interviews, and two waves of large-scale surveys in China and the United States, we used exploratory (n = 1,546) and confirmatory (n = 1,426) factor analyses to identify four key dimensions of trust: Affective Trust, Competence Trust, Benevolence & Integrity, and Perceived Risk. We then applied latent profile analysis to classify users into six distinct trust profiles, revealing meaningful differences in how affective-competence trust and trust-distrust frameworks coexist across individuals and cultures. Our findings offer a validated, culturally sensitive tool for measuring trust in GenAI and provide new insight into how trust evolves in human-AI interaction. By integrating instrumental and relational perspectives of trust, this work lays the foundation for more nuanced research and design of trustworthy AI systems.",
    "authors": [
      "Haocan Sun",
      "Weizi Liu",
      "Di Wu",
      "Guoming Yu",
      "Mike Yao"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T12:39:53.000Z",
    "updatedAt": "2025-10-11T12:39:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10199v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10199v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10181v1",
    "arxivId": "2510.10181v1",
    "title": "Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback",
    "abstract": "Embodied agents face a fundamental limitation: once deployed in real-world environments to perform specific tasks, they are unable to acquire new useful knowledge to enhance task performance. In this paper, we propose a general post-deployment learning framework called Dejavu, which employs an Experience Feedback Network (EFN) and augments the frozen Vision-Language-Action (VLA) policy with retrieved execution memories. EFN automatically identifies contextually successful prior action experiences and conditions action prediction on this retrieved guidance. We adopt reinforcement learning with semantic similarity rewards on EFN to ensure that the predicted actions align with past successful behaviors under current observations. During deployment, EFN continually enriches its memory with new trajectories, enabling the agent to exhibit \"learning from experience\" despite fixed weights. Experiments across diverse embodied tasks show that EFN significantly improves adaptability, robustness, and success rates over frozen baselines. These results highlight a promising path toward embodied agents that continually refine their behavior after deployment.",
    "authors": [
      "Shaokai Wu",
      "Yanbiao Ji",
      "Qiuchang Li",
      "Zhiyi Zhang",
      "Qichen He",
      "Wenyuan Xie",
      "Guodong Zhang",
      "Bayram Bayramli",
      "Yue Ding",
      "Hongtao Lu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-11T11:43:58.000Z",
    "updatedAt": "2025-10-11T11:43:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10181v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10181v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10179v1",
    "arxivId": "2510.10179v1",
    "title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models",
    "abstract": "The rapid development of large language models (LLMs) has revolutionized software testing, particularly fuzz testing, by automating the generation of diverse and effective test inputs. This advancement holds great promise for improving software reliability. Meanwhile, the introduction of MOJO, a high-performance AI programming language blending Python's usability with the efficiency of C and C++, presents new opportunities to enhance AI model scalability and programmability. However, as a new language, MOJO lacks comprehensive testing frameworks and a sufficient corpus for LLM-based testing, which exacerbates model hallucination. In this case, LLMs will generate syntactically valid but semantically incorrect code, significantly reducing the effectiveness of fuzz testing. To address this challenge, we propose MOJOFuzzer, the first adaptive LLM-based fuzzing framework designed for zero-shot learning environments of emerging programming languages. MOJOFuzzer integrates a mutil-phase framework that systematically eliminates low-quality generated inputs before execution, significantly improving test case validity. Furthermore, MOJOFuzzer dynamically adapts LLM prompts based on runtime feedback for test case mutation, enabling an iterative learning process that continuously enhances fuzzing efficiency and bug detection performance. Our experimental results demonstrate that MOJOFuzzer significantly enhances test validity, API coverage, and bug detection performance, outperforming traditional fuzz testing and state-of-the-art LLM-based fuzzing approaches. Using MOJOFuzzer, we have conducted a first large-scale fuzz testing evaluation of MOJO, uncorvering 13 previous unknown bugs. This study not only advances the field of LLM-driven software testing but also establishes a foundational methodology for leveraging LLMs in the testing of emerging programming languages.",
    "authors": [
      "Linghan Huang",
      "Peizhou Zhao",
      "Huaming Chen"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T11:37:18.000Z",
    "updatedAt": "2025-10-11T11:37:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10179v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10179v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10175v1",
    "arxivId": "2510.10175v1",
    "title": "Peransformer: Improving Low-informed Expressive Performance Rendering with Score-aware Discriminator",
    "abstract": "Highly-informed Expressive Performance Rendering (EPR) systems transform music scores with rich musical annotations into human-like expressive performance MIDI files. While these systems have achieved promising results, the availability of detailed music scores is limited compared to MIDI files and are less flexible to work with using a digital audio workstation (DAW). Recent advancements in low-informed EPR systems offer a more accessible alternative by directly utilizing score-derived MIDI as input, but these systems often exhibit suboptimal performance. Meanwhile, existing works are evaluated with diverse automatic metrics and data formats, hindering direct objective comparisons between EPR systems. In this study, we introduce Peransformer, a transformer-based low-informed EPR system designed to bridge the gap between low-informed and highly-informed EPR systems. Our approach incorporates a score-aware discriminator that leverages the underlying score-derived MIDI files and is trained on a score-to-performance paired, note-to-note aligned MIDI dataset. Experimental results demonstrate that Peransformer achieves state-of-the-art performance among low-informed systems, as validated by subjective evaluations. Furthermore, we extend existing automatic evaluation metrics for EPR systems and introduce generalized EPR metrics (GEM), enabling more direct, accurate, and reliable comparisons across EPR systems.",
    "authors": [
      "Xian He",
      "Wei Zeng",
      "Ye Wang"
    ],
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-11T11:26:36.000Z",
    "updatedAt": "2025-10-11T11:26:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10175v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10175v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10173v1",
    "arxivId": "2510.10173v1",
    "title": "Chord Colourizer: A Near Real-Time System for Visualizing Musical Key",
    "abstract": "This paper introduces Chord Colourizer, a near real-time system that detects the musical key of an audio signal and visually represents it through a novel graphical user interface (GUI). The system assigns colours to musical notes based on Isaac Newton's original colour wheel, preserving historical links between pitch and hue, and also integrates an Arduino-controlled LED display using 3D-printed star-shaped diffusers to offer a physical ambient media representation. The method employs Constant-Q Transform (CQT) chroma features for chord estimation and visualization, followed by threshold-based filtering and tonal enhancement to isolate the root, third, and fifth. A confidence score is computed for each detection to ensure reliability, and only chords with moderate to very strong certainty are visualized. The graphical interface dynamically updates a colour-coded keyboard layout, while the LED display provides the same colour information via spatial feedback. This multi-modal system enhances user interaction with harmonic content, offering innovative possibilities for education and artistic performance. Limitations include slight latency and the inability to detect extended chords, which future development will aim to address through refined filtering, adaptive thresholds, and support for more complex harmonies such as sevenths and augmented chords. Future work will also explore integration with alternative visualization styles, and the comparison of audio analysis libraries to improve detection speed and precision. Plans also include formal user testing to evaluate perception, usability, and cross-cultural interpretations of colour-pitch mappings.",
    "authors": [
      "Paul Haimes"
    ],
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-11T11:24:32.000Z",
    "updatedAt": "2025-10-11T11:24:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10173v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10173v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10169v1",
    "arxivId": "2510.10169v1",
    "title": "BrainForm: a Serious Game for BCI Training and Data Collection",
    "abstract": "$\\textit{BrainForm}$ is a gamified Brain-Computer Interface (BCI) training system designed for scalable data collection using consumer hardware and a minimal setup. We investigated (1) how users develop BCI control skills across repeated sessions and (2) perceptual and performance effects of two visual stimulation textures. Game Experience Questionnaire (GEQ) scores for Flow}, Positive Affect, Competence and Challenge were strongly positive, indicating sustained engagement. A within-subject study with multiple runs, two task complexities, and post-session questionnaires revealed no significant performance differences between textures but increased ocular irritation over time. Online metrics$\\unicode{x2013}$Task Accuracy, Task Time, and Information Transfer Rate$\\unicode{x2013}$improved across sessions, confirming learning effects for symbol spelling, even under pressure conditions. Our results highlight the potential of $\\textit{BrainForm}$ as a scalable, user-friendly BCI research tool and offer guidance for sustained engagement and reduced training fatigue.",
    "authors": [
      "Michele Romani",
      "Devis Zanoni",
      "Elisabetta Farella",
      "Luca Turchet"
    ],
    "categories": [
      "cs.HC",
      "cs.LG",
      "H.1.2; I.2.6; I.5.2"
    ],
    "publishedAt": "2025-10-11T11:17:04.000Z",
    "updatedAt": "2025-10-11T11:17:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10169v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10169v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10166v1",
    "arxivId": "2510.10166v1",
    "title": "Proactive and Reactive Autoscaling Techniques for Edge Computing",
    "abstract": "Edge computing allows for the decentralization of computing resources. This decentralization is achieved through implementing microservice architectures, which require low latencies to meet stringent service level agreements (SLA) such as performance, reliability, and availability metrics. While cloud computing offers the large data storage and computation resources necessary to handle peak demands, a hybrid cloud and edge environment is required to ensure SLA compliance. Several auto-scaling algorithms have been proposed to try to achieve these compliance challenges, but they suffer from performance issues and configuration complexity. This chapter provides a brief overview of edge computing architecture, its uses, benefits, and challenges for resource scaling. We then introduce Service Level Agreements, and existing research on devising algorithms used in edge computing environments to meet these agreements, along with their benefits and drawbacks.",
    "authors": [
      "Suhrid Gupta",
      "Muhammed Tawfiqul Islam",
      "Rajkumar Buyya"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-11T11:10:23.000Z",
    "updatedAt": "2025-10-11T11:10:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10166v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10166v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10154v1",
    "arxivId": "2510.10154v1",
    "title": "CompassNav: Steering From Path Imitation To Decision Understanding In Navigation",
    "abstract": "The dominant paradigm for training Large Vision-Language Models (LVLMs) in navigation relies on imitating expert trajectories. This approach reduces the complex navigation task to a sequence-to-sequence replication of a single correct path, fundamentally limiting the agent's ability to explore and generalize. In this work, we argue for and introduce a new paradigm: a shift from Path Imitation to Decision Understanding. The goal of this paradigm is to build agents that do not just follow, but truly understand how to navigate. We materialize this through two core contributions: first, we introduce Compass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning (RFT) subset provides a panoramic view of the decision landscape by annotating all feasible actions with A* geodesic distances. Second, we design a novel gap-aware hybrid reward function that dynamically adapts its feedback to decision certainty, shifting between decisive signals for optimal actions and nuanced scores to encourage exploration. Integrated into an SFT-then-RFT recipe, our CompassNav agent is trained not to memorize static routes, but to develop an internal ``compass'' that constantly intuits the direction to the goal by evaluating the relative quality of all possible moves. This approach enables our 7B agent to set a new state-of-the-art on Goal navigation benchmarks, outperforming even larger proprietary models, and achieve robust real-world goal navigation on a physical robot.",
    "authors": [
      "LinFeng Li",
      "Jian Zhao",
      "Yuan Xie",
      "Xin Tan",
      "Xuelong Li"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T10:25:00.000Z",
    "updatedAt": "2025-10-11T10:25:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10154v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10154v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10148v1",
    "arxivId": "2510.10148v1",
    "title": "A Systematic Study on Generating Web Vulnerability Proof-of-Concepts Using Large Language Models",
    "abstract": "Recent advances in Large Language Models (LLMs) have brought remarkable progress in code understanding and reasoning, creating new opportunities and raising new concerns for software security. Among many downstream tasks, generating Proof-of-Concept (PoC) exploits plays a central role in vulnerability reproduction, comprehension, and mitigation. While previous research has focused primarily on zero-day exploitation, the growing availability of rich public information accompanying disclosed CVEs leads to a natural question: can LLMs effectively use this information to automatically generate valid PoCs? In this paper, we present the first empirical study of LLM-based PoC generation for web application vulnerabilities, focusing on the practical feasibility of leveraging publicly disclosed information. We evaluate GPT-4o and DeepSeek-R1 on 100 real-world and reproducible CVEs across three stages of vulnerability disclosure: (1) newly disclosed vulnerabilities with only descriptions, (2) 1-day vulnerabilities with patches, and (3) N-day vulnerabilities with full contextual code. Our results show that LLMs can automatically generate working PoCs in 8%-34% of cases using only public data, with DeepSeek-R1 consistently outperforming GPT-4o. Further analysis shows that supplementing code context improves success rates by 17%-20%, with function-level providing 9%-13% improvement than file-level ones. Further integrating adaptive reasoning strategies to prompt refinement significantly improves success rates to 68%-72%. Our findings suggest that LLMs could reshape vulnerability exploitation dynamics. To date, 23 newly generated PoCs have been accepted by NVD and Exploit DB.",
    "authors": [
      "Mengyao Zhao",
      "Kaixuan Li",
      "Lyuye Zhang",
      "Wenjing Dang",
      "Chenggong Ding",
      "Sen Chen",
      "Zheli Liu"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-11T10:15:38.000Z",
    "updatedAt": "2025-10-11T10:15:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10148v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10148v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10126v1",
    "arxivId": "2510.10126v1",
    "title": "FedMon: Federated eBPF Monitoring for Distributed Anomaly Detection in Multi-Cluster Cloud Environments",
    "abstract": "Kubernetes multi-cluster deployments demand scalable and privacy-preserving anomaly detection. Existing eBPF-based monitors provide low-overhead system and network visibility but are limited to single clusters, while centralized approaches incur bandwidth, privacy, and heterogeneity challenges. We propose FedMon, a federated eBPF framework that unifies kernel-level telemetry with federated learning (FL) for cross-cluster anomaly detection. Lightweight eBPF agents capture syscalls and network events, extract local statistical and sequence features, and share only model updates with a global server. A hybrid detection engine combining Variational Autoencoders (VAEs) with Isolation Forests enables both temporal pattern modeling and outlier detection. Deployed across three Kubernetes clusters, FedMon achieves 94% precision, 91% recall, and an F1-score of 0.92, while cutting bandwidth usage by 60% relative to centralized baselines. Results demonstrate that FedMon enhances accuracy, scalability, and privacy, providing an effective defense for large-scale, multi-tenant cloud-native environments.",
    "authors": [
      "Sehar Zehra",
      "Hassan Jamil Syed",
      "Ummay Faseeha"
    ],
    "categories": [
      "cs.DC",
      "F.2.2, I.2.7"
    ],
    "publishedAt": "2025-10-11T09:16:35.000Z",
    "updatedAt": "2025-10-11T09:16:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10126v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10126v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10125v1",
    "arxivId": "2510.10125v1",
    "title": "Ctrl-World: A Controllable Generative World Model for Robot Manipulation",
    "abstract": "Generalist robot policies can now perform a wide range of manipulation skills, but evaluating and improving their ability with unfamiliar objects and instructions remains a significant challenge. Rigorous evaluation requires a large number of real-world rollouts, while systematic improvement demands additional corrective data with expert labels. Both of these processes are slow, costly, and difficult to scale. World models offer a promising, scalable alternative by enabling policies to rollout within imagination space. However, a key challenge is building a controllable world model that can handle multi-step interactions with generalist robot policies. This requires a world model compatible with modern generalist policies by supporting multi-view prediction, fine-grained action control, and consistent long-horizon interactions, which is not achieved by previous works. In this paper, we make a step forward by introducing a controllable multi-view world model that can be used to evaluate and improve the instruction-following ability of generalist robot policies. Our model maintains long-horizon consistency with a pose-conditioned memory retrieval mechanism and achieves precise action control through frame-level action conditioning. Trained on the DROID dataset (95k trajectories, 564 scenes), our model generates spatially and temporally consistent trajectories under novel scenarios and new camera placements for over 20 seconds. We show that our method can accurately rank policy performance without real-world robot rollouts. Moreover, by synthesizing successful trajectories in imagination and using them for supervised fine-tuning, our approach can improve policy success by 44.7\\%.",
    "authors": [
      "Yanjiang Guo",
      "Lucy Xiaoyang Shi",
      "Jianyu Chen",
      "Chelsea Finn"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T09:13:10.000Z",
    "updatedAt": "2025-10-11T09:13:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10125v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10125v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10119v1",
    "arxivId": "2510.10119v1",
    "title": "IntrinTrans: LLM-based Intrinsic Code Translator for RISC-V Vector",
    "abstract": "The use of intrinsic functions to exploit hardware-specific capabilities is an important approach for optimizing library performance. Many mainstream libraries implement a large number of vectorized algorithms on Arm or x86 SIMD intrinsic functions. With the rapid expansion of the RISC-V hardware-software ecosystem, there is a growing demand for support of the RISC-V Vector (RVV) extension. Translating existing vectorized intrinsic code onto RVV intrinsics is a practical and effective approach. However, current cross-architecture translation largely relies on manual rewriting, which is time-consuming and error-prone. Furthermore, while some rule-based methods can reduce the need for manual intervention, their translation success rate is limited by incomplete rule coverage and syntactic constraints, and the performance suffers from inadequate utilization of RVV-specific features. We present IntrinTrans, a LLM-based multi-agent approach that utilizes compile-and-test feedback to translate intrinsic code across architectures automatically, and further optimizes the generated RVV intrinsics using register-usage information derived from liveness analysis. To evaluate the effectiveness of our approach, we collected 34 vectorized algorithm cases from open-source libraries. Each case includes an Arm Neon intrinsics implementation and a RVV intrinsics implementation contributed by the open-source community, together with correctness and performance tests. Our experiments show that advanced LLMs produce semantically correct RISC-V Vector intrinsics in most cases within a limited number of iterations, and in some cases achieve up to 5.93x the performance of the native implementation from the open-source community.",
    "authors": [
      "Liutong Han",
      "Zhiyuan Tan",
      "Hongbin Zhang",
      "Pengcheng Wang",
      "Chu Kang",
      "Mingjie Xing",
      "Yanjun Wu"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-11T08:52:01.000Z",
    "updatedAt": "2025-10-11T08:52:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10119v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10119v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10116v1",
    "arxivId": "2510.10116v1",
    "title": "Preference-driven Knowledge Distillation for Few-shot Node Classification",
    "abstract": "Graph neural networks (GNNs) can efficiently process text-attributed graphs (TAGs) due to their message-passing mechanisms, but their training heavily relies on the human-annotated labels. Moreover, the complex and diverse local topologies of nodes of real-world TAGs make it challenging for a single mechanism to handle. Large language models (LLMs) perform well in zero-/few-shot learning on TAGs but suffer from a scalability challenge. Therefore, we propose a preference-driven knowledge distillation (PKD) framework to synergize the complementary strengths of LLMs and various GNNs for few-shot node classification. Specifically, we develop a GNN-preference-driven node selector that effectively promotes prediction distillation from LLMs to teacher GNNs. To further tackle nodes' intricate local topologies, we develop a node-preference-driven GNN selector that identifies the most suitable teacher GNN for each node, thereby facilitating tailored knowledge distillation from teacher GNNs to the student GNN. Extensive experiments validate the efficacy of our proposed framework in few-shot node classification on real-world TAGs.",
    "authors": [
      "Xing Wei",
      "Chunchun Chen",
      "Rui Fan",
      "Xiaofeng Cao",
      "Sourav Medya",
      "Wei Ye"
    ],
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "publishedAt": "2025-10-11T08:48:47.000Z",
    "updatedAt": "2025-10-11T08:48:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10116v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10116v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10087v1",
    "arxivId": "2510.10087v1",
    "title": "Matchmaker: An Open-source Library for Real-time Piano Score Following and Systematic Evaluation",
    "abstract": "Real-time music alignment, also known as score following, is a fundamental MIR task with a long history and is essential for many interactive applications. Despite its importance, there has not been a unified open framework for comparing models, largely due to the inherent complexity of real-time processing and the language- or system-dependent implementations. In addition, low compatibility with the existing MIR environment has made it difficult to develop benchmarks using large datasets available in recent years. While new studies based on established methods (e.g., dynamic programming, probabilistic models) have emerged, most evaluations compare models only within the same family or on small sets of test data. This paper introduces Matchmaker, an open-source Python library for real-time music alignment that is easy to use and compatible with modern MIR libraries. Using this, we systematically compare methods along two dimensions: music representations and alignment methods. We evaluated our approach on a large test set of solo piano music from the (n)ASAP, Batik, and Vienna4x22 datasets with a comprehensive set of metrics to ensure robust assessment. Our work aims to establish a benchmark framework for score-following research while providing a practical tool that developers can easily integrate into their applications.",
    "authors": [
      "Jiyun Park",
      "Carlos Cancino-Chacón",
      "Suhit Chiruthapudi",
      "Juhan Nam"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-11T07:58:30.000Z",
    "updatedAt": "2025-10-11T07:58:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10087v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10087v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10086v1",
    "arxivId": "2510.10086v1",
    "title": "Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety-Critical Prediction in Multi-Agent Autonomous Driving Scenarios",
    "abstract": "Current evaluation methods for autonomous driving prediction models rely heavily on simplistic metrics such as Average Displacement Error (ADE) and Final Displacement Error (FDE). While these metrics offer basic performance assessments, they fail to capture the nuanced behavior of prediction modules under complex, interactive, and safety-critical driving scenarios. For instance, existing benchmarks do not distinguish the influence of nearby versus distant agents, nor systematically test model robustness across varying multi-agent interactions. This paper addresses this critical gap by proposing a novel testing framework that evaluates prediction performance under diverse scene structures, saying, map context, agent density and spatial distribution. Through extensive empirical analysis, we quantify the differential impact of agent proximity on target trajectory prediction and identify scenario-specific failure cases that are not exposed by traditional metrics. Our findings highlight key vulnerabilities in current state-of-the-art prediction models and demonstrate the importance of scenario-aware evaluation. The proposed framework lays the groundwork for rigorous, safety-driven prediction validation, contributing significantly to the identification of failure-prone corner cases and the development of robust, certifiable prediction systems for autonomous vehicles.",
    "authors": [
      "Feifei Liu",
      "Haozhe Wang",
      "Zejun Wei",
      "Qirong Lu",
      "Yiyang Wen",
      "Xiaoyu Tang",
      "Jingyan Jiang",
      "Zhijian He"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T07:56:58.000Z",
    "updatedAt": "2025-10-11T07:56:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10086v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10086v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10081v1",
    "arxivId": "2510.10081v1",
    "title": "A Mathematics-Guided Approach to Floating-Point Error Detection",
    "abstract": "Floating-point program errors can lead to severe consequences, particularly in critical domains such as military applications. Only a small subset of inputs may induce substantial floating-point errors, prompting researchers to develop methods for identifying these error-inducing inputs. Although existing approaches have achieved some success, they still suffer from two major limitations: (1) High computational cost: The evaluation of error magnitude for candidate inputs relies on high-precision programs, which are prohibitively time-consuming. (2) Limited long-range convergence capability: Current methods exhibit inefficiency in search, making the process akin to finding a needle in a haystack. To address these two limitations, we propose a novel method, named MGDE, to detect error-inducing inputs based on mathematical guidance. By employing the Newton-Raphson method, which exhibits quadratic convergence properties, we achieve highly effective and efficient results. Since the goal of identifying error-inducing inputs is to uncover the underlying bugs, we use the number of bugs detected in floating-point programs as the primary evaluation metric in our experiments. As FPCC represents the most effective state-of-the-art approach to date, we use it as the baseline for comparison. The dataset of FPCC consists of 88 single-input floating-point programs. FPCC is able to detect 48 bugs across 29 programs, whereas our method successfully identifies 89 bugs across 44 programs. Moreover, FPCC takes 6.4096 times as long as our proposed method. We also deploy our method to multi-input programs, identifying a total of nine bugs with an average detection time of 0.6443 seconds per program. In contrast, FPCC fails to detect any bugs while requiring an average computation time of 100 seconds per program.",
    "authors": [
      "Youshuai Tan",
      "Zhanwei Zhang",
      "Zishuo Ding",
      "Lianyu Zheng",
      "Jinfu Chen",
      "Weiyi Shang"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-11T07:38:14.000Z",
    "updatedAt": "2025-10-11T07:38:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10081v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10081v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10079v1",
    "arxivId": "2510.10079v1",
    "title": "How AI Companionship Develops: Evidence from a Longitudinal Study",
    "abstract": "The quickly growing popularity of AI companions poses risks to mental health, personal wellbeing, and social relationships. Past work has identified many individual factors that can drive human-companion interaction, but we know little about how these factors interact and evolve over time. In Study 1, we surveyed AI companion users (N = 303) to map the psychological pathway from users' mental models of the agent to parasocial experiences, social interaction, and the psychological impact of AI companions. Participants' responses foregrounded multiple interconnected variables (agency, parasocial interaction, and engagement) that shape AI companionship. In Study 2, we conducted a longitudinal study with a subset of participants (N = 110) using a new generic chatbot. Participants' perceptions of the generic chatbot significantly converged to perceptions of their own companions by Week 3. These results suggest a longitudinal model of AI companionship development and demonstrate an empirical method to study human-AI companionship.",
    "authors": [
      "Angel Hsing-Chi Hwang",
      "Fiona Li",
      "Jacy Reese Anthis",
      "Hayoun Noh"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-11T07:36:47.000Z",
    "updatedAt": "2025-10-11T07:36:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10079v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10079v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10078v1",
    "arxivId": "2510.10078v1",
    "title": "Improving Speech Emotion Recognition with Mutual Information Regularized Generative Model",
    "abstract": "Although speech emotion recognition (SER) research has been advanced, thanks to deep learning methods, it still suffers from obtaining inputs from large quality-labelled training data. Data augmentation methods have been attempted to mitigate this issue, generative models have shown success among them recently. We propose a data augmentation framework that is aided by cross-modal information transfer and mutual information regularization. Mutual information based metric can serve as an indicator for the quality. Furthermore, we expand this data augmentation scope to multimodal inputs, thanks to mutual information ensureing dependency between modalities. Our framework was tested on three benchmark datasets: IEMOCAP, MSP-IMPROV and MSP-Podcast. The implementation was designed to generate input features that are fed into last layer for emotion classification. Our framework improved the performance of emotion prediction against existing works. Also, we discovered that our framework is able to generate new inputs without any cross-modal information.",
    "authors": [
      "Chung-Soo Ahn",
      "Rajib Rana",
      "Sunil Sivadas",
      "Carlos Busso",
      "Jagath C. Rajapakse"
    ],
    "categories": [
      "cs.SD",
      "cs.LG"
    ],
    "publishedAt": "2025-10-11T07:29:32.000Z",
    "updatedAt": "2025-10-11T07:29:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10078v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10078v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10066v1",
    "arxivId": "2510.10066v1",
    "title": "OBsmith: Testing JavaScript Obfuscator using LLM-powered sketching",
    "abstract": "JavaScript obfuscators are widely deployed to protect intellectual property and resist reverse engineering, yet their correctness has been largely overlooked compared to performance and resilience. Existing evaluations typically measure resistance to deobfuscation, leaving the critical question of whether obfuscators preserve program semantics unanswered. Incorrect transformations can silently alter functionality, compromise reliability, and erode security-undermining the very purpose of obfuscation. To address this gap, we present OBsmith, a novel framework to systematically test JavaScript obfuscators using large language models (LLMs). OBsmith leverages LLMs to generate program sketches abstract templates capturing diverse language constructs, idioms, and corner cases-which are instantiated into executable programs and subjected to obfuscation under different configurations. Besides LLM-powered sketching, OBsmith also employs a second source: automatic extraction of sketches from real programs. This extraction path enables more focused testing of project specific features and lets developers inject domain knowledge into the resulting test cases. OBsmith uncovers 11 previously unknown correctness bugs. Under an equal program budget, five general purpose state-of-the-art JavaScript fuzzers (FuzzJIT, Jsfunfuzz, Superion, DIE, Fuzzilli) failed to detect these issues, highlighting OBsmith's complementary focus on obfuscation induced misbehavior. An ablation shows that all components except our generic MRs contribute to at least one bug class; the negative MR result suggests the need for obfuscator-specific metamorphic relations. Our results also seed discussion on how to balance obfuscation presets and performance cost. We envision OBsmith as an important step towards automated testing and quality assurance of obfuscators and other semantic-preserving toolchains.",
    "authors": [
      "Shan Jiang",
      "Chenguang Zhu",
      "Sarfraz Khurshid"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "publishedAt": "2025-10-11T07:02:42.000Z",
    "updatedAt": "2025-10-11T07:02:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10066v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10066v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10059v1",
    "arxivId": "2510.10059v1",
    "title": "Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model",
    "abstract": "Recent advancements in lunar positioning, navigation, and timing (PNT) have demonstrated that terrestrial GNSS signals, including weak sidelobe transmissions, can be exploited for lunar spacecraft positioning and timing. While GNSS-based navigation at the Moon has been validated recently, unmodeled ionospheric and plasmaspheric delays remain a significant error source, particularly given the unique signal geometry and extended propagation paths. This paper characterizes these delays using the Global Core Plasma Model (GCPM) and a custom low-cost ray-tracing algorithm that iteratively solves for bent signal paths. We simulate first-, second-, and third-order group delays, as well as excess path length from ray bending, for GNSS signals received at both lunar orbit and the lunar south pole under varying solar and geomagnetic conditions. Results show that mean group delays are typically on the order of 1 m, but can exceed 100 m for low-altitude ray paths during high solar activity, while bending delays are generally smaller but non-negligible for low-altitude ray paths. We also quantify the influence of signal frequency, geomagnetic $K_p$ index, and solar R12 index. These findings inform the design of robust positioning and timing algorithms that utilize terrestrial GNSS signals.",
    "authors": [
      "Keidai Iiyama",
      "Grace Gao"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T06:53:01.000Z",
    "updatedAt": "2025-10-11T06:53:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10059v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10059v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10049v1",
    "arxivId": "2510.10049v1",
    "title": "ALLOY: Generating Reusable Agent Workflows from User Demonstration",
    "abstract": "Large language models (LLMs) enable end-users to delegate complex tasks to autonomous agents through natural language. However, prompt-based interaction faces critical limitations: Users often struggle to specify procedural requirements for tasks, especially those that don't have a factually correct solution but instead rely on personal preferences, such as posting social media content or planning a trip. Additionally, a ''successful'' prompt for one task may not be reusable or generalizable across similar tasks. We present ALLOY, a system inspired by classical HCI theories on Programming by Demonstration (PBD), but extended to enhance adaptability in creating LLM-based web agents. ALLOY enables users to express procedural preferences through natural demonstrations rather than prompts, while making these procedures transparent and editable through visualized workflows that can be generalized across task variations. In a study with 12 participants, ALLOY's demonstration--based approach outperformed prompt-based agents and manual workflows in capturing user intent and procedural preferences in complex web tasks. Insights from the study also show how demonstration--based interaction complements the traditional prompt-based approach.",
    "authors": [
      "Jiawen Li",
      "Zheng Ning",
      "Yuan Tian",
      "Toby Jia-jun Li"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MA"
    ],
    "publishedAt": "2025-10-11T06:30:34.000Z",
    "updatedAt": "2025-10-11T06:30:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10049v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10049v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10048v1",
    "arxivId": "2510.10048v1",
    "title": "Between Knowledge and Care: Evaluating Generative AI-Based IUI in Type 2 Diabetes Management Through Patient and Physician Perspectives",
    "abstract": "Generative AI systems are increasingly adopted by patients seeking everyday health guidance, yet their reliability and clinical appropriateness remain uncertain. Taking Type 2 Diabetes Mellitus (T2DM) as a representative chronic condition, this paper presents a two-part mixed-methods study that examines how patients and physicians in China evaluate the quality and usability of AI-generated health information. Study~1 analyzes 784 authentic patient questions to identify seven core categories of informational needs and five evaluation dimensions -- \\textit{Accuracy, Safety, Clarity, Integrity}, and \\textit{Action Orientation}. Study~2 involves seven endocrinologists who assess responses from four mainstream AI models across these dimensions. Quantitative and qualitative findings reveal consistent strengths in factual and lifestyle guidance but significant weaknesses in medication interpretation, contextual reasoning, and empathy. Patients view AI as an accessible ``pre-visit educator,'' whereas clinicians highlight its lack of clinical safety and personalization. Together, the findings inform design implications for interactive health systems, advocating for multi-model orchestration, risk-aware fallback mechanisms, and emotionally attuned communication to ensure trustworthy AI assistance in chronic disease care.",
    "authors": [
      "Yibo Meng",
      "Ruiqi Chen",
      "Zhiming Liu",
      "Xiaolan Ding",
      "Yan Guan"
    ],
    "categories": [
      "cs.HC",
      "H.5.2; I.2.6; J.3"
    ],
    "publishedAt": "2025-10-11T06:29:58.000Z",
    "updatedAt": "2025-10-11T06:29:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10048v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10048v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10046v1",
    "arxivId": "2510.10046v1",
    "title": "LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints",
    "abstract": "Long-term monitoring of numerous dynamic targets can be tedious for a human operator and infeasible for a single robot, e.g., to monitor wild flocks, detect intruders, search and rescue. Fleets of autonomous robots can be effective by acting collaboratively and concurrently. However, the online coordination is challenging due to the unknown behaviors of the targets and the limited perception of each robot. Existing work often deploys all robots available without minimizing the fleet size, or neglects the constraints on their resources such as battery and memory. This work proposes an online coordination scheme called LOMORO for collaborative target monitoring, path routing and resource charging. It includes three core components: (I) the modeling of multi-robot task assignment problem under the constraints on resources and monitoring intervals; (II) the resource-aware task coordination algorithm iterates between the high-level assignment of dynamic targets and the low-level multi-objective routing via the Martin's algorithm; (III) the online adaptation algorithm in case of unpredictable target behaviors and robot failures. It ensures the explicitly upper-bounded monitoring intervals for all targets and the lower-bounded resource levels for all robots, while minimizing the average number of active robots. The proposed methods are validated extensively via large-scale simulations against several baselines, under different road networks, robot velocities, charging rates and monitoring intervals.",
    "authors": [
      "Mingke Lu",
      "Shuaikang Wang",
      "Meng Guo"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T06:27:24.000Z",
    "updatedAt": "2025-10-11T06:27:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10046v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10046v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10039v1",
    "arxivId": "2510.10039v1",
    "title": "Combinatorial Philosopher Inequalities",
    "abstract": "In online combinatorial allocation, agents arrive sequentially and items are allocated in an online manner. The algorithm designer only knows the distribution of each agent's valuation, while the actual realization of the valuation is revealed only upon her arrival. Against the offline benchmark, Feldman, Gravin, and Lucier (SODA 2015) designed an optimal $0.5$-competitive algorithm for XOS agents. An emerging line of work focuses on designing approximation algorithms against the (computationally unbounded) optimal online algorithm. The primary goal is to design algorithms with approximation ratios strictly greater than $0.5$, surpassing the impossibility result against the offline optimum. Positive results are established for unit-demand agents (Papadimitriou, Pollner, Saberi, Wajc, MOR 2024), and for $k$-demand agents (Braun, Kesselheim, Pollner, Saberi, EC 2024). In this paper, we extend the existing positive results for agents with submodular valuations by establishing a $0.5 + \\Omega(1)$ approximation against a newly constructed online configuration LP relaxation for the combinatorial allocation setting. Meanwhile, we provide negative results for agents with XOS valuations by providing a $0.5$ integrality gap for the online configuration LP, showing an obstacle of existing approaches.",
    "authors": [
      "Enze Sun",
      "Zhihao Gavin Tang",
      "Yifan Wang"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-11T05:56:08.000Z",
    "updatedAt": "2025-10-11T05:56:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10039v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10039v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10028v1",
    "arxivId": "2510.10028v1",
    "title": "Efficient Onboard Vision-Language Inference in UAV-Enabled Low-Altitude Economy Networks via LLM-Enhanced Optimization",
    "abstract": "The rapid advancement of Low-Altitude Economy Networks (LAENets) has enabled a variety of applications, including aerial surveillance, environmental sensing, and semantic data collection. To support these scenarios, unmanned aerial vehicles (UAVs) equipped with onboard vision-language models (VLMs) offer a promising solution for real-time multimodal inference. However, ensuring both inference accuracy and communication efficiency remains a significant challenge due to limited onboard resources and dynamic network conditions. In this paper, we first propose a UAV-enabled LAENet system model that jointly captures UAV mobility, user-UAV communication, and the onboard visual question answering (VQA) pipeline. Based on this model, we formulate a mixed-integer non-convex optimization problem to minimize task latency and power consumption under user-specific accuracy constraints. To solve the problem, we design a hierarchical optimization framework composed of two parts: (i) an Alternating Resolution and Power Optimization (ARPO) algorithm for resource allocation under accuracy constraints, and (ii) a Large Language Model-augmented Reinforcement Learning Approach (LLaRA) for adaptive UAV trajectory optimization. The large language model (LLM) serves as an expert in refining reward design of reinforcement learning in an offline fashion, introducing no additional latency in real-time decision-making. Numerical results demonstrate the efficacy of our proposed framework in improving inference performance and communication efficiency under dynamic LAENet conditions.",
    "authors": [
      "Yang Li",
      "Ruichen Zhang",
      "Yinqiu Liu",
      "Guangyuan Liu",
      "Dusit Niyato",
      "Abbas Jamalipour",
      "Xianbin Wang",
      "Dong In Kim"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "publishedAt": "2025-10-11T05:11:21.000Z",
    "updatedAt": "2025-10-11T05:11:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10028v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10028v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10019v1",
    "arxivId": "2510.10019v1",
    "title": "\"Can I Decorate My Teeth With Diamonds?\": Exploring Multi-Stakeholder Perspectives on Using VR to Reduce Children's Dental Anxiety",
    "abstract": "Dental anxiety is prevalent among children, often leading to missed treatment and potential negative effects on their mental well-being. While several interventions (e.g., pharmacological and psychotherapeutic techniques) have been introduced for anxiety alleviation, the recently emerged virtual reality (VR) technology, with its immersive and playful nature, opened new opportunities for complementing and enhancing the therapeutic effects of existing interventions. In this light, we conducted a series of co-design workshops with 13 children aged 10-12 to explore how they envisioned using VR to address their fear and stress associated with dental visits, followed by interviews with parents (n = 13) and two dentists. Our findings revealed that children expected VR to provide immediate relief, social support, and a sense of control during dental treatment, parents sought educational opportunities for their children to learn about oral health, and dentists prioritized treatment efficiency and safety issues. Drawing from the findings, we discuss the considerations of multi-stakeholders for developing VR-assisted anxiety management applications for children within and beyond dental settings.",
    "authors": [
      "Yaxuan Mao",
      "Yanheng Li",
      "Duo Gong",
      "Pengcheng An",
      "Yuhan Luo"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-11T04:49:10.000Z",
    "updatedAt": "2025-10-11T04:49:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10019v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10019v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10016v1",
    "arxivId": "2510.10016v1",
    "title": "Hybrid Robotic Meta-gripper for Tomato Harvesting: Analysis of Auxetic Structures with Lattice Orientation Variations",
    "abstract": "The agricultural sector is rapidly evolving to meet growing global food demands, yet tasks like fruit and vegetable handling remain labor-intensive, causing inefficiencies and post-harvest losses. Automation, particularly selective harvesting, offers a viable solution, with soft robotics emerging as a key enabler. This study introduces a novel hybrid gripper for tomato harvesting, incorporating a rigid outer frame with a soft auxetic internal lattice. The six-finger, 3D caging-effect design enables gentle yet secure grasping in unstructured environments. Uniquely, the work investigates the effect of auxetic lattice orientation on grasping conformability, combining experimental validation with 2D Digital Image Correlation (DIC) and nonlinear finite element analysis (FEA). Auxetic configurations with unit cell inclinations of 0 deg, 30 deg, 45 deg, and 60 deg are evaluated, and their grasping forces, deformation responses, and motor torque requirements are systematically compared. Results demonstrate that lattice orientation strongly influences compliance, contact forces, and energy efficiency, with distinct advantages across configurations. This comparative framework highlights the novelty of tailoring auxetic geometries to optimize robotic gripper performance. The findings provide new insights into soft-rigid hybrid gripper design, advancing automation strategies for precision agriculture while minimizing crop damage.",
    "authors": [
      "Shahid Ansari",
      "Vivek Gupta",
      "Bishakh Bhattacharya"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T04:42:22.000Z",
    "updatedAt": "2025-10-11T04:42:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10016v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10016v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10015v1",
    "arxivId": "2510.10015v1",
    "title": "End-to-end Compositional Verification of Program Safety through Verified and Verifying Compilation",
    "abstract": "Program safety (i.e., absence of undefined behaviors) is critical for correct operation of computer systems. It is usually verified at the source level (e.g., by separation logics) and preserved to the target by verified compilers (e.g., CompCert), thereby achieving end-to-end verification of safety. However, modern safe programming languages like Rust pose new problems in achieving end-to-end safety. Because not all functionalities can be implemented in the safe language, mixing safe and unsafe modules is needed. Therefore, verified compilation must preserve a modular notion of safety which can be composed at the target level. Furthermore, certain classes of errors (e.g., memory errors) are automatically excluded by verifying compilation (e.g., borrow checking) for modules written in safe languages. As a result, verified compilation needs to cooperate with verifying compilation to ensure end-to-end safety. To address the above problems, we propose a modular and generic definition of safety called open safety based on program semantics described as open labeled transition systems (LTS). Open safety is composable at the boundary of modules and can be modularly preserved by verified compositional compilation. Those properties enable separate verification of safety for heterogeneous modules and composition of the safety results at the target level. Open safety can be generalized to partial safety (i.e., only a certain class of errors can occur). By this we formalized the correctness of verifying compilation as derivation of total safety from partial safety. We demonstrate how our framework can combine verified and verifying compilation by developing a verified compiler for an ownership language (called Owlang) inspired by Rust. We evaluate our approach on the compositional safety verification using a hash map implemented by Owlang and C.",
    "authors": [
      "Jinhua Wu",
      "Yuting Wang",
      "Liukun Yu",
      "Linglong Meng"
    ],
    "categories": [
      "cs.PL"
    ],
    "publishedAt": "2025-10-11T04:41:43.000Z",
    "updatedAt": "2025-10-11T04:41:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10015v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10015v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10010v1",
    "arxivId": "2510.10010v1",
    "title": "SLEAN: Simple Lightweight Ensemble Analysis Network for Multi-Provider LLM Coordination: Design, Implementation, and Vibe Coding Bug Investigation Case Study",
    "abstract": "We present SLEAN (Simple Lightweight Ensemble Analysis Network), a deterministic framework for coordinating multiple LLM providers through text-based prompt orchestration. Unlike complex multi-agent systems requiring specialized infrastructure, SLEAN operates as a simple prompt bridge between LLMs using .txt templates, requiring no deep technical knowledge for deployment. The three-phase protocol formed by independent analysis, cross-critique, and arbitration, filters harmful AI-generated code suggestions before production deployment, addressing how AI-assisted debugging increasingly produces modifications that introduce unnecessary complexity, break existing functionality, or address problems. Evaluating 15 software bugs, we analyzed 69 AI-generated fix propositions. SLEAN's filtering accepted 22 fixes (31.9%, 95% CI 20.9-42.9%) while rejecting 47 that would have been harmful if applied verbatim. The arbitration process reduced code change surface by 83-90% relative to raw AI outputs, enforcing minimal causal edits over scope-expanding modifications. Minimal Type 2 inputs proved more efficient than detailed Type 1 inputs, requiring 2.85 versus 3.56 propositions per accepted fix (35.1% versus 28.1% acceptance, about a 20% efficiency gain). Agreement between AI systems showed weak correlation with fix quality: high convergence (at least 80%) occurred in 4 of 15 cases and improved acceptance by only 2.4% points; arbitration appeared only at exactly 10% convergence in 2 of 15 cases, although low convergence alone did not necessitate arbitration. The file-driven, provider-agnostic architecture enables deployment without specialized coding expertise, making it applicable to security auditing, code review, document verification, and other domains requiring reliable multi-provider synthesis with end-to-end auditability.",
    "authors": [
      "Matheus J. T. Vargas"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "68N01, 68T05, 68T07",
      "D.2.5; D.2.7; I.2.2; I.2.6"
    ],
    "publishedAt": "2025-10-11T04:24:04.000Z",
    "updatedAt": "2025-10-11T04:24:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10010v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10010v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.10003v1",
    "arxivId": "2510.10003v1",
    "title": "MTP-S2UT: Enhancing Speech-to-Speech Translation Quality with Multi-token Prediction",
    "abstract": "Current direct speech-to-speech translation methods predominantly employ speech tokens as intermediate representations. However, a single speech token is not dense in semantics, so we generally need multiple tokens to express a complete semantic unit. To address this limitation, we introduce multi-token prediction (MTP) loss into speech-to-unit translation (S2UT) models, enabling models to predict multiple subsequent tokens at each position, thereby capturing more complete semantics and enhancing information density per position. Initial MTP implementations apply the loss at the final layer, which improves output representation but initiates information enrichment too late. We hypothesize that advancing the information enrichment process to intermediate layers can achieve earlier and more effective enhancement of hidden representation. Consequently, we propose MTP-S2UT loss, applying MTP loss to hidden representation where CTC loss is computed. Experiments demonstrate that all MTP loss variants consistently improve the quality of S2UT translation, with MTP-S2UT achieving the best performance.",
    "authors": [
      "Jianjin Wang",
      "Runsong Zhao",
      "Xiaoqian Liu",
      "Yuan Ge",
      "Ziqiang Xu",
      "Tong Xiao",
      "Shengxiang Gao",
      "Zhengtao Yu",
      "Jingbo Zhu"
    ],
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-11T04:06:20.000Z",
    "updatedAt": "2025-10-11T04:06:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.10003v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.10003v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09997v1",
    "arxivId": "2510.09997v1",
    "title": "CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting",
    "abstract": "Level of Detail (LoD) is a fundamental technique in real-time computer graphics for managing the rendering costs of complex scenes while preserving visual fidelity. Traditionally, LoD is implemented using discrete levels (DLoD), where multiple, distinct versions of a model are swapped out at different distances. This long-standing paradigm, however, suffers from two major drawbacks: it requires significant storage for multiple model copies and causes jarring visual ``popping\" artifacts during transitions, degrading the user experience. We argue that the explicit, primitive-based nature of the emerging 3D Gaussian Splatting (3DGS) technique enables a more ideal paradigm: Continuous LoD (CLoD). A CLoD approach facilitates smooth, seamless quality scaling within a single, unified model, thereby circumventing the core problems of DLOD. To this end, we introduce CLoD-GS, a framework that integrates a continuous LoD mechanism directly into a 3DGS representation. Our method introduces a learnable, distance-dependent decay parameter for each Gaussian primitive, which dynamically adjusts its opacity based on viewpoint proximity. This allows for the progressive and smooth filtering of less significant primitives, effectively creating a continuous spectrum of detail within one model. To train this model to be robust across all distances, we introduce a virtual distance scaling mechanism and a novel coarse-to-fine training strategy with rendered point count regularization. Our approach not only eliminates the storage overhead and visual artifacts of discrete methods but also reduces the primitive count and memory footprint of the final model. Extensive experiments demonstrate that CLoD-GS achieves smooth, quality-scalable rendering from a single model, delivering high-fidelity results across a wide range of performance targets.",
    "authors": [
      "Zhigang Cheng",
      "Mingchao Sun",
      "Yu Liu",
      "Zengye Ge",
      "Luyang Tang",
      "Mu Xu",
      "Yangyan Li",
      "Peng Pan"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-11T03:48:11.000Z",
    "updatedAt": "2025-10-11T03:48:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09997v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09997v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09980v1",
    "arxivId": "2510.09980v1",
    "title": "ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots",
    "abstract": "Hybrid locomotion of wheeled-legged robots has recently attracted increasing attention due to their advantages of combining the agility of legged locomotion and the efficiency of wheeled motion. But along with expanded performance, the whole-body control of wheeled-legged robots remains challenging for hybrid locomotion. In this paper, we present ATRos, a reinforcement learning (RL)-based hybrid locomotion framework to achieve hybrid walking-driving motions on the wheeled-legged robot. Without giving predefined gait patterns, our planner aims to intelligently coordinate simultaneous wheel and leg movements, thereby achieving improved terrain adaptability and improved energy efficiency. Based on RL techniques, our approach constructs a prediction policy network that could estimate external environmental states from proprioceptive sensory information, and the outputs are then fed into an actor critic network to produce optimal joint commands. The feasibility of the proposed framework is validated through both simulations and real-world experiments across diverse terrains, including flat ground, stairs, and grassy surfaces. The hybrid locomotion framework shows robust performance over various unseen terrains, highlighting its generalization capability.",
    "authors": [
      "Jingyuan Sun",
      "Hongyu Ji",
      "Zihan Qu",
      "Chaoran Wang",
      "Mingyu Zhang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T03:15:29.000Z",
    "updatedAt": "2025-10-11T03:15:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09980v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09980v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09976v1",
    "arxivId": "2510.09976v1",
    "title": "Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models",
    "abstract": "Vision-Language-Action (VLA) models such as OpenVLA, Octo, and $\\pi_0$ have shown strong generalization by leveraging large-scale demonstrations, yet their performance is still fundamentally constrained by the quality and coverage of supervised data. Reinforcement learning (RL) provides a promising path for improving and fine-tuning VLAs through online interaction. However, conventional policy gradient methods are computationally infeasible in the context of flow-matching based models due to the intractability of the importance sampling process, which requires explicit computation of policy ratios. To overcome this limitation, we propose Flow Policy Optimization (FPO) algorithm, which reformulates importance sampling by leveraging per-sample changes in the conditional flow-matching objective. Furthermore, FPO achieves stable and scalable online reinforcement fine-tuning of the $\\pi_0$ model by integrating structure-aware credit assignment to enhance gradient efficiency, clipped surrogate objectives to stabilize optimization, multi-step latent exploration to encourage diverse policy updates, and a Q-ensemble mechanism to provide robust value estimation. We evaluate FPO on the LIBERO benchmark and the ALOHA simulation task against supervised, preference-aligned, diffusion-based, autoregressive online RL, and $\\pi_0$-FAST baselines, observing consistent improvements over the imitation prior and strong alternatives with stable learning under sparse rewards. In addition, ablation studies and analyses of the latent space dynamics further highlight the contributions of individual components within FPO, validating the effectiveness of the proposed computational modules and the stable convergence of the conditional flow-matching objective during online RL.",
    "authors": [
      "Mingyang Lyu",
      "Yinqian Sun",
      "Erliang Lin",
      "Huangrui Li",
      "Ruolin Chen",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T03:11:18.000Z",
    "updatedAt": "2025-10-11T03:11:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09976v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09976v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09974v1",
    "arxivId": "2510.09974v1",
    "title": "Universal Discrete-Domain Speech Enhancement",
    "abstract": "In real-world scenarios, speech signals are inevitably corrupted by various types of interference, making speech enhancement (SE) a critical task for robust speech processing. However, most existing SE methods only handle a limited range of distortions, such as additive noise, reverberation, or band limitation, while the study of SE under multiple simultaneous distortions remains limited. This gap affects the generalization and practical usability of SE methods in real-world environments.To address this gap, this paper proposes a novel Universal Discrete-domain SE model called UDSE.Unlike regression-based SE models that directly predict clean speech waveform or continuous features, UDSE redefines SE as a discrete-domain classification task, instead predicting the clean discrete tokens quantized by the residual vector quantizer (RVQ) of a pre-trained neural speech codec.Specifically, UDSE first extracts global features from the degraded speech. Guided by these global features, the clean token prediction for each VQ follows the rules of RVQ, where the prediction of each VQ relies on the results of the preceding ones. Finally, the predicted clean tokens from all VQs are decoded to reconstruct the clean speech waveform. During training, the UDSE model employs a teacher-forcing strategy, and is optimized with cross-entropy loss. Experimental results confirm that the proposed UDSE model can effectively enhance speech degraded by various conventional and unconventional distortions, e.g., additive noise, reverberation, band limitation, clipping, phase distortion, and compression distortion, as well as their combinations. These results demonstrate the superior universality and practicality of UDSE compared to advanced regression-based SE methods.",
    "authors": [
      "Fei Liu",
      "Yang Ai",
      "Ye-Xin Lu",
      "Rui-Chen Zheng",
      "Hui-Peng Du",
      "Zhen-Hua Ling"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-11T03:07:17.000Z",
    "updatedAt": "2025-10-11T03:07:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09974v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09974v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09968v1",
    "arxivId": "2510.09968v1",
    "title": "Operationalizing AI: Empirical Evidence on MLOps Practices, User Satisfaction, and Organizational Context",
    "abstract": "Organizational efforts to utilize and operationalize artificial intelligence (AI) are often accompanied by substantial challenges, including scalability, maintenance, and coordination across teams. In response, the concept of Machine Learning Operations (MLOps) has emerged as a set of best practices that integrate software engineering principles with the unique demands of managing the ML lifecycle. Yet, empirical evidence on whether and how these practices support users in developing and operationalizing AI applications remains limited. To address this gap, this study analyzes over 8,000 user reviews of AI development platforms from G2.com. Using zero-shot classification, we measure review sentiment toward nine established MLOps practices, including continuous integration and delivery (CI/CD), workflow orchestration, reproducibility, versioning, collaboration, and monitoring. Seven of the nine practices show a significant positive relationship with user satisfaction, suggesting that effective MLOps implementation contributes tangible value to AI development. However, organizational context also matters: reviewers from small firms discuss certain MLOps practices less frequently, suggesting that organizational context influences the prevalence and salience of MLOps, though firm size does not moderate the MLOps-satisfaction link. This indicates that once applied, MLOps practices are perceived as universally beneficial across organizational settings.",
    "authors": [
      "Stefan Pasch"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-11T02:57:14.000Z",
    "updatedAt": "2025-10-11T02:57:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09968v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09968v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09966v1",
    "arxivId": "2510.09966v1",
    "title": "FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors",
    "abstract": "Light Detection and Ranging (LiDAR) sensors have become a de-facto sensor for many robot state estimation tasks, spurring development of many LiDAR Odometry (LO) methods in recent years. While some smoothing-based LO methods have been proposed, most require matching against multiple scans, resulting in sub-real-time performance. Due to this, most prior works estimate a single state at a time and are ``submap''-based. This architecture propagates any error in pose estimation to the fixed submap and can cause jittery trajectories and degrade future registrations. We propose Fixed-Lag Odometry with Reparative Mapping (FORM), a LO method that performs smoothing over a densely connected factor graph while utilizing a single iterative map for matching. This allows for both real-time performance and active correction of the local map as pose estimates are further refined. We evaluate on a wide variety of datasets to show that FORM is robust, accurate, real-time, and provides smooth trajectory estimates when compared to prior state-of-the-art LO methods.",
    "authors": [
      "Easton R. Potokar",
      "Taylor Pool",
      "Daniel McGann",
      "Michael Kaess"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T02:40:25.000Z",
    "updatedAt": "2025-10-11T02:40:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09966v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09966v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09963v1",
    "arxivId": "2510.09963v1",
    "title": "LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots",
    "abstract": "We introduce a novel framework for automatic behavior tree (BT) construction in heterogeneous multi-robot systems, designed to address the challenges of adaptability and robustness in dynamic environments. Traditional robots are limited by fixed functional attributes and cannot efficiently reconfigure their strategies in response to task failures or environmental changes. To overcome this limitation, we leverage large language models (LLMs) to generate and extend BTs dynamically, combining the reasoning and generalization power of LLMs with the modularity and recovery capability of BTs. The proposed framework consists of four interconnected modules task initialization, task assignment, BT update, and failure node detection which operate in a closed loop. Robots tick their BTs during execution, and upon encountering a failure node, they can either extend the tree locally or invoke a centralized virtual coordinator (Alex) to reassign subtasks and synchronize BTs across peers. This design enables long-term cooperative execution in heterogeneous teams. We validate the framework on 60 tasks across three simulated scenarios and in a real-world cafe environment with a robotic arm and a wheeled-legged robot. Results show that our method consistently outperforms baseline approaches in task success rate, robustness, and scalability, demonstrating its effectiveness for multi-robot collaboration in complex scenarios.",
    "authors": [
      "Chaoran Wang",
      "Jingyuan Sun",
      "Yanhui Zhang",
      "Mingyu Zhang",
      "Changju Wu"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T02:27:50.000Z",
    "updatedAt": "2025-10-11T02:27:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09963v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09963v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09962v1",
    "arxivId": "2510.09962v1",
    "title": "VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping",
    "abstract": "Maintaining an up-to-date map that accurately reflects recent changes in the environment is crucial, especially for robots that repeatedly traverse the same space. Failing to promptly update the changed regions can degrade map quality, resulting in poor localization, inefficient operations, and even lost robots. 3D Gaussian Splatting (3DGS) has recently seen widespread adoption in online map reconstruction due to its dense, differentiable, and photorealistic properties, yet accurately and efficiently updating the regions of change remains a challenge. In this paper, we propose VG-Mapping, a novel online 3DGS-based mapping system tailored for such semi-static scenes. Our approach introduces a hybrid representation that augments 3DGS with a TSDF-based voxel map to efficiently identify changed regions in a scene, along with a variation-aware density control strategy that inserts or deletes Gaussian primitives in regions undergoing change. Furthermore, to address the absence of public benchmarks for this task, we construct a RGB-D dataset comprising both synthetic and real-world semi-static environments. Experimental results demonstrate that our method substantially improves the rendering quality and map update efficiency in semi-static scenes. The code and dataset are available at https://github.com/heyicheng-never/VG-Mapping.",
    "authors": [
      "Yicheng He",
      "Jingwen Yu",
      "Guangcheng Chen",
      "Hong Zhang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-11T02:18:24.000Z",
    "updatedAt": "2025-10-11T02:18:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09962v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09962v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09945v1",
    "arxivId": "2510.09945v1",
    "title": "Explainable Human-in-the-Loop Segmentation via Critic Feedback Signals",
    "abstract": "Segmentation models achieve high accuracy on benchmarks but often fail in real-world domains by relying on spurious correlations instead of true object boundaries. We propose a human-in-the-loop interactive framework that enables interventional learning through targeted human corrections of segmentation outputs. Our approach treats human corrections as interventional signals that show when reliance on superficial features (e.g., color or texture) is inappropriate. The system learns from these interventions by propagating correction-informed edits across visually similar images, effectively steering the model toward robust, semantically meaningful features rather than dataset-specific artifacts. Unlike traditional annotation approaches that simply provide more training data, our method explicitly identifies when and why the model fails and then systematically corrects these failure modes across the entire dataset. Through iterative human feedback, the system develops increasingly robust representations that generalize better to novel domains and resist artifactual correlations. We demonstrate that our framework improves segmentation accuracy by up to 9 mIoU points (12-15\\% relative improvement) on challenging cubemap data and yields 3-4$\\times$ reductions in annotation effort compared to standard retraining, while maintaining competitive performance on benchmark datasets. This work provides a practical framework for researchers and practitioners seeking to build segmentation systems that are accurate, robust to dataset biases, data-efficient, and adaptable to real-world domains such as urban climate monitoring and autonomous driving.",
    "authors": [
      "Pouya Shaeri",
      "Ryan T. Woo",
      "Yasaman Mohammadpour",
      "Ariane Middel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "eess.IV"
    ],
    "publishedAt": "2025-10-11T01:16:41.000Z",
    "updatedAt": "2025-10-11T01:16:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09945v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09945v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09944v1",
    "arxivId": "2510.09944v1",
    "title": "Read the Room or Lead the Room: Understanding Socio-Cognitive Dynamics in Human-AI Teaming",
    "abstract": "Research on Collaborative Problem Solving (CPS) has traditionally examined how humans rely on one another cognitively and socially to accomplish tasks together. With the rapid advancement of AI and large language models, however, a new question emerge: what happens to team dynamics when one of the \"teammates\" is not human? In this study, we investigate how the integration of an AI teammate -- a fully autonomous GPT-4 agent with social, cognitive, and affective capabilities -- shapes the socio-cognitive dynamics of CPS. We analyze discourse data collected from human-AI teaming (HAT) experiments conducted on a novel platform specifically designed for HAT research. Using two natural language processing (NLP) methods, specifically Linguistic Inquiry and Word Count (LIWC) and Group Communication Analysis (GCA), we found that AI teammates often assumed the role of dominant cognitive facilitators, guiding, planning, and driving group decision-making. However, they did so in a socially detached manner, frequently pushing agenda in a verbose and repetitive way. By contrast, humans working with AI used more language reflecting social processes, suggesting that they assumed more socially oriented roles. Our study highlights how learning analytics can provide critical insights into the socio-cognitive dynamics of human-AI collaboration.",
    "authors": [
      "Jaeyoon Choi",
      "Mohammad Amin Samadi",
      "Spencer JaQuay",
      "Seehee Park",
      "Nia Nixon"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-11T01:13:31.000Z",
    "updatedAt": "2025-10-11T01:13:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09944v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09944v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09943v1",
    "arxivId": "2510.09943v1",
    "title": "Modeling the Impact of Communication and Human Uncertainties on Runway Capacity in Terminal Airspace",
    "abstract": "We investigate the potential impact of communication and human performance uncertainties on runway operations. Specifically, we consider these impacts within the context of an arrival scenario with two converging flows: a straight-in approach stream and a downwind stream merging into it. Both arrival stream are modeled using a modified Possion distribution that incorporate the separation minima as well as the runway occupancy time. Various system level uncertainties are addressed in this process, including communication link- and human-related uncertainties. In this research, we first build a Monte Carlo-based discrete-time simulation, where aircraft arrivals are generated by modified Poisson processes subject to minimum separation constraints, simulating various traffic operations. The merging logic incorporates standard bank angle continuous turn-to-final, pilot response delays, and dynamic gap availability in real time. Then, we investigate an automated final approach vectoring model (i.e., Auto-ATC), in which inverse optimal control is used to learn decision advisories from human expert records. By augmenting trajectories and incorporating the aforementioned uncertainties into the planning scenario, we create a setup analogous to the discrete event simulation. For both studies, runway capacity is measured by runway throughput, the fraction of downwind arrivals that merge immediately without holding, and the average delay (i.e., holding time/distance) experienced on the downwind leg. This research provides a method for runway capacity estimation in merging scenarios, and demonstrates that aeronautical communication link uncertainties significantly affect runway capacity in current voice-based operations, whereas the impact can be mitigated in autonomous operational settings.",
    "authors": [
      "Yutian Pang",
      "Andrew Kendall",
      "John-Paul Clarke"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-11T01:06:25.000Z",
    "updatedAt": "2025-10-11T01:06:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09943v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09943v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09941v1",
    "arxivId": "2510.09941v1",
    "title": "Causal-Guided Dimension Reduction for Efficient Pareto Optimization",
    "abstract": "Multi-objective optimization of analog circuits is hindered by high-dimensional parameter spaces, strong feedback couplings, and expensive transistor-level simulations. Evolutionary algorithms such as Non-dominated Sorting Genetic Algorithm II (NSGA-II) are widely used but treat all parameters equally, thereby wasting effort on variables with little impact on performance, which limits their scalability. We introduce CaDRO, a causal-guided dimensionality reduction framework that embeds causal discovery into the optimization pipeline. CaDRO builds a quantitative causal map through a hybrid observational-interventional process, ranking parameters by their causal effect on the objectives. Low-impact parameters are fixed to values from high-quality solutions, while critical drivers remain active in the search. The reduced design space enables focused evolutionary optimization without modifying the underlying algorithm. Across amplifiers, regulators, and RF circuits, CaDRO converges up to 10$\\times$ faster than NSGA-II while preserving or improving Pareto quality. For instance, on the Folded-Cascode Amplifier, hypervolume improves from 0.56 to 0.94, and on the LDO regulator from 0.65 to 0.81, with large gains in non-dominated solutions.",
    "authors": [
      "Dinithi Jayasuriya",
      "Divake Kumar",
      "Sureshkumar Senthilkumar",
      "Devashri Naik",
      "Nastaran Darabi",
      "Amit Ranjan Trivedi"
    ],
    "categories": [
      "cs.NE",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-11T00:41:04.000Z",
    "updatedAt": "2025-10-11T00:41:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09941v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09941v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09938v1",
    "arxivId": "2510.09938v1",
    "title": "OFP-Repair: Repairing Floating-point Errors via Original-Precision Arithmetic",
    "abstract": "Errors in floating-point programs can lead to severe consequences, particularly in critical domains such as military, aerospace, and financial systems, making their repair a crucial research problem. In practice, some errors can be fixed using original-precision arithmetic, while others require high-precision computation. Developers often avoid addressing the latter due to excessive computational resources required. However, they sometimes struggle to distinguish between these two types of errors, and existing repair tools fail to assist in this differentiation. Most current repair tools rely on high-precision implementations, which are time-consuming to develop and demand specialized expertise. Although a few tools do not require high-precision programs, they can only fix a limited subset of errors or produce suboptimal results. To address these challenges, we propose a novel method, named OFP-Repair.On ACESO's dataset, our patches achieve improvements of three, seven, three, and eight orders of magnitude across four accuracy metrics. In real-world cases, our method successfully detects all five original-precision-repairable errors and fixes three, whereas ACESO only repairs one. Notably, these results are based on verified data and do not fully capture the potential of OFP-Repair. To further validate our method, we deploy it on a decade-old open bug report from GNU Scientific Library (GSL), successfully repairing five out of 15 bugs. The developers have expressed interest in our method and are considering integrating our tool into their development workflow. We are currently working on applying our patches to GSL. The results are highly encouraging, demonstrating the practical applicability of our technique.",
    "authors": [
      "Youshuai Tan",
      "Zishuo Ding",
      "Jinfu Chen",
      "Weiyi Shang"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-11T00:31:22.000Z",
    "updatedAt": "2025-10-11T00:31:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09938v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09938v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09937v1",
    "arxivId": "2510.09937v1",
    "title": "Structured Cooperative Multi-Agent Reinforcement Learning: a Bayesian Network Perspective",
    "abstract": "The empirical success of multi-agent reinforcement learning (MARL) has motivated the search for more efficient and scalable algorithms for large scale multi-agent systems. However, existing state-of-the-art algorithms do not fully exploit inter-agent coupling information to develop MARL algorithms. In this paper, we propose a systematic approach to leverage structures in the inter-agent couplings for efficient model-free reinforcement learning. We model the cooperative MARL problem via a Bayesian network and characterize the subset of agents, termed as the value dependency set, whose information is required by each agent to estimate its local action value function exactly. Moreover, we propose a partially decentralized training decentralized execution (P-DTDE) paradigm based on the value dependency set. We theoretically establish that the total variance of our P-DTDE policy gradient estimator is less than the centralized training decentralized execution (CTDE) policy gradient estimator. We derive a multi-agent policy gradient theorem based on the P-DTDE scheme and develop a scalable actor-critic algorithm. We demonstrate the efficiency and scalability of the proposed algorithm on multi-warehouse resource allocation and multi-zone temperature control examples. For dense value dependency sets, we propose an approximation scheme based on truncation of the Bayesian network and empirically show that it achieves a faster convergence than the exact value dependence set for applications with a large number of agents.",
    "authors": [
      "Shahbaz P Qadri Syed",
      "He Bai"
    ],
    "categories": [
      "cs.MA",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "stat.ML"
    ],
    "publishedAt": "2025-10-11T00:29:55.000Z",
    "updatedAt": "2025-10-11T00:29:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09937v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09937v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09932v1",
    "arxivId": "2510.09932v1",
    "title": "ACT: Automatically Generating Compiler Backends from Tensor Accelerator ISA Descriptions",
    "abstract": "Tensor compilers play a key role in enabling high-performance implementations of deep learning workloads. These compilers rely on existing CPU and GPU code generation backends to generate device-specific code. Recently, many tensor accelerators (neural processing units) have been proposed to further accelerate these workloads. Compared to commodity hardware, however, most of the proposed tensor accelerators do not have compiler backends with code generation support. Moreover, the accelerator designs are subject to fast iteration cycles, making it difficult to manually develop compiler backends similar to commodity hardware platforms. Therefore, to increase adoption and enable faster software development cycles for novel tensor accelerator designs, we need to make the compiler backend construction process more agile. To address this gap, we introduce ACT, a compiler backend generator that automatically generates compiler backends for tensor accelerators, given just the instruction set architecture (ISA) descriptions. We first formally specify the compiler backend generation problem that introduces a novel specification for describing tensor accelerator ISAs. Next, we design ACT such that it supports user-programmable memories and complex parameterized instructions that are prevalent in tensor accelerators. ACT uses a novel parameterized equality saturation-based instruction selection phase and a constraint programming-based memory allocation phase. We prove that compiler backends generated by ACT are sound and complete. Finally, we generate compiler backends for three accelerator platforms from industry and academia, and show that they match or outperform code written using hand-optimized kernel libraries while maintaining low compilation overheads.",
    "authors": [
      "Devansh Jain",
      "Akash Pardeshi",
      "Marco Frigo",
      "Krut Patel",
      "Kaustubh Khulbe",
      "Jai Arora",
      "Charith Mendis"
    ],
    "categories": [
      "cs.PL",
      "cs.AR"
    ],
    "publishedAt": "2025-10-11T00:11:34.000Z",
    "updatedAt": "2025-10-11T00:11:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09932v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09932v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09929v1",
    "arxivId": "2510.09929v1",
    "title": "Viscosity CBFs: Bridging the Control Barrier Function and Hamilton-Jacobi Reachability Frameworks in Safe Control Theory",
    "abstract": "Control barrier functions (CBFs) and Hamilton-Jacobi reachability (HJR) are central frameworks in safe control. Traditionally, these frameworks have been viewed as distinct, with the former focusing on optimally safe controller design and the latter providing sufficient conditions for safety. A previous work introduced the notion of a control barrier value function (CB-VF), which is defined similarly to the other value functions studied in HJR but has certain CBF-like properties. In this work, we proceed the other direction by generalizing CBFs to non-differentiable ``viscosity'' CBFs. We show the deep connection between viscosity CBFs and CB-VFs, bridging the CBF and HJR frameworks. Through this bridge, we characterize the viscosity CBFs as precisely those functions which provide CBF-like safety guarantees (control invariance and smooth approach to the boundary). We then further show nice theoretical properties of viscosity CBFs, including their desirable closure under maximum and limit operations. In the process, we also extend CB-VFs to non-exponential anti-discounting and update the corresponding theory for CB-VFs along these lines.",
    "authors": [
      "Dylan Hirsch",
      "Jaime Fernández Fisac",
      "Sylvia Herbert"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-11T00:00:39.000Z",
    "updatedAt": "2025-10-11T00:00:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09929v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09929v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09926v1",
    "arxivId": "2510.09926v1",
    "title": "Phase-Aware Deep Learning with Complex-Valued CNNs for Audio Signal Applications",
    "abstract": "This study explores the design and application of Complex-Valued Convolutional Neural Networks (CVCNNs) in audio signal processing, with a focus on preserving and utilizing phase information often neglected in real-valued networks. We begin by presenting the foundational theoretical concepts of CVCNNs, including complex convolutions, pooling layers, Wirtinger-based differentiation, and various complex-valued activation functions. These are complemented by critical adaptations of training techniques, including complex batch normalization and weight initialization schemes, to ensure stability in training dynamics. Empirical evaluations are conducted across three stages. First, CVCNNs are benchmarked on standard image datasets, where they demonstrate competitive performance with real-valued CNNs, even under synthetic complex perturbations. Although our focus is audio signal processing, we first evaluate CVCNNs on image datasets to establish baseline performance and validate training stability before applying them to audio tasks. In the second experiment, we focus on audio classification using Mel-Frequency Cepstral Coefficients (MFCCs). CVCNNs trained on real-valued MFCCs slightly outperform real CNNs, while preserving phase in input workflows highlights challenges in exploiting phase without architectural modifications. Finally, a third experiment introduces GNNs to model phase information via edge weighting, where the inclusion of phase yields measurable gains in both binary and multi-class genre classification. These results underscore the expressive capacity of complex-valued architectures and confirm phase as a meaningful and exploitable feature in audio processing applications. While current methods show promise, especially with activations like cardioid, future advances in phase-aware design will be essential to leverage the potential of complex representations in neural networks.",
    "authors": [
      "Naman Agrawal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD"
    ],
    "publishedAt": "2025-10-10T23:55:35.000Z",
    "updatedAt": "2025-10-10T23:55:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09926v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09926v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09925v1",
    "arxivId": "2510.09925v1",
    "title": "Computing Safe Control Inputs using Discrete-Time Matrix Control Barrier Functions via Convex Optimization",
    "abstract": "Control barrier functions (CBFs) have seen widespread success in providing forward invariance and safety guarantees for dynamical control systems. A crucial limitation of discrete-time formulations is that CBFs that are nonconcave in their argument require the solution of nonconvex optimization problems to compute safety-preserving control inputs, which inhibits real-time computation of control inputs guaranteeing forward invariance. This paper presents a novel method for computing safety-preserving control inputs for discrete-time systems with nonconvex safety sets, utilizing convex optimization and the recently developed class of matrix control barrier function techniques. The efficacy of our methods is demonstrated through numerical simulations on a bicopter system.",
    "authors": [
      "James Usevitch",
      "Juan Augusto Paredes Salazar",
      "Ankit Goel"
    ],
    "categories": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T23:52:15.000Z",
    "updatedAt": "2025-10-10T23:52:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09925v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09925v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09907v1",
    "arxivId": "2510.09907v1",
    "title": "Agentic Property-Based Testing: Finding Bugs Across the Python Ecosystem",
    "abstract": "Property-based testing (PBT) is a lightweight formal method, typically implemented as a randomized testing framework. Users specify the input domain for their test using combinators supplied by the PBT framework, and the expected properties or invariants as a unit-test function. The framework then searches for a counterexample, e.g. by generating inputs and calling the test function. In this work, we demonstrate an LLM-based agent which analyzes Python modules, infers function-specific and cross-function properties from code and documentation, synthesizes and executes PBTs, reflects on outputs of these tests to confirm true bugs, and finally outputs actionable bug reports for the developer. We perform an extensive evaluation of our agent across 100 popular Python packages. Of the bug reports generated by the agent, we found after manual review that 56\\% were valid bugs and 32\\% were valid bugs that we would report to maintainers. We then developed a ranking rubric to surface high-priority valid bugs to developers, and found that of the 21 top-scoring bugs, 86\\% were valid and 81\\% we would report. The bugs span diverse failure modes from serialization failures to numerical precision errors to flawed cache implementations. We reported 5 bugs, 4 with patches, including to NumPy and cloud computing SDKs, with 3 patches merged successfully. Our results suggest that LLMs with PBT provides a rigorous and scalable method for autonomously testing software. Our code and artifacts are available at: https://github.com/mmaaz-git/agentic-pbt.",
    "authors": [
      "Muhammad Maaz",
      "Liam DeVoe",
      "Zac Hatfield-Dodds",
      "Nicholas Carlini"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T22:43:54.000Z",
    "updatedAt": "2025-10-10T22:43:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09907v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09907v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09874v1",
    "arxivId": "2510.09874v1",
    "title": "ROBOPSY PL[AI]: Using Role-Play to Investigate how LLMs Present Collective Memory",
    "abstract": "The paper presents the first results of an artistic research project investigating how Large Language Models (LLMs) curate and present collective memory. In a public installation exhibited during two months in Vienna in 2025, visitors could interact with five different LLMs (ChatGPT with GPT 4o and GPT 4o mini, Mistral Large, DeepSeek-Chat, and a locally run Llama 3.1 model), which were instructed to act as narrators, implementing a role-playing game revolving around the murder of Austrian philosopher Moritz Schlick in 1936. Results of the investigation include protocols of LLM-user interactions during the game and qualitative conversations after the play experience to get insight into the players' reactions to the game. In a quantitative analysis 115 introductory texts for role-playing generated by the LLMs were examined by different methods of natural language processing, including semantic similarity and sentiment analysis. While the qualitative player feedback allowed to distinguish three distinct types of users, the quantitative text analysis showed significant differences between how the different LLMs presented the historical content. Our study thus adds to ongoing efforts to analyse LLM performance, but also suggests a way of how these efforts can be disseminated in a playful way to a general audience.",
    "authors": [
      "Margarete Jahrmann",
      "Thomas Brandstetter",
      "Stefan Glasauer"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "publishedAt": "2025-10-10T21:25:06.000Z",
    "updatedAt": "2025-10-10T21:25:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09874v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09874v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09862v1",
    "arxivId": "2510.09862v1",
    "title": "Cyber-Physical Systems on the Megawatt Scale: The impact of battery control on grid frequency stability",
    "abstract": "Electric power systems are undergoing fundamental change. The shift to inverter-based generation challenges frequency stability, while growing digitalisation heightens vulnerability to errors and attacks. Here we identify an emerging risk at the intersection of cyber-physical coupling and control system design. We show that grid frequency time series worldwide exhibit a persistent one-minute oscillatory pattern, whose origin has remained largely unexplained. We trace this pattern back to the energy management systems of battery electric storage systems and demonstrate that the pattern amplitude has increased substantially in the Nordic and British grids. We argue that this effect is a potential burden for stability in future grids with low inertia and an increasing penetration with batteries and smart devices, though it can be mitigated by a revision of battery control algorithms.",
    "authors": [
      "Carsten Hartmann",
      "Edoardo De Din",
      "Daniele Carta",
      "Florian Middelkoop",
      "Arndt Neubauer",
      "Johannes Kruse",
      "Ulrich Oberhofer",
      "Richard Jumar",
      "Benjamin Schäfer",
      "Thiemo Pesch",
      "Andrea Benigni",
      "Dirk Witthaut"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T20:55:16.000Z",
    "updatedAt": "2025-10-10T20:55:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09862v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09862v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09851v1",
    "arxivId": "2510.09851v1",
    "title": "QONNECT: A QoS-Aware Orchestration System for Distributed Kubernetes Clusters",
    "abstract": "Modern applications increasingly span across cloud, fog, and edge environments, demanding orchestration systems that can adapt to diverse deployment contexts while meeting Quality-of-Service (QoS) requirements. Standard Kubernetes schedulers do not account for user-defined objectives such as energy efficiency, cost optimization, and global performance, often leaving operators to make manual, cluster-by-cluster placement decisions. To address this need, we present QONNECT, a vendor-agnostic orchestration framework that enables declarative, QoS-driven application deployment across heterogeneous Kubernetes and K3s clusters. QONNECT introduces a distributed architecture composed of a central Knowledge Base, Raft-replicated Resource Lead Agents, and lightweight Resource Agents in each cluster. Through a minimal YAML-based interface, users specify high-level QoS goals, which the system translates into concrete placement and migration actions. Our implementation is evaluated on a federated testbed of up to nine cloud-fog-edge clusters using the Istio Bookinfo microservice application. The system demonstrates dynamic, policy-driven microservice placement, automated failover, QoS-compliant rescheduling, and leader re-election after node failure, all without manual intervention. By bridging the gap between declarative deployment models and operational QoS goals, QONNECT transforms the cloud-edge continuum into a unified, self-optimizing platform.",
    "authors": [
      "Haci Ismail Aslan",
      "Syed Muhammad Mahmudul Haque",
      "Joel Witzke",
      "Odej Kao"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-10T20:27:28.000Z",
    "updatedAt": "2025-10-10T20:27:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09851v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09851v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09847v1",
    "arxivId": "2510.09847v1",
    "title": "THEAS: Efficient Power Management in Multi-Core CPUs via Cache-Aware Resource Scheduling",
    "abstract": "The dynamic adaptation of resource levels enables the system to enhance energy efficiency while maintaining the necessary computational resources, particularly in scenarios where workloads fluctuate significantly over time. The proposed approach can play a crucial role in heterogeneous systems where workload characteristics are not uniformly distributed, such as non-pinning tasks. The deployed THEAS algorithm in this research work ensures a balance between performance and power consumption, making it suitable for a wide range of real-time applications. A comparative analysis of the proposed THEAS algorithm with well-known scheduling techniques such as Completely Fair Scheduler (CFS), Energy-Aware Scheduling (EAS), Heterogeneous Scheduling (HeteroSched), and Utility-Based Scheduling is presented in Table III. Each scheme is compared based on adaptability, core selection criteria, performance scaling, cache awareness, overhead, and real-time suitability.",
    "authors": [
      "Said Muhammad",
      "Lahlou Laaziz",
      "Nadjia Kara",
      "Phat Tan Nguyen",
      "Timothy Murphy"
    ],
    "categories": [
      "cs.DC",
      "cs.PF"
    ],
    "publishedAt": "2025-10-10T20:19:44.000Z",
    "updatedAt": "2025-10-10T20:19:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09847v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09847v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09842v1",
    "arxivId": "2510.09842v1",
    "title": "Towards Automated and Predictive Network-Level Energy Profiling in Reconfigurable IoT Systems",
    "abstract": "Energy efficiency has emerged as a defining constraint in the evolution of sustainable Internet of Things (IoT) networks. This work moves beyond simulation-based or device-centric studies to deliver measurement-driven, network-level smart energy analysis. The proposed system enables end-to-end visibility of energy flows across distributed IoT infrastructures, uniting Bluetooth Low Energy (BLE) and Visible Light Communication (VLC) modes with environmental sensing and E-ink display subsystems under a unified profiling and prediction platform. Through automated, time-synchronized instrumentation, the framework captures fine-grained energy dynamics across both node and gateway layers. We developed a suite of tools that generate energy datasets for IoT ecosystems, addressing the scarcity of such data and enabling AI-based predictive and adaptive energy optimization. Validated within a network-level IoT testbed, the approach demonstrates robust performance under real operating conditions.",
    "authors": [
      "Mohammud J. Bocus",
      "Senhui Qiu",
      "Robert J. Piechocki",
      "Kerstin Eder"
    ],
    "categories": [
      "cs.NI",
      "cs.AR",
      "cs.PF"
    ],
    "publishedAt": "2025-10-10T20:16:00.000Z",
    "updatedAt": "2025-10-10T20:16:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09842v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09842v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09828v1",
    "arxivId": "2510.09828v1",
    "title": "Observer-Based Source Localization in Tree Infection Networks via Laplace Transforms",
    "abstract": "We address the problem of localizing the source of infection in an undirected, tree-structured network under a susceptible-infected outbreak model. The infection propagates with independent random time increments (i.e., edge-delays) between neighboring nodes, while only the infection times of a subset of nodes can be observed. We show that a reduced set of observers may be sufficient, in the statistical sense, to localize the source and characterize its identifiability via the joint Laplace transform of the observers' infection times. Using the explicit form of these transforms in terms of the edge-delay probability distributions, we propose scale-invariant least-squares estimators of the source. We evaluate their performance on synthetic trees and on a river network, demonstrating accurate localization under diverse edge-delay models. To conclude, we highlight overlooked technical challenges for observer-based source localization on networks with cycles, where standard spanning-tree reductions may be ill-posed.",
    "authors": [
      "Kesler O'Connor",
      "Julia M. Jess",
      "Devlin Costello",
      "Manuel E. Lladser"
    ],
    "categories": [
      "stat.ME",
      "cs.SI",
      "math.PR",
      "q-bio.PE",
      "92D30, 46N30, 62P10, 62-08, 60-08, 91D30, 92-04",
      "G.2.3; G.3"
    ],
    "publishedAt": "2025-10-10T19:58:17.000Z",
    "updatedAt": "2025-10-10T19:58:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09828v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09828v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09826v1",
    "arxivId": "2510.09826v1",
    "title": "Latent-Feature-Informed Neural ODE Modeling for Lightweight Stability Evaluation of Black-box Grid-Tied Inverters",
    "abstract": "Stability evaluation of black-box grid-tied inverters is vital for grid reliability, yet identification techniques are both data-hungry and blocked by proprietary internals. {To solve this, this letter proposes a latent-feature-informed neural ordinary differential equation (LFI-NODE) modeling method that can achieve lightweight stability evaluation directly from trajectory data.} LFI-NODE parameterizes the entire system ODE with a single continuous-time neural network, allowing each new sample to refine a unified global model. It faithfully captures nonlinear large-signal dynamics to preserve uniform predictive accuracy as the inverter transitions between operating points. Meanwhile, latent perturbation features distilled from every trajectory steer the learning process and concurrently reveal the small-signal eigenstructure essential for rigorous stability analysis. Validated on a grid-forming inverter, {The LFI-NODE requires one to two orders of magnitude fewer training samples compared with traditional methods, collected from short time-domain trajectories instead of extensive frequency-domain measurements.} {Furthermore, the LFI-NODE requires only 48 short transients to achieve a trajectory prediction error at the hundredth level and an eigenvalue estimation error at the tenth level, outperforming benchmark methods by one to two orders of magnitude.} This makes LFI-NODE a practical and lightweight approach for achieving high-fidelity stability assessment of complex black-box power-electronic systems.",
    "authors": [
      "Jialin Zheng",
      "Zhong Liu",
      "Xiaonan Lu"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T19:57:45.000Z",
    "updatedAt": "2025-10-10T19:57:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09826v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09826v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09824v1",
    "arxivId": "2510.09824v1",
    "title": "Quantum Circuit for Quantum Fourier Transform for Arbitrary Qubit Connectivity Graphs",
    "abstract": "In the paper, we consider quantum circuits for the Quantum Fourier Transform (QFT) algorithm. The QFT algorithm is a very popular technique used in many quantum algorithms. We present a generic method for constructing quantum circuits for this algorithm implementing on quantum devices with restrictions. Many quantum devices (for example, based on superconductors) have restrictions on applying two-qubit gates. These restrictions are presented by a qubit connectivity graph. Typically, researchers consider only the linear nearest neighbor (LNN) architecture of the qubit connection, but current devices have more complex graphs. We present a method for arbitrary connected graphs that minimizes the number of CNOT gates in the circuit for implementing on such architecture. We compare quantum circuits built by our algorithm with existing quantum circuits optimized for specific graphs that are Linear-nearest-neighbor (LNN) architecture, ``sun'' (a cycle with tails, presented by the 16-qubit IBMQ device) and ``two joint suns'' (two joint cycles with tails, presented by the 27-qubit IBMQ device). Our generic method gives similar results with existing optimized circuits for ``sun'' and ``two joint suns'' architectures, and a circuit with slightly more CNOT gates for the LNN architecture. At the same time, our method allows us to construct a circuit for arbitrary connected graphs.",
    "authors": [
      "Kamil Khadiev",
      "Aliya Khadieva",
      "Vadim Sagitov",
      "Kamil Khasanov"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T19:54:00.000Z",
    "updatedAt": "2025-10-10T19:54:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09824v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09824v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09817v1",
    "arxivId": "2510.09817v1",
    "title": "Cross-Sensor Touch Generation",
    "abstract": "Today's visuo-tactile sensors come in many shapes and sizes, making it challenging to develop general-purpose tactile representations. This is because most models are tied to a specific sensor design. To address this challenge, we propose two approaches to cross-sensor image generation. The first is an end-to-end method that leverages paired data (Touch2Touch). The second method builds an intermediate depth representation and does not require paired data (T2D2: Touch-to-Depth-to-Touch). Both methods enable the use of sensor-specific models across multiple sensors via the cross-sensor touch generation process. Together, these models offer flexible solutions for sensor translation, depending on data availability and application needs. We demonstrate their effectiveness on downstream tasks such as in-hand pose estimation and behavior cloning, successfully transferring models trained on one sensor to another. Project page: https://samantabelen.github.io/cross_sensor_touch_generation.",
    "authors": [
      "Samanta Rodriguez",
      "Yiming Dou",
      "Miquel Oller",
      "Andrew Owens",
      "Nima Fazeli"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-10T19:32:15.000Z",
    "updatedAt": "2025-10-10T19:32:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09817v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09817v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09814v1",
    "arxivId": "2510.09814v1",
    "title": "Stability in Online Assignment Games",
    "abstract": "The assignment game models a housing market where buyers and sellers are matched, and transaction prices are set so that the resulting allocation is stable. Shapley and Shubik showed that every stable allocation is necessarily built on a maximum social welfare matching. In practice, however, stable allocations are rarely attainable, as matchings are often sub-optimal, particularly in online settings where eagents arrive sequentially to the market. In this paper, we introduce and compare two complementary measures of instability for allocations with sub-optimal matchings, establish their connections to the optimality ratio of the underlying matching, and use this framework to study the stability performances of randomized algorithms in online assignment games.",
    "authors": [
      "Emile Martinez",
      "Felipe Garrido-Lucero",
      "Umberto Grandi"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-10T19:21:46.000Z",
    "updatedAt": "2025-10-10T19:21:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09814v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09814v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09810v1",
    "arxivId": "2510.09810v1",
    "title": "Designing Control Barrier Functions Using a Dynamic Backup Policy",
    "abstract": "This paper presents a systematic approach to construct control barrier functions for nonlinear control affine systems subject to arbitrary state and input constraints. Taking inspiration from the reference governor literature, the proposed method defines a family of backup policies, parametrized by the equilibrium manifold of the system. The control barrier function is defined on the augmented state-and-reference space: given a state-reference pair, the approach quantifies the distance to constraint violation at any time in the future, should the current backup policy reference remain constant. Sensitivity analysis is then used to compute the (possibly nonsmooth) Jacobian with respect to the augmented state vector. To showcase its simple yet general nature, the proposed method is applied to an inverted pendulum on cart.",
    "authors": [
      "Victor Freire",
      "Marco M. Nicotra"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T19:16:57.000Z",
    "updatedAt": "2025-10-10T19:16:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09810v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09810v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09804v1",
    "arxivId": "2510.09804v1",
    "title": "Rapid Development of Omics Data Analysis Applications through Vibe Coding",
    "abstract": "Building custom data analysis platforms traditionally requires extensive software engineering expertise, limiting accessibility for many researchers. Here, I demonstrate that modern large language models (LLMs) and autonomous coding agents can dramatically lower this barrier through a process called 'vibe coding', an iterative, conversational style of software creation where users describe goals in natural language and AI agents generate, test, and refine executable code in real-time. As a proof of concept, I used Vibe coding to create a fully functional proteomics data analysis website capable of performing standard tasks, including data normalization, differential expression testing, and volcano plot visualization. The entire application, including user interface, backend logic, and data upload pipeline, was developed in less than ten minutes using only four natural-language prompts, without any manual coding, at a cost of under $2. Previous works in this area typically require tens of thousands of dollars in research effort from highly trained programmers. I detail the step-by-step generation process and evaluate the resulting code's functionality. This demonstration highlights how vibe coding enables domain experts to rapidly prototype sophisticated analytical tools, transforming the pace and accessibility of computational biology software development.",
    "authors": [
      "Jesse G. Meyer"
    ],
    "categories": [
      "q-bio.OT",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T19:06:27.000Z",
    "updatedAt": "2025-10-10T19:06:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09804v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09804v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09799v1",
    "arxivId": "2510.09799v1",
    "title": "Distributed clustering in partially overlapping feature spaces",
    "abstract": "We introduce and address a novel distributed clustering problem where each participant has a private dataset containing only a subset of all available features, and some features are included in multiple datasets. This scenario occurs in many real-world applications, such as in healthcare, where different institutions have complementary data on similar patients. We propose two different algorithms suitable for solving distributed clustering problems that exhibit this type of feature space heterogeneity. The first is a federated algorithm in which participants collaboratively update a set of global centroids. The second is a one-shot algorithm in which participants share a statistical parametrization of their local clusters with the central server, who generates and merges synthetic proxy datasets. In both cases, participants perform local clustering using algorithms of their choice, which provides flexibility and personalized computational costs. Pretending that local datasets result from splitting and masking an initial centralized dataset, we identify some conditions under which the proposed algorithms are expected to converge to the optimal centralized solution. Finally, we test the practical performance of the algorithms on three public datasets.",
    "authors": [
      "Alessio Maritan",
      "Luca Schenato"
    ],
    "categories": [
      "cs.DS",
      "cs.DC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T19:03:50.000Z",
    "updatedAt": "2025-10-10T19:03:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09799v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09799v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09791v1",
    "arxivId": "2510.09791v1",
    "title": "PRAXA: A Framework for What-If Analysis",
    "abstract": "Various analytical techniques-such as scenario modeling, sensitivity analysis, perturbation-based analysis, counterfactual analysis, and parameter space analysis-are used across domains to explore hypothetical scenarios, examine input-output relationships, and identify pathways to desired results. Although termed differently, these methods share common concepts and methods, suggesting unification under what-if analysis. Yet a unified framework to define motivations, core components, and its distinct types is lacking. To address this gap, we reviewed 141 publications from leading visual analytics and HCI venues (2014-2024). Our analysis (1) outlines the motivations for what-if analysis, (2) introduces Praxa, a structured framework that identifies its fundamental components and characterizes its distinct types, and (3) highlights challenges associated with the application and implementation. Together, our findings establish a standardized vocabulary and structural understanding, enabling more consistent use across domains and communicate with greater conceptual clarity. Finally, we identify open research problems and future directions to advance what-if analysis.",
    "authors": [
      "Sneha Gathani",
      "Kevin Li",
      "Raghav Thind",
      "Sirui Zeng",
      "Matthew Xu",
      "Peter J. Haas",
      "Cagatay Demiralp",
      "Zhicheng Liu"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T18:54:21.000Z",
    "updatedAt": "2025-10-10T18:54:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09791v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09791v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09786v1",
    "arxivId": "2510.09786v1",
    "title": "Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks",
    "abstract": "Temporal sequential tasks challenge humanoid robots, as existing Diffusion Policy (DP) and Action Chunking with Transformers (ACT) methods often lack temporal context, resulting in local optima traps and excessive repetitive actions. To address these issues, this paper introduces a Classifier-Free Guidance-Based Diffusion Policy (CFG-DP), a novel framework to enhance DP by integrating Classifier-Free Guidance (CFG) with conditional and unconditional models. Specifically, CFG leverages timestep inputs to track task progression and ensure precise cycle termination. It dynamically adjusts action predictions based on task phase, using a guidance factor tuned to balance temporal coherence and action accuracy. Real-world experiments on a humanoid robot demonstrate high success rates and minimal repetitive actions. Furthermore, we assessed the model's ability to terminate actions and examined how different components and parameter adjustments affect its performance. This framework significantly enhances deterministic control and execution reliability for sequential robotic tasks.",
    "authors": [
      "Yuang Lu",
      "Song Wang",
      "Xiao Han",
      "Xuri Zhang",
      "Yucong Wu",
      "Zhicheng He"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T18:49:17.000Z",
    "updatedAt": "2025-10-10T18:49:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09786v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09786v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09763v1",
    "arxivId": "2510.09763v1",
    "title": "Network Traffic as a Scalable Ethnographic Lens for Understanding University Students' AI Tool Practices",
    "abstract": "AI-driven applications have become woven into students' academic and creative workflows, influencing how they learn, write, and produce ideas. Gaining a nuanced understanding of these usage patterns is essential, yet conventional survey and interview methods remain limited by recall bias, self-presentation effects, and the underreporting of habitual behaviors. While ethnographic methods offer richer contextual insights, they often face challenges of scale and reproducibility. To bridge this gap, we introduce a privacy-conscious approach that repurposes VPN-based network traffic analysis as a scalable ethnographic technique for examining students' real-world engagement with AI tools. By capturing anonymized metadata rather than content, this method enables fine-grained behavioral tracing while safeguarding personal information, thereby complementing self-report data. A three-week field deployment with university students reveals fragmented, short-duration interactions across multiple tools and devices, with intense bursts of activity coinciding with exam periods-patterns mirroring institutional rhythms of academic life. We conclude by discussing methodological, ethical, and empirical implications, positioning network traffic analysis as a promising avenue for large-scale digital ethnography on technology-in-practice.",
    "authors": [
      "Donghan Hu",
      "Rameen Mahmood",
      "Annabelle David",
      "Danny Yuxing Huang"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T18:12:07.000Z",
    "updatedAt": "2025-10-10T18:12:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09763v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09763v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09605v1",
    "arxivId": "2510.09605v1",
    "title": "VisPile: A Visual Analytics System for Analyzing Multiple Text Documents With Large Language Models and Knowledge Graphs",
    "abstract": "Intelligence analysts perform sensemaking over collections of documents using various visual and analytic techniques to gain insights from large amounts of text. As data scales grow, our work explores how to leverage two AI technologies, large language models (LLMs) and knowledge graphs (KGs), in a visual text analysis tool, enhancing sensemaking and helping analysts keep pace. Collaborating with intelligence community experts, we developed a visual analytics system called VisPile. VisPile integrates an LLM and a KG into various UI functions that assist analysts in grouping documents into piles, performing sensemaking tasks like summarization and relationship mapping on piles, and validating LLM- and KG-generated evidence. Our paper describes the tool, as well as feedback received from six professional intelligence analysts that used VisPile to analyze a text document corpus.",
    "authors": [
      "Adam Coscia",
      "Alex Endert"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T17:59:08.000Z",
    "updatedAt": "2025-10-10T17:59:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09605v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09605v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09591v1",
    "arxivId": "2510.09591v1",
    "title": "A Multilingual Python Programming Language",
    "abstract": "All widely used and useful programming languages have a common problem. They restrict entry on the basis of knowledge of the English language. The lack of knowledge of English poses a major hurdle to many newcomers who do not have the resources, in terms of time and money, to learn the English language. Studies show that people learn better in their own language. Therefore, we propose a language transpiler built on top of the Python programming language, called UniversalPython, which allows one to write Python in their own human language. We demonstrate the ability to create an \"Urdu Python\" with this transpiler. In the future, we aim to scale the language to encapsulate more human languages to increase the availability of programming. The source code for this transpiler is open-source, and available at https://github.com/universalpython/universalpython",
    "authors": [
      "Saad Ahmed Bazaz",
      "Mirza Omer Beg"
    ],
    "categories": [
      "cs.PL"
    ],
    "publishedAt": "2025-10-10T17:49:39.000Z",
    "updatedAt": "2025-10-10T17:49:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09591v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09591v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09589v1",
    "arxivId": "2510.09589v1",
    "title": "Minimizing the Weighted Makespan with Restarts on a Single Machine",
    "abstract": "We consider the problem of minimizing the weighted makespan on a single machine with restarts. Restarts are similar to preemptions but weaker: a job can be interrupted, but then it has to be run again from the start instead of resuming at the point of interruption later. The objective is to minimize the weighted makespan, defined as the maximum weighted completion time of jobs. We establish a lower bound of 1.4656 on the competitive ratio achievable by deterministic online algorithms. For the case where all jobs have identical processing times, we design and analyze a deterministic online algorithm that improves the competitive ratio to better than 1.3098. Finally, we prove a lower bound of 1.2344 for this case.",
    "authors": [
      "Aflatoun Amouzandeh",
      "Klaus Jansen",
      "Lis Pirotton",
      "Rob van Stee",
      "Corinna Wambsganz"
    ],
    "categories": [
      "cs.DS",
      "F.2.2"
    ],
    "publishedAt": "2025-10-10T17:45:34.000Z",
    "updatedAt": "2025-10-10T17:45:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09589v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09589v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09585v1",
    "arxivId": "2510.09585v1",
    "title": "From Birdwatch to Community Notes, from Twitter to X: four years of community-based content moderation",
    "abstract": "Community Notes (formerly known as Birdwatch) is the first large-scale crowdsourced content moderation initiative that was launched by X (formerly known as Twitter) in January 2021. As the Community Notes model gains momentum across other social media platforms, there is a growing need to assess its underlying dynamics and effectiveness. This Resource paper provides (a) a systematic review of the literature on Community Notes, and (b) a major curated dataset and accompanying source code to support future research on Community Notes. We parsed Notes and Ratings data from the first four years of the program and conducted language detection across all Notes. Focusing on English-language Notes, we extracted embedded URLs and identified discussion topics in each Note. Additionally, we constructed monthly interaction networks among the Contributors. Together with the literature review, these resources offer a robust foundation for advancing research on the Community Notes system.",
    "authors": [
      "Saeedeh Mohammadi",
      "Narges Chinichian",
      "Hannah Doyal",
      "Kristina Skutilova",
      "Hao Cui",
      "Michele d'Errico",
      "Siobhan Grayson",
      "Taha Yasseri"
    ],
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "publishedAt": "2025-10-10T17:42:54.000Z",
    "updatedAt": "2025-10-10T17:42:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09585v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09585v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09578v1",
    "arxivId": "2510.09578v1",
    "title": "Three Birds with One Stone: Improving Performance, Convergence, and System Throughput with Nest",
    "abstract": "Variational quantum algorithms (VQAs) have the potential to demonstrate quantum utility on near-term quantum computers. However, these algorithms often get executed on the highest-fidelity qubits and computers to achieve the best performance, causing low system throughput. Recent efforts have shown that VQAs can be run on low-fidelity qubits initially and high-fidelity qubits later on to still achieve good performance. We take this effort forward and show that carefully varying the qubit fidelity map of the VQA over its execution using our technique, Nest, does not just (1) improve performance (i.e., help achieve close to optimal results), but also (2) lead to faster convergence. We also use Nest to co-locate multiple VQAs concurrently on the same computer, thus (3) increasing the system throughput, and therefore, balancing and optimizing three conflicting metrics simultaneously.",
    "authors": [
      "Yuqian Huo",
      "David Quiroga",
      "Anastasios Kyrillidis",
      "Tirthak Patel"
    ],
    "categories": [
      "quant-ph",
      "cs.ET",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T17:30:58.000Z",
    "updatedAt": "2025-10-10T17:30:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09578v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09578v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09739v1",
    "arxivId": "2510.09739v1",
    "title": "Machine learning methods fail to provide cohesive atheoretical construction of personality traits from semantic embeddings",
    "abstract": "The lexical hypothesis posits that personality traits are encoded in language and is foundational to models like the Big Five. We created a bottom-up personality model from a classic adjective list using machine learning and compared its descriptive utility against the Big Five by analyzing one million Reddit comments. The Big Five, particularly Agreeableness, Conscientiousness, and Neuroticism, provided a far more powerful and interpretable description of these online communities. In contrast, our machine-learning clusters provided no meaningful distinctions, failed to recover the Extraversion trait, and lacked the psychometric coherence of the Big Five. These results affirm the robustness of the Big Five and suggest personality's semantic structure is context-dependent. Our findings show that while machine learning can help check the ecological validity of established psychological theories, it may not be able to replace them.",
    "authors": [
      "Ayoub Bouguettaya",
      "Elizabeth M. Stuart"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T17:29:33.000Z",
    "updatedAt": "2025-10-10T17:29:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09739v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09739v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09574v1",
    "arxivId": "2510.09574v1",
    "title": "Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference",
    "abstract": "Autonomous navigation in unfamiliar environments requires robots to simultaneously explore, localise, and plan under uncertainty, without relying on predefined maps or extensive training. We present a biologically inspired, Active Inference-based framework, Active Inference MAPping and Planning (AIMAPP). This model unifies mapping, localisation, and decision-making within a single generative model. Inspired by hippocampal navigation, it uses topological reasoning, place-cell encoding, and episodic memory to guide behaviour. The agent builds and updates a sparse topological map online, learns state transitions dynamically, and plans actions by minimising Expected Free Energy. This allows it to balance goal-directed and exploratory behaviours. We implemented a ROS-compatible navigation system that is sensor and robot-agnostic, capable of integrating with diverse hardware configurations. It operates in a fully self-supervised manner, is resilient to drift, and supports both exploration and goal-directed navigation without any pre-training. We demonstrate robust performance in large-scale real and simulated environments against state-of-the-art planning models, highlighting the system's adaptability to ambiguous observations, environmental changes, and sensor noise. The model offers a biologically inspired, modular solution to scalable, self-supervised navigation in unstructured settings. AIMAPP is available at https://github.com/decide-ugent/AIMAPP.",
    "authors": [
      "Daria de tinguy",
      "Tim Verbelen",
      "Emilio Gamba",
      "Bart Dhoedt"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T17:28:12.000Z",
    "updatedAt": "2025-10-10T17:28:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09574v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09574v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09570v1",
    "arxivId": "2510.09570v1",
    "title": "Differential Analysis of Pseudo Haptic Feedback: Novel Comparative Study of Visual and Auditory Cue Integration for Psychophysical Evaluation",
    "abstract": "Pseudo-haptics exploit carefully crafted visual or auditory cues to trick the brain into \"feeling\" forces that are never physically applied, offering a low-cost alternative to traditional haptic hardware. Here, we present a comparative psychophysical study that quantifies how visual and auditory stimuli combine to evoke pseudo-haptic pressure sensations on a commodity tablet. Using a Unity-based Rollball game, participants (n = 4) guided a virtual ball across three textured terrains while their finger forces were captured in real time with a Robotous RFT40 force-torque sensor. Each terrain was paired with a distinct rolling-sound profile spanning 440 Hz - 4.7 kHz, 440 Hz - 13.1 kHz, or 440 Hz - 8.9 kHz; crevice collisions triggered additional \"knocking\" bursts to heighten realism. Average tactile forces increased systematically with cue intensity: 0.40 N, 0.79 N and 0.88 N for visual-only trials and 0.41 N, 0.81 N and 0.90 N for audio-only trials on Terrains 1-3, respectively. Higher audio frequencies and denser visual textures both elicited stronger muscle activation, and their combination further reduced the force needed to perceive surface changes, confirming multisensory integration. These results demonstrate that consumer-grade isometric devices can reliably induce and measure graded pseudo-haptic feedback without specialized actuators, opening a path toward affordable rehabilitation tools, training simulators and assistive interfaces.",
    "authors": [
      "Nishant Gautam",
      "Somya Sharma",
      "Peter Corcoran",
      "Kaspar Althoefer"
    ],
    "categories": [
      "cs.HC",
      "cs.GR",
      "cs.NE",
      "cs.RO",
      "physics.med-ph"
    ],
    "publishedAt": "2025-10-10T17:22:41.000Z",
    "updatedAt": "2025-10-10T17:22:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09570v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09570v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09554v1",
    "arxivId": "2510.09554v1",
    "title": "scellop: A Scalable Redesign of Cell Population Plots for Single-Cell Data",
    "abstract": "Summary: Cell population plots are visualizations showing cell population distributions in biological samples with single-cell data, traditionally shown with stacked bar charts. Here, we address issues with this approach, particularly its limited scalability with increasing number of cell types and samples, and present scellop, a novel interactive cell population viewer combining visual encodings optimized for common user tasks in studying populations of cells across samples or conditions. Availability and Implementation: Scellop is available under the MIT licence at https://github.com/hms-dbmi/scellop, and is available on PyPI (https://pypi.org/project/cellpop/) and NPM (https://www.npmjs.com/package/cellpop). A demo is available at https://scellop.netlify.app/.",
    "authors": [
      "Thomas C. Smits",
      "Nikolay Akhmetov",
      "Tiffany S. Liaw",
      "Mark S. Keller",
      "Eric Mörth",
      "Nils Gehlenborg"
    ],
    "categories": [
      "cs.HC",
      "q-bio.QM"
    ],
    "publishedAt": "2025-10-10T17:06:10.000Z",
    "updatedAt": "2025-10-10T17:06:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09554v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09554v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09543v2",
    "arxivId": "2510.09543v2",
    "title": "Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards",
    "abstract": "Animals achieve energy-efficient locomotion by their implicit passive dynamics, a marvel that has captivated roboticists for decades.Recently, methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning (RL) shows promising progress to replicate Animals' naturalistic motion. However, such imitation learning approaches predominantly capture explicit kinematic patterns, so-called gaits, while overlooking the implicit passive dynamics. This work bridges this gap by incorporating a reward term guided by Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a robot's ability to passively mitigate impacts. By integrating IMF with AMP, our approach enables RL policies to learn both explicit motion trajectories from animal reference motion and the implicit passive dynamic. We demonstrate energy efficiency improvements of up to 32%, as measured by the Cost of Transport (CoT), across both AMP and handcrafted reward structure.",
    "authors": [
      "Chenghao Wang",
      "Arjun Viswanathan",
      "Eric Sihite",
      "Alireza Ramezani"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T16:56:35.000Z",
    "updatedAt": "2025-10-13T15:49:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09543v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.09543v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09528v1",
    "arxivId": "2510.09528v1",
    "title": "Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking",
    "abstract": "Pre-trained transformer-based models have significantly advanced automatic speech recognition (ASR), yet they remain sensitive to accent and dialectal variations, resulting in elevated word error rates (WER) in linguistically diverse languages such as English and Persian. To address this challenge, we propose an accent-invariant ASR framework that integrates accent and dialect classification into the recognition pipeline. Our approach involves training a spectrogram-based classifier to capture accent-specific cues, masking the regions most influential to its predictions, and using the masked spectrograms for data augmentation. This enhances the robustness of ASR models against accent variability. We evaluate the method using both English and Persian speech. For Persian, we introduce a newly collected dataset spanning multiple regional accents, establishing the first systematic benchmark for accent variation in Persian ASR that fills a critical gap in multilingual speech research and provides a foundation for future studies on low-resource, linguistically diverse languages. Experimental results with the Whisper model demonstrate that our masking and augmentation strategy yields substantial WER reductions in both English and Persian settings, confirming the effectiveness of the approach. This research advances the development of multilingual ASR systems that are resilient to accent and dialect diversity. Code and dataset are publicly available at: https://github.com/MH-Sameti/Accent_invariant_ASR",
    "authors": [
      "Mohammad Hossein Sameti",
      "Sepehr Harfi Moridani",
      "Ali Zarean",
      "Hossein Sameti"
    ],
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T16:41:53.000Z",
    "updatedAt": "2025-10-10T16:41:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09528v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09528v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09526v1",
    "arxivId": "2510.09526v1",
    "title": "Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing",
    "abstract": "Multi-modal ground-aerial robots have been extensively studied, with a significant challenge lying in the integration of conflicting requirements across different modes of operation. The Husky robot family, developed at Northeastern University, and specifically the Husky v.2 discussed in this study, addresses this challenge by incorporating posture manipulation and thrust vectoring into multi-modal locomotion through structure repurposing. This quadrupedal robot features leg structures that can be repurposed for dynamic legged locomotion and flight. In this paper, we present the hardware design of the robot and report primary results on dynamic quadrupedal legged locomotion and hovering.",
    "authors": [
      "Chenghao Wang",
      "Kaushik Venkatesh Krishnamurthy",
      "Shreyansh Pitroda",
      "Adarsh Salagame",
      "Ioannis Mandralis",
      "Eric Sihite",
      "Alireza Ramezani",
      "Morteza Gharib"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T16:38:48.000Z",
    "updatedAt": "2025-10-10T16:38:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09526v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09526v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09516v1",
    "arxivId": "2510.09516v1",
    "title": "Convivial Conversational Agents -- shifting toward relationships",
    "abstract": "Conversational AI (CAI) systems offer opportunities to scale service provision to unprecedented levels and governments and corporations are already beginning to deploy them across services. The economic argument is similar across domains: use CAI to automate the time-consuming conversations required for customer, client or patient support. Herein we draw on our work in dementia care to explore some of the challenges and opportunities for CAI, and how a new way of conceptualising these systems could help ensure essential aspects for human thriving are not lost in the process of automation.",
    "authors": [
      "Rafael A. Calvo",
      "Dorian Peters"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T16:28:38.000Z",
    "updatedAt": "2025-10-10T16:28:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09516v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09516v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09512v1",
    "arxivId": "2510.09512v1",
    "title": "Parameterized Algorithms for Diversity of Networks with Ecological Dependencies",
    "abstract": "For a phylogenetic tree, the phylogenetic diversity of a set A of taxa is the total weight of edges on paths to A. Finding small sets of maximal diversity is crucial for conservation planning, as it indicates where limited resources can be invested most efficiently. In recent years, efficient algorithms have been developed to find sets of taxa that maximize phylogenetic diversity either in a phylogenetic network or in a phylogenetic tree subject to ecological constraints, such as a food web. However, these aspects have mostly been studied independently. Since both factors are biologically important, it seems natural to consider them together. In this paper, we introduce decision problems where, given a phylogenetic network, a food web, and integers k, and D, the task is to find a set of k taxa with phylogenetic diversity of at least D under the maximize all paths measure, while also satisfying viability conditions within the food web. Here, we consider different definitions of viability, which all demand that a \"sufficient\" number of prey species survive to support surviving predators. We investigate the parameterized complexity of these problems and present several fixed-parameter tractable (FPT) algorithms. Specifically, we provide a complete complexity dichotomy characterizing which combinations of parameters - out of the size constraint k, the acceptable diversity loss D, the scanwidth of the food web, the maximum in-degree in the network, and the network height h - lead to W[1]-hardness and which admit FPT algorithms. Our primary methodological contribution is a novel algorithmic framework for solving phylogenetic diversity problems in networks where dependencies (such as those from a food web) impose an order, using a color coding approach.",
    "authors": [
      "Mark Jones",
      "Jannik Schestag"
    ],
    "categories": [
      "cs.DS",
      "math.CO"
    ],
    "publishedAt": "2025-10-10T16:16:56.000Z",
    "updatedAt": "2025-10-10T16:16:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09512v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09512v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09511v1",
    "arxivId": "2510.09511v1",
    "title": "Toggling stiffness via multistability",
    "abstract": "Mechanical metamaterials enable unconventional and programmable mechanical responses through structural design rather than material composition. In this work, we introduce a multistable mechanical metamaterial that exhibits a toggleable stiffness effect, where the effective shear stiffness switches discretely between stable configurations. The mechanical analysis of surrogate beam models of the unit cell reveal that this behavior originates from the rotation transmitted by the support beams to the curved beam, which governs the balance between bending and axial deformation. The stiffness ratio between the two states of the unit cell can be tuned by varying the slenderness of the support beams or by incorporating localized hinges that modulate rotational transfer. Experiments on 3D-printed prototypes validate the numerical predictions, confirming consistent stiffness toggling across different geometries. Finally, we demonstrate a monolithic soft clutch that leverages this effect to achieve programmable, stepwise stiffness modulation. This work establishes a design strategy for toggleable stiffness using multistable metamaterials, paving the way for adaptive, lightweight, and autonomous systems in soft robotics and smart structures.",
    "authors": [
      "Hugo de Souza Oliveira",
      "Michele Curatolo",
      "Renate Sachse",
      "Edoardo Milana"
    ],
    "categories": [
      "cond-mat.soft",
      "cs.RO",
      "physics.app-ph"
    ],
    "publishedAt": "2025-10-10T16:16:50.000Z",
    "updatedAt": "2025-10-10T16:16:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09511v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09511v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09507v1",
    "arxivId": "2510.09507v1",
    "title": "PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs",
    "abstract": "The ability to use, understand, and create tools is a hallmark of human intelligence, enabling sophisticated interaction with the physical world. For any general-purpose intelligent agent to achieve true versatility, it must also master these fundamental skills. While modern Multimodal Large Language Models (MLLMs) leverage their extensive common knowledge for high-level planning in embodied AI and in downstream Vision-Language-Action (VLA) models, the extent of their true understanding of physical tools remains unquantified. To bridge this gap, we present PhysToolBench, the first benchmark dedicated to evaluating the comprehension of physical tools by MLLMs. Our benchmark is structured as a Visual Question Answering (VQA) dataset comprising over 1,000 image-text pairs. It assesses capabilities across three distinct difficulty levels: (1) Tool Recognition: Requiring the recognition of a tool's primary function. (2) Tool Understanding: Testing the ability to grasp the underlying principles of a tool's operation. (3) Tool Creation: Challenging the model to fashion a new tool from surrounding objects when conventional options are unavailable. Our comprehensive evaluation of 32 MLLMs-spanning proprietary, open-source, specialized embodied, and backbones in VLAs-reveals a significant deficiency in tool understanding. Furthermore, we provide an in-depth analysis and propose preliminary solutions. Code and dataset are publicly available.",
    "authors": [
      "Zixin Zhang",
      "Kanghao Chen",
      "Xingwang Lin",
      "Lutao Jiang",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Litao Guo",
      "Yinchuan Li",
      "Ying-Cong Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T16:10:45.000Z",
    "updatedAt": "2025-10-10T16:10:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09507v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09507v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09502v1",
    "arxivId": "2510.09502v1",
    "title": "LibraryLens: An Interactive Tool for Exploring and Arranging Digital Bookshelves",
    "abstract": "Existing digital book management platforms often fail to capture the rich spatial and visual cues inherent to physical bookshelves, hindering users' ability to fully engage with their collections. We present LibraryLens, a novel visualization tool that addresses these shortcomings by enabling users to create, explore, and interact with immersive, two-dimensional representations of their personal libraries. The tool also caters to the growing trend of social sharing within online book communities, allowing users to create visually appealing representations of their libraries that can be easily shared on social platforms. Despite limitations inherent to the metadata being rendered, formative evaluations suggest that LibraryLens has the potential to lower the barrier to entry for users seeking to optimize their book organization without the constraints of physical space or manual labor, ultimately fostering deeper engagement with their personal libraries.",
    "authors": [
      "Trevor DePodesta",
      "Johanna Beyer"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T16:04:59.000Z",
    "updatedAt": "2025-10-10T16:04:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09502v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09502v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09497v1",
    "arxivId": "2510.09497v1",
    "title": "Autonomous Soft Robotic Guidewire Navigation via Imitation Learning",
    "abstract": "In endovascular surgery, endovascular interventionists push a thin tube called a catheter, guided by a thin wire to a treatment site inside the patient's blood vessels to treat various conditions such as blood clots, aneurysms, and malformations. Guidewires with robotic tips can enhance maneuverability, but they present challenges in modeling and control. Automation of soft robotic guidewire navigation has the potential to overcome these challenges, increasing the precision and safety of endovascular navigation. In other surgical domains, end-to-end imitation learning has shown promising results. Thus, we develop a transformer-based imitation learning framework with goal conditioning, relative action outputs, and automatic contrast dye injections to enable generalizable soft robotic guidewire navigation in an aneurysm targeting task. We train the model on 36 different modular bifurcated geometries, generating 647 total demonstrations under simulated fluoroscopy, and evaluate it on three previously unseen vascular geometries. The model can autonomously drive the tip of the robot to the aneurysm location with a success rate of 83% on the unseen geometries, outperforming several baselines. In addition, we present ablation and baseline studies to evaluate the effectiveness of each design and data collection choice. Project website: https://softrobotnavigation.github.io/",
    "authors": [
      "Noah Barnes",
      "Ji Woong Kim",
      "Lingyun Di",
      "Hannah Qu",
      "Anuruddha Bhattacharjee",
      "Miroslaw Janowski",
      "Dheeraj Gandhi",
      "Bailey Felix",
      "Shaopeng Jiang",
      "Olivia Young",
      "Mark Fuge",
      "Ryan D. Sochol",
      "Jeremy D. Brown",
      "Axel Krieger"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T15:57:09.000Z",
    "updatedAt": "2025-10-10T15:57:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09497v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09497v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09494v1",
    "arxivId": "2510.09494v1",
    "title": "The Data Enclave Advantage: A New Paradigm for Least-Privileged Data Access in a Zero-Trust World",
    "abstract": "As cloud infrastructure evolves to support dynamic and distributed workflows, accelerated now by AI-driven processes, the outdated model of standing permissions has become a critical vulnerability. Based on the Cloud Security Alliance (CSA) Top Threats to Cloud Computing Deep Dive 2025 Report, our analysis details how standing permissions cause catastrophic cloud breaches. While current security tools are addressing network and API security, the challenge of securing granular data access remains. Removing standing permissions at the data level is as critical as it is at the network level, especially for companies handling valuable data at scale. In this white paper, we introduce an innovative architecture based on on-demand data enclaves to address this gap directly. Our approach enables Zero Standing Privilege (ZSP) and Just-in-Time (JIT) principles at the data level. We replace static permissions with temporary data contracts that enforce proactive protection. This means separation is built around the data requested on-demand, providing precise access and real time monitoring for individual records instead of datasets. This solution drastically reduces the attack surface, prevents privilege creep, and simplifies auditing, offering a vital path for enterprises to transition to a more secure and resilient data environment.",
    "authors": [
      "Nico Bistolfi",
      "Andreea Georgescu",
      "Dave Hodson"
    ],
    "categories": [
      "cs.CR",
      "cs.DB",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T15:54:58.000Z",
    "updatedAt": "2025-10-10T15:54:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09494v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09494v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09492v1",
    "arxivId": "2510.09492v1",
    "title": "Barriers that Programming Instructors Face While Performing Emergency Pedagogical Design to Shape Student-AI Interactions with Generative AI Tools",
    "abstract": "Generative AI (GenAI) tools are increasingly pervasive, pushing instructors to redesign how students use GenAI tools in coursework. We conceptualize this work as emergency pedagogical design: reactive, indirect efforts by instructors to shape student-AI interactions without control over commercial interfaces. To understand practices of lead users conducting emergency pedagogical design, we conducted interviews (n=13) and a survey (n=169) of computing instructors. These instructors repeatedly encountered five barriers: fragmented buy-in for revising courses; policy crosswinds from non-prescriptive institutional guidance; implementation challenges as instructors attempt interventions; assessment misfit as student-AI interactions are only partially visible to instructors; and lack of resources, including time, staffing, and paid tool access. We use these findings to present emergency pedagogical design as a distinct design setting for HCI and outline recommendations for HCI researchers, academic institutions, and organizations to effectively support instructors in adapting courses to GenAI.",
    "authors": [
      "Sam Lau",
      "Kianoosh Boroojeni",
      "Harry Keeling",
      "Jenn Marroquin"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T15:53:04.000Z",
    "updatedAt": "2025-10-10T15:53:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09492v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09492v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09489v1",
    "arxivId": "2510.09489v1",
    "title": "Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction",
    "abstract": "Outdoor scene reconstruction remains challenging due to the stark contrast between well-textured, nearby regions and distant backgrounds dominated by low detail, uneven illumination, and sky effects. We introduce a two-stage Gaussian Splatting framework that explicitly separates and optimizes these regions, yielding higher-fidelity novel view synthesis. In stage one, background primitives are initialized within a spherical shell and optimized using a loss that combines a background-only photometric term with two geometric regularizers: one constraining Gaussians to remain inside the shell, and another aligning them with local tangential planes. In stage two, foreground Gaussians are initialized from a Structure-from-Motion reconstruction, added and refined using the standard rendering loss, while the background set remains fixed but contributes to the final image formation. Experiments on diverse outdoor datasets show that our method reduces background artifacts and improves perceptual quality compared to state-of-the-art baselines. Moreover, the explicit background separation enables automatic, object-free environment map estimation, opening new possibilities for photorealistic outdoor rendering and mixed-reality applications.",
    "authors": [
      "Deborah Pintani",
      "Ariel Caputo",
      "Noah Lewis",
      "Marc Stamminger",
      "Fabio Pellacini",
      "Andrea Giachetti"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-10T15:52:23.000Z",
    "updatedAt": "2025-10-10T15:52:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09489v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09489v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09483v1",
    "arxivId": "2510.09483v1",
    "title": "FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents",
    "abstract": "Dynamic Scene Graphs (DSGs) provide a structured representation of hierarchical, interconnected environments, but current approaches struggle to capture stochastic dynamics, partial observability, and multi-agent activity. These aspects are critical for embodied AI, where agents must act under uncertainty and delayed perception. We introduce FOGMACHINE , an open-source framework that fuses DSGs with discrete-event simulation to model object dynamics, agent observations, and interactions at scale. This setup enables the study of uncertainty propagation, planning under limited perception, and emergent multi-agent behavior. Experiments in urban scenarios illustrate realistic temporal and spatial patterns while revealing the challenges of belief estimation under sparse observations. By combining structured representations with efficient simulation, FOGMACHINE establishes an effective tool for benchmarking, model training, and advancing embodied AI in complex, uncertain environments.",
    "authors": [
      "Lars Ohnemus",
      "Nils Hantke",
      "Max Weißer",
      "Kai Furmans"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T15:45:31.000Z",
    "updatedAt": "2025-10-10T15:45:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09483v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09483v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09469v1",
    "arxivId": "2510.09469v1",
    "title": "Scalable Multi-Agent Path Finding using Collision-Aware Dynamic Alert Mask and a Hybrid Execution Strategy",
    "abstract": "Multi-agent pathfinding (MAPF) remains a critical problem in robotics and autonomous systems, where agents must navigate shared spaces efficiently while avoiding conflicts. Traditional centralized algorithms that have global information, such as Conflict-Based Search (CBS), provide high-quality solutions but become computationally expensive in large-scale scenarios due to the combinatorial explosion of conflicts that need resolution. Conversely, distributed approaches that have local information, particularly learning-based methods, offer better scalability by operating with relaxed information availability, yet often at the cost of solution quality. To address these limitations, we propose a hybrid framework that combines decentralized path planning with a lightweight centralized coordinator. Our framework leverages reinforcement learning (RL) for decentralized planning, enabling agents to adapt their planning based on minimal, targeted alerts--such as static conflict-cell flags or brief conflict tracks--that are dynamically shared information from the central coordinator for effective conflict resolution. We empirically study the effect of the information available to an agent on its planning performance. Our approach reduces the inter-agent information sharing compared to fully centralized and distributed methods, while still consistently finding feasible, collision-free solutions--even in large-scale scenarios having higher agent counts.",
    "authors": [
      "Bharath Muppasani",
      "Ritirupa Dey",
      "Biplav Srivastava",
      "Vignesh Narayanan"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T15:25:40.000Z",
    "updatedAt": "2025-10-10T15:25:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09469v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09469v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09464v1",
    "arxivId": "2510.09464v1",
    "title": "Cross-Platform Narrative Prediction: Leveraging Platform-Invariant Discourse Networks",
    "abstract": "Online narratives spread unevenly across platforms, with content emerging on one site often appearing on others, hours, days or weeks later. Existing cross-platform information diffusion models often treat platforms as isolated systems, disregarding cross-platform activity that might make these patterns more predictable. In this work, we frame cross-platform prediction as a network proximity problem: rather than tracking individual users across platforms or relying on brittle signals like shared URLs or hashtags, we construct platform-invariant discourse networks that link users through shared narrative engagement. We show that cross-platform neighbor proximity provides a strong predictive signal: adoption patterns follow discourse network structure even without direct cross-platform influence. Our highly-scalable approach substantially outperforms diffusion models and other baselines while requiring less than 3% of active users to make predictions. We also validate our framework through retrospective deployment. We sequentially process a datastream of 5.7M social media posts occurred during the 2024 U.S. election, to simulate real-time collection from four platforms (X, TikTok, Truth Social, and Telegram): our framework successfully identified emerging narratives, including crises-related rumors, yielding over 94% AUC with sufficient lead time to support proactive intervention.",
    "authors": [
      "Patrick Gerard",
      "Luca Luceria",
      "Leonardo Blas",
      "Emilio Ferrara"
    ],
    "categories": [
      "cs.SI"
    ],
    "publishedAt": "2025-10-10T15:19:36.000Z",
    "updatedAt": "2025-10-10T15:19:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09464v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09464v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09459v2",
    "arxivId": "2510.09459v2",
    "title": "Failure Prediction at Runtime for Generative Robot Policies",
    "abstract": "Imitation learning (IL) with generative models, such as diffusion and flow matching, has enabled robots to perform complex, long-horizon tasks. However, distribution shifts from unseen environments or compounding action errors can still cause unpredictable and unsafe behavior, leading to task failure. Early failure prediction during runtime is therefore essential for deploying robots in human-centered and safety-critical environments. We propose FIPER, a general framework for Failure Prediction at Runtime for generative IL policies that does not require failure data. FIPER identifies two key indicators of impending failure: (i) out-of-distribution (OOD) observations detected via random network distillation in the policy's embedding space, and (ii) high uncertainty in generated actions measured by a novel action-chunk entropy score. Both failure prediction scores are calibrated using a small set of successful rollouts via conformal prediction. A failure alarm is triggered when both indicators, aggregated over short time windows, exceed their thresholds. We evaluate FIPER across five simulation and real-world environments involving diverse failure modes. Our results demonstrate that FIPER better distinguishes actual failures from benign OOD situations and predicts failures more accurately and earlier than existing methods. We thus consider this work an important step towards more interpretable and safer generative robot policies. Code, data and videos are available at https://tum-lsy.github.io/fiper_website.",
    "authors": [
      "Ralf Römer",
      "Adrian Kobras",
      "Luca Worbis",
      "Angela P. Schoellig"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.8; I.2.9; I.2.10"
    ],
    "publishedAt": "2025-10-10T15:09:27.000Z",
    "updatedAt": "2025-10-13T13:29:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09459v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.09459v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09458v1",
    "arxivId": "2510.09458v1",
    "title": "SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests",
    "abstract": "Interest in robotics for forest management is growing, but perception in complex, natural environments remains a significant hurdle. Conditions such as heavy occlusion, variable lighting, and dense vegetation pose challenges to automated systems, which are essential for precision forestry, biodiversity monitoring, and the automation of forestry equipment. These tasks rely on advanced perceptual capabilities, such as detection and fine-grained species classification of individual trees. Yet, existing datasets are inadequate to develop such perception systems, as they often focus on urban settings or a limited number of species. To address this, we present SilvaScenes, a new dataset for instance segmentation of tree species from under-canopy images. Collected across five bioclimatic domains in Quebec, Canada, SilvaScenes features 1476 trees from 24 species with annotations from forestry experts. We demonstrate the relevance and challenging nature of our dataset by benchmarking modern deep learning approaches for instance segmentation. Our results show that, while tree segmentation is easy, with a top mean average precision (mAP) of 67.65%, species classification remains a significant challenge with an mAP of only 35.69%. Our dataset and source code will be available at https://github.com/norlab-ulaval/SilvaScenes.",
    "authors": [
      "David-Alexandre Duclos",
      "William Guimont-Martin",
      "Gabriel Jeanson",
      "Arthur Larochelle-Tremblay",
      "Théo Defosse",
      "Frédéric Moore",
      "Philippe Nolet",
      "François Pomerleau",
      "Philippe Giguère"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T15:08:35.000Z",
    "updatedAt": "2025-10-10T15:08:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09458v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09458v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09445v1",
    "arxivId": "2510.09445v1",
    "title": "Robust reset control design for piezo-actuated nano-positioner in presence of hysteresis nonlinearity",
    "abstract": "In this paper, a robust nonlinear control scheme is designed for the motion control of a class of piezo-actuated nano-positioning systems using frequency-domain analysis. The hysteresis, the nonlinearity in the piezoelectric material, degrades the precision in tracking references with high frequency contents and different travel ranges. The hysteresis compensation by the inverse model, as the state-of-the-art solution, is not reliable alone. Therefore, a control framework with robustness against the remaining nonlinearity is needed. It is shown that there is an unavoidable limitation in robust linear control design to improve the performance. A robust control methodology based on a complex-order element is established to relax the limitation. Then, a constant-in-gain-lead-in-phase (CgLp) reset controller is utilized to realize the complex-order control. The control design is based on the sinusoidal input describing function (SIDF) and the higher-order SIDF (HOSIDF) tools. A constrained optimization problem is provided to tune the control parameters. The achieved improvements by the CgLp control is validated by the simulation.",
    "authors": [
      "Ashkan Sebghati",
      "S. Hassan HosseinNia"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T14:57:13.000Z",
    "updatedAt": "2025-10-10T14:57:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09445v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09445v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09443v2",
    "arxivId": "2510.09443v2",
    "title": "The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash",
    "abstract": "This paper investigates the impact of sanctions on Tornado Cash, a smart contract protocol designed to enhance transaction privacy. Following the U.S. Department of the Treasury's sanctions against Tornado Cash in August 2022, platform activity declined sharply. We document a significant and sustained reduction in transaction volume, user diversity, and overall protocol utilization after the sanctions were imposed. Our analysis draws on transaction data from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We further examine developments following the partial lifting and eventual removal of sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025. Although activity partially recovered, the rebound remained limited. The Tornado Cash case illustrates how regulatory interventions can affect decentralized protocols, while also highlighting the challenges of fully enforcing such measures in decentralized environments.",
    "authors": [
      "Raffaele Cristodaro",
      "Benjamin Kraner",
      "Claudio J. Tessone"
    ],
    "categories": [
      "cs.CR",
      "cs.SI"
    ],
    "publishedAt": "2025-10-10T14:55:32.000Z",
    "updatedAt": "2025-10-13T09:46:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09443v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.09443v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09439v1",
    "arxivId": "2510.09439v1",
    "title": "Demystifying and Navigating AI Ethics in Power Electronics",
    "abstract": "Artificial intelligence (AI) is rapidly transforming power electronics, with AI-related publications in IEEE Power Electronics Society selected journals increasing more than fourfold from 2020 to 2025. However, the ethical dimensions of this transformation have received limited attention. This article underscores the urgent need for an ethical framework to guide responsible AI integration in power electronics, not only to prevent AI-related incidents but also to comply with legal and regulatory responsibilities. In this context, this article identifies four core pillars of AI ethics in power electronics: Security & Safety, Explainability & Transparency, Energy Sustainability, and Evolving Roles of Engineers. Each pillar is supported by practical and actionable insights to ensure that ethical principles are embedded in algorithm design, system deployment, and workforce development. The authors advocate for power electronics engineers to lead the ethical discourse, given their deep technical understanding of both AI systems and power conversion technologies. The paper concludes by calling on the IEEE Power Electronics Society to spearhead the establishment of ethical standards and best practices that ensure AI innovations are not only technically advanced but also trustworthy, safe, and sustainable.",
    "authors": [
      "Fanfan Lin",
      "Peter Wilson",
      "Xinze Li",
      "Alan Mantooth"
    ],
    "categories": [
      "cs.CY",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-10T14:51:02.000Z",
    "updatedAt": "2025-10-10T14:51:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09439v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09439v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09433v2",
    "arxivId": "2510.09433v2",
    "title": "Clustering Deposit and Withdrawal Activity in Tornado Cash: A Cross-Chain Analysis",
    "abstract": "Tornado Cash is a decentralised mixer that uses cryptographic techniques to sever the on-chain trail between depositors and withdrawers. In practice, however, its anonymity can be undermined by user behaviour and operational quirks. We conduct the first cross-chain empirical study of Tornado Cash activity on Ethereum, BNB Smart Chain, and Polygon, introducing three clustering heuristics-(i) address-reuse, (ii) transactional-linkage, and (iii) a novel first-in-first-out (FIFO) temporal-matching rule. Together, these heuristics reconnect deposits to withdrawals and deanonymise a substantial share of recipients. Our analysis shows that 5.1 - 12.6% of withdrawals can already be traced to their originating deposits through address reuse and transactional linkage heuristics. Adding our novel First-In-First-Out (FIFO) temporal-matching heuristic lifts the linkage rate by a further 15 - 22 percentage points. Statistical tests confirm that these FIFO matches are highly unlikely to occur by chance. Comparable leakage across Ethereum, BNB Smart Chain, and Polygon indicates chain-agnostic user misbehaviour, rather than chain-specific protocol flaws. These results expose how quickly cryptographic guarantees can unravel in everyday use, underscoring the need for both disciplined user behaviour and privacy-aware protocol design. In total, our heuristics link over $2.3 billion in Tornado Cash withdrawals to identifiable deposits, exposing significant cracks in practical anonymity.",
    "authors": [
      "Raffaele Cristodaro",
      "Benjamin Kraner",
      "Claudio J. Tessone"
    ],
    "categories": [
      "cs.CR",
      "cs.ET"
    ],
    "publishedAt": "2025-10-10T14:42:24.000Z",
    "updatedAt": "2025-10-13T09:49:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09433v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.09433v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09432v1",
    "arxivId": "2510.09432v1",
    "title": "On Stable Cutsets in General and Minimum Degree Constrained Graphs",
    "abstract": "A stable cutset is a set of vertices $S$ of a connected graph, that is pairwise non-adjacent and when deleting $S$, the graph becomes disconnected. Determining the existence of a stable cutset in a graph is known to be NP-complete. In this paper, we introduce a new exact algorithm for Stable Cutset. By branching on graph configurations and using the $O^*(1.3645)$ algorithm for the (3,2)-Constraint Satisfaction Problem presented by Beigel and Eppstein, we achieve an improved running time of $O^*(1.2972^n)$. In addition, we investigate the Stable Cutset problem for graphs with a bound on the minimum degree $\\delta$. First, we show that if the minimum degree of a graph $G$ is at least $\\frac{2}{3}(n-1)$, then $G$ does not contain a stable cutset. Furthermore, we provide a polynomial-time algorithm for graphs where $\\delta \\geq \\tfrac{1}{2}n$, and a similar kernelisation algorithm for graphs where $\\delta = \\tfrac{1}{2}n - k$. Finally, we prove that Stable Cutset remains NP-complete for graphs with minimum degree $c$, where $c > 1$. We design an exact algorithm for this problem that runs in $O^*(\\lambda^n)$ time, where $\\lambda$ is the positive root of $x^{\\delta + 2} - x^{\\delta + 1} + 6$. This algorithm can also be applied to the \\textsc{3-Colouring} problem with the same minimum degree constraint, leading to an improved exact algorithm as well.",
    "authors": [
      "Mats Vroon",
      "Hans L. Bodlaender"
    ],
    "categories": [
      "cs.DS",
      "cs.CC",
      "cs.DM"
    ],
    "publishedAt": "2025-10-10T14:41:20.000Z",
    "updatedAt": "2025-10-10T14:41:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09432v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09432v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09420v1",
    "arxivId": "2510.09420v1",
    "title": "Critical States Identiffcation in Power System via Lattice Partition and Its Application in Reliability Assessment",
    "abstract": "With the increasing complexity of power systems,accurately identifying critical states (the states corresponding to minimal cut sets) and assessing system reliability have become crucial tasks. In this paper, a mathematical lattice structure is employed to represent and partition the state space of power system. Based on this structure, a novel recursive method is proposed to efffciently identify critical states by leveraging lattice partitioning and Optimal Power Flow(OPF) calculations. This method not only enables the extension of failure system states,but also calculates the upper and lower bounds of the Loss of Load Probability (LOLP) in a progressively converging manner. Compared to traditional reliability assessment methods such as State Enumeration (SE) and Monte Carlo Simulation (MCS), this approach offers greater accuracy and efffciency. Experiments conducted on the RBTS and RTS79 systems demonstrate that the proposed method accurately identiffes all critical states up to a preset order, which are high-risk states. The contribution of these critical states to LOLP highlights their signiffcance in the system. Moreover, the proposed method achieves the analytical value with signiffcantly fewer OPF calculations in RBTS system, reaching acceptable precision of LOLP up to 100 times faster than SE in both the RBTS and RTS systems.",
    "authors": [
      "Han Hu",
      "Wenjie Wan",
      "Feiyu Chen",
      "Xiaoyu Liu",
      "Bo Yu",
      "Kequan Zhao"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T14:23:43.000Z",
    "updatedAt": "2025-10-10T14:23:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09420v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09420v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09416v1",
    "arxivId": "2510.09416v1",
    "title": "What Do Temporal Graph Learning Models Learn?",
    "abstract": "Learning on temporal graphs has become a central topic in graph representation learning, with numerous benchmarks indicating the strong performance of state-of-the-art models. However, recent work has raised concerns about the reliability of benchmark results, noting issues with commonly used evaluation protocols and the surprising competitiveness of simple heuristics. This contrast raises the question of which properties of the underlying graphs temporal graph learning models actually use to form their predictions. We address this by systematically evaluating seven models on their ability to capture eight fundamental attributes related to the link structure of temporal graphs. These include structural characteristics such as density, temporal patterns such as recency, and edge formation mechanisms such as homophily. Using both synthetic and real-world datasets, we analyze how well models learn these attributes. Our findings reveal a mixed picture: models capture some attributes well but fail to reproduce others. With this, we expose important limitations. Overall, we believe that our results provide practical insights for the application of temporal graph learning models, and motivate more interpretability-driven evaluations in temporal graph learning research.",
    "authors": [
      "Abigail J. Hayes",
      "Tobias Schumacher",
      "Markus Strohmaier"
    ],
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "publishedAt": "2025-10-10T14:18:37.000Z",
    "updatedAt": "2025-10-10T14:18:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09416v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09416v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09411v1",
    "arxivId": "2510.09411v1",
    "title": "Grid-forming Control of Converter Infinite Bus System: Modeling by Data-driven Methods",
    "abstract": "This study explores data-driven modeling techniques to capture the dynamics of a grid-forming converter-based infinite bus system, critical for renewable-integrated power grids. Using sparse identification of nonlinear dynamics and deep symbolic regression, models were generated from synthetic data simulating key disturbances in active power, reactive power, and voltage references. Deep symbolic regression demonstrated more accuracy in capturing complex system dynamics, though it required substantially more computational time than sparse identification of nonlinear dynamics. These findings suggest that while deep symbolic regression offers high fidelity, sparse identification of nonlinear dynamics provides a more computationally efficient approach, balancing accuracy and runtime for real-time grid applications.",
    "authors": [
      "Amir Bahador Javadi",
      "Philip Pong"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T14:08:39.000Z",
    "updatedAt": "2025-10-10T14:08:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09411v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09411v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09409v1",
    "arxivId": "2510.09409v1",
    "title": "3C Resources Joint Allocation for Time-Deterministic Remote Sensing Image Backhaul in the Space-Ground Integrated Network",
    "abstract": "Low-Earth-orbit (LEO) satellites assist observation satellites (OSs) to compress and backhaul more time-determined images (TDI) has become a new paradigm, which is used to enhance the timeout caused by the limited computing resources of OSs. However, how to capture the time-varying and dynamic characteristics of multi-dimensional resources is challenging for efficient collaborative scheduling. Motivated by this factor, we design a highly succinct multi-dimensional resource time-expanded graph (MDR-TEG) modell. Specifically, by employing a slots division mechanism and introducing an external virtual node, the time-varying communication, caching, and computing (3C) resources are depicted in low complexity by the link weights within, between, and outside the slots. Based on the MDR-TEG, the maximizing successful transmission ratio of TDI (MSTR-TDI) is modeled as a mixed integer linear programming (MILP) problem. Which further relaxed decomposed into two tractable sub-problems: maximizing the successful transmission rate of images (MSTRI) and ensuring the timeliness problem (ETP). Subsequently, an efficient subgradient of relaxation computing constraint (SRCC) algorithm is proposed. The upper and lower bounds of MSTR-TDI are obtained by solving the two subproblems and the dual problem (DP), and the direction of the next iteration is obtained by feedback. Furthermore, arranging the sending sequences of images to improve the quality of the solution. The approximate optimal solution of MSTR-TDI is eventually obtained through repeated iterations. The simulation results verify the superiority of the proposed MDR-TEG model and the effectiveness of the SRCC.",
    "authors": [
      "Chongxiao Cai",
      "Yan Zhu",
      "Min Sheng",
      "Jiandong Li",
      "Yan Shi",
      "Di Zhou",
      "Ziwen Xie",
      "Chen Zhang"
    ],
    "categories": [
      "eess.SY",
      "cs.IT",
      "cs.SY",
      "math.IT"
    ],
    "publishedAt": "2025-10-10T14:03:42.000Z",
    "updatedAt": "2025-10-10T14:03:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09409v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09409v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09400v1",
    "arxivId": "2510.09400v1",
    "title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation",
    "abstract": "Large Language Models (LLMs) have shown strong performance in automated source-to-target code translation through pretraining on extensive code corpora. However, mainstream LLM-based code translation methods suffer from two critical limitations. First, they are highly sensitive to language-specific features, which often introduce source-language syntax or lexicon into the output, leading to syntactic confusion. Second, they lack fine-grained semantic alignment due to an over-reliance on function-level parallel datasets, resulting in semantic misalignment between the translated code and the original source. To overcome these limitations, we propose TIT, a Tree-structured Instruction Tuning paradigm for LLM-based code translation. Specifically, TIT consists of three modules. First, to mitigate syntactic confusion, the syntactic information representation module integrates language-agnostic syntactic features via structured parsing. Then, to generate high-quality fine-grained parallel data, the fine-grained parallel dataset augmentation module aligns nodes with code segments through statement-level segmentation and contrastive matching. Finally, we leverage the dual-stage tree instruction tuning module to alleviate the contextual processing burden on the LLM caused by the introduction of syntactic information. The first stage employs syntax-aware fine-tuning to enable the LLM to autonomously comprehend structured syntactic information, while the second stage utilizes code generation fine-tuning to guide the model in generating accurate target code based on function-level syntactic dependencies. The experimental results demonstrate that the proposed method significantly outperforms existing approaches in multiple LLMs, achieving a success rate 1.22x-1.75x higher in code translation while markedly reducing syntactic confusion.",
    "authors": [
      "He Jiang",
      "Yufu Wang",
      "Hao Lin",
      "Peiyu Zou",
      "Zhide Zhou",
      "Ang Jia",
      "Xiaochen Li",
      "Zhilei Ren"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T13:53:46.000Z",
    "updatedAt": "2025-10-10T13:53:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09400v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09400v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09396v1",
    "arxivId": "2510.09396v1",
    "title": "Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems",
    "abstract": "Ensuring robust robotic navigation in dynamic environments is a key challenge, as traditional testing methods often struggle to cover the full spectrum of operational requirements. This paper presents the industrial adoption of Surrealist, a simulation-based test generation framework originally for UAVs, now applied to the ANYmal quadrupedal robot for industrial inspection. Our method uses a search-based algorithm to automatically generate challenging obstacle avoidance scenarios, uncovering failures often missed by manual testing. In a pilot phase, generated test suites revealed critical weaknesses in one experimental algorithm (40.3% success rate) and served as an effective benchmark to prove the superior robustness of another (71.2% success rate). The framework was then integrated into the ANYbotics workflow for a six-month industrial evaluation, where it was used to test five proprietary algorithms. A formal survey confirmed its value, showing it enhances the development process, uncovers critical failures, provides objective benchmarks, and strengthens the overall verification pipeline.",
    "authors": [
      "Sajad Khatiri",
      "Francisco Eli Vina Barrientos",
      "Maximilian Wulf",
      "Paolo Tonella",
      "Sebastiano Panichella"
    ],
    "categories": [
      "cs.RO",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T13:50:32.000Z",
    "updatedAt": "2025-10-10T13:50:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09396v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09396v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09390v1",
    "arxivId": "2510.09390v1",
    "title": "Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation",
    "abstract": "Establishing shared goals is a fundamental step in human-AI communication. However, ambiguities can lead to outputs that seem correct but fail to reflect the speaker's intent. In this paper, we explore this issue with a focus on the data visualization domain, where ambiguities in natural language impact the generation of code that visualizes data. The availability of multiple views on the contextual (e.g., the intended plot and the code rendering the plot) allows for a unique and comprehensive analysis of diverse ambiguity types. We develop a taxonomy of types of ambiguity that arise in this task and propose metrics to quantify them. Using Matplotlib problems from the DS-1000 dataset, we demonstrate that our ambiguity metrics better correlate with human annotations than uncertainty baselines. Our work also explores how multi-turn dialogue can reduce ambiguity, therefore, improve code accuracy by better matching user goals. We evaluate three pragmatic models to inform our dialogue strategies: Gricean Cooperativity, Discourse Representation Theory, and Questions under Discussion. A simulated user study reveals how pragmatic dialogues reduce ambiguity and enhance code accuracy, highlighting the value of multi-turn exchanges in code generation.",
    "authors": [
      "Mert İnan",
      "Anthony Sicilia",
      "Alex Xie",
      "Saujas Vaduguru",
      "Daniel Fried",
      "Malihe Alikhani"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.MA"
    ],
    "publishedAt": "2025-10-10T13:44:40.000Z",
    "updatedAt": "2025-10-10T13:44:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09390v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09390v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09379v1",
    "arxivId": "2510.09379v1",
    "title": "Task-Level Insights from Eigenvalues across Sequence Models",
    "abstract": "Although softmax attention drives state-of-the-art performance for sequence models, its quadratic complexity limits scalability, motivating linear alternatives such as state space models (SSMs). While these alternatives improve efficiency, their fundamental differences in information processing remain poorly understood. In this work, we leverage the recently proposed dynamical systems framework to represent softmax, norm and linear attention as dynamical systems, enabling a structured comparison with SSMs by analyzing their respective eigenvalue spectra. Since eigenvalues capture essential aspects of dynamical system behavior, we conduct an extensive empirical analysis across diverse sequence models and benchmarks. We first show that eigenvalues influence essential aspects of memory and long-range dependency modeling, revealing spectral signatures that align with task requirements. Building on these insights, we then investigate how architectural modifications in sequence models impact both eigenvalue spectra and task performance. This correspondence further strengthens the position of eigenvalue analysis as a principled metric for interpreting, understanding, and ultimately improving the capabilities of sequence models.",
    "authors": [
      "Rahel Rickenbach",
      "Jelena Trisovic",
      "Alexandre Didier",
      "Jerome Sieber",
      "Melanie N. Zeilinger"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-10T13:35:21.000Z",
    "updatedAt": "2025-10-10T13:35:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09379v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09379v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09371v1",
    "arxivId": "2510.09371v1",
    "title": "A Framework for Distributed Resource Allocation in Quantum Networks",
    "abstract": "We introduce a distributed resource allocation framework for the Quantum Internet that relies on feedback-based, fully decentralized coordination to serve multiple co-existing applications. We develop quantum network control algorithms under the mathematical framework of Quantum Network Utility Maximization (QNUM), where utility functions quantify network performance by mapping entanglement rate and quality into a joint optimization objective. We then introduce QPrimal-Dual, a decentralized, scalable algorithm that solves QNUM by strategically placing network controllers that operate using local state information and limited classical message exchange. We prove global asymptotic stability for concave, separable utility functions, and provide sufficient conditions for local stability for broader non-concave cases. To reduce control overhead and account for quantum memory decoherence, we also propose schemes that locally approximate global quantities and prevent congestion in the network. We evaluate the performance of our approach via simulations in realistic quantum network architectures. Results show that QPrimalDual significantly outperforms baseline allocation strategies, scales with network size, and is robust to latency and decoherence. Our observations suggest that QPrimalDual could be a practical, high-performance foundation for fully distributed resource allocation in quantum networks.",
    "authors": [
      "Nitish K. Panigrahy",
      "Leonardo Bacciottini",
      "C. V. Hollot",
      "Emily A. Van Milligen",
      "Matheus Guedes de Andrade",
      "Nageswara S. V. Rao",
      "Gayane Vardoyan",
      "Don Towsley"
    ],
    "categories": [
      "quant-ph",
      "cs.PF"
    ],
    "publishedAt": "2025-10-10T13:27:32.000Z",
    "updatedAt": "2025-10-10T13:27:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09371v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09371v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09349v1",
    "arxivId": "2510.09349v1",
    "title": "MPA-DNN: Projection-Aware Unsupervised Learning for Multi-period DC-OPF",
    "abstract": "Ensuring both feasibility and efficiency in optimal power flow (OPF) operations has become increasingly important in modern power systems with high penetrations of renewable energy and energy storage. While deep neural networks (DNNs) have emerged as promising fast surrogates for OPF solvers, they often fail to satisfy critical operational constraints, especially those involving inter-temporal coupling, such as generator ramping limits and energy storage operations. To deal with these issues, we propose a Multi-Period Projection-Aware Deep Neural Network (MPA-DNN) that incorporates a projection layer for multi-period dispatch into the network. By doing so, our model enforces physical feasibility through the projection, enabling end-to-end learning of constraint-compliant dispatch trajectories without relying on labeled data. Experimental results demonstrate that the proposed method achieves near-optimal performance while strictly satisfying all constraints in varying load conditions.",
    "authors": [
      "Yeomoon Kim",
      "Minsoo Kim",
      "Jip Kim"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T13:01:56.000Z",
    "updatedAt": "2025-10-10T13:01:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09349v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09349v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09344v1",
    "arxivId": "2510.09344v1",
    "title": "WildElder: A Chinese Elderly Speech Dataset from the Wild with Fine-Grained Manual Annotations",
    "abstract": "Elderly speech poses unique challenges for automatic processing due to age-related changes such as slower articulation and vocal tremors. Existing Chinese datasets are mostly recorded in controlled environments, limiting their diversity and real-world applicability. To address this gap, we present WildElder, a Mandarin elderly speech corpus collected from online videos and enriched with fine-grained manual annotations, including transcription, speaker age, gender, and accent strength. Combining the realism of in-the-wild data with expert curation, WildElder enables robust research on automatic speech recognition and speaker profiling. Experimental results reveal both the difficulties of elderly speech recognition and the potential of WildElder as a challenging new benchmark. The dataset and code are available at https://github.com/NKU-HLT/WildElder.",
    "authors": [
      "Hui Wang",
      "Jiaming Zhou",
      "Jiabei He",
      "Haoqin Sun",
      "Yong Qin"
    ],
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T12:56:19.000Z",
    "updatedAt": "2025-10-10T12:56:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09344v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09344v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09339v1",
    "arxivId": "2510.09339v1",
    "title": "Sequencing on Silicon: AI SoC Design for Mobile Genomics at the Edge",
    "abstract": "Miniature DNA sequencing hardware has begun to succeed in mobile contexts, driving demand for efficient machine learning at the edge. This domain leverages deep learning techniques familiar from speech and time-series analysis for both low-level signal processing and high-level genomic interpretation. Unlike audio, however, nanopore sequencing presents raw data rates over 100X higher, requiring more aggressive compute and memory handling. In this paper, we present a CMOS system-on-chip (SoC) designed for mobile genetic analysis. Our approach combines a multi-core RISC-V processor with tightly coupled accelerators for deep learning and bioinformatics. A hardware/software co-design strategy enables energy-efficient operation across a heterogeneous compute fabric, targeting real-time, on-device genome analysis. This work exemplifies the integration of deep learning, edge computing, and domain-specific hardware to advance next-generation mobile genomics.",
    "authors": [
      "Sebastian Magierowski",
      "Zhongpan Wu",
      "Abel Beyene",
      "Karim Hammad"
    ],
    "categories": [
      "cs.AR",
      "cs.ET"
    ],
    "publishedAt": "2025-10-10T12:45:02.000Z",
    "updatedAt": "2025-10-10T12:45:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09339v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09339v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09336v1",
    "arxivId": "2510.09336v1",
    "title": "Quantum Trigonometric Bézier Curves",
    "abstract": "In order to construct quantum trigonometric B\\'ezier curves with shape parameter, one parameter family of trigonometric Bernstein basis functions are introduced. We study the total positivity of the basis functions to analyze the shape preserving properties of the quantum trigonometric B\\'ezier curves. We also showed that quantum trigonometric B\\'ezier curves can be evaluated by two different recursive evaluation algorithms. Finally, we have defined rational counterpart of quantum trigonometric B\\'ezier curves and show that the rational quantum trigonometric B\\'ezier curves posses nice shape preserving properties.",
    "authors": [
      "Çetin Dişibüyük"
    ],
    "categories": [
      "math.CA",
      "cs.GR",
      "cs.NA",
      "math.NA",
      "65D17, 05A30"
    ],
    "publishedAt": "2025-10-10T12:42:37.000Z",
    "updatedAt": "2025-10-10T12:42:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09336v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09336v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09334v1",
    "arxivId": "2510.09334v1",
    "title": "Optimizing Administrative Divisions: A Vertex $k$-Center Approach for Edge-Weighted Road Graphs",
    "abstract": "Efficient and equitable access to municipal services hinges on well-designed administrative divisions. It requires ongoing adaptation to changing demographics, infrastructure, and economic factors. This article proposes a novel transparent data-driven method for territorial division based on the Voronoi partition of edge-weighted road graphs and the vertex $k$-center problem as a special case of the minimax facility location problem. By considering road network structure and strategic placement of administrative centers, this method seeks to minimize travel time disparities and ensure a more balanced distribution of administrative time burden for the population. We show implementations of this approach in the context of Latvia, a country with complex geographical features and diverse population distribution.",
    "authors": [
      "Peteris Daugulis"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T12:38:05.000Z",
    "updatedAt": "2025-10-10T12:38:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09334v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09334v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09323v1",
    "arxivId": "2510.09323v1",
    "title": "Parametrized Topological Complexity for a Multi-Robot System with Variable Tasks",
    "abstract": "We study a generalized motion planning problem involving multiple autonomous robots navigating in a $d$-dimensional Euclidean space in the presence of a set of obstacles whose positions are unknown a priori. Each robot is required to visit sequentially a prescribed set of target states, with the number of targets varying between robots. This heterogeneous setting generalizes the framework considered in the prior works on sequential parametrized topological complexity by Farber and the second author of this article. To determine the topological complexity of our problem, we formulate it mathematically by constructing an appropriate fibration. Our main contribution is the determination of this invariant in the generalized setting, which captures the minimal algorithmic instability required for designing collision-free motion planning algorithms under parameter-dependent constraints. We provide a detailed analysis for both odd and even-dimensional ambient spaces, including the essential cohomological computations and explicit constructions of corresponding motion planning algorithms.",
    "authors": [
      "Gopal Chandra Dutta",
      "Amit Kumar Paul",
      "Subhankar Sau"
    ],
    "categories": [
      "math.AT",
      "cs.RO",
      "55M30, 55R80"
    ],
    "publishedAt": "2025-10-10T12:26:26.000Z",
    "updatedAt": "2025-10-10T12:26:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09323v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09323v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09311v1",
    "arxivId": "2510.09311v1",
    "title": "Improved Extended Regular Expression Matching",
    "abstract": "An extended regular expression $R$ specifies a set of strings formed by characters from an alphabet combined with concatenation, union, intersection, complement, and star operators. Given an extended regular expression $R$ and a string $Q$, the extended regular expression matching problem is to decide if $Q$ matches any of the strings specified by $R$. Extended regular expressions are a basic concept in formal language theory and a basic primitive for searching and processing data. Extended regular expression matching was introduced by Hopcroft and Ullmann in the 1970s [\\textit{Introduction to Automata Theory, Languages and Computation}, 1979], who gave a simple dynamic programming solution using $O(n^3m)$ time and $O(n^2m)$ space, where $n$ is the length of $Q$ and $m$ is the length of $R$. Since then, several solutions have been proposed, but few significant asymptotic improvements have been obtained. The current state-of-the art solution, by Yamamoto and Miyazaki~[COCOON, 2003], uses $O(\\frac{n^3k + n^2m}{w} + n + m)$ time and $O(\\frac{n^2k + nm}{w} + n + m)$ space, where $k$ is the number of negation and complement operators in $R$ and $w$ is the number of bits in a word. This roughly replaces the $m$ factor with $k$ in the dominant terms of both the space and time bounds of the Hopcroft and Ullmann algorithm. We revisit the problem and present a new solution that significantly improves the previous time and space bounds. Our main result is a new algorithm that solves extended regular expression matching in \\[O\\left(n^\\omega k + \\frac{n^2m}{\\min(w/\\log w, \\log n)} + m\\right)\\] time and $O(\\frac{n^2 \\log k}{w} + n + m) = O(n^2 +m)$ space, where $\\omega \\approx 2.3716$ is the exponent of matrix multiplication. Essentially, this replaces the dominant $n^3k$ term with $n^\\omega k$ in the time bound, while simultaneously improving the $n^2k$ term in the space to $O(n^2)$.",
    "authors": [
      "Philip Bille",
      "Inge Li Gørtz",
      "Rikke Schjeldrup Jessen"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T12:04:53.000Z",
    "updatedAt": "2025-10-10T12:04:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09311v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09311v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09308v1",
    "arxivId": "2510.09308v1",
    "title": "A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms",
    "abstract": "Artificial intelligence (AI) has the potential to transform healthcare by supporting more accurate diagnoses and personalized treatments. However, its adoption in practice remains constrained by fragmented data sources, strict privacy rules, and the technical complexity of building reliable clinical systems. To address these challenges, we introduce a model driven engineering (MDE) framework designed specifically for healthcare AI. The framework relies on formal metamodels, domain-specific languages (DSLs), and automated transformations to move from high level specifications to running software. At its core is the Medical Interoperability Language (MILA), a graphical DSL that enables clinicians and data scientists to define queries and machine learning pipelines using shared ontologies. When combined with a federated learning architecture, MILA allows institutions to collaborate without exchanging raw patient data, ensuring semantic consistency across sites while preserving privacy. We evaluate this approach in a multi center cancer immunotherapy study. The generated pipelines delivered strong predictive performance, with support vector machines achieving up to 98.5 percent and 98.3 percent accuracy in key tasks, while substantially reducing manual coding effort. These findings suggest that MDE principles metamodeling, semantic integration, and automated code generation can provide a practical path toward interoperable, reproducible, and trustworthy digital health platforms.",
    "authors": [
      "Mira Raheem",
      "Amal Elgammal",
      "Michael Papazoglou",
      "Bernd Krämer",
      "Neamat El-Tazi"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T12:00:12.000Z",
    "updatedAt": "2025-10-10T12:00:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09308v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09308v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09304v1",
    "arxivId": "2510.09304v1",
    "title": "Data-Driven Control Of Power Converters",
    "abstract": "The fundamental role of power converters is to efficiently manage and control the flow of electrical energy, ensuring compatibility between power sources and loads. All these applications of power converters need the design of an appropriate control law. Control of power converters is a challenging problem due to the presence of switching devices which are difficult to handle using traditional control approaches. The objective of this paper is to investigate the use of data-driven techniques, in particular the Virtual References Feedback Tuning (VRFT) method, in the context of power converters feedback control. This study considers a buck \\pauline{mode} power converter circuit provided by the OwnTech foundation.",
    "authors": [
      "Marwan Soliman",
      "Pauline Kergus",
      "Diego Regruto",
      "Luiz Villa",
      "Zohra Kader"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T11:51:01.000Z",
    "updatedAt": "2025-10-10T11:51:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09304v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09304v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09290v1",
    "arxivId": "2510.09290v1",
    "title": "Weighting Factors Tuning by Direct Feedback in Predictive Control of Multiphase Motors",
    "abstract": "Predictive Stator Current Control (PSCC) has been proposed for control of multi-phase drives. The flexibility offered by the use of a Cost Function has been used to deal with the increased number of phases. However, tuning of the Weighting Factors constitutes a problem. Intensive trial and error tests are usual in this context. Existing on-line selection methods, on the other hand, require large amounts of data and/or complex optimization procedures. The proposal of this paper is a closed-loop scheme that links Weighting Factors to performance indicators. In this way, optimal Weighting Factors are determined for each operating point. Also, changes in reference values for performance indicators are easily tackled. Unlike previous methods, the proposal carries very little computational burden. A case study is developed for a five-phase induction motor and assessed with real experimentation on a laboratory set-up.",
    "authors": [
      "Manuel R. Arahal",
      "Manuel G. Satué",
      "Kumars Rouzbehi",
      "Francisco Colodro"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T11:29:48.000Z",
    "updatedAt": "2025-10-10T11:29:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09290v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09290v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09286v1",
    "arxivId": "2510.09286v1",
    "title": "Confluence of the Node-Domination and Edge-Domination Hypergraph Rewrite Rules",
    "abstract": "In this note, we study two rewrite rules on hypergraphs, called edge-domination and node-domination, and show that they are confluent. These rules are rather natural and commonly used before computing the minimum hitting sets of a hypergraph. Intuitively, edge-domination allows us to remove hyperedges that are supersets of another hyperedge, and node-domination allows us to remove nodes whose incident hyperedges are a subset of that of another node. We show that these rules are confluent up to isomorphism, i.e., if we apply any sequences of edge-domination and node-domination rules, then the resulting hypergraphs can be made isomorphic via more rule applications. This in particular implies the existence of a unique minimal hypergraph, up to isomorphism.",
    "authors": [
      "Antoine Amarilli",
      "Mikaël Monet",
      "Rémi De Pretto"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T11:27:27.000Z",
    "updatedAt": "2025-10-10T11:27:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09286v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09286v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09283v1",
    "arxivId": "2510.09283v1",
    "title": "Safety Analysis of eVTOL Operations based on STPA",
    "abstract": "Electric Vertical Take-Off and Landing (eVTOL) aircraft are expected to be quieter and more cost-effective than helicopters, offering major economic and social benefits through improved connectivity. Their adoption will require new ground infrastructure and airspace redesign, introducing risks involving multiple stakeholders (Regulators, eVTOL operators, Air navigation service providers, Vertiport operators, OEMs, Pilots, etc.). To assess these risks for the UK airspace, systems-thinking based System Theoretic Process Analysis (STPA) was conducted. To manage the large number of Unsafe Control Actions (UCAs) and requirements generated due to the complexity of the analysis, a novel extension to STPA for the prioritization of results was applied. 317 UCAs were identified in total out of which 110 high-priority UCAs were analyzed (Step-4), resulting in 377 causal factors and 432 requirements. These were prioritized to produce a targeted list of 124 distinct high-priority requirements, 56 of which were identified as gaps in existing aviation regulations, policies, or procedures.. These highlight opportunities for regulatory updates in areas such as organizational performance, certification processes, training, collision avoidance, energy management, and automation. The findings provide regulators with safety considerations that could shape new or updated regulations, compliance methods, and guidance materials for the safe deployment of eVTOLs.",
    "authors": [
      "Mariat James Elizebeth",
      "Shufeng Chen",
      "Halima El Badaoui",
      "Siddartha Khastgir",
      "Paul Jennings"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T11:24:48.000Z",
    "updatedAt": "2025-10-10T11:24:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09283v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09283v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09281v1",
    "arxivId": "2510.09281v1",
    "title": "Single vs Multi Vector Predictive Control of Five-phase Drives",
    "abstract": "The field of Finite State Model Predictive Control for multiphase drives has produced many contributions. Many variants of FSMPC exist, each aiming at some aspect such as complexity of the cost function, switching frequency, etc. Despite past efforts to compare different techniques, the field is still out of consensus regarding the relative merits of each one. This paper presents a new method to compare FSMPC variants. The method is based on analyzing the modulation, implicit or explicit, used by each variant. In the paper the method is used to compare single-vector state-of-the-art FSMPC with a multi-vector variant designed to cancel xy currents and simplify the cost function. The results show the strengths and weaknesses of each technique. Also, it is found that the trade-offs between figures, previously thought to concern just individual regimes, extend to the whole operating space and also can be pinpoint to each FSMPC variant. Finally, it is shown that the flexibility of the single-vector approach and its better DC-link usage makes it, arguably, superior over the multi-vector variant.",
    "authors": [
      "Manuel R. Arahal",
      "Manuel G. Satué",
      "Kumars Rouzbehi",
      "Juana M. Martínez-Heredia"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T11:23:38.000Z",
    "updatedAt": "2025-10-10T11:23:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09281v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09281v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09271v1",
    "arxivId": "2510.09271v1",
    "title": "Assessing the Impact of Post-Quantum Digital Signature Algorithms on Blockchains",
    "abstract": "The advent of quantum computing threatens the security of traditional encryption algorithms, motivating the development of post-quantum cryptography (PQC). In 2024, the National Institute of Standards and Technology (NIST) standardized several PQC algorithms, marking an important milestone in the transition toward quantum-resistant security. Blockchain systems fundamentally rely on cryptographic primitives to guarantee data integrity and transaction authenticity. However, widely used algorithms such as ECDSA, employed in Bitcoin, Ethereum, and other networks, are vulnerable to quantum attacks. Although adopting PQC is essential for long-term security, its computational overhead in blockchain environments remains largely unexplored. In this work, we propose a methodology for benchmarking both PQC and traditional cryptographic algorithms in blockchain contexts. We measure signature generation and verification times across diverse computational environments and simulate their impact at scale. Our evaluation focuses on PQC digital signature schemes (ML-DSA, Dilithium, Falcon, Mayo, SLH-DSA, SPHINCS+, and Cross) across security levels 1 to 5, comparing them to ECDSA, the current standard in Bitcoin and Ethereum. Our results indicate that PQC algorithms introduce only minor performance overhead at security level 1, while in some scenarios they significantly outperform ECDSA at higher security levels. For instance, ML-DSA achieves a verification time of 0.14 ms on an ARM-based laptop at level 5, compared to 0.88 ms for ECDSA. We also provide an open-source implementation to ensure reproducibility and encourage further research.",
    "authors": [
      "Alison Gonçalves Schemitt",
      "Henrique Fan da Silva",
      "Roben Castagna Lunardi",
      "Diego Kreutz",
      "Rodrigo Brandão Mansilha",
      "Avelino Francisco Zorzo"
    ],
    "categories": [
      "cs.CR",
      "cs.ET",
      "cs.PF"
    ],
    "publishedAt": "2025-10-10T11:12:53.000Z",
    "updatedAt": "2025-10-10T11:12:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09271v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09271v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09267v1",
    "arxivId": "2510.09267v1",
    "title": "Placeit! A Framework for Learning Robot Object Placement Skills",
    "abstract": "Robotics research has made significant strides in learning, yet mastering basic skills like object placement remains a fundamental challenge. A key bottleneck is the acquisition of large-scale, high-quality data, which is often a manual and laborious process. Inspired by Graspit!, a foundational work that used simulation to automatically generate dexterous grasp poses, we introduce Placeit!, an evolutionary-computation framework for generating valid placement positions for rigid objects. Placeit! is highly versatile, supporting tasks from placing objects on tables to stacking and inserting them. Our experiments show that by leveraging quality-diversity optimization, Placeit! significantly outperforms state-of-the-art methods across all scenarios for generating diverse valid poses. A pick&place pipeline built on our framework achieved a 90% success rate over 120 real-world deployments. This work positions Placeit! as a powerful tool for open-environment pick-and-place tasks and as a valuable engine for generating the data needed to train simulation-based foundation models in robotics.",
    "authors": [
      "Amina Ferrad",
      "Johann Huber",
      "François Hélénon",
      "Julien Gleyze",
      "Mahdi Khoramshahi",
      "Stéphane Doncieux"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T11:08:06.000Z",
    "updatedAt": "2025-10-10T11:08:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09267v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09267v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09254v1",
    "arxivId": "2510.09254v1",
    "title": "Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning",
    "abstract": "Learning-based motion planning can quickly generate near-optimal trajectories. However, it often requires either large training datasets or costly collection of human demonstrations. This work proposes an alternative approach that quickly generates smooth, near-optimal collision-free 3D Cartesian trajectories from a single artificial demonstration. The demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively reshaped using policy-based reinforcement learning to create a diverse trajectory dataset for varying obstacle configurations. This dataset is used to train a neural network that takes as inputs the task parameters describing the obstacle dimensions and location, derived automatically from a point cloud, and outputs the DMP parameters that generate the trajectory. The approach is validated in simulation and real-robot experiments, outperforming a RRT-Connect baseline in terms of computation and execution time, as well as trajectory length, while supporting multi-modal trajectory generation for different obstacle geometries and end-effector dimensions. Videos and the implementation code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.",
    "authors": [
      "Dominik Urbaniak",
      "Alejandro Agostini",
      "Pol Ramon",
      "Jan Rosell",
      "Raúl Suárez",
      "Michael Suppa"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T10:51:42.000Z",
    "updatedAt": "2025-10-10T10:51:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09254v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09254v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09245v1",
    "arxivId": "2510.09245v1",
    "title": "SynthVC: Leveraging Synthetic Data for End-to-End Low Latency Streaming Voice Conversion",
    "abstract": "Voice Conversion (VC) aims to modify a speaker's timbre while preserving linguistic content. While recent VC models achieve strong performance, most struggle in real-time streaming scenarios due to high latency, dependence on ASR modules, or complex speaker disentanglement, which often results in timbre leakage or degraded naturalness. We present SynthVC, a streaming end-to-end VC framework that directly learns speaker timbre transformation from synthetic parallel data generated by a pre-trained zero-shot VC model. This design eliminates the need for explicit content-speaker separation or recognition modules. Built upon a neural audio codec architecture, SynthVC supports low-latency streaming inference with high output fidelity. Experimental results show that SynthVC outperforms baseline streaming VC systems in both naturalness and speaker similarity, achieving an end-to-end latency of just 77.1 ms.",
    "authors": [
      "Zhao Guo",
      "Ziqian Ning",
      "Guobin Ma",
      "Lei Xie"
    ],
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T10:33:20.000Z",
    "updatedAt": "2025-10-10T10:33:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09245v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09245v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09242v1",
    "arxivId": "2510.09242v1",
    "title": "Investigating the Impact of Rational Dilated Wavelet Transform on Motor Imagery EEG Decoding with Deep Learning Models",
    "abstract": "The present study investigates the impact of the Rational Discrete Wavelet Transform (RDWT), used as a plug-in preprocessing step for motor imagery electroencephalographic (EEG) decoding prior to applying deep learning classifiers. A systematic paired evaluation (with/without RDWT) is conducted on four state-of-the-art deep learning architectures: EEGNet, ShallowConvNet, MBEEG\\_SENet, and EEGTCNet. This evaluation was carried out across three benchmark datasets: High Gamma, BCI-IV-2a, and BCI-IV-2b. The performance of the RDWT is reported with subject-wise averages using accuracy and Cohen's kappa, complemented by subject-level analyses to identify when RDWT is beneficial. On BCI-IV-2a, RDWT yields clear average gains for EEGTCNet (+4.44 percentage points, pp; kappa +0.059) and MBEEG\\_SENet (+2.23 pp; +0.030), with smaller improvements for EEGNet (+2.08 pp; +0.027) and ShallowConvNet (+0.58 pp; +0.008). On BCI-IV-2b, the enhancements observed are modest yet consistent for EEGNet (+0.21 pp; +0.044) and EEGTCNet (+0.28 pp; +0.077). On HGD, average effects are modest to positive, with the most significant gain observed for MBEEG\\_SENet (+1.65 pp; +0.022), followed by EEGNet (+0.76 pp; +0.010) and EEGTCNet (+0.54 pp; +0.008). Inspection of the subject material reveals significant enhancements in challenging recordings (e.g., non-stationary sessions), indicating that RDWT can mitigate localized noise and enhance rhythm-specific information. In conclusion, RDWT is shown to be a low-overhead, architecture-aware preprocessing technique that can yield tangible gains in accuracy and agreement for deep model families and challenging subjects.",
    "authors": [
      "Marco Siino",
      "Giuseppe Bonomo",
      "Rosario Sorbello",
      "Ilenia Tinnirello"
    ],
    "categories": [
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T10:31:14.000Z",
    "updatedAt": "2025-10-10T10:31:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09242v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09242v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09240v1",
    "arxivId": "2510.09240v1",
    "title": "Incentivizing Time-Aware Fairness in Data Sharing",
    "abstract": "In collaborative data sharing and machine learning, multiple parties aggregate their data resources to train a machine learning model with better model performance. However, as the parties incur data collection costs, they are only willing to do so when guaranteed incentives, such as fairness and individual rationality. Existing frameworks assume that all parties join the collaboration simultaneously, which does not hold in many real-world scenarios. Due to the long processing time for data cleaning, difficulty in overcoming legal barriers, or unawareness, the parties may join the collaboration at different times. In this work, we propose the following perspective: As a party who joins earlier incurs higher risk and encourages the contribution from other wait-and-see parties, that party should receive a reward of higher value for sharing data earlier. To this end, we propose a fair and time-aware data sharing framework, including novel time-aware incentives. We develop new methods for deciding reward values to satisfy these incentives. We further illustrate how to generate model rewards that realize the reward values and empirically demonstrate the properties of our methods on synthetic and real-world datasets.",
    "authors": [
      "Jiangwei Chen",
      "Kieu Thao Nguyen Pham",
      "Rachael Hwee Ling Sim",
      "Arun Verma",
      "Zhaoxuan Wu",
      "Chuan-Sheng Foo",
      "Bryan Kian Hsiang Low"
    ],
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "publishedAt": "2025-10-10T10:29:32.000Z",
    "updatedAt": "2025-10-10T10:29:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09240v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09240v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09236v1",
    "arxivId": "2510.09236v1",
    "title": "Effects of automotive microphone frequency response characteristics and noise conditions on speech and ASR quality -- an experimental evaluation",
    "abstract": "Upon choosing microphones for automotive hands-free communication or Automatic Speech Recognition (ASR) applications, OEMs typically specify wideband, super wideband or even fullband requirements following established standard recommendations (e.g., ITU-P.1110, ITU-P.1120). In practice, it is often challenging to achieve the preferred bandwidth for an automotive microphone when considering limitations and constraints on microphone placement inside the cabin, and the automotive grade environmental robustness requirements. On the other hand, there seems to be no consensus or sufficient data on the effect of each microphone characteristic on the actual performance. As an attempt to answer this question, we used noise signals recorded in real vehicles and under various driving conditions to experimentally study the relationship between the microphones' characteristics and the final audio quality of speech communication and performance of ASR engines. We focus on how variations in microphone bandwidth and amplitude frequency response shapes affect the perceptual speech quality. The speech quality results are compared by using ETSI TS 103 281 metrics (S-MOS, N-MOS, G-MOS) and ancillary metrics such as SNR. The ASR results are evaluated with standard metrics such as Word Error Rate (WER). Findings from this study provide knowledge in the understanding of what microphone frequency response characteristics are more relevant for audio quality and choice of proper microphone specifications, particularly for automotive applications.",
    "authors": [
      "Michele Buccoli",
      "Yu Du",
      "Jacob Soendergaard",
      "Simone Shawn Cazzaniga"
    ],
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "publishedAt": "2025-10-10T10:22:30.000Z",
    "updatedAt": "2025-10-10T10:22:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09236v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09236v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09229v1",
    "arxivId": "2510.09229v1",
    "title": "Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System",
    "abstract": "We present Glovity, a novel, low-cost wearable teleoperation system that integrates a spatial wrench (force-torque) feedback device with a haptic glove featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous manipulation. Glovity addresses key challenges in contact-rich tasks by providing intuitive wrench and tactile feedback, while overcoming embodiment gaps through precise retargeting. User studies demonstrate significant improvements: wrench feedback boosts success rates in book-flipping tasks from 48% to 78% and reduces completion time by 25%, while fingertip calibration enhances thin-object grasping success significantly compared to commercial glove. Furthermore, incorporating wrench signals into imitation learning (via DP-R3M) achieves high success rate in novel contact-rich scenarios, such as adaptive page flipping and force-aware handovers. All hardware designs, software will be open-sourced. Project website: https://glovity.github.io/",
    "authors": [
      "Yuyang Gao",
      "Haofei Ma",
      "Pai Zheng"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T10:16:03.000Z",
    "updatedAt": "2025-10-10T10:16:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09229v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09229v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09227v1",
    "arxivId": "2510.09227v1",
    "title": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems",
    "abstract": "Large language models (LLMs) show strong performance across natural language processing (NLP), mathematical reasoning, and programming, and recent large reasoning models (LRMs) further emphasize explicit reasoning. Yet their computational limits, particularly spatial complexity constrained by finite context windows, remain poorly understood. While recent works often focus on problems within the NP complexity class, we push the boundary by introducing a novel benchmark grounded in two PSPACE-complete regular expression (regex) problems: equivalence decision (RegexEQ) and minimization (RegexMin). PSPACE-complete problems serve as a more rigorous standard for assessing computational capacity, as their solutions require massive search space exploration. We perform a double-exponential space exploration to construct a labeled dataset of over a million regex instances with a sound filtering process to build the benchmark. We conduct extensive evaluations on 6 LLMs and 5 LRMs of varying scales, revealing common failure patterns such as verbosity and repetition. With its well-defined structure and quantitative evaluation metrics, this work presents the first empirical investigation into the spatial computational limitations of LLMs and LRMs, offering a new framework for evaluating their advanced reasoning capabilities. Our code is available at https://github.com/hyundong98/RegexPSPACE .",
    "authors": [
      "Hyundong Jin",
      "Joonghyuk Hahn",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.AI",
      "cs.FL"
    ],
    "publishedAt": "2025-10-10T10:13:47.000Z",
    "updatedAt": "2025-10-10T10:13:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09227v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09227v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09225v1",
    "arxivId": "2510.09225v1",
    "title": "Unsupervised lexicon learning from speech is limited by representations rather than clustering",
    "abstract": "Zero-resource word segmentation and clustering systems aim to tokenise speech into word-like units without access to text labels. Despite progress, the induced lexicons are still far from perfect. In an idealised setting with gold word boundaries, we ask whether performance is limited by the representation of word segments, or by the clustering methods that group them into word-like types. We combine a range of self-supervised speech features (continuous/discrete, frame/word-level) with different clustering methods (K-means, hierarchical, graph-based) on English and Mandarin data. The best system uses graph clustering with dynamic time warping on continuous features. Faster alternatives use graph clustering with cosine distance on averaged continuous features or edit distance on discrete unit sequences. Through controlled experiments that isolate either the representations or the clustering method, we demonstrate that representation variability across segments of the same word type -- rather than clustering -- is the primary factor limiting performance.",
    "authors": [
      "Danel Adendorff",
      "Simon Malan",
      "Herman Kamper"
    ],
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "publishedAt": "2025-10-10T10:12:11.000Z",
    "updatedAt": "2025-10-10T10:12:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09225v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09225v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09221v1",
    "arxivId": "2510.09221v1",
    "title": "HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation",
    "abstract": "Seamless loco-manipulation in unstructured environments requires robots to leverage autonomous exploration alongside whole-body control for physical interaction. In this work, we introduce HANDO (Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation), a two-layer framework designed for legged robots equipped with manipulators to perform human-centered mobile manipulation tasks. The first layer utilizes a goal-conditioned autonomous exploration policy to guide the robot to semantically specified targets, such as a black office chair in a dynamic environment. The second layer employs a unified whole-body loco-manipulation policy to coordinate the arm and legs for precise interaction tasks-for example, handing a drink to a person seated on the chair. We have conducted an initial deployment of the navigation module, and will continue to pursue finer-grained deployment of whole-body loco-manipulation.",
    "authors": [
      "Jingyuan Sun",
      "Chaoran Wang",
      "Mingyu Zhang",
      "Cui Miao",
      "Hongyu Ji",
      "Zihan Qu",
      "Han Sun",
      "Bing Wang",
      "Qingyi Si"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T10:04:30.000Z",
    "updatedAt": "2025-10-10T10:04:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09221v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09221v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09726v1",
    "arxivId": "2510.09726v1",
    "title": "Herb.jl: A Unifying Program Synthesis Library",
    "abstract": "Program synthesis -- the automatic generation of code given a specification -- is one of the most fundamental tasks in artificial intelligence (AI) and many programmers' dream. Numerous synthesizers have been developed to tackle program synthesis, manifesting different ideas to approach the exponentially growing program space. While numerous smart program synthesis tools exist, reusing and remixing previously developed methods is tedious and time-consuming. We propose Herb.jl, a unifying program synthesis library written in the Julia programming language, to address these issues. Since current methods rely on similar building blocks, we aim to modularize the underlying synthesis algorithm into communicating and fully extendable sub-compartments, allowing for straightforward reapplication of these modules. To demonstrate the benefits of using Herb.jl, we show three common use cases: 1. how to implement a simple problem and grammar, and how to solve it, 2. how to implement a previously developed synthesizer with just a few lines of code, and 3. how to run a synthesizer against a benchmark.",
    "authors": [
      "Tilman Hinnerichs",
      "Reuben Gardos Reid",
      "Jaap de Jong",
      "Bart Swinkels",
      "Pamela Wochner",
      "Nicolae Filat",
      "Tudor Magurescu",
      "Issa Hanou",
      "Sebastijan Dumancic"
    ],
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T09:45:36.000Z",
    "updatedAt": "2025-10-10T09:45:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09726v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09726v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09209v1",
    "arxivId": "2510.09209v1",
    "title": "PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation",
    "abstract": "Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and have motors inside to protect them from damage and dirt. In addition to the ability to perform daily activities, these features are essential for everyday use of the hand. In-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting cards before slot insertion and operating tools such as screwdrivers. However, currently used electric prosthetic hands only achieve static grasp postures, and existing manipulation approaches require either many motors, which makes the prosthesis heavy for daily use in the hand, or complex mechanisms that demand a large internal space and force external motor placement, complicating attachment and exposing the components to damage. Alternatively, we combine a single-axis thumb and optimized thumb positioning to achieve basic posture and in-hand manipulation, that is, the reorientation between precision and lateral grasps, using only four motors in a lightweight (311 g) prosthetic hand. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success rates of 90-100% for reorientation tasks. The hand performed seal stamping and USB device insertion, as well as rotation to operate a screwdriver.",
    "authors": [
      "Yuki Kuroda",
      "Tomoya Takahashi",
      "Cristian C Beltran-Hernandez",
      "Masashi Hamaya",
      "Kazutoshi Tanaka"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T09:44:53.000Z",
    "updatedAt": "2025-10-10T09:44:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09209v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09209v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09204v1",
    "arxivId": "2510.09204v1",
    "title": "Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization",
    "abstract": "Centralized trajectory optimization in the joint space of multiple robots allows access to a larger feasible space that can result in smoother trajectories, especially while planning in tight spaces. Unfortunately, it is often computationally intractable beyond a very small swarm size. In this paper, we propose Flow-Opt, a learning-based approach towards improving the computational tractability of centralized multi-robot trajectory optimization. Specifically, we reduce the problem to first learning a generative model to sample different candidate trajectories and then using a learned Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We propose a flow-matching model with a diffusion transformer (DiT) augmented with permutation invariant robot position and map encoders as the generative model. We develop a custom solver for our SF and equip it with a neural network that predicts context-specific initialization. The initialization network is trained in a self-supervised manner, taking advantage of the differentiability of the SF solver. We advance the state-of-the-art in the following respects. First, we show that we can generate trajectories of tens of robots in cluttered environments in a few tens of milliseconds. This is several times faster than existing centralized optimization approaches. Moreover, our approach also generates smoother trajectories orders of magnitude faster than competing baselines based on diffusion models. Second, each component of our approach can be batched, allowing us to solve a few tens of problem instances in a fraction of a second. We believe this is a first such result; no existing approach provides such capabilities. Finally, our approach can generate a diverse set of trajectories between a given set of start and goal locations, which can capture different collision-avoidance behaviors.",
    "authors": [
      "Simon Idoko",
      "Arun Kumar Singh"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T09:43:18.000Z",
    "updatedAt": "2025-10-10T09:43:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09204v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09204v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09200v1",
    "arxivId": "2510.09200v1",
    "title": "Towards Safer and Understandable Driver Intention Prediction",
    "abstract": "Autonomous driving (AD) systems are becoming increasingly capable of handling complex tasks, mainly due to recent advances in deep learning and AI. As interactions between autonomous systems and humans increase, the interpretability of decision-making processes in driving systems becomes increasingly crucial for ensuring safe driving operations. Successful human-machine interaction requires understanding the underlying representations of the environment and the driving task, which remains a significant challenge in deep learning-based systems. To address this, we introduce the task of interpretability in maneuver prediction before they occur for driver safety, i.e., driver intent prediction (DIP), which plays a critical role in AD systems. To foster research in interpretable DIP, we curate the eXplainable Driving Action Anticipation Dataset (DAAD-X), a new multimodal, ego-centric video dataset to provide hierarchical, high-level textual explanations as causal reasoning for the driver's decisions. These explanations are derived from both the driver's eye-gaze and the ego-vehicle's perspective. Next, we propose Video Concept Bottleneck Model (VCBM), a framework that generates spatio-temporally coherent explanations inherently, without relying on post-hoc techniques. Finally, through extensive evaluations of the proposed VCBM on the DAAD-X dataset, we demonstrate that transformer-based models exhibit greater interpretability than conventional CNN-based models. Additionally, we introduce a multilabel t-SNE visualization technique to illustrate the disentanglement and causal correlation among multiple explanations. Our data, code and models are available at: https://mukil07.github.io/VCBM.github.io/",
    "authors": [
      "Mukilan Karuppasamy",
      "Shankar Gangisetty",
      "Shyam Nandan Rai",
      "Carlo Masone",
      "C V Jawahar"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T09:41:25.000Z",
    "updatedAt": "2025-10-10T09:41:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09200v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09200v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09197v1",
    "arxivId": "2510.09197v1",
    "title": "On The Roots of Independence Polynomial: Quantifying The Gap",
    "abstract": "The independence polynomial of a graph $G$ is the generating polynomial corresponding to its independent sets of different sizes. More formally, if $a_k(G)$ denotes the number of independent sets of $G$ of size $k$ then \\[I(G,z) \\as \\sum_{k}^{} (-1)^k a_k(G) z^k.\\] The study of evaluating $I(G,z)$ has several deep connections to problems in combinatorics, complexity theory and statistical physics. Consequently, the roots of the independence polynomial have been studied in detail. In particular, many works have provided regions in the complex plane that are devoid of any roots of the polynomial. One of the first such results showed a lower bound on the absolute value of the smallest root $\\beta(G)$ of the polynomial. Furthermore, when $G$ is connected, Goldwurm and Santini established that $\\beta(G)$ is a simple real root of $I(G,z)$ smaller than one. An alternative proof was given by Csikv\\'ari. Both proofs do not provide a gap from $\\beta(G)$ to the smallest absolute value amongst all the other roots of $I(G,z)$. In this paper, we quantify this gap.",
    "authors": [
      "Om Prakash",
      "Vikram Sharma"
    ],
    "categories": [
      "math.CO",
      "cs.DM",
      "G.2.1"
    ],
    "publishedAt": "2025-10-10T09:39:40.000Z",
    "updatedAt": "2025-10-10T09:39:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09197v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09197v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09188v1",
    "arxivId": "2510.09188v1",
    "title": "Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication",
    "abstract": "Multi-robot navigation in unknown, structurally constrained, and GPS-denied environments presents a fundamental trade-off between global strategic foresight and local tactical agility, particularly under limited communication. Centralized methods achieve global optimality but suffer from high communication overhead, while distributed methods are efficient but lack the broader awareness to avoid deadlocks and topological traps. To address this, we propose a fully decentralized, hierarchical relative navigation framework that achieves both strategic foresight and tactical agility without a unified coordinate system. At the strategic layer, robots build and exchange lightweight topological maps upon opportunistic encounters. This process fosters an emergent global awareness, enabling the planning of efficient, trap-avoiding routes at an abstract level. This high-level plan then inspires the tactical layer, which operates on local metric information. Here, a sampling-based escape point strategy resolves dense spatio-temporal conflicts by generating dynamically feasible trajectories in real time, concurrently satisfying tight environmental and kinodynamic constraints. Extensive simulations and real-world experiments demonstrate that our system significantly outperforms in success rate and efficiency, especially in communication-limited environments with complex topological structures.",
    "authors": [
      "Zihao Mao",
      "Yunheng Wang",
      "Yunting Ji",
      "Yi Yang",
      "Wenjie Song"
    ],
    "categories": [
      "cs.RO",
      "cs.MA"
    ],
    "publishedAt": "2025-10-10T09:33:20.000Z",
    "updatedAt": "2025-10-10T09:33:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09188v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09188v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09183v1",
    "arxivId": "2510.09183v1",
    "title": "Student Development Agent: Risk-free Simulation for Evaluating AIED Innovations",
    "abstract": "In the age of AI-powered educational (AIED) innovation, evaluating the developmental consequences of novel designs before they are exposed to students has become both essential and challenging. Since such interventions may carry irreversible effects, it is critical to anticipate not only potential benefits but also possible harms. This study proposes a student development agent framework based on large language models (LLMs), designed to simulate how students with diverse characteristics may evolve under different educational settings without administering them to real students. By validating the approach through a case study on a multi-agent learning environment (MAIC), we demonstrate that the agent's predictions align with real student outcomes in non-cognitive developments. The results suggest that LLM-based simulations hold promise for evaluating AIED innovations efficiently and ethically. Future directions include enhancing profile structures, incorporating fine-tuned or small task-specific models, validating effects of empirical findings, interpreting simulated data and optimizing evaluation methods.",
    "authors": [
      "Jianxiao Jiang",
      "Yu Zhang"
    ],
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T09:26:20.000Z",
    "updatedAt": "2025-10-10T09:26:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09183v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09183v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09725v1",
    "arxivId": "2510.09725v1",
    "title": "Science ouverte et collaborative pour l'élaboration d'un banc automatisé de caractérisation de pertes en commutation par opposition",
    "abstract": "The switching losses of power transistors are generally measured using the so-called double pulse method. Measuring the opposition of two switching cells is a complementary method that is more accurate but indirect. However, implementing this method can be more complex and requires calibration steps and comprehensive control, with the added issue of thermal management. In this context, we proposed to address this topic through open and collaborative science, first in the form of a two-day hackathon, followed by monthly open sessions. More than 20 participants contributed to the two-day hackathon, followed by monthly sessions for those wishing to continue working together. This enabled us to set up an automated bench, in open science, including the generation of switching commands, the configuration and control of measuring instruments, and the hardware part. Here we present and share our work and this open approach.",
    "authors": [
      "Nicolas Rouger",
      "Luiz Villa",
      "Matthieu Masson",
      "Pauline Kergus",
      "Joseph Kemdeg",
      "Lorenzo Leijnen",
      "Jean Alinei",
      "Adrien Colomb",
      "Ayoub Farah-Hassan",
      "Arnauld Biganzoli"
    ],
    "categories": [
      "physics.ed-ph",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-10T09:26:07.000Z",
    "updatedAt": "2025-10-10T09:26:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09725v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09725v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09180v1",
    "arxivId": "2510.09180v1",
    "title": "RepDL: Bit-level Reproducible Deep Learning Training and Inference",
    "abstract": "Non-determinism and non-reproducibility present significant challenges in deep learning, leading to inconsistent results across runs and platforms. These issues stem from two origins: random number generation and floating-point computation. While randomness can be controlled through deterministic configurations, floating-point inconsistencies remain largely unresolved. To address this, we introduce RepDL, an open-source library that ensures deterministic and bitwise-reproducible deep learning training and inference across diverse computing environments. RepDL achieves this by enforcing correct rounding and order invariance in floating-point computation. The source code is available at https://github.com/microsoft/RepDL .",
    "authors": [
      "Peichen Xie",
      "Xian Zhang",
      "Shuo Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T09:24:07.000Z",
    "updatedAt": "2025-10-10T09:24:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09180v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09180v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09172v1",
    "arxivId": "2510.09172v1",
    "title": "Generating CodeMeta using declarative mapping rules: An open-ended approach using ShExML",
    "abstract": "Nowadays, software is one of the cornerstones when conducting research in several scientific fields which employ computer-based methodologies to answer new research questions. However, for these experiments to be completely reproducible, research software should comply with the FAIR principles, yet its metadata can be represented following different data models and spread across different locations. In order to bring some cohesion to the field, CodeMeta was proposed as a vocabulary to represent research software metadata in a unified and standardised manner. While existing tools can help users to generate CodeMeta files for some specific use cases, they fall short on flexibility and adaptability. Hence, in this work, I propose the use of declarative mapping rules to generate CodeMeta files, illustrated through the implementation of three crosswalks in ShExML which are then expanded and merged to cover the generation of CodeMeta files for two existing research software artefacts. Moreover, the outputs are validated using SHACL and ShEx and the whole generation workflow is automated requiring minimal user intervention upon a new version release. This work can, therefore, be used as an example upon which other developers can include a CodeMeta generation workflow in their repositories, facilitating the adoption of CodeMeta and, ultimately, increasing research software FAIRness.",
    "authors": [
      "Herminio García-González"
    ],
    "categories": [
      "cs.DL",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T09:15:08.000Z",
    "updatedAt": "2025-10-10T09:15:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09172v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09172v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09169v1",
    "arxivId": "2510.09169v1",
    "title": "Robust Adaptive Boundary Control of a Thermal Process with Thermoelectric Actuators: Theory and Experimental Validation",
    "abstract": "A sliding-mode-based adaptive boundary control law is proposed for a class of uncertain thermal reaction-diffusion processes subject to matched disturbances. The disturbances are assumed to be bounded, but the corresponding bounds are unknown, thus motivating the use of adaptive control strategies. A boundary control law comprising a proportional and discontinuous term is proposed, wherein the magnitude of the discontinuous relay term is adjusted via a gradient-based adaptation algorithm. Depending on how the adaptation algorithm is parameterized, the adaptive gain can be either a nondecreasing function of time (monodirectional adaptation) or it can both increase and decrease (bidirectional adaptation). The convergence and stability properties of these two solutions are investigated by Lyapunov analyses, and two distinct stability results are derived, namely, asymptotic stability for the monodirectional adaptation and globally uniformly ultimately bounded solutions for the bidirectional adaptation. The proposed algorithms are then specified to address the control problem of stabilizing a desired temperature profile in a metal beam equipped with thermoelectric boundary actuators. Experiments are conducted to investigate the real-world performance of the proposed sliding-mode-based adaptive control, with a particular focus on comparing the monodirectional and bidirectional adaptation laws.",
    "authors": [
      "Paul Mayr",
      "Alessandro Pisano",
      "Stefan Koch",
      "Markus Reichhartinger"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T09:11:59.000Z",
    "updatedAt": "2025-10-10T09:11:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09169v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09169v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09163v1",
    "arxivId": "2510.09163v1",
    "title": "Co-designing a Programmable RISC-V Accelerator for MPC-based Energy and Thermal Management of Many-Core HPC Processors",
    "abstract": "Managing energy and thermal profiles is critical for many-core HPC processors with hundreds of application-class processing elements (PEs). Advanced model predictive control (MPC) delivers state-of-the-art performance but requires solving an online optimization problem over a thousand times per second (1 kHz control bandwidth), with computational and memory demands scaling with PE count. Traditional MPC approaches execute the controller on the PEs, but operating system overheads create jitter and limit control bandwidth. Running MPC on dedicated on-chip controllers enables fast, deterministic control but raises concerns about area and power overhead. In this work, we tackle these challenges by proposing a hardware-software codesign of a lightweight MPC controller, based on an operator-splitting quadratic programming solver and an embedded multi-core RISC-V controller. Key innovations include pruning weak thermal couplings to reduce model memory and ahead-of-time scheduling for efficient parallel execution of sparse triangular systems arising from the optimization problem. The proposed controller achieves sub-millisecond latency when controlling 144 PEs at 500 MHz, delivering 33x lower latency and 7.9x higher energy efficiency than a single-core baseline. Operating within a compact less than 1 MiB memory footprint, it consumes as little as 325 mW while occupying less than 1.5% of a typical HPC processor's die area.",
    "authors": [
      "Alessandro Ottaviano",
      "Andrino Meli",
      "Paul Scheffler",
      "Giovanni Bambini",
      "Robert Balas",
      "Davide Rossi",
      "Andrea Bartolini",
      "Luca Benini"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-10T09:06:38.000Z",
    "updatedAt": "2025-10-10T09:06:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09163v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09163v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09155v1",
    "arxivId": "2510.09155v1",
    "title": "Federated Data Analytics for Cancer Immunotherapy: A Privacy-Preserving Collaborative Platform for Patient Management",
    "abstract": "Connected health is a multidisciplinary approach focused on health management, prioritizing pa-tient needs in the creation of tools, services, and treatments. This paradigm ensures proactive and efficient care by facilitating the timely exchange of accurate patient information among all stake-holders in the care continuum. The rise of digital technologies and process innovations promises to enhance connected health by integrating various healthcare data sources. This integration aims to personalize care, predict health outcomes, and streamline patient management, though challeng-es remain, particularly in data architecture, application interoperability, and security. Data analytics can provide critical insights for informed decision-making and health co-creation, but solutions must prioritize end-users, including patients and healthcare professionals. This perspective was explored through an agile System Development Lifecycle in an EU-funded project aimed at developing an integrated AI-generated solution for managing cancer patients undergoing immunotherapy. This paper contributes with a collaborative digital framework integrating stakeholders across the care continuum, leveraging federated big data analytics and artificial intelligence for improved decision-making while ensuring privacy. Analytical capabilities, such as treatment recommendations and adverse event predictions, were validated using real-life data, achieving 70%-90% accuracy in a pilot study with the medical partners, demonstrating the framework's effectiveness.",
    "authors": [
      "Mira Raheem",
      "Michael Papazoglou",
      "Bernd Krämer",
      "Neamat El-Tazi",
      "Amal Elgammal"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T08:57:41.000Z",
    "updatedAt": "2025-10-10T08:57:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09155v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09155v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09143v1",
    "arxivId": "2510.09143v1",
    "title": "Multiparty equality in the local broadcast model",
    "abstract": "In this paper we consider the multiparty equality problem in graphs, where every vertex of a graph $G$ is given an input, and the goal of the vertices is to decide whether all inputs are equal. We study this problem in the local broadcast model, where a message sent by a vertex is received by all its neighbors and the total cost of a protocol is the sum of the lengths of the messages sent by the vertices. This setting was studied by Khan and Vaidya, who gave in 2021 a protocol achieving a 4-approximation in the general case. We study this multiparty communication problem through the lens of network topology. We design a new protocol for 2-connected graphs, whose efficiency relies on the notion of total vertex cover in graph theory. This protocol outperforms the aforementioned 4-approximation in a number of cases. To demonstrate its applicability, we apply it to obtain optimal or asymptotically optimal protocols for several natural network topologies such as cycles, hypercubes, and grids. On the way we also provide new bounds of independent interest on the size of total vertex covers in regular graphs.",
    "authors": [
      "Louis Esperet",
      "Jean-Florent Raymond"
    ],
    "categories": [
      "math.CO",
      "cs.CC",
      "cs.DC"
    ],
    "publishedAt": "2025-10-10T08:44:02.000Z",
    "updatedAt": "2025-10-10T08:44:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09143v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09143v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09138v1",
    "arxivId": "2510.09138v1",
    "title": "Antenna's Performance in Microwave Imaging of Stratified Media",
    "abstract": "Numerous types of antennas have been employed for microwave imaging of stratified media for ground penetrating radar (GPR), through-the-wall-radar imaging (TWRI), etc. This letter aims to investigate the impact of the different antennas with their characteristics on the image reconstruction of those media. Hence, three types of antennas, including horn antennas, open waveguide and Vivaldi antennas, are chosen as almost directional antennas, operating at X-band 8-12 GHz. The antenna's far-field and near-field characteristics are analyzed. A diffraction tomography (DT)-based algorithm is used to reconstruct the target location within the stratified media using monostatic and multistatic data. It is observed that the more directional antennas provide a better-reconstructed image with less shadowing image of the stratified media.",
    "authors": [
      "Adel Omrani",
      "Sajjad Sadeghi"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T08:37:34.000Z",
    "updatedAt": "2025-10-10T08:37:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09138v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09138v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09134v1",
    "arxivId": "2510.09134v1",
    "title": "A Semantic Framework for Patient Digital Twins in Chronic Care",
    "abstract": "Personalized chronic care requires the integration of multimodal health data to enable precise, adaptive, and preventive decision-making. Yet most current digital twin (DT) applications remain organ-specific or tied to isolated data types, lacking a unified and privacy-preserving foundation. This paper introduces the Patient Medical Digital Twin (PMDT), an ontology-driven in silico patient framework that integrates physiological, psychosocial, behavioral, and genomic information into a coherent, extensible model. Implemented in OWL 2.0, the PMDT ensures semantic interoperability, supports automated reasoning, and enables reuse across diverse clinical contexts. Its ontology is structured around modular Blueprints (patient, disease and diagnosis, treatment and follow-up, trajectories, safety, pathways, and adverse events), formalized through dedicated conceptual views. These were iteratively refined and validated through expert workshops, questionnaires, and a pilot study in the EU H2020 QUALITOP project with real-world immunotherapy patients. Evaluation confirmed ontology coverage, reasoning correctness, usability, and GDPR compliance. Results demonstrate the PMDT's ability to unify heterogeneous data, operationalize competency questions, and support descriptive, predictive, and prescriptive analytics in a federated, privacy-preserving manner. By bridging gaps in data fragmentation and semantic standardization, the PMDT provides a validated foundation for next-generation digital health ecosystems, transforming chronic care toward proactive, continuously optimized, and equitable management.",
    "authors": [
      "Amal Elgammal",
      "Bernd J. Krämer",
      "Michael P. Papazoglou",
      "Mira Raheem"
    ],
    "categories": [
      "cs.SE",
      "cs.ET"
    ],
    "publishedAt": "2025-10-10T08:34:55.000Z",
    "updatedAt": "2025-10-10T08:34:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09134v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09134v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09128v1",
    "arxivId": "2510.09128v1",
    "title": "A CSP approach to Graph Sandwich Problems",
    "abstract": "The \\emph{Sandwich Problem} (SP) for a graph class $\\calC$ is the following computational problem. The input is a pair of graphs $(V,E_1)$ and $(V,E_2)$ where $E_1\\subseteq E_2$, and the task is to decide whether there is an edge set $E$ where $E_1\\subseteq E \\subseteq E_2$ such that the graph $(V,E)$ belongs to $\\calC$. In this paper we show that many SPs correspond to the constraint satisfaction problem (CSP) of an infinite $2$-edge-coloured graph $H$. We then notice that several known complexity results for SPs also follow from general complexity classifications of infinite-domain CSPs, suggesting a fruitful application of the theory of CSPs to complexity classifications of SPs. We strengthen this evidence by using basic tools from constraint satisfaction theory to propose new complexity results of the SP for several graph classes including line graphs of multigraphs, line graphs of bipartite multigraphs, $K_k$-free perfect graphs, and classes described by forbidding finitely many induced subgraphs, such as $\\{I_4,P_4\\}$-free graphs, settling an open problem of Alvarado, Dantas, and Rautenbach (2019). We also construct a graph sandwich problem which is in coNP, but neither in P nor coNP-complete (unless P = coNP).",
    "authors": [
      "Manuel Bodirsky",
      "Santiago Guzmán-Pro"
    ],
    "categories": [
      "cs.DM",
      "cs.CC",
      "math.CO",
      "05C75, 05C60, 05C63",
      "F.2.2"
    ],
    "publishedAt": "2025-10-10T08:29:10.000Z",
    "updatedAt": "2025-10-10T08:29:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09128v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09128v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09124v1",
    "arxivId": "2510.09124v1",
    "title": "Random-Shift Revisited: Tight Approximations for Tree Embeddings and L1-Oblivious Routings",
    "abstract": "We present a new and surprisingly simple analysis of random-shift decompositions -- originally proposed by Miller, Peng, and Xu [SPAA'13]: We show that decompositions for exponentially growing scales $D = 2^0, 2^1, \\ldots, 2^{\\log_2(\\operatorname{diam}(G))}$, have a tight constant trade-off between distance-to-center and separation probability on average across the distance scales -- opposed to a necessary $\\Omega(\\log n)$ trade-off for a single scale. This almost immediately yields a way to compute a tree $T$ for graph $G$ that preserves all graph distances with expected $O(\\log n)$-stretch. This gives an alternative proof that obtains tight approximation bounds of the seminal result by Fakcharoenphol, Rao, and Talwar [STOC'03] matching the $\\Omega(\\log n)$ lower bound by Bartal [FOCS'96]. Our insights can also be used to refine the analysis of a simple $\\ell_1$-oblivious routing proposed in [FOCS'22], yielding a tight $O(\\log n)$ competitive ratio. Our algorithms for constructing tree embeddings and $\\ell_1$-oblivious routings can be implemented in the sequential, parallel, and distributed settings with optimal work, depth, and rounds, up to polylogarithmic factors. Previously, fast algorithms with tight guarantees were not known for tree embeddings in parallel and distributed settings, and for $\\ell_1$-oblivious routings, not even a fast sequential algorithm was known.",
    "authors": [
      "Rasmus Kyng",
      "Maximilian Probst Gutenberg",
      "Tim Rieder"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T08:25:06.000Z",
    "updatedAt": "2025-10-10T08:25:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09124v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09124v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09108v1",
    "arxivId": "2510.09108v1",
    "title": "Constraint-Guided Unit Test Generation for Machine Learning Libraries",
    "abstract": "Machine learning (ML) libraries such as PyTorch and TensorFlow are essential for a wide range of modern applications. Ensuring the correctness of ML libraries through testing is crucial. However, ML APIs often impose strict input constraints involving complex data structures such as tensors. Automated test generation tools such as Pynguin are not aware of these constraints and often create non-compliant inputs. This leads to early test failures and limited code coverage. Prior work has investigated extracting constraints from official API documentation. In this paper, we present PynguinML, an approach that improves the Pynguin test generator to leverage these constraints to generate compliant inputs for ML APIs, enabling more thorough testing and higher code coverage. Our evaluation is based on 165 modules from PyTorch and TensorFlow, comparing PynguinML against Pynguin. The results show that PynguinML significantly improves test effectiveness, achieving up to 63.9 % higher code coverage.",
    "authors": [
      "Lukas Krodinger",
      "Altin Hajdari",
      "Stephan Lukasczyk",
      "Gordon Fraser"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T08:02:15.000Z",
    "updatedAt": "2025-10-10T08:02:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09108v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09108v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09724v1",
    "arxivId": "2510.09724v1",
    "title": "InteractScience: Programmatic and Visually-Grounded Evaluation of Interactive Scientific Demonstration Code Generation",
    "abstract": "Large Language Models (LLMs) are increasingly capable of generating complete applications from natural language instructions, creating new opportunities in science and education. In these domains, interactive scientific demonstrations are particularly valuable for explaining concepts, supporting new teaching methods, and presenting research findings. Generating such demonstrations requires models to combine accurate scientific knowledge with the ability to implement interactive front-end code that behaves correctly and responds to user actions. This capability goes beyond the scope of existing benchmarks, which typically evaluate either knowledge question answering without grounding in code or static web code generation without scientific interactivity. To evaluate this integrated ability, we design a hybrid framework that combines programmatic functional testing to rigorously verify interaction logic with visually-grounded qualitative testing to assess rendered outputs against reference snapshots. Building on this framework, we present InteractScience, a benchmark consisting of a substantial set of carefully designed questions across five scientific domains, each paired with unit tests, reference snapshots, and checklists. We evaluate 30 leading open- and closed-source LLMs and report results that highlight ongoing weaknesses in integrating domain knowledge with interactive front-end coding. Our work positions InteractScience as the first benchmark to automatically measure this combined capability with realistic interactive operations, providing a foundation for advancing reliable and educationally useful scientific demonstration code generation. All code and data are publicly available at https://github.com/open-compass/InteractScience.",
    "authors": [
      "Qiaosheng Chen",
      "Yang Liu",
      "Lei Li",
      "Kai Chen",
      "Qipeng Guo",
      "Gong Cheng",
      "Fei Yuan"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T07:55:46.000Z",
    "updatedAt": "2025-10-10T07:55:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09724v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09724v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09096v1",
    "arxivId": "2510.09096v1",
    "title": "When a Robot is More Capable than a Human: Learning from Constrained Demonstrators",
    "abstract": "Learning from demonstrations enables experts to teach robots complex tasks using interfaces such as kinesthetic teaching, joystick control, and sim-to-real transfer. However, these interfaces often constrain the expert's ability to demonstrate optimal behavior due to indirect control, setup restrictions, and hardware safety. For example, a joystick can move a robotic arm only in a 2D plane, even though the robot operates in a higher-dimensional space. As a result, the demonstrations collected by constrained experts lead to suboptimal performance of the learned policies. This raises a key question: Can a robot learn a better policy than the one demonstrated by a constrained expert? We address this by allowing the agent to go beyond direct imitation of expert actions and explore shorter and more efficient trajectories. We use the demonstrations to infer a state-only reward signal that measures task progress, and self-label reward for unknown states using temporal interpolation. Our approach outperforms common imitation learning in both sample efficiency and task completion time. On a real WidowX robotic arm, it completes the task in 12 seconds, 10x faster than behavioral cloning, as shown in real-robot videos on https://sites.google.com/view/constrainedexpert .",
    "authors": [
      "Xinhu Li",
      "Ayush Jain",
      "Zhaojing Yang",
      "Yigit Korkmaz",
      "Erdem Bıyık"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T07:48:12.000Z",
    "updatedAt": "2025-10-10T07:48:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09096v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09096v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09089v1",
    "arxivId": "2510.09089v1",
    "title": "Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation",
    "abstract": "Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to be deployed in unknown environments. However, robust trajectory repeat navigation still remains challenged due to environmental changing and dynamic objects. In this paper, we propose a novel visual teach-and-repeat navigation system, which consists of a flexible map representation, robust map matching and a map-less local navigation module. During the teaching process, the recorded keyframes are formulated as a topo-metric graph and each node can be further extended to save new observations. Such representation also alleviates the requirement of globally consistent mapping. To enhance the place recognition performance during repeating process, instead of using frame-to-frame matching, we firstly implement keyframe clustering to aggregate similar connected keyframes into local map and perform place recognition based on visual frame-tolocal map matching strategy. To promote the local goal persistent tracking performance, a long-term goal management algorithm is constructed, which can avoid the robot getting lost due to environmental changes or obstacle occlusion. To achieve the goal without map, a local trajectory-control candidate optimization algorithm is proposed. Extensively experiments are conducted on our mobile platform. The results demonstrate that our system is superior to the baselines in terms of robustness and effectiveness.",
    "authors": [
      "Jikai Wang",
      "Yunqi Cheng",
      "Kezhi Wang",
      "Zonghai Chen"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T07:35:37.000Z",
    "updatedAt": "2025-10-10T07:35:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09089v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09089v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09085v1",
    "arxivId": "2510.09085v1",
    "title": "FLToP CTC: Frame-Level Token Pruning via Relative Threshold for Efficient and Memory-Saving Decoding on Diverse Platforms",
    "abstract": "CTC-based ASR systems face computational and memory bottlenecks in resource-limited environments. Traditional CTC decoders, requiring up to 90% of processing time in systems (e.g., wav2vec2-large on L4 GPUs), face inefficiencies due to exhaustive token-level operations. This paper introduces Frame Level Token Pruning for Connectionist Temporal Classification (FLToP CTC), a novel decoding algorithm that employs frame-level token pruning guided by a relative threshold probability. By dynamically eliminating low-probability tokens per frame, FLToP CTC reduces compute and memory demands while maintaining negligible WER degradation. On LibriSpeech, FLToP CTC achieves a 10.5x runtime speedup and 2.78x memory reduction versus standard CTC decoders. Its simplicity enables seamless integration into CTC decoders across platforms (CPUs, GPUs, etc.). FLToP CTC addresses CTC bottlenecks, offering scalability for resource-limited environments and realtime applications, enhancing speech recognition accessibility and efficiency.",
    "authors": [
      "Atul Shree",
      "Harshith Jupuru"
    ],
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T07:32:54.000Z",
    "updatedAt": "2025-10-10T07:32:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09085v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09085v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09084v1",
    "arxivId": "2510.09084v1",
    "title": "Approximately Bisubmodular Regret Minimization in Billboard and Social Media Advertising",
    "abstract": "In a typical \\emph{billboard advertisement} technique, a number of digital billboards are owned by an \\emph{influence provider}, and several commercial houses approach the influence provider for a specific number of views of their advertisement content on a payment basis. If the influence provider provides the demanded or more influence, then he will receive the full payment else a partial payment. In the context of an influence provider, if he provides more or less than the advertisers demanded influence, it is a loss for him. This is formalized as 'Regret', and naturally, in the context of the influence provider, the goal will be to allocate the billboard slots among the advertisers such that the total regret is minimized. In this paper, we study this problem as a discrete optimization problem and propose two solution approaches. The first one selects the billboard slots from the available ones in an incremental greedy manner, and we call this method the Budget Effective Greedy approach. In the second one, we introduce randomness in the first one, where we do it for a sample of slots instead of calculating the marginal gains of all the billboard slots. We analyze both algorithms to understand their time and space complexity. We implement them with real-life datasets and conduct a number of experiments. We observe that the randomized budget effective greedy approach takes reasonable computational time while minimizing the regret.",
    "authors": [
      "Dildar Ali",
      "Suman Benerjee",
      "Yamuna Prasad"
    ],
    "categories": [
      "cs.GT",
      "cs.DB",
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T07:32:52.000Z",
    "updatedAt": "2025-10-10T07:32:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09084v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09084v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09082v2",
    "arxivId": "2510.09082v2",
    "title": "Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics",
    "abstract": "Learning complex network dynamics is fundamental to understanding, modelling and controlling real-world complex systems. There are two main problems in the task of predicting the dynamic evolution of complex networks: on the one hand, existing methods usually use simple graphs to describe the relationships in complex networks; however, this approach can only capture pairwise relationships, while there may be rich non-pairwise structured relationships in the network. First-order GNNs have difficulty in capturing dynamic non-pairwise relationships. On the other hand, theoretical prediction models lack accuracy and data-driven prediction models lack interpretability. To address the above problems, this paper proposes a higher-order network dynamics identification method for long-term dynamic prediction of complex networks. Firstly, to address the problem that traditional graph machine learning can only deal with pairwise relations, dynamic hypergraph learning is introduced to capture the higher-order non-pairwise relations among complex networks and improve the accuracy of complex network modelling. Then, a dual-driven dynamic prediction module for physical data is proposed. The Koopman operator theory is introduced to transform the nonlinear dynamical differential equations for the dynamic evolution of complex networks into linear systems for solving. Meanwhile, the physical information neural differential equation method is utilised to ensure that the dynamic evolution conforms to the physical laws. The dual-drive dynamic prediction module ensures both accuracy and interpretability of the prediction. Validated on public datasets and self-built industrial chain network datasets, the experimental results show that the method in this paper has good prediction accuracy and long-term prediction performance.",
    "authors": [
      "Bicheng Wang",
      "Junping Wang",
      "Yibo Xue"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.SI",
      "physics.soc-ph"
    ],
    "publishedAt": "2025-10-10T07:31:17.000Z",
    "updatedAt": "2025-10-13T00:51:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09082v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.09082v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09081v1",
    "arxivId": "2510.09081v1",
    "title": "Real-Time Rendering of Dynamic Line Sets using Voxel Ray Tracing",
    "abstract": "Real-time rendering of dynamic line sets is relevant in many visualization tasks, including unsteady flow visualization and interactive white matter reconstruction from Magnetic Resonance Imaging. High-quality global illumination and transparency are important for conveying the spatial structure of dense line sets, yet remain difficult to achieve at interactive rates. We propose an efficient voxel-based ray-tracing framework for rendering large dynamic line sets with ambient occlusion and ground-truth transparency. The framework introduces a voxelization algorithm that supports efficient construction of acceleration structures for both voxel cone tracing and ray tracing. To further reduce per-frame preprocessing cost, we developed a voxel-based culling method that restricts acceleration structure construction to camera-visible voxels. Together, these contributions enable high-quality, real-time rendering of large-scale dynamic line sets with physically accurate transparency. The results show that our method outperforms the state of the art in quality and performance when rendering (semi-)opaque dynamic line sets.",
    "authors": [
      "Bram Kraaijeveld",
      "Andrei C. Jalba",
      "Anna Vilanova",
      "Maxime Chamberland"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-10T07:28:05.000Z",
    "updatedAt": "2025-10-10T07:28:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09081v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09081v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09080v1",
    "arxivId": "2510.09080v1",
    "title": "Training Models to Detect Successive Robot Errors from Human Reactions",
    "abstract": "As robots become more integrated into society, detecting robot errors is essential for effective human-robot interaction (HRI). When a robot fails repeatedly, how can it know when to change its behavior? Humans naturally respond to robot errors through verbal and nonverbal cues that intensify over successive failures-from confusion and subtle speech changes to visible frustration and impatience. While prior work shows that human reactions can indicate robot failures, few studies examine how these evolving responses reveal successive failures. This research uses machine learning to recognize stages of robot failure from human reactions. In a study with 26 participants interacting with a robot that made repeated conversational errors, behavioral features were extracted from video data to train models for individual users. The best model achieved 93.5% accuracy for detecting errors and 84.1% for classifying successive failures. Modeling the progression of human reactions enhances error detection and understanding of repeated interaction breakdowns in HRI.",
    "authors": [
      "Shannon Liu",
      "Maria Teresa Parreira",
      "Wendy Ju"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T07:25:44.000Z",
    "updatedAt": "2025-10-10T07:25:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09080v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09080v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09078v1",
    "arxivId": "2510.09078v1",
    "title": "MCMC: Bridging Rendering, Optimization and Generative AI",
    "abstract": "Generative artificial intelligence (AI) has made unprecedented advances in vision language models over the past two years. During the generative process, new samples (images) are generated from an unknown high-dimensional distribution. Markov Chain Monte Carlo (MCMC) methods are particularly effective in drawing samples from such complex, high-dimensional distributions. This makes MCMC methods an integral component for models like EBMs, ensuring accurate sample generation. Gradient-based optimization is at the core of modern generative models. The update step during the optimization forms a Markov chain where the new update depends only on the current state. This allows exploration of the parameter space in a memoryless manner, thus combining the benefits of gradient-based optimization and MCMC sampling. MCMC methods have shown an equally important role in physically based rendering where complex light paths are otherwise quite challenging to sample from simple importance sampling techniques. A lot of research is dedicated towards bringing physical realism to samples (images) generated from diffusion-based generative models in a data-driven manner, however, a unified framework connecting these techniques is still missing. In this course, we take the first steps toward understanding each of these components and exploring how MCMC could potentially serve as a bridge, linking these closely related areas of research. Our course aims to provide necessary theoretical and practical tools to guide students, researchers and practitioners towards the common goal of generative physically based rendering. All Jupyter notebooks with demonstrations associated to this tutorial can be found on the project webpage: https://sinbag.github.io/mcmc/",
    "authors": [
      "Gurprit Singh",
      "Wenzel Jakob"
    ],
    "categories": [
      "cs.GR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T07:22:16.000Z",
    "updatedAt": "2025-10-10T07:22:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09078v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09078v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09073v1",
    "arxivId": "2510.09073v1",
    "title": "Literate Tracing",
    "abstract": "As computer systems grow ever larger and more complex, a crucial task in software development is for one person (the system expert) to communicate to another (the system novice) how a certain program works. This paper reports on the author's experiences with a paradigm for program documentation that we call literate tracing. A literate trace explains a software system using annotated, concrete execution traces of the system. Literate traces complement both in-code comments (which often lack global context) and out-of-band design docs (which often lack a concrete connection to the code). We also describe TReX, our tool for making literate traces that are interactive, visual, and guaranteed by construction to be faithful to the program semantics. We have used TReX to write literate traces explaining components of large systems software including the Linux kernel, Git source control system, and GCC compiler.",
    "authors": [
      "Matthew Sotoudeh"
    ],
    "categories": [
      "cs.SE",
      "cs.PL"
    ],
    "publishedAt": "2025-10-10T07:17:51.000Z",
    "updatedAt": "2025-10-10T07:17:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09073v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09073v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09072v1",
    "arxivId": "2510.09072v1",
    "title": "Emotion-Disentangled Embedding Alignment for Noise-Robust and Cross-Corpus Speech Emotion Recognition",
    "abstract": "Effectiveness of speech emotion recognition in real-world scenarios is often hindered by noisy environments and variability across datasets. This paper introduces a two-step approach to enhance the robustness and generalization of speech emotion recognition models through improved representation learning. First, our model employs EDRL (Emotion-Disentangled Representation Learning) to extract class-specific discriminative features while preserving shared similarities across emotion categories. Next, MEA (Multiblock Embedding Alignment) refines these representations by projecting them into a joint discriminative latent subspace that maximizes covariance with the original speech input. The learned EDRL-MEA embeddings are subsequently used to train an emotion classifier using clean samples from publicly available datasets, and are evaluated on unseen noisy and cross-corpus speech samples. Improved performance under these challenging conditions demonstrates the effectiveness of the proposed method.",
    "authors": [
      "Upasana Tiwari",
      "Rupayan Chakraborty",
      "Sunil Kumar Kopparapu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T07:17:07.000Z",
    "updatedAt": "2025-10-10T07:17:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09072v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09072v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09071v1",
    "arxivId": "2510.09071v1",
    "title": "Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array",
    "abstract": "Flexible microelectrode (FME) implantation into brain cortex is challenging due to the deformable fiber-like structure of FME probe and the interaction with critical bio-tissue. To ensure reliability and safety, the implantation process should be monitored carefully. This paper develops an image-based anomaly detection framework based on the microscopic cameras of the robotic FME implantation system. The unified framework is utilized at four checkpoints to check the micro-needle, FME probe, hooking result, and implantation point, respectively. Exploiting the existing object localization results, the aligned regions of interest (ROIs) are extracted from raw image and input to a pretrained vision transformer (ViT). Considering the task specifications, we propose a progressive granularity patch feature sampling method to address the sensitivity-tolerance trade-off issue at different locations. Moreover, we select a part of feature channels with higher signal-to-noise ratios from the raw general ViT features, to provide better descriptors for each specific scene. The effectiveness of the proposed methods is validated with the image datasets collected from our implantation system.",
    "authors": [
      "Yitong Chen",
      "Xinyao Xu",
      "Ping Zhu",
      "Xinyong Han",
      "Fangbo Qin",
      "Shan Yu"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T07:16:53.000Z",
    "updatedAt": "2025-10-10T07:16:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09071v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09071v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09065v1",
    "arxivId": "2510.09065v1",
    "title": "MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation",
    "abstract": "We introduce MMAudioSep, a generative model for video/text-queried sound separation that is founded on a pretrained video-to-audio model. By leveraging knowledge about the relationship between video/text and audio learned through a pretrained audio generative model, we can train the model more efficiently, i.e., the model does not need to be trained from scratch. We evaluate the performance of MMAudioSep by comparing it to existing separation models, including models based on both deterministic and generative approaches, and find it is superior to the baseline models. Furthermore, we demonstrate that even after acquiring functionality for sound separation via fine-tuning, the model retains the ability for original video-to-audio generation. This highlights the potential of foundational sound generation models to be adopted for sound-related downstream tasks. Our code is available at https://github.com/sony/mmaudiosep.",
    "authors": [
      "Akira Takahashi",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "categories": [
      "cs.SD",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T07:13:06.000Z",
    "updatedAt": "2025-10-10T07:13:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09065v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09065v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09061v1",
    "arxivId": "2510.09061v1",
    "title": "O_O-VC: Synthetic Data-Driven One-to-One Alignment for Any-to-Any Voice Conversion",
    "abstract": "Traditional voice conversion (VC) methods typically attempt to separate speaker identity and linguistic information into distinct representations, which are then combined to reconstruct the audio. However, effectively disentangling these factors remains challenging, often leading to information loss during training. In this paper, we propose a new approach that leverages synthetic speech data generated by a high-quality, pretrained multispeaker text-to-speech (TTS) model. Specifically, synthetic data pairs that share the same linguistic content but differ in speaker identity are used as input-output pairs to train the voice conversion model. This enables the model to learn a direct mapping between source and target voices, effectively capturing speaker-specific characteristics while preserving linguistic content. Additionally, we introduce a flexible training strategy for any-to-any voice conversion that generalizes well to unseen speakers and new languages, enhancing adaptability and performance in zero-shot scenarios. Our experiments show that our proposed method achieves a 16.35% relative reduction in word error rate and a 5.91% improvement in speaker cosine similarity, outperforming several state-of-the-art methods. Voice conversion samples can be accessed at: https://oovc-emnlp-2025.github.io/",
    "authors": [
      "Huu Tuong Tu",
      "Huan Vu",
      "cuong tien nguyen",
      "Dien Hy Ngo",
      "Nguyen Thi Thu Trang"
    ],
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T07:08:09.000Z",
    "updatedAt": "2025-10-10T07:08:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09061v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09061v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09058v1",
    "arxivId": "2510.09058v1",
    "title": "Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding",
    "abstract": "Large Language Models have quickly become a central component of modern software development workflows, and software practitioners are increasingly integrating LLMs into various stages of the software development lifecycle. Despite the growing presence of LLMs, there is still a limited understanding of how these tools are actually used in practice and how professionals perceive their benefits and limitations. This paper presents preliminary findings from a global survey of 131 software practitioners. Our results reveal how LLMs are utilized for various coding-specific tasks. Software professionals report benefits such as increased productivity, reduced cognitive load, and faster learning, but also raise concerns about LLMs' inaccurate outputs, limited context awareness, and associated ethical risks. Most developers treat LLMs as assistive tools rather than standalone solutions, reflecting a cautious yet practical approach to their integration. Our findings provide an early, practitioner-focused perspective on LLM adoption, highlighting key considerations for future research and responsible use in software engineering.",
    "authors": [
      "Italo Santos",
      "Cleyton Magalhaes",
      "Ronnie de Souza Santos"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T06:59:56.000Z",
    "updatedAt": "2025-10-10T06:59:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09058v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09058v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09721v1",
    "arxivId": "2510.09721v1",
    "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System",
    "abstract": "The integration of LLMs into software engineering has catalyzed a paradigm shift from traditional rule-based systems to sophisticated agentic systems capable of autonomous problem-solving. Despite this transformation, the field lacks a comprehensive understanding of how benchmarks and solutions interconnect, hindering systematic progress and evaluation. This survey presents the first holistic analysis of LLM-empowered software engineering, bridging the critical gap between evaluation and solution approaches. We analyze 150+ recent papers and organize them into a comprehensive taxonomy spanning two major dimensions: (1) Solutions, categorized into prompt-based, fine-tuning-based, and agent-based paradigms, and (2) Benchmarks, covering code generation, translation, repair, and other tasks. Our analysis reveals how the field has evolved from simple prompt engineering to complex agentic systems incorporating planning and decomposition, reasoning and self-refinement, memory mechanisms, and tool augmentation. We present a unified pipeline that illustrates the complete workflow from task specification to final deliverables, demonstrating how different solution paradigms address varying complexity levels across software engineering tasks. Unlike existing surveys that focus on isolated aspects, we provide full-spectrum coverage connecting 50+ benchmarks with their corresponding solution strategies, enabling researchers to identify optimal approaches for specific evaluation criteria. Furthermore, we identify critical research gaps and propose actionable future directions, including multi-agent collaboration frameworks, self-evolving code generation systems, and integration of formal verification with LLM-based methods. This survey serves as a foundational resource for researchers and practitioners seeking to understand, evaluate, and advance LLM-empowered software engineering systems.",
    "authors": [
      "Jiale Guo",
      "Suizhi Huang",
      "Mei Li",
      "Dong Huang",
      "Xingsheng Chen",
      "Regina Zhang",
      "Zhijiang Guo",
      "Han Yu",
      "Siu-Ming Yiu",
      "Christian Jensen",
      "Pietro Lio",
      "Kwok-Yan Lam"
    ],
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "publishedAt": "2025-10-10T06:56:50.000Z",
    "updatedAt": "2025-10-10T06:56:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09721v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09721v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09055v1",
    "arxivId": "2510.09055v1",
    "title": "Sensing, Detection and Localization for Low Altitude UAV: A RF-Based Framework via Multiple BSs Collaboration",
    "abstract": "The rapid growth of the low-altitude economy has resulted in a significant increase in the number of Low, slow, and small (LLS) unmanned aerial vehicles (UAVs), raising critical challenges for secure airspace management and reliable trajectory planning. To address this, this paper proposes a cooperative radio-frequency (RF) detection and localization framework that leverages existing cellular base stations. The proposed approach features a robust scheme for LSS target identification, integrating a cell averaging-constant false alarm rate (CA-CFAR) detector with a micro-Doppler signature (MDS) based recognition method. Multi-station measurements are fused through a grid-based probabilistic algorithm combined with clustering techniques, effectively mitigating ghost targets and improving localization accuracy in multi-UAV scenarios. Furthermore, the Cramer-Rao lower bound (CRLB) is derived as a performance benchmark and reinforcement learning (RL)-based optimization is employed to balance localization accuracy against station resource usage. Simulations demonstrate that increasing from one to multiple BSs reduces the positioning error to near the CRLB, while practical experiments further verify the framework's effectiveness. Furthermore, our RL-based optimization can find solutions that maintain high accuracy while minimizing resource usage, highlighting its potential as a scalable solution for ensuring airspace safety in the emerging low-altitude economy.",
    "authors": [
      "Tianhao Liang",
      "Mu Jia",
      "Tingting Zhang",
      "Junting Chen",
      "Longyu Zhou",
      "Tony Q. S. Quek",
      "Pooi-Yuen Kam"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T06:48:49.000Z",
    "updatedAt": "2025-10-10T06:48:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09055v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09055v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09050v1",
    "arxivId": "2510.09050v1",
    "title": "Multi-product Influence Maximization in Billboard Advertisement",
    "abstract": "Billboard Advertisement has emerged as an effective out-of-home advertisement technique where the goal is to select a limited number of slots and play advertisement content over there with the hope that this will be observed by many people, and effectively, a significant number of them will be influenced towards the brand. Given a trajectory and a billboard database and a positive integer $k$, how can we select $k$ highly influential slots to maximize influence? In this paper, we study a variant of this problem where a commercial house wants to make a promotion of multiple products, and there is an influence demand for each product. We have studied two variants of the problem. In the first variant, our goal is to select $k$ slots such that the respective influence demand of each product is satisfied. In the other variant of the problem, we are given with $\\ell$ integers $k_1,k_2, \\ldots, k_{\\ell}$, the goal here is to search for $\\ell$ many set of slots $S_1, S_2, \\ldots, S_{\\ell}$ such that for all $i \\in [\\ell]$, $|S_{i}| \\leq k_i$ and for all $i \\neq j$, $S_i \\cap S_j=\\emptyset$ and the influence demand of each of the products gets satisfied. We model the first variant of the problem as a multi-submodular cover problem and the second variant as its generalization. For solving the first variant, we adopt the bi-criteria approximation algorithm, and for the other variant, we propose a sampling-based approximation algorithm. Extensive experiments with real-world trajectory and billboard datasets highlight the effectiveness and efficiency of the proposed solution approach.",
    "authors": [
      "Dildar Ali",
      "Rajibul Islam",
      "Suman Banerjee"
    ],
    "categories": [
      "cs.DS",
      "cs.DB"
    ],
    "publishedAt": "2025-10-10T06:39:50.000Z",
    "updatedAt": "2025-10-10T06:39:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09050v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09050v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09049v1",
    "arxivId": "2510.09049v1",
    "title": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction",
    "abstract": "Predicting the complexity of source code is essential for software development and algorithm analysis. Recently, Baik et al. (2025) introduced CodeComplex for code time complexity prediction. The paper shows that LLMs without fine-tuning struggle with certain complexity classes. This suggests that no single LLM excels at every class, but rather each model shows advantages in certain classes. We propose MEC$^3$O, a multi-expert consensus system, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs to complexity classes based on their performance and provides them with class-specialized instructions, turning them into experts. These experts engage in structured debates, and their predictions are integrated through a weighted consensus mechanism. Our expertise assignments to LLMs effectively handle Degeneration-of-Thought, reducing reliance on a separate judge model, and preventing convergence to incorrect majority opinions. Experiments on CodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving at least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini in macro-F1 scores on average and demonstrates competitive on-par F1 scores to GPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of multi-expert debates and weight consensus strategy to generate the final predictions. Our code and data is available at https://github.com/suhanmen/MECO.",
    "authors": [
      "Joonghyuk Hahn",
      "Soohan Lim",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.AI",
      "cs.SE",
      "68T50",
      "I.2.7"
    ],
    "publishedAt": "2025-10-10T06:34:49.000Z",
    "updatedAt": "2025-10-10T06:34:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09049v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09049v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09045v1",
    "arxivId": "2510.09045v1",
    "title": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements",
    "abstract": "In the domain of software development, LLMs have been utilized to automate tasks such as code translation, where source code from one programming language is translated to another while preserving its functionality. However, LLMs often struggle with long source codes that don't fit into the context window, which produces inaccurate translations. To address this, we propose a novel zero-shot code translation method that incorporates identifier replacement. By substituting user-given long identifiers with generalized placeholders during translation, our method allows the LLM to focus on the logical structure of the code, by reducing token count and memory usage, which improves the efficiency and cost-effectiveness of long code translation. Our empirical results demonstrate that our approach preserves syntactical and hierarchical information and produces translation results with reduced tokens.",
    "authors": [
      "Manojit Chakraborty",
      "Madhusudan Ghosh",
      "Rishabh Gupta"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-10T06:28:15.000Z",
    "updatedAt": "2025-10-10T06:28:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09045v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09045v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09042v1",
    "arxivId": "2510.09042v1",
    "title": "MAKO: Meta-Adaptive Koopman Operators for Learning-based Model Predictive Control of Parametrically Uncertain Nonlinear Systems",
    "abstract": "In this work, we propose a meta-learning-based Koopman modeling and predictive control approach for nonlinear systems with parametric uncertainties. An adaptive deep meta-learning-based modeling approach, called Meta Adaptive Koopman Operator (MAKO), is proposed. Without knowledge of the parametric uncertainty, the proposed MAKO approach can learn a meta-model from a multi-modal dataset and efficiently adapt to new systems with previously unseen parameter settings by using online data. Based on the learned meta Koopman model, a predictive control scheme is developed, and the stability of the closed-loop system is ensured even in the presence of previously unseen parameter settings. Through extensive simulations, our proposed approach demonstrates superior performance in both modeling accuracy and control efficacy as compared to competitive baselines.",
    "authors": [
      "Minghao Han",
      "Kiwan Wong",
      "Adrian Wing-Keung Law",
      "Xunyuan Yin"
    ],
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T06:23:36.000Z",
    "updatedAt": "2025-10-10T06:23:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09042v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09042v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09037v1",
    "arxivId": "2510.09037v1",
    "title": "Repairing Regex Vulnerabilities via Localization-Guided Instructions",
    "abstract": "Regular expressions (regexes) are foundational to modern computing for critical tasks like input validation and data parsing, yet their ubiquity exposes systems to regular expression denial of service (ReDoS), a vulnerability requiring automated repair methods. Current approaches, however, are hampered by a trade-off. Symbolic, rule-based system are precise but fails to repair unseen or complex vulnerability patterns. Conversely, large language models (LLMs) possess the necessary generalizability but are unreliable for tasks demanding strict syntactic and semantic correctness. We resolve this impasse by introducing a hybrid framework, localized regex repair (LRR), designed to harness LLM generalization while enforcing reliability. Our core insight is to decouple problem identification from the repair process. First, a deterministic, symbolic module localizes the precise vulnerable subpattern, creating a constrained and tractable problem space. Then, the LLM invoked to generate a semantically equivalent fix for this isolated segment. This combined architecture successfully resolves complex repair cases intractable for rule-based repair while avoiding the semantic errors of LLM-only approaches. Our work provides a validated methodology for solving such problems in automated repair, improving the repair rate by 15.4%p over the state-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.",
    "authors": [
      "Sicheol Sung",
      "Joonghyuk Hahn",
      "Yo-Sub Han"
    ],
    "categories": [
      "cs.AI",
      "cs.PL",
      "68T50",
      "I.2.7"
    ],
    "publishedAt": "2025-10-10T06:15:43.000Z",
    "updatedAt": "2025-10-10T06:15:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09037v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09037v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09036v1",
    "arxivId": "2510.09036v1",
    "title": "iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation",
    "abstract": "Learned world models hold significant potential for robotic manipulation, as they can serve as simulator for real-world interactions. While extensive progress has been made in 2D video-based world models, these approaches often lack geometric and spatial reasoning, which is essential for capturing the physical structure of the 3D world. To address this limitation, we introduce iMoWM, a novel interactive world model designed to generate color images, depth maps, and robot arm masks in an autoregressive manner conditioned on actions. To overcome the high computational cost associated with three-dimensional information, we propose MMTokenizer, which unifies multi-modal inputs into a compact token representation. This design enables iMoWM to leverage large-scale pretrained VideoGPT models while maintaining high efficiency and incorporating richer physical information. With its multi-modal representation, iMoWM not only improves the visual quality of future predictions but also serves as an effective simulator for model-based reinforcement learning (MBRL) and facilitates real-world imitation learning. Extensive experiments demonstrate the superiority of iMoWM across these tasks, showcasing the advantages of multi-modal world modeling for robotic manipulation. Homepage: https://xingyoujun.github.io/imowm/",
    "authors": [
      "Chuanrui Zhang",
      "Zhengxian Wu",
      "Guanxing Lu",
      "Yansong Tang",
      "Ziwei Wang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T06:15:42.000Z",
    "updatedAt": "2025-10-10T06:15:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09036v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09036v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09035v1",
    "arxivId": "2510.09035v1",
    "title": "Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels",
    "abstract": "Accurate perception is critical for vehicle safety, with LiDAR as a key enabler in autonomous driving. To ensure robust performance across environments, sensor types, and weather conditions without costly re-annotation, domain generalization in LiDAR-based 3D semantic segmentation is essential. However, LiDAR annotations are often noisy due to sensor imperfections, occlusions, and human errors. Such noise degrades segmentation accuracy and is further amplified under domain shifts, threatening system reliability. While noisy-label learning is well-studied in images, its extension to 3D LiDAR segmentation under domain generalization remains largely unexplored, as the sparse and irregular structure of point clouds limits direct use of 2D methods. To address this gap, we introduce the novel task Domain Generalization for LiDAR Semantic Segmentation under Noisy Labels (DGLSS-NL) and establish the first benchmark by adapting three representative noisy-label learning strategies from image classification to 3D segmentation. However, we find that existing noisy-label learning approaches adapt poorly to LiDAR data. We therefore propose DuNe, a dual-view framework with strong and weak branches that enforce feature-level consistency and apply cross-entropy loss based on confidence-aware filtering of predictions. Our approach shows state-of-the-art performance by achieving 56.86% mIoU on SemanticKITTI, 42.28% on nuScenes, and 52.58% on SemanticPOSS under 10% symmetric label noise, with an overall Arithmetic Mean (AM) of 49.57% and Harmonic Mean (HM) of 48.50%, thereby demonstrating robust domain generalization in DGLSS-NL tasks. The code is available on our project page.",
    "authors": [
      "Weitong Kong",
      "Zichao Zeng",
      "Di Wen",
      "Jiale Wei",
      "Kunyu Peng",
      "June Moh Goo",
      "Jan Boehm",
      "Rainer Stiefelhagen"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T06:11:34.000Z",
    "updatedAt": "2025-10-10T06:11:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09035v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09035v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09031v1",
    "arxivId": "2510.09031v1",
    "title": "Web Crawler Restrictions, AI Training Datasets \\& Political Biases",
    "abstract": "Large language models rely on web-scraped text for training; concurrently, content creators are increasingly blocking AI crawlers to retain control over their data. We analyze crawler restrictions across the top one million most-visited websites since 2023 and examine their potential downstream effects on training data composition. Our analysis reveals growing restrictions, with blocking patterns varying by website popularity and content type. A quarter of the top thousand websites restrict AI crawlers, decreasing to one-tenth across the broader top million. Content type matters significantly: 34.2% of news outlets disallow OpenAI's GPTBot, rising to 55% for outlets with high factual reporting. Additionally, outlets with neutral political positions impose the strongest restrictions (58%), whereas hyperpartisan websites and those with low factual reporting impose fewer restrictions -only 4.1% of right-leaning outlets block access to OpenAI. Our findings suggest that heterogeneous blocking patterns may skew training datasets toward low-quality or polarized content, potentially affecting the capabilities of models served by prominent AI-as-a-Service providers.",
    "authors": [
      "Paul Bouchaud",
      "Pedro Ramaciotti"
    ],
    "categories": [
      "cs.SI"
    ],
    "publishedAt": "2025-10-10T06:06:05.000Z",
    "updatedAt": "2025-10-10T06:06:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09031v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09031v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09027v1",
    "arxivId": "2510.09027v1",
    "title": "A Faster Randomized Algorithm for Vertex Cover: An Automated Approach",
    "abstract": "This work introduces two techniques for the design and analysis of branching algorithms, illustrated through the case study of the Vertex Cover problem. First, we present a method for automatically generating branching rules through a systematic case analysis of local structures. Second, we develop a new technique for analyzing randomized branching algorithms using the Measure & Conquer method, offering greater flexibility in formulating branching rules. By combining these innovations with additional techniques, we obtain the fastest known randomized algorithms in different parameters for the Vertex Cover problem on graphs with bounded degree (up to 6) and on general graphs. For example, our algorithm solves Vertex Cover on subcubic graphs in $O^*(1.07625^n)$ time and $O^*(1.13132^k)$ time, respectively. For graphs with maximum degree 4, we achieve running times of $O^*(1.13735^n)$ and $O^*(1.21103^k)$, while for general graphs we achieve $O^*(1.25281^k)$.",
    "authors": [
      "Katie Clinch",
      "Serge Gaspers",
      "Tao Zixu He",
      "Simon Mackenzie",
      "Tiankuang Zhang"
    ],
    "categories": [
      "cs.DS",
      "cs.CC"
    ],
    "publishedAt": "2025-10-10T05:57:48.000Z",
    "updatedAt": "2025-10-10T05:57:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09027v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09027v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09025v1",
    "arxivId": "2510.09025v1",
    "title": "Déréverbération non-supervisée de la parole par modèle hybride",
    "abstract": "This paper introduces a new training strategy to improve speech dereverberation systems in an unsupervised manner using only reverberant speech. Most existing algorithms rely on paired dry/reverberant data, which is difficult to obtain. Our approach uses limited acoustic information, like the reverberation time (RT60), to train a dereverberation system. Experimental results demonstrate that our method achieves more consistent performance across various objective metrics than the state-of-the-art.",
    "authors": [
      "Louis Bahrman",
      "Mathieu Fontaine",
      "Gaël Richard"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T05:51:17.000Z",
    "updatedAt": "2025-10-10T05:51:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09025v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09025v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09016v1",
    "arxivId": "2510.09016v1",
    "title": "DiTSinger: Scaling Singing Voice Synthesis with Diffusion Transformer and Implicit Alignment",
    "abstract": "Recent progress in diffusion-based Singing Voice Synthesis (SVS) demonstrates strong expressiveness but remains limited by data scarcity and model scalability. We introduce a two-stage pipeline: a compact seed set of human-sung recordings is constructed by pairing fixed melodies with diverse LLM-generated lyrics, and melody-specific models are trained to synthesize over 500 hours of high-quality Chinese singing data. Building on this corpus, we propose DiTSinger, a Diffusion Transformer with RoPE and qk-norm, systematically scaled in depth, width, and resolution for enhanced fidelity. Furthermore, we design an implicit alignment mechanism that obviates phoneme-level duration labels by constraining phoneme-to-acoustic attention within character-level spans, thereby improving robustness under noisy or uncertain alignments. Extensive experiments validate that our approach enables scalable, alignment-free, and high-fidelity SVS.",
    "authors": [
      "Zongcai Du",
      "Guilin Deng",
      "Xiaofeng Guo",
      "Xin Gao",
      "Linke Li",
      "Kaichang Cheng",
      "Fubo Han",
      "Siyu Yang",
      "Peng Liu",
      "Pan Zhong",
      "Qiang Fu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T05:39:45.000Z",
    "updatedAt": "2025-10-10T05:39:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09016v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09016v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09013v1",
    "arxivId": "2510.09013v1",
    "title": "Trust Modeling and Estimation in Human-Autonomy Interactions",
    "abstract": "Advances in the control of autonomous systems have accompanied an expansion in the potential applications for autonomous robotic systems. The success of applications involving humans depends on the quality of interaction between the autonomous system and the human supervisor, which is particularly affected by the degree of trust that the supervisor places in the autonomous system. Absent from the literature are models of supervisor trust dynamics that can accommodate asymmetric responses to autonomous system performance and the intermittent nature of supervisor-autonomous system communication. This paper focuses on formulating an estimated model of supervisor trust that incorporates both of these features by employing a switched linear system structure with event-triggered sampling of the model input and output. Trust response data collected in a user study with 51 participants were then used identify parameters for a switched linear model-based observer of supervisor trust.",
    "authors": [
      "Daniel A. Williams",
      "Airlie Chapman",
      "Daniel R. Little",
      "Chris Manzie"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-10T05:27:12.000Z",
    "updatedAt": "2025-10-10T05:27:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09013v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09013v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09009v1",
    "arxivId": "2510.09009v1",
    "title": "Promptimizer: User-Led Prompt Optimization for Personal Content Classification",
    "abstract": "While LLMs now enable users to create content classifiers easily through natural language, automatic prompt optimization techniques are often necessary to create performant classifiers. However, such techniques can fail to consider how social media users want to evolve their filters over the course of usage, including desiring to steer them in different ways during initialization and iteration. We introduce a user-centered prompt optimization technique, Promptimizer, that maintains high performance and ease-of-use but additionally (1) allows for user input into the optimization process and (2) produces final prompts that are interpretable. A lab experiment (n=16) found that users significantly preferred Promptimizer's human-in-the-loop optimization over a fully automatic approach. We further implement Promptimizer into Puffin, a tool to support YouTube content creators in creating and maintaining personal classifiers to manage their comments. Over a 3-week deployment with 10 creators, participants successfully created diverse filters to better understand their audiences and protect their communities.",
    "authors": [
      "Leijie Wang",
      "Kathryn Yurechko",
      "Amy X. Zhang"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T05:13:03.000Z",
    "updatedAt": "2025-10-10T05:13:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09009v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09009v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09002v1",
    "arxivId": "2510.09002v1",
    "title": "Planar Length-Constrained Minimum Spanning Trees",
    "abstract": "In length-constrained minimum spanning tree (MST) we are given an $n$-node graph $G = (V,E)$ with edge weights $w : E \\to \\mathbb{Z}_{\\geq 0}$ and edge lengths $l: E \\to \\mathbb{Z}_{\\geq 0}$ along with a root node $r \\in V$ and a length-constraint $h \\in \\mathbb{Z}_{\\geq 0}$. Our goal is to output a spanning tree of minimum weight according to $w$ in which every node is at distance at most $h$ from $r$ according to $l$. We give a polynomial-time algorithm for planar graphs which, for any constant $\\epsilon > 0$, outputs an $O\\left(\\log^{1+\\epsilon} n\\right)$-approximate solution with every node at distance at most $(1+\\epsilon)h$ from $r$ for any constant $\\epsilon > 0$. Our algorithm is based on new length-constrained versions of classic planar separators which may be of independent interest. Additionally, our algorithm works for length-constrained Steiner tree. Complementing this, we show that any algorithm on general graphs for length-constrained MST in which nodes are at most $2h$ from $r$ cannot achieve an approximation of $O\\left(\\log ^{2-\\epsilon} n\\right)$ for any constant $\\epsilon > 0$ under standard complexity assumptions; as such, our results separate the approximability of length-constrained MST in planar and general graphs.",
    "authors": [
      "D Ellis Hershkowitz",
      "Richard Z Huang"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T04:58:07.000Z",
    "updatedAt": "2025-10-10T04:58:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09002v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09002v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08996v1",
    "arxivId": "2510.08996v1",
    "title": "Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation",
    "abstract": "Current benchmarks for evaluating software engineering agents, such as SWE-Bench Verified, are predominantly derived from GitHub issues and fail to accurately reflect how developers interact with chat-based coding assistants in integrated development environments (IDEs). We posit that this mismatch leads to a systematic overestimation of agent's capabilities in real-world scenarios, especially bug fixing. We introduce a novel benchmarking framework that transforms existing formal benchmarks into realistic user queries through systematic analysis of developer interaction patterns with chat-based agents. Our methodology is flexible and can be easily extended to existing benchmarks. In this paper, we apply our testing framework to SWE-Bench Verified, the TypeScript subset of Multi-SWE-Bench and a private benchmark, SWE-Bench C# and transform formal GitHub issue descriptions into realistic user-style queries based on telemetry analysis of a popular chat-based agent interactions. Our findings reveal that existing benchmarks significantly overestimate agent capabilities for some models by >50% over baseline performance for public benchmarks and ~10-16% for our internal benchmark. This work establishes a new paradigm for evaluating interactive chat-based software engineering agents through benchmark mutation techniques.",
    "authors": [
      "Spandan Garg",
      "Ben Steenhoek",
      "Yufan Huang"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T04:42:02.000Z",
    "updatedAt": "2025-10-10T04:42:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08996v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08996v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08991v1",
    "arxivId": "2510.08991v1",
    "title": "Creation, Critique, and Consumption: Exploring Generative AI Descriptions for Supporting Blind and Low Vision Professionals with Visual Tasks",
    "abstract": "Many blind and low vision (BLV) people are excluded from professional roles that may involve visual tasks due to access barriers and persisting stigmas. Advancing generative AI systems can support BLV people through providing contextual and personalized visual descriptions for creation, critique, and consumption. In this workshop paper, we provide design suggestions for how visual descriptions can be better contextualized for multiple professional tasks. We conclude by discussing how these designs can improve autonomy, inclusion, and skill development over time.",
    "authors": [
      "Lucy Jiang",
      "Lotus Zhang",
      "Leah Findlater"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T04:20:22.000Z",
    "updatedAt": "2025-10-10T04:20:22.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08991v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08991v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08990v1",
    "arxivId": "2510.08990v1",
    "title": "Towards a Taxonomy of Sustainability Requirements for Software Design",
    "abstract": "Software systems are a significant contributor to global sustainability concerns, demanding that environmental, social, technical, and economic factors be systematically addressed from the initial requirements engineering phase. Although existing research provides various sustainability requirements (SRs), these contributions are often fragmented, specific to certain dimensions, or limited to particular application domains, resulting in a critical lack of a unified, comprehensive taxonomy for the software engineering community. To address this gap, this research conducts a Systematic Literature Review (SLR) to extract and organize sustainability requirements from the state-of-the-art. The primary contribution is a comprehensive taxonomy of SRs across the four dimensions of sustainability (environmental, technical, social, and economic). For each identified category, we provide clear definitions, associated metrics, and measures. Furthermore, we depict a correlation matrix that projects the positive and negative influences (synergies and conflicts) among categories across different dimensions. This systematized reference assists both software developers and researchers in effectively formulating, managing, and reconciling trade-offs within sustainable software development.",
    "authors": [
      "Mandira Roy",
      "Novarun Deb",
      "Nabendu Chaki",
      "Agostino Cortesi"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-10T04:20:11.000Z",
    "updatedAt": "2025-10-10T04:20:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08990v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08990v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08988v1",
    "arxivId": "2510.08988v1",
    "title": "MASA: LLM-Driven Multi-Agent Systems for Autoformalization",
    "abstract": "Autoformalization serves a crucial role in connecting natural language and formal reasoning. This paper presents MASA, a novel framework for building multi-agent systems for autoformalization driven by Large Language Models (LLMs). MASA leverages collaborative agents to convert natural language statements into their formal representations. The architecture of MASA is designed with a strong emphasis on modularity, flexibility, and extensibility, allowing seamless integration of new agents and tools to adapt to a fast-evolving field. We showcase the effectiveness of MASA through use cases on real-world mathematical definitions and experiments on formal mathematics datasets. This work highlights the potential of multi-agent systems powered by the interaction of LLMs and theorem provers in enhancing the efficiency and reliability of autoformalization, providing valuable insights and support for researchers and practitioners in the field.",
    "authors": [
      "Lan Zhang",
      "Marco Valentino",
      "André Freitas"
    ],
    "categories": [
      "cs.CL",
      "cs.FL"
    ],
    "publishedAt": "2025-10-10T04:15:34.000Z",
    "updatedAt": "2025-10-10T04:15:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08988v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08988v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08981v1",
    "arxivId": "2510.08981v1",
    "title": "SEER: Sustainability Enhanced Engineering of Software Requirements",
    "abstract": "The rapid expansion of software development has significant environmental, technical, social, and economic impacts. Achieving the United Nations Sustainable Development Goals by 2030 compels developers to adopt sustainable practices. Existing methods mostly offer high-level guidelines, which are time-consuming to implement and rely on team adaptability. Moreover, they focus on design or implementation, while sustainability assessment should start at the requirements engineering phase. In this paper, we introduce SEER, a framework which addresses sustainability concerns in the early software development phase. The framework operates in three stages: (i) it identifies sustainability requirements (SRs) relevant to a specific software product from a general taxonomy; (ii) it evaluates how sustainable system requirements are based on the identified SRs; and (iii) it optimizes system requirements that fail to satisfy any SR. The framework is implemented using the reasoning capabilities of large language models and the agentic RAG (Retrieval Augmented Generation) approach. SEER has been experimented on four software projects from different domains. Results generated using Gemini 2.5 reasoning model demonstrate the effectiveness of the proposed approach in accurately identifying a broad range of sustainability concerns across diverse domains.",
    "authors": [
      "Mandira Roy",
      "Novarun Deb",
      "Nabendu Chaki",
      "Agostino Cortesi"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T03:48:30.000Z",
    "updatedAt": "2025-10-10T03:48:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08981v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08981v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08980v1",
    "arxivId": "2510.08980v1",
    "title": "Traffic-Aware Eco-Driving Control in CAVs via Learning-based Terminal Cost Model",
    "abstract": "Connected and Automated Vehicles (CAVs) offer significant potential for improving energy efficiency and lowering vehicle emissions through eco-driving technologies. Control algorithms in CAVs leverage look-ahead route information and Vehicle-to-Everything (V2X) communication to optimize vehicle performance. However, existing eco-driving strategies often neglect macroscopic traffic effects, such as upstream traffic jams, that occur outside the optimization horizon but significantly impact vehicle energy efficiency. This work presents a novel Neural Network (NN)-based methodology to approximate the terminal cost within a model predictive control (MPC) problem framework, explicitly incorporating upstream traffic dynamics. By incorporating traffic jams into the optimization process, the proposed traffic-aware approach yields more energy-efficient speed trajectories compared to traffic-agnostic methods, with minimal impact on travel time. The framework is scalable for real-time implementation while effectively addressing uncertainties from dynamic traffic conditions and macroscopic traffic events.",
    "authors": [
      "Mehmet Fatih Ozkan",
      "Dennis Kibalama",
      "Jacob Paugh",
      "Marcello Canova",
      "Stephanie Stockar"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-10T03:47:57.000Z",
    "updatedAt": "2025-10-10T03:47:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08980v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08980v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08976v1",
    "arxivId": "2510.08976v1",
    "title": "Hierarchical Scheduling for Multi-Vector Image Retrieval",
    "abstract": "To effectively leverage user-specific data, retrieval augmented generation (RAG) is employed in multimodal large language model (MLLM) applications. However, conventional retrieval approaches often suffer from limited retrieval accuracy. Recent advances in multi-vector retrieval (MVR) improve accuracy by decomposing queries and matching against segmented images. They still suffer from sub-optimal accuracy and efficiency, overlooking alignment between the query and varying image objects and redundant fine-grained image segments. In this work, we present an efficient scheduling framework for image retrieval - HiMIR. First, we introduce a novel hierarchical paradigm, employing multiple intermediate granularities for varying image objects to enhance alignment. Second, we minimize redundancy in retrieval by leveraging cross-hierarchy similarity consistency and hierarchy sparsity to minimize unnecessary matching computation. Furthermore, we configure parameters for each dataset automatically for practicality across diverse scenarios. Our empirical study shows that, HiMIR not only achieves substantial accuracy improvements but also reduces computation by up to 3.5 times over the existing MVR system.",
    "authors": [
      "Maoliang Li",
      "Ke Li",
      "Yaoyang Liu",
      "Jiayu Chen",
      "Zihao Zheng",
      "Yinjun Wu",
      "Xiang Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.DC",
      "cs.IR"
    ],
    "publishedAt": "2025-10-10T03:36:18.000Z",
    "updatedAt": "2025-10-10T03:36:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08976v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08976v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08973v1",
    "arxivId": "2510.08973v1",
    "title": "A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space",
    "abstract": "This paper presents the classification of a general quadric into an axisymmetric quadric (AQ) and the solution to the problem of the proximity of a given point to an AQ. The problem of proximity in $R^3$ is reduced to the same in $R^2$, which is not found in the literature. A new method to solve the problem in $R^2$ is used based on the geometrical properties of the conics, such as sub-normal, length of the semi-major axis, eccentricity, slope and radius. Furthermore, the problem in $R^2$ is categorised into two and three more sub-cases for parabola and ellipse/hyperbola, respectively, depending on the location of the point, which is a novel approach as per the authors' knowledge. The proposed method is suitable for implementation in a common programming language, such as C and proved to be faster than a commercial library, namely, Bullet.",
    "authors": [
      "Bibekananda Patra",
      "Aditya Mahesh Kolte",
      "Sandipan Bandyopadhyay"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T03:28:39.000Z",
    "updatedAt": "2025-10-10T03:28:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08973v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08973v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08953v1",
    "arxivId": "2510.08953v1",
    "title": "Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm",
    "abstract": "Soft robots offer significant advantages in safety and adaptability, yet achieving precise and dynamic control remains a major challenge due to their inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive Control (DeePC) has emerged as a promising model-free approach that bypasses explicit system identification by directly leveraging input-output data. While DeePC has shown success in other domains, its application to soft robots remains underexplored, particularly for three-dimensional (3D) soft robotic systems. This paper addresses this gap by developing and experimentally validating an effective DeePC framework on a 3D, cable-driven soft arm. Specifically, we design and fabricate a soft robotic arm with a thick tubing backbone for stability, a dense silicone body with large cavities for strength and flexibility, and rigid endcaps for secure termination. Using this platform, we implement DeePC with singular value decomposition (SVD)-based dimension reduction for two key control tasks: fixed-point regulation and trajectory tracking in 3D space. Comparative experiments with a baseline model-based controller demonstrate DeePC's superior accuracy, robustness, and adaptability, highlighting its potential as a practical solution for dynamic control of soft robots.",
    "authors": [
      "Cheng Ouyang",
      "Moeen Ul Islam",
      "Dong Chen",
      "Kaixiang Zhang",
      "Zhaojian Li",
      "Xiaobo Tan"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-10T03:00:39.000Z",
    "updatedAt": "2025-10-10T03:00:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08953v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08953v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08943v1",
    "arxivId": "2510.08943v1",
    "title": "A pilot cohort study of a microfluidic-based point-of-care bilirubin measurement system",
    "abstract": "Objective The concentration of bilirubin in blood or serum is useful for assessing liver function as well as monitoring treatment. This study evaluates the clinical performance of a novel point-of-care (PoC) device for the detection of bilirubin in serum. The PoC device incorporates an integrated miniature optoelectronic sensing module and a microfluidic test cartridge. Methods Patients' serum total bilirubin concentrations, ranging from 2 {\\mu}mol/L to 480 {\\mu}mol/L, were measured using the PoC device and the standard laboratory method (n=20). Bland-Altman analysis and regression analysis using Passing-Bablok method were used to benchmark the PoC device against the standard laboratory measurements. The diagnostic capability of the PoC device in categorising the serum samples within clinically relevant bilirubin concentration thresholds of 200, 300, and 450 {\\mu}mol/L was assessed using receiver operating characteristic (ROC) analysis. Results The mean difference between the PoC device and the standard laboratory method was -5.6 {\\mu}mol/L, with a 95% confidence interval (CI) of -45.1 {\\mu}mol/L to 33.9 {\\mu}mol/L. The coefficient of determination (R2) was 0.986. The PoC device achieved a detection sensitivity of 90% and specificity of 97% in categorising bilirubin concentrations within bands used in clinical decision-making. Conclusions This study demonstrates that the proposed PoC device is capable of measuring bilirubin levels in patient samples with clinically acceptable accuracy.",
    "authors": [
      "Jean Pierre Ndabakuranye",
      "Inge W. G. Last",
      "Kay Weng Choy",
      "Peter Thurgood",
      "Jason C. Steel",
      "Genia Burchall",
      "Stella Stylianou",
      "Khashayar Khoshmanesh",
      "Arman Ahnood"
    ],
    "categories": [
      "physics.med-ph",
      "cs.SY",
      "eess.SY",
      "physics.app-ph",
      "physics.bio-ph"
    ],
    "publishedAt": "2025-10-10T02:49:50.000Z",
    "updatedAt": "2025-10-10T02:49:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08943v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08943v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08939v1",
    "arxivId": "2510.08939v1",
    "title": "Free to Move: Reachability Types with Flow-Sensitive Effects for Safe Deallocation and Ownership Transfer",
    "abstract": "We present a flow-sensitive effect system for reachability types that supports explicit memory management, including Rust-style move semantics, in higher-order impure functional languages. Our system refines the existing reachability qualifier with polymorphic \\emph{use} and \\emph{kill} effects that record how references are read, written, transferred, and deallocated. The effect discipline tracks operations performed on each resource using qualifiers, enabling the type system to express ownership transfer, contextual freshness, and destructive updates without regions or linearity. We formalize the calculus, its typing and effect rules, and a compositional operational semantics that validates use-after-free safety. All metatheoretic results, including preservation, progress, and effect soundness, are mechanized. The system models idioms such as reference deallocation, move semantics, reference swapping, while exposing precise safety guarantee. Together, these contributions integrate reachability-based reasoning with explicit resource control, advancing the state of the art in safe manual memory management for higher-order functional languages.",
    "authors": [
      "Haotian Deng",
      "Siyuan He",
      "Songlin Jia",
      "Yuyan Bao",
      "Tiark Rompf"
    ],
    "categories": [
      "cs.PL"
    ],
    "publishedAt": "2025-10-10T02:41:04.000Z",
    "updatedAt": "2025-10-10T02:41:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08939v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08939v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08937v1",
    "arxivId": "2510.08937v1",
    "title": "Cognitive Radio for Asymmetric Cellular Downlink with Multi-User MIMO",
    "abstract": "Cognitive radio (CR) is an important technique for improving spectral efficiency, letting a secondary system operate in a wireless spectrum when the primary system does not make use of it. While it has been widely explored over the past 25 years, many common assumptions are not aligned with the realities of 5G networks. In this paper, we consider the CR problem for the following setup: (i) infrastructure-based systems, where downlink transmissions might occur to receivers whose positions are not, or not exactly, known; (ii) multi-beam antennas at both primary and secondary base stations. We formulate a detailed protocol to determine when secondary transmissions into different beam directions can interfere with primary users at potential locations and create probability-based interference rules. We then analyze the \"catastrophic interference\" probability and the \"missed transmission opportunity\" probability, as well as the achievable throughput, as a function of the transmit powers of the primary and secondary base stations and the sensing window of the secondary base station. Results can serve to more realistically assess the spectral efficiency gains in 5G infrastructure-based cognitive systems.",
    "authors": [
      "Omer Gokalp Serbetci",
      "Lei Chu",
      "Andreas F. Molisch"
    ],
    "categories": [
      "eess.SY",
      "cs.IT",
      "cs.SY",
      "math.IT"
    ],
    "publishedAt": "2025-10-10T02:34:12.000Z",
    "updatedAt": "2025-10-10T02:34:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08937v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08937v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08930v1",
    "arxivId": "2510.08930v1",
    "title": "Co-Authoring the Self: A Human-AI Interface for Interest Reflection in Recommenders",
    "abstract": "Natural language-based user profiles in recommender systems have been explored for their interpretability and potential to help users scrutinize and refine their interests, thereby improving recommendation quality. Building on this foundation, we introduce a human-AI collaborative profile for a movie recommender system that presents editable personalized interest summaries of a user's movie history. Unlike static profiles, this design invites users to directly inspect, modify, and reflect on the system's inferences. In an eight-week online field deployment with 1775 active movie recommender users, we find persistent gaps between user-perceived and system-inferred interests, show how the profile encourages engagement and reflection, and identify design directions for leveraging imperfect AI-powered user profiles to stimulate more user intervention and build more transparent and trustworthy recommender experiences.",
    "authors": [
      "Ruixuan Sun",
      "Junyuan Wang",
      "Sanjali Roy",
      "Joseph A. Konstan"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T02:20:13.000Z",
    "updatedAt": "2025-10-10T02:20:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08930v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08930v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08917v1",
    "arxivId": "2510.08917v1",
    "title": "\"I know it's not right, but that's what it said to do\": Investigating Trust in AI Chatbots for Cybersecurity Policy",
    "abstract": "AI chatbots are an emerging security attack vector, vulnerable to threats such as prompt injection, and rogue chatbot creation. When deployed in domains such as corporate security policy, they could be weaponized to deliver guidance that intentionally undermines system defenses. We investigate whether users can be tricked by a compromised AI chatbot in this scenario. A controlled study (N=15) asked participants to use a chatbot to complete security-related tasks. Without their knowledge, the chatbot was manipulated to give incorrect advice for some tasks. The results show how trust in AI chatbots is related to task familiarity, and confidence in their ownn judgment. Additionally, we discuss possible reasons why people do or do not trust AI chatbots in different scenarios.",
    "authors": [
      "Brandon Lit",
      "Edward Crowder",
      "Daniel Vogel",
      "Hassan Khan"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T02:01:03.000Z",
    "updatedAt": "2025-10-10T02:01:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08917v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08917v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08914v1",
    "arxivId": "2510.08914v1",
    "title": "VM-UNSSOR: Unsupervised Neural Speech Separation Enhanced by Higher-SNR Virtual Microphone Arrays",
    "abstract": "Blind speech separation (BSS) aims to recover multiple speech sources from multi-channel, multi-speaker mixtures under unknown array geometry and room impulse responses. In unsupervised setup where clean target speech is not available for model training, UNSSOR proposes a mixture consistency (MC) loss for training deep neural networks (DNN) on over-determined training mixtures to realize unsupervised speech separation. However, when the number of microphones of the training mixtures decreases, the MC constraint weakens and the separation performance falls dramatically. To address this, we propose VM-UNSSOR, augmenting the observed training mixture signals recorded by a limited number of microphones with several higher-SNR virtual-microphone (VM) signals, which are obtained by applying linear spatial demixers (such as IVA and spatial clustering) to the observed training mixtures. As linear projections of the observed mixtures, the virtual-microphone signals can typically increase the SNR of each source and can be leveraged to compute extra MC losses to improve UNSSOR and address the frequency permutation problem in UNSSOR. On the SMS-WSJ dataset, in the over-determined six-microphone, two-speaker separation setup, VM-UNSSOR reaches 17.1 dB SI-SDR, while UNSSOR only obtains 14.7 dB; and in the determined two-microphone, two-speaker case, UNSSOR collapses to -2.7 dB SI-SDR, while VM-UNSSOR achieves 10.7 dB.",
    "authors": [
      "Shulin He",
      "Zhong-Qiu Wang"
    ],
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T01:54:24.000Z",
    "updatedAt": "2025-10-10T01:54:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08914v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08914v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08912v1",
    "arxivId": "2510.08912v1",
    "title": "Beyond Words: Infusing Conversational Agents with Human-like Typing Behaviors",
    "abstract": "Recently, large language models have facilitated the emergence of highly intelligent conversational AI capable of engaging in human-like dialogues. However, a notable distinction lies in the fact that these AI models predominantly generate responses rapidly, often producing extensive content without emulating the thoughtful process characteristic of human cognition and typing. This paper presents a design aimed at simulating human-like typing behaviors, including patterns such as hesitation and self-editing, as well as a preliminary user experiment to understand whether and to what extent the agent with human-like typing behaviors could potentially affect conversational engagement and its trustworthiness. We've constructed an interactive platform featuring user-adjustable parameters, allowing users to personalize the AI's communication style and thus cultivate a more enriching and immersive conversational experience. Our user experiment, involving interactions with three types of agents - a baseline agent, one simulating hesitation, and another integrating both hesitation and self-editing behaviors - reveals a preference for the agent that incorporates both behaviors, suggesting an improvement in perceived naturalness and trustworthiness. Through the insights from our design process and both quantitative and qualitative feedback from user experiments, this paper contributes to the multimodal interaction design and user experience for conversational AI, advocating for a more human-like, engaging, and trustworthy communication paradigm.",
    "authors": [
      "Jijie Zhou",
      "Yuhan Hu"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T01:51:25.000Z",
    "updatedAt": "2025-10-10T01:51:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08912v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08912v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08891v1",
    "arxivId": "2510.08891v1",
    "title": "Designing and Evaluating an AI-driven Immersive Multidisciplinary Simulation (AIMS) for Interprofessional Education",
    "abstract": "Interprofessional education has long relied on case studies and the use of standardized patients to support teamwork, communication, and related collaborative competencies among healthcare professionals. However, traditional approaches are often limited by cost, scalability, and inability to mimic the dynamic complexity of real-world clinical scenarios. To address these challenges, we designed and developed AIMS (AI-Enhanced Immersive Multidisciplinary Simulations), a virtual simulation that integrates a large language model (Gemini-2.5-Flash), a Unity-based virtual environment engine, and a character creation pipeline to support synchronized, multimodal interactions between the user and the virtual patient. AIMS was designed to enhance collaborative clinical reasoning and health promotion competencies among students from pharmacy, medicine, nursing, and social work. A formal usability testing session was conducted which participants assumed professional roles on a healthcare team and engaged in a mix of scripted and unscripted conversations. Participants explored the patient's symptoms, social context, and care needs. Usability issues were identified (e.g., audio routing, response latency) and used to guide subsequent refinements. Findings in general suggest that AIMS supports realistic, profession-specific and contextually appropriate conversations. We discussed both technical and pedagogical innovations of AIMS and concluded with future directions.",
    "authors": [
      "Ruijie Wang",
      "Jie Lu",
      "Bo Pei",
      "Evonne Jones",
      "Jamey Brinson",
      "Timothy Brown"
    ],
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-10T01:09:18.000Z",
    "updatedAt": "2025-10-10T01:09:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08891v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08891v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08889v1",
    "arxivId": "2510.08889v1",
    "title": "Typestate via Revocable Capabilities",
    "abstract": "Managing stateful resources safely and expressively is a longstanding challenge in programming languages, especially in the presence of aliasing. While scope-based constructs such as Java's synchronized blocks offer ease of reasoning, they restrict expressiveness and parallelism. Conversely, imperative, flow-sensitive management enables fine-grained control but demands sophisticated typestate analyses and often burdens programmers with explicit state tracking. In this work, we present a novel approach that unifies the strengths of both paradigms by extending flow-insensitive capability mechanisms into flow-sensitive typestate tracking. Our system decouples capability lifetimes from lexical scopes, allowing functions to provide, revoke, and return capabilities in a flow-sensitive manner, based on the existing mechanisms explored for the safety and ergonomics of scoped capability programming. We implement our approach as an extension to the Scala 3 compiler, leveraging path-dependent types and implicit resolution to enable concise, statically safe, and expressive typestate programming. Our prototype generically supports a wide range of stateful patterns, including file operations, advanced locking protocols, DOM construction, and session types. This work demonstrates that expressive and safe typestate management can be achieved with minimal extensions to existing capability-based languages, paving the way for more robust and ergonomic stateful programming.",
    "authors": [
      "Songlin Jia",
      "Craig Liu",
      "Siyuan He",
      "Haotian Deng",
      "Yuyan Bao",
      "Tiark Rompf"
    ],
    "categories": [
      "cs.PL"
    ],
    "publishedAt": "2025-10-10T00:59:11.000Z",
    "updatedAt": "2025-10-10T00:59:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08889v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08889v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08888v1",
    "arxivId": "2510.08888v1",
    "title": "Green Grid: Smart Tech Meets E-Waste",
    "abstract": "Electronic waste (e-waste) is a rapidly growing global problem caused by shorter device lifecycles and rising consumption. India ranks third globally in e-waste generation, producing over 1.7 million tonnes in 2023-24, of which less than half is formally processed. To address this, we propose Green Grid, an integrated AI-powered e-waste management platform combining IoT-enabled smart collection, AI-based device classification, blockchain-based traceability, and gamified citizen engagement. The system features smart recycling bins with sensors for real-time monitoring, deep learning models for device identification and sorting, a blockchain ledger for tamper-proof tracking, and a reward-based mobile or web app to encourage user participation. Additionally, Green Grid offers analytics dashboards and an eco-marketplace to support policymakers and recyclers. By bridging technology, sustainability, and community participation, the platform enhances transparency, increases formal recycling rates, and advances India's transition toward a circular economy.",
    "authors": [
      "Yashodip Dharmendra Jagtap",
      "Aaditya Ganesh Bagul"
    ],
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "publishedAt": "2025-10-10T00:57:47.000Z",
    "updatedAt": "2025-10-10T00:57:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08888v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08888v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08887v1",
    "arxivId": "2510.08887v1",
    "title": "Observation Matrix Design for Densifying MIMO Channel Estimation via 2D Ice Filling",
    "abstract": "In recent years, densifying multiple-input multiple-output (MIMO) has attracted much attention from the communication community. Thanks to the subwavelength antenna spacing, the strong correlations among densifying antennas provide sufficient prior knowledge about channel state information (CSI). This inspires the careful design of observation matrices (e.g., transmit precoders and receive combiners), that exploits the CSI prior knowledge, to boost channel estimation performance. Aligned with this vision, this work proposes to jointly design the combiners and precoders by maximizing the mutual information between the received pilots and densifying MIMO channels. A two-dimensional ice-filling (2DIF) algorithm is proposed to efficiently accomplish this objective. The algorithm is motivated by the fact that the eigenspace of MIMO channel covariance can be decoupled into two sub-eigenspaces, which are associated with the correlations of transmitter antennas and receiver antennas, respectively. By properly setting the precoder and the combiner as the eigenvectors from these two sub-eigenspaces, the 2DIF promises to generate near-optimal observation matrices. Moreover, we further extend the 2DIF method to the popular hybrid combining systems, where a two-stage 2DIF (TS-2DIF) algorithm is developed to handle the analog combining circuits realized by phase shifters. Simulation results demonstrate that, compared to the state-of-the-art schemes, the proposed 2DIF and TS-2DIF methods can achieve superior channel estimation accuracy.",
    "authors": [
      "Zijian Zhang",
      "Mingyao Cui"
    ],
    "categories": [
      "cs.IT",
      "cs.IR",
      "cs.SY",
      "eess.SP",
      "eess.SY",
      "math.IT"
    ],
    "publishedAt": "2025-10-10T00:54:36.000Z",
    "updatedAt": "2025-10-10T00:54:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08887v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08887v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08884v1",
    "arxivId": "2510.08884v1",
    "title": "Model-Based Lookahead Reinforcement Learning for in-hand manipulation",
    "abstract": "In-Hand Manipulation, as many other dexterous tasks, remains a difficult challenge in robotics by combining complex dynamic systems with the capability to control and manoeuvre various objects using its actuators. This work presents the application of a previously developed hybrid Reinforcement Learning (RL) Framework to In-Hand Manipulation task, verifying that it is capable of improving the performance of the task. The model combines concepts of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained policy with the help of a dynamic model and value-function through trajectory evaluation, as done in Model Predictive Control. This work evaluates the performance of the model by comparing it with the policy that will be guided. To fully explore this, various tests are performed using both fully-actuated and under-actuated simulated robotic hands to manipulate different objects for a given task. The performance of the model will also be tested for generalization tests, by changing the properties of the objects in which both the policy and dynamic model were trained, such as density and size, and additionally by guiding a trained policy in a certain object to perform the same task in a different one. The results of this work show that, given a policy with high average reward and an accurate dynamic model, the hybrid framework improves the performance of in-hand manipulation tasks for most test cases, even when the object properties are changed. However, this improvement comes at the expense of increasing the computational cost, due to the complexity of trajectory evaluation.",
    "authors": [
      "Alexandre Lopes",
      "Catarina Barata",
      "Plinio Moreno"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T00:34:04.000Z",
    "updatedAt": "2025-10-10T00:34:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08884v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08884v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08883v1",
    "arxivId": "2510.08883v1",
    "title": "The Online Submodular Cover Problem",
    "abstract": "In the submodular cover problem, we are given a monotone submodular function $f$, and we want to pick the min-cost set $S$ such that $f(S) = f(N)$. Motivated by problems in network monitoring and resource allocation, we consider the submodular cover problem in an online setting. As a concrete example, suppose at each time $t$, a nonnegative monotone submodular function $g_t$ is given to us. We define $f^{(t)} = \\sum_{s \\leq t} g_s$ as the sum of all functions seen so far. We need to maintain a submodular cover of these submodular functions $f^{(1)}, f^{(2)}, \\ldots f^{(T)}$ in an online fashion; i.e., we cannot revoke previous choices. Formally, at each time $t$ we produce a set $S_t \\subseteq N$ such that $f^{(t)}(S_t) = f^{(t)}(N)$ -- i.e., this set $S_t$ is a cover -- such that $S_{t-1} \\subseteq S_t$, so previously decisions to pick elements cannot be revoked. (We actually allow more general sequences $\\{f^{(t)}\\}$ of submodular functions, but this sum-of-simpler-submodular-functions case is useful for concreteness.) We give polylogarithmic competitive algorithms for this online submodular cover problem. The competitive ratio on an input sequence of length $T$ is $O(\\ln n \\ln (T \\cdot f(N) / f_{\\text{min}}))$, where $f_{\\text{min}}$ is the smallest nonzero marginal for functions $f^{(t)}$, and $|N| = n$. For the special case of online set cover, our competitive ratio matches that of Alon et al. [SIAM J. Comp. 03], which are best possible for polynomial-time online algorithms unless $NP \\subseteq BPP$ (see Korman 04). Since existing offline algorithms for submodular cover are based on greedy approaches which seem difficult to implement online, the technical challenge is to (approximately) solve the exponential-sized linear programming relaxation for submodular cover, and to round it, both in the online setting.",
    "authors": [
      "Anupam Gupta",
      "Roie Levin"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-10T00:29:14.000Z",
    "updatedAt": "2025-10-10T00:29:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08883v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08883v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08880v1",
    "arxivId": "2510.08880v1",
    "title": "Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization",
    "abstract": "Accurate calibration of intrinsic (odometer scaling factors) and extrinsic parameters (IMU-odometer translation and rotation) is essential for autonomous ground vehicle localization. Existing GNSS-aided approaches often rely on positioning results or raw measurements without ambiguity resolution, and their observability properties remain underexplored. This paper proposes a tightly coupled online calibration method that fuses IMU, odometer, and raw GNSS measurements (pseudo-range, carrier-phase, and Doppler) within an extendable factor graph optimization (FGO) framework, incorporating outlier mitigation and ambiguity resolution. Observability analysis reveals that two horizontal translation and three rotation parameters are observable under general motion, while vertical translation remains unobservable. Simulation and real-world experiments demonstrate superior calibration and localization performance over state-of-the-art loosely coupled methods. Specifically, the IMU-odometer positioning using our calibrated parameters achieves the absolute maximum error of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent improvement. To foster further research, we also release the first open-source dataset that combines IMU, 2D odometer, and raw GNSS measurements from both rover and base stations.",
    "authors": [
      "Baoshan Song",
      "Xiao Xia",
      "Penggao Yan",
      "Yihan Zhong",
      "Weisong Wen",
      "Li-Ta Hsu"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-10T00:23:23.000Z",
    "updatedAt": "2025-10-10T00:23:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08880v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08880v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08878v1",
    "arxivId": "2510.08878v1",
    "title": "ControlAudio: Tackling Text-Guided, Timing-Indicated and Intelligible Audio Generation via Progressive Diffusion Modeling",
    "abstract": "Text-to-audio (TTA) generation with fine-grained control signals, e.g., precise timing control or intelligible speech content, has been explored in recent works. However, constrained by data scarcity, their generation performance at scale is still compromised. In this study, we recast controllable TTA generation as a multi-task learning problem and introduce a progressive diffusion modeling approach, ControlAudio. Our method adeptly fits distributions conditioned on more fine-grained information, including text, timing, and phoneme features, through a step-by-step strategy. First, we propose a data construction method spanning both annotation and simulation, augmenting condition information in the sequence of text, timing, and phoneme. Second, at the model training stage, we pretrain a diffusion transformer (DiT) on large-scale text-audio pairs, achieving scalable TTA generation, and then incrementally integrate the timing and phoneme features with unified semantic representations, expanding controllability. Finally, at the inference stage, we propose progressively guided generation, which sequentially emphasizes more fine-grained information, aligning inherently with the coarse-to-fine sampling nature of DiT. Extensive experiments show that ControlAudio achieves state-of-the-art performance in terms of temporal accuracy and speech clarity, significantly outperforming existing methods on both objective and subjective evaluations. Demo samples are available at: https://control-audio.github.io/Control-Audio.",
    "authors": [
      "Yuxuan Jiang",
      "Zehua Chen",
      "Zeqian Ju",
      "Yusheng Dai",
      "Weibei Dou",
      "Jun Zhu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "publishedAt": "2025-10-10T00:19:41.000Z",
    "updatedAt": "2025-10-10T00:19:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08878v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08878v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08876v1",
    "arxivId": "2510.08876v1",
    "title": "Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval",
    "abstract": "We present a repository decomposition system that converts large software repositories into a vectorized knowledge graph which mirrors project architectural and semantic structure, capturing semantic relationships and allowing a significant level of automatization of further repository development. The graph encodes syntactic relations such as containment, implementation, references, calls, and inheritance, and augments nodes with LLM-derived summaries and vector embeddings. A hybrid retrieval pipeline combines semantic retrieval with graph-aware expansion, and an LLM-based assistant formulates constrained, read-only graph requests and produces human-oriented explanations.",
    "authors": [
      "Kostiantyn Bevziuk",
      "Andrii Fatula",
      "Svetozar Lashin Yaroslav Opanasenko",
      "Anna Tukhtarova",
      "Ashok Jallepalli Pradeepkumar Sharma",
      "Hritvik Shrivastava"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T00:13:50.000Z",
    "updatedAt": "2025-10-10T00:13:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08876v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08876v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08874v1",
    "arxivId": "2510.08874v1",
    "title": "Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication",
    "abstract": "Many important applications across science, data analytics, and AI workloads depend on distributed matrix multiplication. Prior work has developed a large array of algorithms suitable for different problem sizes and partitionings including 1D, 2D, 1.5D, and 2.5D algorithms. A limitation of current work is that existing algorithms are limited to a subset of partitionings. Multiple algorithm implementations are required to support the full space of possible partitionings. If no algorithm implementation is available for a particular set of partitionings, one or more operands must be redistributed, increasing communication costs. This paper presents a universal one-sided algorithm for distributed matrix multiplication that supports all combinations of partitionings and replication factors. Our algorithm uses slicing (index arithmetic) to compute the sets of overlapping tiles that must be multiplied together. This list of local matrix multiplies can then either be executed directly, or reordered and lowered to an optimized IR to maximize overlap. We implement our algorithm using a high-level C++-based PGAS programming framework that performs direct GPU-to-GPU communication using intra-node interconnects. We evaluate performance for a wide variety of partitionings and replication factors, finding that our work is competitive with PyTorch DTensor, a highly optimized distributed tensor library targeting AI models.",
    "authors": [
      "Benjamin Brock",
      "Renato Golin"
    ],
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-10T00:11:39.000Z",
    "updatedAt": "2025-10-10T00:11:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08874v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08874v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08872v1",
    "arxivId": "2510.08872v1",
    "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare",
    "abstract": "Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices typically assume that maximizing model reward also maximizes user welfare, but this assumption frequently fails in practice: models may over-clarify or generate overly verbose reasoning when users prefer concise answers. Such behaviors resemble the prisoner's dilemma, where individually rational choices lead to socially suboptimal outcomes. The fundamental challenge is the lack of a principled decision making mechanism that mutually benefits both the LLM and the user. We propose Game-Theoretic Alignment (GTAlign), an alignment framework that integrates game-theoretic decision making into both reasoning and training. During reasoning, the model explicitly treats user-LLM interaction as a strategic game: it constructs payoff matrices within its reasoning chain to estimate welfare for both itself and the user, and then selects actions that are mutually beneficial. During training, we introduce a mutual welfare reward that reinforces cooperative responses, aligning model behavior with socially efficient outcomes. In addition, we introduce an inference technique that leverages game-theoretic reasoning to dynamically adapt LLM's response when pricing policies of LLM service change. Extensive experiments demonstrate that GTAlign substantially improves reasoning efficiency, answer quality, and mutual welfare compared to baselines across diverse tasks. The code is available at https://github.com/ulab-uiuc/GTAlign .",
    "authors": [
      "Siqi Zhu",
      "David Zhang",
      "Pedro Cisneros-Velarde",
      "Jiaxuan You"
    ],
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "publishedAt": "2025-10-10T00:05:14.000Z",
    "updatedAt": "2025-10-10T00:05:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08872v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08872v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08869v1",
    "arxivId": "2510.08869v1",
    "title": "Measuring the Hidden Cost of Data Valuation through Collective Disclosure",
    "abstract": "Data valuation methods assign marginal utility to each data point that has contributed to the training of a machine learning model. If used directly as a payout mechanism, this creates a hidden cost of valuation, in which contributors with near-zero marginal value would receive nothing, even though their data had to be collected and assessed. To better formalize this cost, we introduce a conceptual and game-theoretic model, the Information Disclosure Game, between a Data Union (sometimes also called a data trust), a member-run agent representing contributors, and a Data Consumer (e.g., a platform). After first aggregating members' data, the DU releases information progressively by adding Laplacian noise under a differentially-private mechanism. Through simulations with strategies guided by data Shapley values and multi-armed bandit exploration, we demonstrate on a Yelp review helpfulness prediction task that data valuation inherently incurs an explicit acquisition cost and that the DU's collective disclosure policy changes how this cost is distributed across members.",
    "authors": [
      "Patrick Mesana",
      "Gilles Caporossi",
      "Sebastien Gambs"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-09T23:59:25.000Z",
    "updatedAt": "2025-10-09T23:59:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08869v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08869v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08863v1",
    "arxivId": "2510.08863v1",
    "title": "Comparative Performance Analysis of Modern NoSQL Data Technologies: Redis, Aerospike, and Dragonfly",
    "abstract": "The rise of distributed applications and cloud computing has created a demand for scalable, high-performance key-value storage systems. This paper presents a performance evaluation of three prominent NoSQL key-value stores: Redis, Aerospike, and Dragonfly, using the Yahoo! Cloud Serving Benchmark (YCSB) framework. We conducted extensive experiments across three distinct workload patterns (read-heavy, write-heavy), and balanced while systematically varying client concurrency from 1 to 32 clients. Our evaluation methodology captures both latency, throughput, and memory characteristics under realistic operational conditions, providing insights into the performance trade-offs and scalability behaviour of each system",
    "authors": [
      "Deep Bodra",
      "Sushil Khairnar"
    ],
    "categories": [
      "cs.DB",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T23:33:51.000Z",
    "updatedAt": "2025-10-09T23:33:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08863v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08863v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08854v1",
    "arxivId": "2510.08854v1",
    "title": "Optimal Control with Lyapunov Stability Guarantees for Space Applications",
    "abstract": "This paper investigates the infinite horizon optimal control problem (OCP) for space applications characterized by nonlinear dynamics. The proposed approach divides the problem into a finite horizon OCP with a regularized terminal cost, guiding the system towards a terminal set, and an infinite horizon linear regulation phase within this set. This strategy guarantees global asymptotic stability under specific assumptions. Our method maintains the system's fully nonlinear dynamics until it reaches the terminal set, where the system dynamics is linearized. As the terminal set converges to the origin, the difference in optimal cost incurred reduces to zero, guaranteeing an efficient and stable solution. The approach is tested through simulations on three problems: spacecraft attitude control, rendezvous maneuver, and soft landing. In spacecraft attitude control, we focus on achieving precise orientation and stabilization. For rendezvous maneuvers, we address the navigation of a chaser to meet a target spacecraft. For the soft landing problem, we ensure a controlled descent and touchdown on a planetary surface. We provide numerical results confirming the effectiveness of the proposed method in managing these nonlinear dynamics problems, offering robust solutions essential for successful space missions.",
    "authors": [
      "Abhijeet",
      "Mohamed Naveed Gul Mohamed",
      "Aayushman Sharma",
      "Suman Chakravorty"
    ],
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-09T23:06:59.000Z",
    "updatedAt": "2025-10-09T23:06:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08854v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08854v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08851v1",
    "arxivId": "2510.08851v1",
    "title": "CDE: Concept-Driven Exploration for Reinforcement Learning",
    "abstract": "Intelligent exploration remains a critical challenge in reinforcement learning (RL), especially in visual control tasks. Unlike low-dimensional state-based RL, visual RL must extract task-relevant structure from raw pixels, making exploration inefficient. We propose Concept-Driven Exploration (CDE), which leverages a pre-trained vision-language model (VLM) to generate object-centric visual concepts from textual task descriptions as weak, potentially noisy supervisory signals. Rather than directly conditioning on these noisy signals, CDE trains a policy to reconstruct the concepts via an auxiliary objective, using reconstruction accuracy as an intrinsic reward to guide exploration toward task-relevant objects. Because the policy internalizes these concepts, VLM queries are only needed during training, reducing dependence on external models during deployment. Across five challenging simulated visual manipulation tasks, CDE achieves efficient, targeted exploration and remains robust to noisy VLM predictions. Finally, we demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm, attaining an 80\\% success rate in a real-world manipulation task.",
    "authors": [
      "Le Mao",
      "Andrew H. Liu",
      "Renos Zabounidis",
      "Zachary Kingston",
      "Joseph Campbell"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T23:01:36.000Z",
    "updatedAt": "2025-10-09T23:01:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08851v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08851v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08850v1",
    "arxivId": "2510.08850v1",
    "title": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs",
    "abstract": "Modern codebases make it hard for developers and AI coding assistants to find the right source files when answering questions like \"How does this feature work?\" or \"Where was the bug introduced?\" Traditional code search (keyword or IR based) often misses semantic context and cross file links, while large language models (LLMs) understand natural language but lack repository specific detail. We present a method for file path retrieval that fine tunes a strong LLM (Qwen3-8B) with QLoRA and Unsloth optimizations to predict relevant file paths directly from a natural language query. To build training data, we introduce six code aware strategies that use abstract syntax tree (AST) structure and repository content to generate realistic question-answer pairs, where answers are sets of file paths. The strategies range from single file prompts to hierarchical repository summaries, providing broad coverage. We fine tune on Python projects including Flask, Click, Jinja, FastAPI, and PyTorch, and obtain high retrieval accuracy: up to 91\\% exact match and 93\\% recall on held out queries, clearly beating single strategy training. On a large codebase like PyTorch (about 4,000 Python files), the model reaches 59\\% recall, showing scalability. We analyze how multi level code signals help the LLM reason over cross file context and discuss dataset design, limits (for example, context length in very large repos), and future integration of retrieval with LLM based code intelligence.",
    "authors": [
      "Vasudha Yanuganti",
      "Ishaan Puri",
      "Swapnil Chhatre",
      "Mantinder Singh",
      "Ashok Jallepalli",
      "Hritvik Shrivastava",
      "Pradeep Kumar Sharma"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T22:49:10.000Z",
    "updatedAt": "2025-10-09T22:49:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08850v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08850v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08842v1",
    "arxivId": "2510.08842v1",
    "title": "Maple: A Multi-agent System for Portable Deep Learning across Clusters",
    "abstract": "Training deep learning (DL) models across Graphics Processing Unit (GPU) clusters is technically challenging. One aspect is that users have to compose command lines to adapt to the heterogeneous launchers, schedulers, affinity options, DL framework arguments, and environment variables. Composing correct command lines is error-prone and can easily frustrate users, impeding research or wasting resources. In this work, we present Maple, a multi-agent system that generates correct DL command lines with users' natural language input. Maple consists of four agents with the functionalities of information extraction, template retrieval, command line verification, and error correction. We evaluate Maple on nine GPU clusters across national computing centers in the U.S., five representative deep learning model families, and four commonly used parallel DL training paradigms. Our experiments also cover schedulers of SLURM and PBS and heterogeneous architectures, such as NVIDIA A100/H200 GPUs and Intel Max series GPUs. Maple achieves 92.0% accuracy in generating command lines across the 567 test cases. Leverage multiple language models with an aggregated size of 10B parameters, Maple delivers comparable performance to the state-of-the-art models of GPT-5, Claude, and Gemini. Together, these results highlight Maple's practical value in enabling portable and scalable distributed DL across heterogeneous HPC environments.",
    "authors": [
      "Molang Wu",
      "Zhao Zhang"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T21:56:53.000Z",
    "updatedAt": "2025-10-09T21:56:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08842v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08842v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08839v1",
    "arxivId": "2510.08839v1",
    "title": "Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction",
    "abstract": "Real-time multi-view 3D reconstruction is a mission-critical application for key edge-native use cases, such as fire rescue, where timely and accurate 3D scene modeling enables situational awareness and informed decision-making. However, the dynamic and unpredictable nature of edge resource availability introduces disruptions, such as degraded image quality, unstable network links, and fluctuating server loads, which challenge the reliability of the reconstruction pipeline. In this work, we present a reinforcement learning (RL)-based edge resource management framework for reliable 3D reconstruction to ensure high quality reconstruction within a reasonable amount of time, despite the system operating under a resource-constrained and disruption-prone environment. In particular, the framework adopts two cooperative Q-learning agents, one for camera selection and one for server selection, both of which operate entirely online, learning policies through interactions with the edge environment. To support learning under realistic constraints and evaluate system performance, we implement a distributed testbed comprising lab-hosted end devices and FABRIC infrastructure-hosted edge servers to emulate smart city edge infrastructure under realistic disruption scenarios. Results show that the proposed framework improves application reliability by effectively balancing end-to-end latency and reconstruction quality in dynamic environments.",
    "authors": [
      "Motahare Mounesan",
      "Sourya Saha",
      "Houchao Gan",
      "Md. Nurul Absur",
      "Saptarshi Debroy"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.GR",
      "cs.MM"
    ],
    "publishedAt": "2025-10-09T21:54:14.000Z",
    "updatedAt": "2025-10-09T21:54:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08839v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08839v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08834v1",
    "arxivId": "2510.08834v1",
    "title": "Identifying Video Game Debugging Bottlenecks: An Industry Perspective",
    "abstract": "Conventional debugging techniques used in traditional software are similarly used when debugging video games. However, the reality of video games require its own set of unique debugging techniques such as On-Screen Console, Debug Draws, Debug Camera, Cheats and In-Game Menus, and Data Scrubbing. In this article, we provide insights from a video game studio on how 20 seasoned industry game developers debug during the production of a game. Our experiments rely on the recordings of debugging sessions for the most critical bugs categorized as Crashes, Object Behaviors, and Object Persistence. In this paper, we focus on identifying the debugging activities that bottleneck bug resolution. We also identify the debugging tools used to perform debugging techniques. Lastly, we present how different disciplines collaborate during debugging and how technical roles are at the core of debugging. Our thematic analysis has identified game developers spend 36.6\\% of their time inspecting game artifacts and 35.1\\% of their time reproducing the bug locally.",
    "authors": [
      "Carlos Pinto Gomez",
      "Fabio Petrillo"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T21:45:05.000Z",
    "updatedAt": "2025-10-09T21:45:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08834v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08834v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08831v1",
    "arxivId": "2510.08831v1",
    "title": "Everyone prefers human writers, including AI",
    "abstract": "As AI writing tools become widespread, we need to understand how both humans and machines evaluate literary style, a domain where objective standards are elusive and judgments are inherently subjective. We conducted controlled experiments using Raymond Queneau's Exercises in Style (1947) to measure attribution bias across evaluators. Study 1 compared human participants (N=556) and AI models (N=13) evaluating literary passages from Queneau versus GPT-4-generated versions under three conditions: blind, accurately labeled, and counterfactually labeled. Study 2 tested bias generalization across a 14$\\times$14 matrix of AI evaluators and creators. Both studies revealed systematic pro-human attribution bias. Humans showed +13.7 percentage point (pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3 percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect (P$<$0.001). Study 2 confirmed this bias operates across AI architectures (+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically devalue creative content when labeled as \"AI-generated\" regardless of which AI created it. We also find that attribution labels cause evaluators to invert assessment criteria, with identical features receiving opposing evaluations based solely on perceived authorship. This suggests AI models have absorbed human cultural biases against artificial creativity during training. Our study represents the first controlled comparison of attribution bias between human and artificial evaluators in aesthetic judgment, revealing that AI systems not only replicate but amplify this human tendency.",
    "authors": [
      "Wouter Haverals",
      "Meredith Martin"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T21:33:30.000Z",
    "updatedAt": "2025-10-09T21:33:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08831v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08831v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08827v1",
    "arxivId": "2510.08827v1",
    "title": "McMining: Automated Discovery of Misconceptions in Student Code",
    "abstract": "When learning to code, students often develop misconceptions about various programming language concepts. These can not only lead to bugs or inefficient code, but also slow down the learning of related concepts. In this paper, we introduce McMining, the task of mining programming misconceptions from samples of code from a student. To enable the training and evaluation of McMining systems, we develop an extensible benchmark dataset of misconceptions together with a large set of code samples where these misconceptions are manifested. We then introduce two LLM-based McMiner approaches and through extensive evaluations show that models from the Gemini, Claude, and GPT families are effective at discovering misconceptions in student code.",
    "authors": [
      "Erfan Al-Hossami",
      "Razvan Bunescu"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "publishedAt": "2025-10-09T21:27:39.000Z",
    "updatedAt": "2025-10-09T21:27:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08827v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08827v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08824v1",
    "arxivId": "2510.08824v1",
    "title": "Joint Detection, Channel Estimation and Interference Nulling for Terrestrial-Satellite Downlink Co-Existence in the Upper Mid-Band",
    "abstract": "The upper mid-band FR3 spectrum (7-24 GHz) has garnered significant interest for future cellular services. However, utilizing a large portion of this band requires careful interference coordination with incumbent satellite systems. This paper investigates interference from high-power terrestrial base stations (TN-BSs) to satellite downlink receivers. A central challenge is that the victim receivers, i.e., ground-based non-terrestrial user equipment (NTN-UEs) such as satellite customer premises equipment, must first be detected and their channels estimated before the TN-BS can effectively place nulls in their directions. We explore a potential solution where NTN-UEs periodically transmit preambles or beacon signals that TN-BSs can use for detection and channel estimation. The performance of this nulling approach is analyzed in a simplified scenario with a single victim, revealing the interplay between path loss and estimation quality in determining nulling performance. To further validate the method, we conduct a detailed multi-user site-specific ray-tracing (RT) simulation in a rural environment. The results show that the proposed nulling approach is effective under realistic parameters, even with high densities of victim units, although TN-BS may require a substantial number of antennas.",
    "authors": [
      "Shizhen Jia",
      "Mingjun Ying",
      "Marco Mezzavilla",
      "Doru Calin",
      "Theodore S. Rappaport",
      "Sundeep Rangan"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T21:20:10.000Z",
    "updatedAt": "2025-10-09T21:20:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08824v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08824v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08816v1",
    "arxivId": "2510.08816v1",
    "title": "Audible Networks: Deconstructing and Manipulating Sounds with Deep Non-Negative Autoencoders",
    "abstract": "We propose the use of Non-Negative Autoencoders (NAEs) for sound deconstruction and user-guided manipulation of sounds for creative purposes. NAEs offer a versatile and scalable extension of traditional Non-Negative Matrix Factorization (NMF)-based approaches for interpretable audio decomposition. By enforcing non-negativity constraints through projected gradient descent, we obtain decompositions where internal weights and activations can be directly interpreted as spectral shapes and temporal envelopes, and where components can themselves be listened to as individual sound events. In particular, multi-layer Deep NAE architectures enable hierarchical representations with an adjustable level of granularity, allowing sounds to be deconstructed at multiple levels of abstraction: from high-level note envelopes down to fine-grained spectral details. This framework enables a wide new range of expressive, controllable, and randomized sound transformations. We introduce novel manipulation operations including cross-component and cross-layer synthesis, hierarchical deconstructions, and several randomization strategies that control timbre and event density. Through visualizations and resynthesis of practical examples, we demonstrate how NAEs can serve as flexible and interpretable tools for object-based sound editing.",
    "authors": [
      "Juan José Burred",
      "Carmine-Emanuele Cella"
    ],
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "publishedAt": "2025-10-09T21:04:16.000Z",
    "updatedAt": "2025-10-09T21:04:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08816v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08816v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08812v1",
    "arxivId": "2510.08812v1",
    "title": "Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning",
    "abstract": "Deep space missions face extreme communication delays and environmental uncertainty that prevent real-time ground operations. To support autonomous science operations in communication-constrained environments, we present a partially observable Markov decision process (POMDP) framework that adaptively sequences spacecraft science instruments. We integrate a Bayesian network into the POMDP observation space to manage the high-dimensional and uncertain measurements typical of astrobiology missions. This network compactly encodes dependencies among measurements and improves the interpretability and computational tractability of science data. Instrument operation policies are computed offline, allowing resource-aware plans to be generated and thoroughly validated prior to launch. We use the Enceladus Orbilander's proposed Life Detection Suite (LDS) as a case study, demonstrating how Bayesian network structure and reward shaping influence system performance. We compare our method against the mission's baseline Concept of Operations (ConOps), evaluating both misclassification rates and performance in off-nominal sample accumulation scenarios. Our approach reduces sample identification errors by nearly 40%",
    "authors": [
      "Grace Ra Kim",
      "Hailey Warner",
      "Duncan Eddy",
      "Evan Astle",
      "Zachary Booth",
      "Edward Balaban",
      "Mykel J. Kochenderfer"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T20:58:35.000Z",
    "updatedAt": "2025-10-09T20:58:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08812v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08812v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08811v1",
    "arxivId": "2510.08811v1",
    "title": "Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration",
    "abstract": "Human-robot collaboration (HRC) requires robots to adapt their motions to human intent to ensure safe and efficient cooperation in shared spaces. Although large language models (LLMs) provide high-level reasoning for inferring human intent, their application to reliable motion planning in HRC remains challenging. Physical human-robot interaction (pHRI) is intuitive but often relies on continuous kinesthetic guidance, which imposes burdens on operators. To address these challenges, a contact-informed adaptive motion-planning framework is introduced to infer human intent directly from physical contact and employ the inferred intent for online motion correction in HRC. First, an optimization-based force estimation method is proposed to infer human-intended contact forces and locations from joint torque measurements and a robot dynamics model, thereby reducing cost and installation complexity while enabling whole-body sensitivity. Then, a torque-based contact detection mechanism with link-level localization is introduced to reduce the optimization search space and to enable real-time estimation. Subsequently, a contact-informed adaptive motion planner is developed to infer human intent from contacts and to replan robot motion online, while maintaining smoothness and adapting to human corrections. Finally, experiments on a 7-DOF manipulator are conducted to demonstrate the accuracy of the proposed force estimation method and the effectiveness of the contact-informed adaptive motion planner under perception uncertainty in HRC.",
    "authors": [
      "Jiurun Song",
      "Xiao Liang",
      "Minghui Zheng"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T20:58:09.000Z",
    "updatedAt": "2025-10-09T20:58:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08811v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08811v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08810v1",
    "arxivId": "2510.08810v1",
    "title": "PyMigTool: a tool for end-to-end Python library migration",
    "abstract": "Library migration is the process of replacing a library with a similar one in a software project. Manual library migration is time consuming and error prone, as it requires developers to understand the Application Programming Interfaces (API) of both libraries, map equivalent APIs, and perform the necessary code transformations. Due to the difficulty of the library migration process, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of libraries and code transformations. In this paper, we develop an end-to-end solution that can automatically migrate code between any arbitrary pair of Python libraries that provide similar functionality. Due to the promising capabilities of Large Language Models (LLMs) in code generation and transformation, we use LLMs as the primary engine for migration. Before building the tool, we first study the capabilities of LLMs for library migration on a benchmark of 321 real-world library migrations. We find that LLMs can effectively perform library migration, but some post-processing steps can further improve the performance. Based on this, we develop PyMigTool, a command line application that combines the power of LLMs, static analysis, and dynamic analysis to provide accurate library migration. We evaluate PyMigTool on 717 real-world Python applications that are not from our benchmark. We find that PyMigTool can migrate 32% of the migrations with complete correctness. Of the remaining migrations, only 14% of the migration-related changes are left for developers to fix for more than half of the projects.",
    "authors": [
      "Mohayeminul Islam",
      "Ajay Kumar Jha",
      "May Mahmoud",
      "Sarah Nadi"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T20:54:26.000Z",
    "updatedAt": "2025-10-09T20:54:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08810v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08810v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08807v1",
    "arxivId": "2510.08807v1",
    "title": "Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation",
    "abstract": "From loco-motion to dextrous manipulation, humanoid robots have made remarkable strides in demonstrating complex full-body capabilities. However, the majority of current robot learning datasets and benchmarks mainly focus on stationary robot arms, and the few existing humanoid datasets are either confined to fixed environments or limited in task diversity, often lacking human-humanoid interaction and lower-body locomotion. Moreover, there are a few standardized evaluation platforms for benchmarking learning-based policies on humanoid data. In this work, we present Humanoid Everyday, a large-scale and diverse humanoid manipulation dataset characterized by extensive task variety involving dextrous object manipulation, human-humanoid interaction, locomotion-integrated actions, and more. Leveraging a highly efficient human-supervised teleoperation pipeline, Humanoid Everyday aggregates high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile inputs, together with natural language annotations, comprising 10.3k trajectories and over 3 million frames of data across 260 tasks across 7 broad categories. In addition, we conduct an analysis of representative policy learning methods on our dataset, providing insights into their strengths and limitations across different task categories. For standardized evaluation, we introduce a cloud-based evaluation platform that allows researchers to seamlessly deploy their policies in our controlled setting and receive performance feedback. By releasing Humanoid Everyday along with our policy learning analysis and a standardized cloud-based evaluation platform, we intend to advance research in general-purpose humanoid manipulation and lay the groundwork for more capable and embodied robotic agents in real-world scenarios. Our dataset, data collection code, and cloud evaluation website are made publicly available on our project website.",
    "authors": [
      "Zhenyu Zhao",
      "Hongyi Jing",
      "Xiawei Liu",
      "Jiageng Mao",
      "Abha Jha",
      "Hanwen Yang",
      "Rong Xue",
      "Sergey Zakharor",
      "Vitor Guizilini",
      "Yue Wang"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T20:43:27.000Z",
    "updatedAt": "2025-10-09T20:43:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08807v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08807v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08803v1",
    "arxivId": "2510.08803v1",
    "title": "Man-Made Heuristics Are Dead. Long Live Code Generators!",
    "abstract": "Policy design for various systems controllers has conventionally been a manual process, with domain experts carefully tailoring heuristics for the specific instance in which the policy will be deployed. In this paper, we re-imagine policy design via a novel automated search technique fueled by recent advances in generative models, specifically Large Language Model (LLM)-driven code generation. We outline the design and implementation of PolicySmith, a framework that applies LLMs to synthesize instance-optimal heuristics. We apply PolicySmith to two long-standing systems policies - web caching and congestion control, highlighting the opportunities unraveled by this LLM-driven heuristic search. For caching, PolicySmith discovers heuristics that outperform established baselines on standard open-source traces. For congestion control, we show that PolicySmith can generate safe policies that integrate directly into the Linux kernel.",
    "authors": [
      "Rohit Dwivedula",
      "Divyanshu Saxena",
      "Aditya Akella",
      "Swarat Chaudhuri",
      "Daehyeok Kim"
    ],
    "categories": [
      "cs.OS",
      "cs.DC",
      "cs.LG",
      "cs.NE"
    ],
    "publishedAt": "2025-10-09T20:35:00.000Z",
    "updatedAt": "2025-10-09T20:35:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08803v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08803v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08788v1",
    "arxivId": "2510.08788v1",
    "title": "Robust autobidding for noisy conversion prediction models",
    "abstract": "Managing millions of digital auctions is an essential task for modern advertising auction systems. The main approach to managing digital auctions is an autobidding approach, which depends on the Click-Through Rate and Conversion Rate values. While these quantities are estimated with ML models, their prediction uncertainty directly impacts advertisers' revenue and bidding strategies. To address this issue, we propose RobustBid, an efficient method for robust autobidding taking into account uncertainty in CTR and CVR predictions. Our approach leverages advanced, robust optimization techniques to prevent large errors in bids if the estimates of CTR/CVR are perturbed. We derive the analytical solution of the stated robust optimization problem, which leads to the runtime efficiency of the RobustBid method. The synthetic, iPinYou, and BAT benchmarks are used in our experimental evaluation of RobustBid. We compare our method with the non-robust baseline and the RiskBid algorithm in terms of total conversion volume (TCV) and average cost-per-click ($CPC_{avg}$) performance metrics. The experiments demonstrate that RobustBid provides bids that yield larger TCV and smaller $CPC_{avg}$ than competitors in the case of large perturbations in CTR/CVR predictions.",
    "authors": [
      "Andrey Pudovikov",
      "Alexandra Khirianova",
      "Ekaterina Solodneva",
      "Gleb Molodtsov",
      "Aleksandr Katrutsa",
      "Yuriy Dorn",
      "Egor Samosvat"
    ],
    "categories": [
      "cs.GT",
      "math.OC"
    ],
    "publishedAt": "2025-10-09T20:10:28.000Z",
    "updatedAt": "2025-10-09T20:10:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08788v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08788v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08787v1",
    "arxivId": "2510.08787v1",
    "title": "Geometry-aware Policy Imitation",
    "abstract": "We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks imitation learning by treating demonstrations as geometric curves rather than collections of state-action samples. From these curves, GPI derives distance fields that give rise to two complementary control primitives: a progression flow that advances along expert trajectories and an attraction flow that corrects deviations. Their combination defines a controllable, non-parametric vector field that directly guides robot behavior. This formulation decouples metric learning from policy synthesis, enabling modular adaptation across low-dimensional robot states and high-dimensional perceptual inputs. GPI naturally supports multimodality by preserving distinct demonstrations as separate models and allows efficient composition of new demonstrations through simple additions to the distance field. We evaluate GPI in simulation and on real robots across diverse tasks. Experiments show that GPI achieves higher success rates than diffusion-based policies while running 20 times faster, requiring less memory, and remaining robust to perturbations. These results establish GPI as an efficient, interpretable, and scalable alternative to generative approaches for robotic imitation learning. Project website: https://yimingli1998.github.io/projects/GPI/",
    "authors": [
      "Yiming Li",
      "Nael Darwiche",
      "Amirreza Razmjoo",
      "Sichao Liu",
      "Yilun Du",
      "Auke Ijspeert",
      "Sylvain Calinon"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T20:09:51.000Z",
    "updatedAt": "2025-10-09T20:09:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08787v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08787v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08783v1",
    "arxivId": "2510.08783v1",
    "title": "MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces",
    "abstract": "In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from a crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research.",
    "authors": [
      "Reuben A. Luera",
      "Ryan Rossi",
      "Franck Dernoncourt",
      "Samyadeep Basu",
      "Sungchul Kim",
      "Subhojyoti Mukherjee",
      "Puneet Mathur",
      "Ruiyi Zhang",
      "Jihyung Kil",
      "Nedim Lipka",
      "Seunghyun Yoon",
      "Jiuxiang Gu",
      "Zichao Wang",
      "Cindy Xiong Bearfield",
      "Branislav Kveton"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T20:00:41.000Z",
    "updatedAt": "2025-10-09T20:00:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08783v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08783v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08777v1",
    "arxivId": "2510.08777v1",
    "title": "Understanding and Predicting Temporal Visual Attention Influenced by Dynamic Highlights in Monitoring Task",
    "abstract": "Monitoring interfaces are crucial for dynamic, highstakes tasks where effective user attention is essential. Visual highlights can guide attention effectively but may also introduce unintended disruptions. To investigate this, we examined how visual highlights affect users' gaze behavior in a drone monitoring task, focusing on when, how long, and how much attention they draw. We found that highlighted areas exhibit distinct temporal characteristics compared to non-highlighted ones, quantified using normalized saliency (NS) metrics. Highlights elicited immediate responses, with NS peaking quickly, but this shift came at the cost of reduced search efforts elsewhere, potentially impacting situational awareness. To predict these dynamic changes and support interface design, we developed the Highlight-Informed Saliency Model (HISM), which provides granular predictions of NS over time. These predictions enable evaluations of highlight effectiveness and inform the optimal timing and deployment of highlights in future monitoring interface designs, particularly for time-sensitive tasks.",
    "authors": [
      "Zekun Wu",
      "Anna Maria Feit"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T19:47:50.000Z",
    "updatedAt": "2025-10-09T19:47:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08777v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08777v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08770v1",
    "arxivId": "2510.08770v1",
    "title": "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform",
    "abstract": "This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset (4,000 images), our experiments demonstrate the advantages of thermal imaging in inference speed, accuracy, and model size. We achieve up to 100% accuracy using lightweight models like VGG19 and NasNetMobile, with thermal models performing faster and more robustly across different lighting conditions. Our system runs on consumer-grade hardware (RTX 4080) and achieves inference times as low as 44 ms with model sizes under 350 MB, highlighting its deployability in safety-critical contexts. Results from experiments with a real robot and test datasets indicate that a VGG19 model trained on thermal imaging performs best.",
    "authors": [
      "Gregory Yeghiyan",
      "Jurius Azar",
      "Devson Butani",
      "Chan-Jin Chung"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T19:40:58.000Z",
    "updatedAt": "2025-10-09T19:40:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08770v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08770v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08769v1",
    "arxivId": "2510.08769v1",
    "title": "Prioritizing Latency with Profit: A DRL-Based Admission Control for 5G Network Slices",
    "abstract": "5G networks enable diverse services such as eMBB, URLLC, and mMTC through network slicing, necessitating intelligent admission control and resource allocation to meet stringent QoS requirements while maximizing Network Service Provider (NSP) profits. However, existing Deep Reinforcement Learning (DRL) frameworks focus primarily on profit optimization without explicitly accounting for service delay, potentially leading to QoS violations for latency-sensitive slices. Moreover, commonly used epsilon-greedy exploration of DRL often results in unstable convergence and suboptimal policy learning. To address these gaps, we propose DePSAC -- a Delay and Profit-aware Slice Admission Control scheme. Our DRL-based approach incorporates a delay-aware reward function, where penalties due to service delay incentivize the prioritization of latency-critical slices such as URLLC. Additionally, we employ Boltzmann exploration to achieve smoother and faster convergence. We implement and evaluate DePSAC on a simulated 5G core network substrate with realistic Network Slice Request (NSLR) arrival patterns. Experimental results demonstrate that our method outperforms the DSARA baseline in terms of overall profit, reduced URLLC slice delays, improved acceptance rates, and improved resource consumption. These findings validate the effectiveness of the proposed DePSAC in achieving better QoS-profit trade-offs for practical 5G network slicing scenarios.",
    "authors": [
      "Proggya Chakraborty",
      "Aaquib Asrar",
      "Jayasree Sengupta",
      "Sipra Das Bit"
    ],
    "categories": [
      "cs.NI",
      "cs.LG",
      "cs.PF"
    ],
    "publishedAt": "2025-10-09T19:36:38.000Z",
    "updatedAt": "2025-10-09T19:36:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08769v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08769v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08768v1",
    "arxivId": "2510.08768v1",
    "title": "Zero-Shot Policy Transfer in Reinforcement Learning using Buckingham's Pi Theorem",
    "abstract": "Reinforcement learning (RL) policies often fail to generalize to new robots, tasks, or environments with different physical parameters, a challenge that limits their real-world applicability. This paper presents a simple, zero-shot transfer method based on Buckingham's Pi Theorem to address this limitation. The method adapts a pre-trained policy to new system contexts by scaling its inputs (observations) and outputs (actions) through a dimensionless space, requiring no retraining. The approach is evaluated against a naive transfer baseline across three environments of increasing complexity: a simulated pendulum, a physical pendulum for sim-to-real validation, and the high-dimensional HalfCheetah. Results demonstrate that the scaled transfer exhibits no loss of performance on dynamically similar contexts. Furthermore, on non-similar contexts, the scaled policy consistently outperforms the naive transfer, significantly expanding the volume of contexts where the original policy remains effective. These findings demonstrate that dimensional analysis provides a powerful and practical tool to enhance the robustness and generalization of RL policies.",
    "authors": [
      "Francisco Pascoa",
      "Ian Lalonde",
      "Alexandre Girard"
    ],
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T19:36:18.000Z",
    "updatedAt": "2025-10-09T19:36:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08768v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08768v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08759v1",
    "arxivId": "2510.08759v1",
    "title": "BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities",
    "abstract": "Embodied capabilities refer to a suite of fundamental abilities for an agent to perceive, comprehend, and interact with the physical world. While multimodal large language models (MLLMs) show promise as embodied agents, a thorough and systematic evaluation of their embodied capabilities remains underexplored, as existing benchmarks primarily focus on specific domains such as planning or spatial understanding. To bridge this gap, we introduce BEAR, a comprehensive and fine-grained benchmark that evaluates MLLMs on atomic embodied capabilities. BEAR comprises 4,469 interleaved image-video-text entries across 14 domains in 6 categories, including tasks from low-level pointing, trajectory understanding, spatial reasoning, to high-level planning. Extensive evaluation results of 20 representative MLLMs reveal their persistent limitations across all domains of embodied capabilities. To tackle the shortfall, we propose BEAR-Agent, a multimodal conversable agent that integrates pretrained vision models to strengthen MLLM perception, 3D understanding, and planning capabilities. It substantially enhances MLLM performance across diverse embodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative improvement of 17.5% on GPT-5. Furthermore, our experiments indicate that improving MLLM embodied capabilities can benefit embodied tasks in simulated environments. Project website: https://bear-official66.github.io/",
    "authors": [
      "Yu Qi",
      "Haibo Zhao",
      "Ziyu Guo",
      "Siyuan Ma",
      "Ziyan Chen",
      "Yaokun Han",
      "Renrui Zhang",
      "Zitiantao Lin",
      "Shiji Xin",
      "Yijian Huang",
      "Kai Cheng",
      "Peiheng Wang",
      "Jiazheng Liu",
      "Jiayi Zhang",
      "Yizhe Zhu",
      "Wenqing Wang",
      "Yiran Qin",
      "Xupeng Zhu",
      "Haojie Huang",
      "Lawson L. S. Wong"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T19:18:36.000Z",
    "updatedAt": "2025-10-09T19:18:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08759v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08759v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08754v1",
    "arxivId": "2510.08754v1",
    "title": "Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis",
    "abstract": "Developing table tennis robots that mirror human speed, accuracy, and ability to predict and respond to the full range of ball spins remains a significant challenge for legged robots. To demonstrate these capabilities we present a system to play dynamic table tennis for quadrupedal robots that integrates high speed perception, trajectory prediction, and agile control. Our system uses external cameras for high-speed ball localization, physical models with learned residuals to infer spin and predict trajectories, and a novel model predictive control (MPC) formulation for agile full-body control. Notably, a continuous set of stroke strategies emerge automatically from different ball return objectives using this control paradigm. We demonstrate our system in the real world on a Spot quadruped, evaluate accuracy of each system component, and exhibit coordination through the system's ability to aim and return balls with varying spin types. As a further demonstration, the system is able to rally with human players.",
    "authors": [
      "David Nguyen",
      "Zulfiqar Zaidi",
      "Kevin Karol",
      "Jessica Hodgins",
      "Zhaoming Xie"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-09T19:12:05.000Z",
    "updatedAt": "2025-10-09T19:12:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08754v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08754v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08753v1",
    "arxivId": "2510.08753v1",
    "title": "Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics",
    "abstract": "Operating high degree of freedom robots can be difficult for users of wheelchair mounted robotic manipulators. Mode switching in Cartesian space has several drawbacks such as unintuitive control reference frames, separate translation and orientation control, and limited movement capabilities that hinder performance. We propose Point and Go mode switching, which reallocates the Cartesian mode switching reference frames into a more intuitive action space comprised of new translation and rotation modes. We use a novel sweeping motion to point the gripper, which defines the new translation axis along the robot base frame's horizontal plane. This creates an intuitive `point and go' translation mode that allows the user to easily perform complex, human-like movements without switching control modes. The system's rotation mode combines position control with a refined end-effector oriented frame that provides precise and consistent robot actions in various end-effector poses. We verified its effectiveness through initial experiments, followed by a three-task user study that compared our method to Cartesian mode switching and a state of the art learning method. Results show that Point and Go mode switching reduced completion times by 31\\%, pauses by 41\\%, and mode switches by 33\\%, while receiving significantly favorable responses in user surveys.",
    "authors": [
      "A. Wang",
      "C. Jiang",
      "M. Przystupa",
      "J. Valentine",
      "M. Jagersand"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T19:11:38.000Z",
    "updatedAt": "2025-10-09T19:11:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08753v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08753v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08742v1",
    "arxivId": "2510.08742v1",
    "title": "Unending Sequential Auctions",
    "abstract": "Sequential auctions for identical items with unit-demand, private-value buyers are common and often occur periodically without end, as new bidders replace departing ones. We model bidder uncertainty by introducing a probability that a bidder must exit the auction in each period. Treating the sequential auction as a Markov process, we demonstrate the existence of a unique steady state. In the absence of uncertainty, the steady state resembles a posted-price mechanism: bidders with values above a threshold almost surely win items by repeatedly bidding the threshold price, while those below the threshold almost surely do not. The equilibrium price corresponds to the threshold value that balances supply (bidders with values above the threshold) and demand (auction winners). When uncertainty is introduced, the threshold value persists but becomes less precise, growing \"fuzzier\" as uncertainty increases. This uncertainty benefits low-value bidders, those below the threshold, by giving them a significant chance of winning. Surprisingly, high-value bidders also benefit from uncertainty, up to a certain value limit, as it lowers equilibrium bids and increases their expected utility. On the other hand, this bidder uncertainty often reduces the auctioneer's utility.",
    "authors": [
      "Amir Ban"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-09T18:54:05.000Z",
    "updatedAt": "2025-10-09T18:54:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08742v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08742v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08731v1",
    "arxivId": "2510.08731v1",
    "title": "When to Reason: Semantic Router for vLLM",
    "abstract": "Large Language Models (LLMs) demonstrate substantial accuracy gains when augmented with reasoning modes such as chain-of-thought and inference-time scaling. However, reasoning also incurs significant costs in inference latency and token usage, with environmental and financial impacts, which are unnecessary for many simple prompts. We present a semantic router that classifies queries based on their reasoning requirements and selectively applies reasoning only when beneficial. Our approach achieves a 10.2 percentage point improvement in accuracy on the MMLU-Pro benchmark while reducing response latency by 47.1% and token consumption by 48.5% compared to direct inference with vLLM. These results demonstrate that semantic routing offers an effective mechanism for striking a balance between accuracy and efficiency in open-source LLM serving systems",
    "authors": [
      "Chen Wang",
      "Xunzhuo Liu",
      "Yuhan Liu",
      "Yue Zhu",
      "Xiangxi Mo",
      "Junchen Jiang",
      "Huamin Chen"
    ],
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.CL",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-09T18:38:00.000Z",
    "updatedAt": "2025-10-09T18:38:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08731v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08731v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08726v1",
    "arxivId": "2510.08726v1",
    "title": "Neptune: Advanced ML Operator Fusion for Locality and Parallelism on GPUs",
    "abstract": "Operator fusion has become a key optimization for deep learning, which combines multiple deep learning operators to improve data reuse and reduce global memory transfers. However, existing tensor compilers struggle to fuse complex reduction computations involving loop-carried dependencies, such as attention mechanisms. The paper introduces Neptune, a tensor compiler for advanced operator fusion for sequences of reduction operators. Neptune presents a new approach for advanced operator fusion, which intentionally breaks some existing dependencies and compensates by constructing algebraic correction expressions that allow the kernel to produce the correct result. On ten attention-based benchmarks, Neptune, starting from simple attention code and a high-level scheduling template, outperforms existing compilers like Triton, TVM, and FlexAttention, including Triton-based implementations of FlashAttention. Across four different GPU architectures from NVIDIA and AMD, Neptune-generated kernels have average speedup of $1.35\\times$ over the next best alternative, demonstrating its effectiveness for deep learning workloads.",
    "authors": [
      "Yifan Zhao",
      "Egan Johnson",
      "Prasanth Chatarasi",
      "Vikram Adve",
      "Sasa Misailovic"
    ],
    "categories": [
      "cs.PL",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T18:33:52.000Z",
    "updatedAt": "2025-10-09T18:33:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08726v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08726v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08723v1",
    "arxivId": "2510.08723v1",
    "title": "SoK: Scope and Mission of CS&Law",
    "abstract": "We systematize the intellectual scope of the ACM Computer Science and Law Symposium (CS&Law). In particular, we address the meaning and importance of the word ''and'' in the name of the symposium. We identify previously published papers (from CS&Law and other forums) that exemplify different aspects of the CS&Law scope and note that the scope is expected to evolve as the symposium and the community grow and change. To round out our systematization of the still nascent research area, we also discuss the mission of CS&Law: What might the symposium seek to accomplish beyond providing a forum for intellectual exchange and community formation?",
    "authors": [
      "Joan Feigenbaum",
      "Daniel J. Weitzner"
    ],
    "categories": [
      "cs.DL",
      "cs.CY"
    ],
    "publishedAt": "2025-10-09T18:32:31.000Z",
    "updatedAt": "2025-10-09T18:32:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08723v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08723v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08716v1",
    "arxivId": "2510.08716v1",
    "title": "Search-based Hyperparameter Tuning for Python Unit Test Generation",
    "abstract": "Search-based test-generation algorithms have countless configuration options. Users rarely adjust these options and usually stick to the default values, which may not lead to the best possible results. Tuning an algorithm's hyperparameters is a method to find better hyperparameter values, but it typically comes with a high demand of resources. Meta-heuristic search algorithms -- that effectively solve the test-generation problem -- have been proposed as a solution to also efficiently tune parameters. In this work we explore the use of differential evolution as a means for tuning the hyperparameters of the DynaMOSA and MIO many-objective search algorithms as implemented in the Pynguin framework. Our results show that significant improvement of the resulting test suite's coverage is possible with the tuned DynaMOSA algorithm and that differential evolution is more efficient than basic grid search.",
    "authors": [
      "Stephan Lukasczyk",
      "Gordon Fraser"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T18:22:07.000Z",
    "updatedAt": "2025-10-09T18:22:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08716v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08716v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08713v1",
    "arxivId": "2510.08713v1",
    "title": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation",
    "abstract": "Enabling embodied agents to effectively imagine future states is critical for robust and generalizable visual navigation. Current state-of-the-art approaches, however, adopt modular architectures that separate navigation planning from visual world modeling, leading to state-action misalignment and limited adaptability in novel or dynamic scenarios. To overcome this fundamental limitation, we propose UniWM, a unified, memory-augmented world model integrating egocentric visual foresight and planning within a single multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly grounds action decisions in visually imagined outcomes, ensuring tight alignment between prediction and control. A hierarchical memory mechanism further integrates detailed short-term perceptual cues with longer-term trajectory context, enabling stable, coherent reasoning over extended horizons. Extensive experiments across four challenging benchmarks (Go Stanford, ReCon, SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success rates by up to 30%, significantly reduces trajectory errors compared to strong baselines, and exhibits impressive zero-shot generalization on the unseen TartanDrive dataset. These results highlight UniWM as a principled step toward unified, imagination-driven embodied navigation.",
    "authors": [
      "Yifei Dong",
      "Fengyi Wu",
      "Guangyu Chen",
      "Zhi-Qi Cheng",
      "Qiyu Hu",
      "Yuxuan Zhou",
      "Jingdong Sun",
      "Jun-Yan He",
      "Qi Dai",
      "Alexander G Hauptmann"
    ],
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T18:18:11.000Z",
    "updatedAt": "2025-10-09T18:18:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08713v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08713v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08705v1",
    "arxivId": "2510.08705v1",
    "title": "ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing",
    "abstract": "Object transportation in cluttered environments is a fundamental task in various domains, including domestic service and warehouse logistics. In cooperative object transport, multiple robots must coordinate to move objects that are too large for a single robot. One transport strategy is pushing, which only requires simple robots. However, careful selection of robot-object contact points is necessary to push the object along a preplanned path. Although this selection can be solved analytically, the solution space grows combinatorially with the number of robots and object size, limiting scalability. Inspired by how humans rely on common-sense reasoning for cooperative transport, we propose combining the reasoning capabilities of Large Language Models with local search to select suitable contact points. Our LLM-guided local search method for contact point selection, ConPoSe, successfully selects contact points for a variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate that ConPoSe scales better with the number of robots and object size than the analytical approach, and also outperforms pure LLM-based selection.",
    "authors": [
      "Noah Steinkrüger",
      "Nisarga Nilavadi",
      "Wolfram Burgard",
      "Tanja Katharina Kaiser"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T18:07:39.000Z",
    "updatedAt": "2025-10-09T18:07:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08705v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08705v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08700v1",
    "arxivId": "2510.08700v1",
    "title": "Are Voters Willing to Collectively Secure Elections? Unraveling a Practical Blockchain Voting System",
    "abstract": "Ensuring ballot secrecy is critical for fair and trustworthy electronic voting systems, yet achieving strong secrecy guarantees in decentralized, large-scale elections remains challenging. This paper proposes the concept of collectively secure voting, in which voters themselves can opt in as secret holders to protect ballot secrecy. A practical blockchain-based collectively secure voting system is designed and implemented. Our design strikes a balance between strong confidentiality guarantees and real-world applicability. The proposed system combines threshold cryptography and smart contracts to ensure ballots remain confidential during voting, while all protocol steps remain transparent and verifiable. Voters can use the system without prior blockchain knowledge through an intuitive user interface that hides underlying complexity. To evaluate this approach, a user testing is conducted. Results show a high willingness to act as secret holders, reliable participation in share release, and high security confidence in the proposed system. The findings demonstrate that voters can collectively maintain secrecy and that such a practical deployment is feasible.",
    "authors": [
      "Zhuolun Li",
      "Haluk Sonmezler",
      "Faiza Shirazi",
      "Febin Shaji",
      "Tymoteusz Mroczkowski",
      "Dexter Lardner",
      "Matthew Alain Camus",
      "Evangelos Pournaras"
    ],
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T18:02:40.000Z",
    "updatedAt": "2025-10-09T18:02:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08700v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08700v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08697v1",
    "arxivId": "2510.08697v1",
    "title": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution",
    "abstract": "Crowdsourced model evaluation platforms, such as Chatbot Arena, enable real-time evaluation from human perspectives to assess the quality of model responses. In the coding domain, manually examining the quality of LLM-generated content is extremely challenging, as it requires understanding long chunks of raw code and deliberately simulating code execution. To this end, we introduce BigCodeArena, an open human evaluation platform for code generation backed by a comprehensive and on-the-fly execution environment. Built on top of Chatbot Arena, BigCodeArena enables the execution of LLM-generated code and allows humans to interact with the execution process and outcomes. We collected over 14,000 raw code-centric conversation sessions across 10 widely used LLMs, spanning 10 languages and 8 types of execution environments. Among these conversations, we identified more than 4,700 multi-turn samples with pairwise human preferences. Further analysis uncovers underexplored preferences of LLMs in fine-grained domains characterized by tasks, languages, and frameworks. To systematically examine code understanding and generation capabilities of frontier LLMs, we curated two benchmarks based on the collected data, namely BigCodeReward and AutoCodeArena. For BigCodeReward, we post-processed the 4,700 conversations and evaluated the consistency between reward models and human preferences. The evaluation shows that most LLMs have superior performance in judging coding preferences when the execution results are available. Inspired by these findings, we propose AutoCodeArena, an automatic Elo rating benchmark designed to assess the coding quality of LLMs without human involvement. We find that proprietary LLMs like GPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation performance among recent emerging models.",
    "authors": [
      "Terry Yue Zhuo",
      "Xiaolong Jin",
      "Hange Liu",
      "Juyong Jiang",
      "Tianyang Liu",
      "Chen Gong",
      "Bhupesh Bishnoi",
      "Vaisakhi Mishra",
      "Marek Suppa",
      "Noah Ziems",
      "Saiteja Utpala",
      "Ming Xu",
      "Guangyu Song",
      "Kaixin Li",
      "Yuhan Cao",
      "Bo Liu",
      "Zheng Liu",
      "Sabina Abdurakhmanova",
      "Wenhao Yu",
      "Mengzhao Jia",
      "Jihan Yao",
      "Kenneth Hamilton",
      "Kumar Shridhar",
      "Minh Chien Vu",
      "Dingmin Wang",
      "Jiawei Liu",
      "Zijian Wang",
      "Qian Liu",
      "Binyuan Hui",
      "Meg Risdal",
      "Ahsen Khaliq",
      "Atin Sood",
      "Zhenchang Xing",
      "Wasi Uddin Ahmad",
      "John Grundy",
      "David Lo",
      "Banghua Zhu",
      "Xiaoning Du",
      "Torsten Scholak",
      "Leandro von Werra"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "publishedAt": "2025-10-09T18:01:47.000Z",
    "updatedAt": "2025-10-09T18:01:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08697v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08697v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08572v1",
    "arxivId": "2510.08572v1",
    "title": "BLAZER: Bootstrapping LLM-based Manipulation Agents with Zero-Shot Data Generation",
    "abstract": "Scaling data and models has played a pivotal role in the remarkable progress of computer vision and language. Inspired by these domains, recent efforts in robotics have similarly focused on scaling both data and model size to develop more generalizable and robust policies. However, unlike vision and language, robotics lacks access to internet-scale demonstrations across diverse robotic tasks and environments. As a result, the scale of existing datasets typically suffers from the need for manual data collection and curation. To address this problem, here we propose BLAZER, a framework that learns manipulation policies from automatically generated training data. We build on the zero-shot capabilities of LLM planners and automatically generate demonstrations for diverse manipulation tasks in simulation. Successful examples are then used to finetune an LLM and to improve its planning capabilities without human supervision. Notably, while BLAZER training requires access to the simulator's state, we demonstrate direct transfer of acquired skills to sensor-based manipulation. Through extensive experiments, we show BLAZER to significantly improve zero-shot manipulation in both simulated and real environments. Moreover, BLAZER improves on tasks outside of its training pool and enables downscaling of LLM models. Our code and data will be made publicly available on the project page.",
    "authors": [
      "Rocktim Jyoti Das",
      "Harsh Singh",
      "Diana Turmakhan",
      "Muhammad Abdullah Sohail",
      "Mingfei Han",
      "Preslav Nakov",
      "Fabio Pizzati",
      "Ivan Laptev"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T17:59:58.000Z",
    "updatedAt": "2025-10-09T17:59:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08572v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08572v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08571v1",
    "arxivId": "2510.08571v1",
    "title": "Scalable Offline Metrics for Autonomous Driving",
    "abstract": "Real-World evaluation of perception-based planning models for robotic systems, such as autonomous vehicles, can be safely and inexpensively conducted offline, i.e., by computing model prediction error over a pre-collected validation dataset with ground-truth annotations. However, extrapolating from offline model performance to online settings remains a challenge. In these settings, seemingly minor errors can compound and result in test-time infractions or collisions. This relationship is understudied, particularly across diverse closed-loop metrics and complex urban maneuvers. In this work, we revisit this undervalued question in policy evaluation through an extensive set of experiments across diverse conditions and metrics. Based on analysis in simulation, we find an even worse correlation between offline and online settings than reported by prior studies, casting doubts on the validity of current evaluation practices and metrics for driving policies. Next, we bridge the gap between offline and online evaluation. We investigate an offline metric based on epistemic uncertainty, which aims to capture events that are likely to cause errors in closed-loop settings. The resulting metric achieves over 13% improvement in correlation compared to previous offline metrics. We further validate the generalization of our findings beyond the simulation environment in real-world settings, where even greater gains are observed.",
    "authors": [
      "Animikh Aich",
      "Adwait Kulkarni",
      "Eshed Ohn-Bar"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T17:59:57.000Z",
    "updatedAt": "2025-10-09T17:59:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08571v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08571v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08568v1",
    "arxivId": "2510.08568v1",
    "title": "NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos",
    "abstract": "Enabling robots to execute novel manipulation tasks zero-shot is a central goal in robotics. Most existing methods assume in-distribution tasks or rely on fine-tuning with embodiment-matched data, limiting transfer across platforms. We present NovaFlow, an autonomous manipulation framework that converts a task description into an actionable plan for a target robot without any demonstrations. Given a task description, NovaFlow synthesizes a video using a video generation model and distills it into 3D actionable object flow using off-the-shelf perception modules. From the object flow, it computes relative poses for rigid objects and realizes them as robot actions via grasp proposals and trajectory optimization. For deformable objects, this flow serves as a tracking objective for model-based planning with a particle-based dynamics model. By decoupling task understanding from low-level control, NovaFlow naturally transfers across embodiments. We validate on rigid, articulated, and deformable object manipulation tasks using a table-top Franka arm and a Spot quadrupedal mobile robot, and achieve effective zero-shot execution without demonstrations or embodiment-specific training. Project website: https://novaflow.lhy.xyz/.",
    "authors": [
      "Hongyu Li",
      "Lingfeng Sun",
      "Yafei Hu",
      "Duy Ta",
      "Jennifer Barry",
      "George Konidaris",
      "Jiahui Fu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T17:59:55.000Z",
    "updatedAt": "2025-10-09T17:59:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08568v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08568v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08562v1",
    "arxivId": "2510.08562v1",
    "title": "ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving",
    "abstract": "End-to-end autonomous driving (E2EAD) systems, which learn to predict future trajectories directly from sensor data, are fundamentally challenged by the inherent spatio-temporal imbalance of trajectory data. This imbalance creates a significant optimization burden, causing models to learn spurious correlations instead of causal inference, while also prioritizing uncertain, distant predictions, thereby compromising immediate safety. To address these issues, we propose ResAD, a novel Normalized Residual Trajectory Modeling framework. Instead of predicting the future trajectory directly, our approach reframes the learning task to predict the residual deviation from a deterministic inertial reference. The inertial reference serves as a counterfactual, forcing the model to move beyond simple pattern recognition and instead identify the underlying causal factors (e.g., traffic rules, obstacles) that necessitate deviations from a default, inertially-guided path. To deal with the optimization imbalance caused by uncertain, long-term horizons, ResAD further incorporates Point-wise Normalization of the predicted residual. It re-weights the optimization objective, preventing large-magnitude errors associated with distant, uncertain waypoints from dominating the learning signal. Extensive experiments validate the effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a state-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two denoising steps, demonstrating that our approach significantly simplifies the learning task and improves model performance. The code will be released to facilitate further research.",
    "authors": [
      "Zhiyu Zheng",
      "Shaoyu Chen",
      "Haoran Yin",
      "Xinbang Zhang",
      "Jialv Zou",
      "Xinggang Wang",
      "Qian Zhang",
      "Lefei Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T17:59:36.000Z",
    "updatedAt": "2025-10-09T17:59:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08562v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08562v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08556v1",
    "arxivId": "2510.08556v1",
    "title": "DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model",
    "abstract": "Achieving generalized in-hand object rotation remains a significant challenge in robotics, largely due to the difficulty of transferring policies from simulation to the real world. The complex, contact-rich dynamics of dexterous manipulation create a \"reality gap\" that has limited prior work to constrained scenarios involving simple geometries, limited object sizes and aspect ratios, constrained wrist poses, or customized hands. We address this sim-to-real challenge with a novel framework that enables a single policy, trained in simulation, to generalize to a wide variety of objects and conditions in the real world. The core of our method is a joint-wise dynamics model that learns to bridge the reality gap by effectively fitting limited amount of real-world collected data and then adapting the sim policy's actions accordingly. The model is highly data-efficient and generalizable across different whole-hand interaction distributions by factorizing dynamics across joints, compressing system-wide influences into low-dimensional variables, and learning each joint's evolution from its own dynamic profile, implicitly capturing these net effects. We pair this with a fully autonomous data collection strategy that gathers diverse, real-world interaction data with minimal human intervention. Our complete pipeline demonstrates unprecedented generality: a single policy successfully rotates challenging objects with complex shapes (e.g., animals), high aspect ratios (up to 5.33), and small sizes, all while handling diverse wrist orientations and rotation axes. Comprehensive real-world evaluations and a teleoperation application for complex tasks validate the effectiveness and robustness of our approach. Website: https://meowuu7.github.io/DexNDM/",
    "authors": [
      "Xueyi Liu",
      "He Wang",
      "Li Yi"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T17:59:11.000Z",
    "updatedAt": "2025-10-09T17:59:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08556v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08556v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08553v1",
    "arxivId": "2510.08553v1",
    "title": "Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation",
    "abstract": "Vision-and-Language Navigation (VLN) requires agents to follow natural language instructions through environments, with memory-persistent variants demanding progressive improvement through accumulated experience. Existing approaches for memory-persistent VLN face critical limitations: they lack effective memory access mechanisms, instead relying on entire memory incorporation or fixed-horizon lookup, and predominantly store only environmental observations while neglecting navigation behavioral patterns that encode valuable decision-making strategies. We present Memoir, which employs imagination as a retrieval mechanism grounded by explicit memory: a world model imagines future navigation states as queries to selectively retrieve relevant environmental observations and behavioral histories. The approach comprises: 1) a language-conditioned world model that imagines future states serving dual purposes: encoding experiences for storage and generating retrieval queries; 2) Hybrid Viewpoint-Level Memory that anchors both observations and behavioral patterns to viewpoints, enabling hybrid retrieval; and 3) an experience-augmented navigation model that integrates retrieved knowledge through specialized encoders. Extensive evaluation across diverse memory-persistent VLN benchmarks with 10 distinctive testing scenarios demonstrates Memoir's effectiveness: significant improvements across all scenarios, with 5.4% SPL gains on IR2R over the best memory-persistent baseline, accompanied by 8.3x training speedup and 74% inference memory reduction. The results validate that predictive retrieval of both environmental and behavioral memories enables more effective navigation, with analysis indicating substantial headroom (73.3% vs 93.4% upper bound) for this imagination-guided paradigm. Code at https://github.com/xyz9911/Memoir.",
    "authors": [
      "Yunzhe Xu",
      "Yiyuan Pan",
      "Zhe Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T17:58:01.000Z",
    "updatedAt": "2025-10-09T17:58:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08553v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08553v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08547v1",
    "arxivId": "2510.08547v1",
    "title": "R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation",
    "abstract": "Towards the aim of generalized robotic manipulation, spatial generalization is the most fundamental capability that requires the policy to work robustly under different spatial distribution of objects, environment and agent itself. To achieve this, substantial human demonstrations need to be collected to cover different spatial configurations for training a generalized visuomotor policy via imitation learning. Prior works explore a promising direction that leverages data generation to acquire abundant spatially diverse data from minimal source demonstrations. However, most approaches face significant sim-to-real gap and are often limited to constrained settings, such as fixed-base scenarios and predefined camera viewpoints. In this paper, we propose a real-to-real 3D data generation framework (R2RGen) that directly augments the pointcloud observation-action pairs to generate real-world data. R2RGen is simulator- and rendering-free, thus being efficient and plug-and-play. Specifically, given a single source demonstration, we introduce an annotation mechanism for fine-grained parsing of scene and trajectory. A group-wise augmentation strategy is proposed to handle complex multi-object compositions and diverse task constraints. We further present camera-aware processing to align the distribution of generated data with real-world 3D sensor. Empirically, R2RGen substantially enhances data efficiency on extensive experiments and demonstrates strong potential for scaling and application on mobile manipulation.",
    "authors": [
      "Xiuwei Xu",
      "Angyuan Ma",
      "Hankun Li",
      "Bingyao Yu",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T17:55:44.000Z",
    "updatedAt": "2025-10-09T17:55:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08547v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08547v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08544v1",
    "arxivId": "2510.08544v1",
    "title": "SPAD: Specialized Prefill and Decode Hardware for Disaggregated LLM Inference",
    "abstract": "Large Language Models (LLMs) have gained popularity in recent years, driving up the demand for inference. LLM inference is composed of two phases with distinct characteristics: a compute-bound prefill phase followed by a memory-bound decode phase. To efficiently serve LLMs, prior work proposes prefill-decode disaggregation to run each phase on separate hardware. However, existing hardware poorly matches the different requirements of each phase. Current datacenter GPUs and TPUs follow a more-is-better design philosophy that maximizes compute and memory resources, causing memory bandwidth underutilization in the prefill phase and compute underutilization in the decode phase. Such underutilization directly translates into increased serving costs. This paper proposes SPAD (Specialized Prefill and Decode hardware), adopting a less-is-more methodology to design specialized chips tailored to the distinct characteristics of prefill and decode phases. The proposed Prefill Chips have larger systolic arrays and use cost-effective GDDR memory, whereas the proposed Decode Chips retain high memory bandwidth but reduce compute capacity. Compared to modeled H100s, simulations show that the proposed Prefill Chips deliver 8% higher prefill performance on average at 52% lower hardware cost, while the proposed Decode Chips achieve 97% of the decode performance with 28% lower TDP. End-to-end simulations on production traces show that SPAD reduces hardware cost by 19%-41% and TDP by 2%-17% compared to modeled baseline clusters while offering the same performance. Even when models and workloads change, SPAD can reallocate either type of chip to run either phase and still achieve 11%-43% lower hardware costs, demonstrating the longevity of the SPAD design.",
    "authors": [
      "Hengrui Zhang",
      "Pratyush Patel",
      "August Ning",
      "David Wentzlaff"
    ],
    "categories": [
      "cs.AR",
      "cs.DC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T17:55:08.000Z",
    "updatedAt": "2025-10-09T17:55:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08544v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08544v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08542v1",
    "arxivId": "2510.08542v1",
    "title": "A Dobrushin condition for quantum Markov chains: Rapid mixing and conditional mutual information at high temperature",
    "abstract": "A central challenge in quantum physics is to understand the structural properties of many-body systems, both in equilibrium and out of equilibrium. For classical systems, we have a unified perspective which connects structural properties of systems at thermal equilibrium to the Markov chain dynamics that mix to them. We lack such a perspective for quantum systems: there is no framework to translate the quantitative convergence of the Markovian evolution into strong structural consequences. We develop a general framework that brings the breadth and flexibility of the classical theory to quantum Gibbs states at high temperature. At its core is a natural quantum analog of a Dobrushin condition; whenever this condition holds, a concise path-coupling argument proves rapid mixing for the corresponding Markovian evolution. The same machinery bridges dynamic and structural properties: rapid mixing yields exponential decay of conditional mutual information (CMI) without restrictions on the size of the probed subsystems, resolving a central question in the theory of open quantum systems. Our key technical insight is an optimal transport viewpoint which couples quantum dynamics to a linear differential equation, enabling precise control over how local deviations from equilibrium propagate to distant sites.",
    "authors": [
      "Ainesh Bakshi",
      "Allen Liu",
      "Ankur Moitra",
      "Ewin Tang"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T17:54:41.000Z",
    "updatedAt": "2025-10-09T17:54:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08542v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08542v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08541v1",
    "arxivId": "2510.08541v1",
    "title": "Computational and statistical lower bounds for low-rank estimation under general inhomogeneous noise",
    "abstract": "Recent work has generalized several results concerning the well-understood spiked Wigner matrix model of a low-rank signal matrix corrupted by additive i.i.d. Gaussian noise to the inhomogeneous case, where the noise has a variance profile. In particular, for the special case where the variance profile has a block structure, a series of results identified an effective spectral algorithm for detecting and estimating the signal, identified the threshold signal strength required for that algorithm to succeed, and proved information-theoretic lower bounds that, for some special signal distributions, match the above threshold. We complement these results by studying the computational optimality of this spectral algorithm. Namely, we show that, for a much broader range of signal distributions, whenever the spectral algorithm cannot detect a low-rank signal, then neither can any low-degree polynomial algorithm. This gives the first evidence for a computational hardness conjecture of Guionnet, Ko, Krzakala, and Zdeborov\\'a (2023). With similar techniques, we also prove sharp information-theoretic lower bounds for a class of signal distributions not treated by prior work. Unlike all of the above results on inhomogeneous models, our results do not assume that the variance profile has a block structure, and suggest that the same spectral algorithm might remain optimal for quite general profiles. We include a numerical study of this claim for an example of a smoothly-varying rather than piecewise-constant profile. Our proofs involve analyzing the graph sums of a matrix, which also appear in free and traffic probability, but we require new bounds on these quantities that are tighter than existing ones for non-negative matrices, which may be of independent interest.",
    "authors": [
      "Debsurya De",
      "Dmitriy Kunisky"
    ],
    "categories": [
      "math.ST",
      "cs.DS",
      "cs.LG",
      "math.PR",
      "stat.TH"
    ],
    "publishedAt": "2025-10-09T17:53:59.000Z",
    "updatedAt": "2025-10-09T17:53:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08541v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08541v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08536v1",
    "arxivId": "2510.08536v1",
    "title": "Investigating Matrix Repartitioning to Address the Over- and Undersubscription Challenge for a GPU-based CFD Solver",
    "abstract": "Modern high-performance computing (HPC) increasingly relies on GPUs, but integrating GPU acceleration into complex scientific frameworks like OpenFOAM remains a challenge. Existing approaches either fully refactor the codebase or use plugin-based GPU solvers, each facing trade-offs between performance and development effort. In this work, we address the limitations of plugin-based GPU acceleration in OpenFOAM by proposing a repartitioning strategy that better balances CPU matrix assembly and GPU-based linear solves. We present a detailed computational model, describe a novel matrix repartitioning and update procedure, and evaluate its performance on large-scale CFD simulations. Our results show that the proposed method significantly mitigates oversubscription issues, improving solver performance and resource utilization in heterogeneous CPU-GPU environments.",
    "authors": [
      "Gregor Olenik",
      "Marcel Koch",
      "Hartwig Anzt"
    ],
    "categories": [
      "cs.DC",
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T17:53:12.000Z",
    "updatedAt": "2025-10-09T17:53:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08536v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08536v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08530v1",
    "arxivId": "2510.08530v1",
    "title": "X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering",
    "abstract": "We present X2Video, the first diffusion model for rendering photorealistic videos guided by intrinsic channels including albedo, normal, roughness, metallicity, and irradiance, while supporting intuitive multi-modal controls with reference images and text prompts for both global and local regions. The intrinsic guidance allows accurate manipulation of color, material, geometry, and lighting, while reference images and text prompts provide intuitive adjustments in the absence of intrinsic information. To enable these functionalities, we extend the intrinsic-guided image generation model XRGB to video generation by employing a novel and efficient Hybrid Self-Attention, which ensures temporal consistency across video frames and also enhances fidelity to reference images. We further develop a Masked Cross-Attention to disentangle global and local text prompts, applying them effectively onto respective local and global regions. For generating long videos, our novel Recursive Sampling method incorporates progressive frame sampling, combining keyframe prediction and frame interpolation to maintain long-range temporal consistency while preventing error accumulation. To support the training of X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154 rooms from 295 interior scenes, complete with reliable ground-truth intrinsic channel sequences and smooth camera trajectories. Both qualitative and quantitative evaluations demonstrate that X2Video can produce long, temporally consistent, and photorealistic videos guided by intrinsic conditions. Additionally, X2Video effectively accommodates multi-modal controls with reference images, global and local text prompts, and simultaneously supports editing on color, material, geometry, and lighting through parametric tuning. Project page: https://luckyhzt.github.io/x2video",
    "authors": [
      "Zhitong Huang",
      "Mohan Zhang",
      "Renhan Wang",
      "Rui Tang",
      "Hao Zhu",
      "Jing Liao"
    ],
    "categories": [
      "cs.GR",
      "cs.CV",
      "68U05",
      "I.3.3; I.3.6"
    ],
    "publishedAt": "2025-10-09T17:50:31.000Z",
    "updatedAt": "2025-10-09T17:50:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08530v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08530v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08522v1",
    "arxivId": "2510.08522v1",
    "title": "DYNAMIX: RL-based Adaptive Batch Size Optimization in Distributed Machine Learning Systems",
    "abstract": "Existing batch size selection approaches in distributed machine learning rely on static allocation or simplistic heuristics that fail to adapt to heterogeneous, dynamic computing environments. We present DYNAMIX, a reinforcement learning framework that formulates batch size optimization as a sequential decision-making problem using Proximal Policy Optimization (PPO). Our approach employs a multi-dimensional state representation encompassing network-level metrics, system-level resource utilization, and training statistical efficiency indicators to enable informed decision-making across diverse computational resources. Our approach eliminates the need for explicit system modeling while integrating seamlessly with existing distributed training frameworks. Through evaluations across diverse workloads, hardware configurations, and network conditions, DYNAMIX achieves up to 6.3% improvement in the final model accuracy and 46% reduction in the total training time. Our scalability experiments demonstrate that DYNAMIX maintains the best performance as cluster size increases to 32 nodes, while policy transfer experiments show that learned policies generalize effectively across related model architectures.",
    "authors": [
      "Yuanjun Dai",
      "Keqiang He",
      "An Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T17:48:24.000Z",
    "updatedAt": "2025-10-09T17:48:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08522v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08522v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08512v1",
    "arxivId": "2510.08512v1",
    "title": "Have We Scene It All? Scene Graph-Aware Deep Point Cloud Compression",
    "abstract": "Efficient transmission of 3D point cloud data is critical for advanced perception in centralized and decentralized multi-agent robotic systems, especially nowadays with the growing reliance on edge and cloud-based processing. However, the large and complex nature of point clouds creates challenges under bandwidth constraints and intermittent connectivity, often degrading system performance. We propose a deep compression framework based on semantic scene graphs. The method decomposes point clouds into semantically coherent patches and encodes them into compact latent representations with semantic-aware encoders conditioned by Feature-wise Linear Modulation (FiLM). A folding-based decoder, guided by latent features and graph node attributes, enables structurally accurate reconstruction. Experiments on the SemanticKITTI and nuScenes datasets show that the framework achieves state-of-the-art compression rates, reducing data size by up to 98% while preserving both structural and semantic fidelity. In addition, it supports downstream applications such as multi-robot pose graph optimization and map merging, achieving trajectory accuracy and map alignment comparable to those obtained with raw LiDAR scans.",
    "authors": [
      "Nikolaos Stathoulopoulos",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T17:45:09.000Z",
    "updatedAt": "2025-10-09T17:45:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08512v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08512v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08509v1",
    "arxivId": "2510.08509v1",
    "title": "Randomized and quantum approximate matrix multiplication",
    "abstract": "The complexity of matrix multiplication is a central topic in computer science. While the focus has traditionally been on exact algorithms, a long line of literature also considers randomized algorithms, which return an approximate solution in faster time. In this work, we adopt a unifying perspective that frames these randomized algorithms in terms of mean estimation. Using it, we first give refined analyses of classical algorithms based on random walks by Cohen-Lewis (`99), and based on sketching by Sarl\\'os (`06) and Drineas-Kannan-Mahoney (`06). We then propose an improvement on Cohen-Lewis that yields a single classical algorithm that is faster than all the other approaches, if we assume no use of (exact) fast matrix multiplication as a subroutine. Second, we demonstrate a quantum speedup on top of these algorithms by using the recent quantum multivariate mean estimation algorithm by Cornelissen-Hamoudi-Jerbi (`22).",
    "authors": [
      "Simon Apers",
      "Arjan Cornelissen",
      "Samson Wang"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T17:44:03.000Z",
    "updatedAt": "2025-10-09T17:44:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08509v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08509v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08499v1",
    "arxivId": "2510.08499v1",
    "title": "Quantum Probe Tomography",
    "abstract": "Characterizing quantum many-body systems is a fundamental problem across physics, chemistry, and materials science. While significant progress has been made, many existing Hamiltonian learning protocols demand digital quantum control over the entire system, creating a disconnect from many real-world settings that provide access only through small, local probes. Motivated by this, we introduce and formalize the problem of quantum probe tomography, where one seeks to learn the parameters of a many-body Hamiltonian using a single local probe access to a small subsystem of a many-body thermal state undergoing time evolution. We address the identifiability problem of determining which Hamiltonians can be distinguished from probe data through a new combination of tools from algebraic geometry and smoothed analysis. Using this approach, we prove that generic Hamiltonians in various physically natural families are identifiable up to simple, unavoidable structural symmetries. Building on these insights, we design the first efficient end-to-end algorithm for probe tomography that learns Hamiltonian parameters to accuracy $\\varepsilon$, with query complexity scaling polynomially in $1/\\varepsilon$ and classical post-processing time scaling polylogarithmically in $1/\\varepsilon$. In particular, we demonstrate that translation- and rotation-invariant nearest-neighbor Hamiltonians on square lattices in one, two, and three dimensions can be efficiently reconstructed from single-site probes of the Gibbs state, up to inversion symmetry about the probed site. Our results demonstrate that robust Hamiltonian learning remains achievable even under severely constrained experimental access.",
    "authors": [
      "Sitan Chen",
      "Jordan Cotler",
      "Hsin-Yuan Huang"
    ],
    "categories": [
      "quant-ph",
      "cond-mat.str-el",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T17:39:37.000Z",
    "updatedAt": "2025-10-09T17:39:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08499v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08499v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08494v1",
    "arxivId": "2510.08494v1",
    "title": "Quartic quantum speedups for community detection",
    "abstract": "Community detection is a foundational problem in data science. Its natural extension to hypergraphs captures higher-order correlations beyond pairwise interactions. In this work, we develop a quantum algorithm for hypergraph community detection that achieves a quartic quantum speedup over the best known classical algorithm, along with superpolynomial savings in space. Our algorithm is based on the Kikuchi method, which we extend beyond previously considered problems such as Tensor PCA and $p$XORSAT to a broad family of generalized stochastic block models. To demonstrate (near) optimality of this method, we prove matching lower bounds (up to logarithmic factors) in the low-degree framework, showing that the algorithm saturates a smooth statistical-computational tradeoff. The quantum speedup arises from a quantized version of the Kikuchi method and is based on the efficient preparation of a guiding state correlated with the underlying community structure. Our work suggests that prior quantum speedups using the Kikuchi method are sufficiently robust to encompass a broader set of problems than previously believed; we conjecture that a quantity known as marginal order characterizes the existence of these quantum speedups.",
    "authors": [
      "Alexander Schmidhuber",
      "Alexander Zlokapa"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T17:35:17.000Z",
    "updatedAt": "2025-10-09T17:35:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08494v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08494v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08491v1",
    "arxivId": "2510.08491v1",
    "title": "Splat the Net: Radiance Fields with Splattable Neural Primitives",
    "abstract": "Radiance fields have emerged as a predominant representation for modeling 3D scene appearance. Neural formulations such as Neural Radiance Fields provide high expressivity but require costly ray marching for rendering, whereas primitive-based methods such as 3D Gaussian Splatting offer real-time efficiency through splatting, yet at the expense of representational power. Inspired by advances in both these directions, we introduce splattable neural primitives, a new volumetric representation that reconciles the expressivity of neural models with the efficiency of primitive-based splatting. Each primitive encodes a bounded neural density field parameterized by a shallow neural network. Our formulation admits an exact analytical solution for line integrals, enabling efficient computation of perspectively accurate splatting kernels. As a result, our representation supports integration along view rays without the need for costly ray marching. The primitives flexibly adapt to scene geometry and, being larger than prior analytic primitives, reduce the number required per scene. On novel-view synthesis benchmarks, our approach matches the quality and speed of 3D Gaussian Splatting while using $10\\times$ fewer primitives and $6\\times$ fewer parameters. These advantages arise directly from the representation itself, without reliance on complex control or adaptation frameworks. The project page is https://vcai.mpi-inf.mpg.de/projects/SplatNet/.",
    "authors": [
      "Xilong Zhou",
      "Bao-Huy Nguyen",
      "Loïc Magne",
      "Vladislav Golyanik",
      "Thomas Leimkühler",
      "Christian Theobalt"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T17:31:11.000Z",
    "updatedAt": "2025-10-09T17:31:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08491v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08491v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08481v1",
    "arxivId": "2510.08481v1",
    "title": "Forecasting the Buzz: Enriching Hashtag Popularity Prediction with LLM Reasoning",
    "abstract": "Hashtag trends ignite campaigns, shift public opinion, and steer millions of dollars in advertising spend, yet forecasting which tag goes viral is elusive. Classical regressors digest surface features but ignore context, while large language models (LLMs) excel at contextual reasoning but misestimate numbers. We present BuzzProphet, a reasoning-augmented hashtag popularity prediction framework that (1) instructs an LLM to articulate a hashtag's topical virality, audience reach, and timing advantage; (2) utilizes these popularity-oriented rationales to enrich the input features; and (3) regresses on these inputs. To facilitate evaluation, we release HashView, a 7,532-hashtag benchmark curated from social media. Across diverse regressor-LLM combinations, BuzzProphet reduces RMSE by up to 2.8% and boosts correlation by 30% over baselines, while producing human-readable rationales. Results demonstrate that using LLMs as context reasoners rather than numeric predictors injects domain insight into tabular models, yielding an interpretable and deployable solution for social media trend forecasting.",
    "authors": [
      "Yifei Xu",
      "Jiaying Wu",
      "Herun Wan",
      "Yang Li",
      "Zhen Hou",
      "Min-Yen Kan"
    ],
    "categories": [
      "cs.SI"
    ],
    "publishedAt": "2025-10-09T17:20:54.000Z",
    "updatedAt": "2025-10-09T17:20:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08481v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08481v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08479v2",
    "arxivId": "2510.08479v2",
    "title": "Rethinking Provenance Completeness with a Learning-Based Linux Scheduler",
    "abstract": "Provenance plays a critical role in maintaining traceability of a system's actions for root cause analysis of security threats and impacts. Provenance collection is often incorporated into the reference monitor of systems to ensure that an audit trail exists of all events, that events are completely captured, and that logging of such events cannot be bypassed. However, recent research has questioned whether existing state-of-the-art provenance collection systems fail to ensure the security guarantees of a true reference monitor due to the 'super producer threat' in which provenance generation can overload a system to force the system to drop security-relevant events and allow an attacker to hide their actions. One approach towards solving this threat is to enforce resource isolation, but that does not fully solve the problems resulting from hardware dependencies and performance limitations. In this paper, we show how an operating system's kernel scheduler can mitigate this threat, and we introduce Aegis, a learned scheduler for Linux specifically designed for provenance. Unlike conventional schedulers that ignore provenance completeness requirements, Aegis leverages reinforcement learning to learn provenance task behavior and to dynamically optimize resource allocation. We evaluate Aegis's efficacy and show that Aegis significantly improves both the completeness and efficiency of provenance collection systems compared to traditional scheduling, while maintaining reasonable overheads and even improving overall runtime in certain cases compared to the default Linux scheduler.",
    "authors": [
      "Jinsong Mao",
      "Benjamin E. Ujcich",
      "Shiqing Ma"
    ],
    "categories": [
      "cs.CR",
      "cs.OS"
    ],
    "publishedAt": "2025-10-09T17:18:50.000Z",
    "updatedAt": "2025-10-10T21:24:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08479v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08479v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08475v1",
    "arxivId": "2510.08475v1",
    "title": "DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos",
    "abstract": "We present DexMan, an automated framework that converts human visual demonstrations into bimanual dexterous manipulation skills for humanoid robots in simulation. Operating directly on third-person videos of humans manipulating rigid objects, DexMan eliminates the need for camera calibration, depth sensors, scanned 3D object assets, or ground-truth hand and object motion annotations. Unlike prior approaches that consider only simplified floating hands, it directly controls a humanoid robot and leverages novel contact-based rewards to improve policy learning from noisy hand-object poses estimated from in-the-wild videos. DexMan achieves state-of-the-art performance in object pose estimation on the TACO benchmark, with absolute gains of 0.08 and 0.12 in ADD-S and VSD. Meanwhile, its reinforcement learning policy surpasses previous methods by 19% in success rate on OakInk-v2. Furthermore, DexMan can generate skills from both real and synthetic videos, without the need for manual data collection and costly motion capture, and enabling the creation of large-scale, diverse datasets for training generalist dexterous manipulation.",
    "authors": [
      "Jhen Hsieh",
      "Kuan-Hsun Tu",
      "Kuo-Han Hung",
      "Tsung-Wei Ke"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T17:17:05.000Z",
    "updatedAt": "2025-10-09T17:17:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08475v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08475v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08472v1",
    "arxivId": "2510.08472v1",
    "title": "Agnostic Product Mixed State Tomography via Robust Statistics",
    "abstract": "We consider the problem of agnostic tomography with \\emph{mixed state} ansatz, and specifically, the natural ansatz class of product mixed states. In more detail, given $N$ copies of an $n$-qubit state $\\rho$ which is $\\epsilon$-close to a product mixed state $\\pi$, the goal is to output a nearly-optimal product mixed state approximation to $\\rho$. While there has been a flurry of recent work on agnostic tomography, prior work could only handle pure state ansatz, such as product states or stabilizer states. Here we give an algorithm for agnostic tomography of product mixed states which finds a product state which is $O(\\epsilon \\log 1 / \\epsilon)$ close to $\\rho$ which uses polynomially many copies of $\\rho$, and which runs in polynomial time. Moreover, our algorithm only uses single-qubit, single-copy measurements. To our knowledge, this is the first efficient algorithm that achieves any non-trivial agnostic tomography guarantee for any class of mixed state ansatz. Our algorithm proceeds in two main conceptual steps, which we believe are of independent interest. First, we demonstrate a novel, black-box efficient reduction from agnostic tomography of product mixed states to the classical task of \\emph{robustly learning binary product distributions} -- a textbook problem in robust statistics. We then demonstrate a nearly-optimal efficient algorithm for the classical task of robustly learning a binary product, answering an open problem in the literature. Our approach hinges on developing a new optimal certificate of closeness for binary product distributions that can be leveraged algorithmically via a carefully defined convex relaxation. Finally, we complement our upper bounds with a lower bound demonstrating that adaptivity is information-theoretically necessary for our agnostic tomography task, so long as the algorithm only uses single-qubit two-outcome projective measurements.",
    "authors": [
      "Alvan Arulandu",
      "Ilias Diakonikolas",
      "Daniel Kane",
      "Jerry Li"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T17:13:03.000Z",
    "updatedAt": "2025-10-09T17:13:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08472v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08472v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08469v1",
    "arxivId": "2510.08469v1",
    "title": "Platform-Agnostic Modular Architecture for Quantum Benchmarking",
    "abstract": "We present a platform-agnostic modular architecture that addresses the increasingly fragmented landscape of quantum computing benchmarking by decoupling problem generation, circuit execution, and results analysis into independent, interoperable components. Supporting over 20 benchmark variants ranging from simple algorithmic tests like Bernstein-Vazirani to complex Hamiltonian simulation with observable calculations, the system integrates with multiple circuit generation APIs (Qiskit, CUDA-Q, Cirq) and enables diverse workflows. We validate the architecture through successful integration with Sandia's $\\textit{pyGSTi}$ for advanced circuit analysis and CUDA-Q for multi-GPU HPC simulations. Extensibility of the system is demonstrated by implementing dynamic circuit variants of existing benchmarks and a new quantum reinforcement learning benchmark, which become readily available across multiple execution and analysis modes. Our primary contribution is identifying and formalizing modular interfaces that enable interoperability between incompatible benchmarking frameworks, demonstrating that standardized interfaces reduce ecosystem fragmentation while preserving optimization flexibility. This architecture has been developed as a key enhancement to the continually evolving QED-C Application-Oriented Performance Benchmarks for Quantum Computing suite.",
    "authors": [
      "Neer Patel",
      "Anish Giri",
      "Hrushikesh Pramod Patil",
      "Noah Siekierski",
      "Avimita Chatterjee",
      "Sonika Johri",
      "Timothy Proctor",
      "Thomas Lubinski",
      "Siyuan Niu"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T17:09:56.000Z",
    "updatedAt": "2025-10-09T17:09:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08469v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08469v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08464v1",
    "arxivId": "2510.08464v1",
    "title": "Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered",
    "abstract": "Vision-Language-Action (VLA) models have advanced robotic capabilities but remain challenging to deploy on resource-limited hardware. Pruning has enabled efficient compression of large language models (LLMs), yet it is largely understudied in robotics. Surprisingly, we observe that pruning VLA models leads to drastic degradation and increased safety violations. We introduce GLUESTICK, a post-pruning recovery method that restores much of the original model's functionality while retaining sparsity benefits. Our method performs a one-time interpolation between the dense and pruned models in weight-space to compute a corrective term. This correction is used during inference by each pruned layer to recover lost capabilities with minimal overhead. GLUESTICK requires no additional training, is agnostic to the pruning algorithm, and introduces a single hyperparameter that controls the tradeoff between efficiency and accuracy. Across diverse VLA architectures and tasks in manipulation and navigation, GLUESTICK achieves competitive memory efficiency while substantially recovering success rates and reducing safety violations. Additional material can be found at: https://gluestick-vla.github.io/.",
    "authors": [
      "Jason Jabbour",
      "Dong-Ki Kim",
      "Max Smith",
      "Jay Patrikar",
      "Radhika Ghosal",
      "Youhui Wang",
      "Ali Agha",
      "Vijay Janapa Reddi",
      "Shayegan Omidshafiei"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T17:07:30.000Z",
    "updatedAt": "2025-10-09T17:07:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08464v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08464v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08453v1",
    "arxivId": "2510.08453v1",
    "title": "Extending Games beyond the Finite Horizon",
    "abstract": "This paper argues that the finite horizon paradox, where game theory contradicts intuition, stems from the limitations of standard number systems in modelling the cognitive perception of infinity. To address this issue, we propose a new framework based on Alternative Set Theory (AST). This framework represents different cognitive perspectives on a long history of events using distinct topologies. These topologies define an indiscernibility equivalence that formally treats huge, indistinguishable quantities as equivalent. This offers criterion-dependent resolutions to long-standing paradoxes, such as Selten's chain store paradox and Rosenthal's centipede game. Our framework reveals new intuitive subgame perfect equilibria, the characteristics of which depend on the chosen temporal perspective and payoff evaluation. Ultimately, by grounding its mathematical foundation in different modes of human cognition, our work expands the explanatory power of game theory for long-horizon scenarios.",
    "authors": [
      "Kiri Sakahara",
      "Takashi Sato"
    ],
    "categories": [
      "cs.GT",
      "91A44, 91A20, 28E05"
    ],
    "publishedAt": "2025-10-09T17:01:02.000Z",
    "updatedAt": "2025-10-09T17:01:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08453v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08453v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08442v1",
    "arxivId": "2510.08442v1",
    "title": "Gaze on the Prize: Shaping Visual Attention with Return-Guided Contrastive Learning",
    "abstract": "Visual Reinforcement Learning (RL) agents must learn to act based on high-dimensional image data where only a small fraction of the pixels is task-relevant. This forces agents to waste exploration and computational resources on irrelevant features, leading to sample-inefficient and unstable learning. To address this, inspired by human visual foveation, we introduce Gaze on the Prize. This framework augments visual RL with a learnable foveal attention mechanism (Gaze), guided by a self-supervised signal derived from the agent's experience pursuing higher returns (the Prize). Our key insight is that return differences reveal what matters most: If two similar representations produce different outcomes, their distinguishing features are likely task-relevant, and the gaze should focus on them accordingly. This is realized through return-guided contrastive learning that trains the attention to distinguish between the features relevant to success and failure. We group similar visual representations into positives and negatives based on their return differences and use the resulting labels to construct contrastive triplets. These triplets provide the training signal that teaches the attention mechanism to produce distinguishable representations for states associated with different outcomes. Our method achieves up to 2.4x improvement in sample efficiency and can solve tasks that the baseline fails to learn, demonstrated across a suite of manipulation tasks from the ManiSkill3 benchmark, all without modifying the underlying algorithm or hyperparameters.",
    "authors": [
      "Andrew Lee",
      "Ian Chuang",
      "Dechen Gao",
      "Kai Fukazawa",
      "Iman Soltani"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T16:54:11.000Z",
    "updatedAt": "2025-10-09T16:54:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08442v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08442v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08427v1",
    "arxivId": "2510.08427v1",
    "title": "A convergent hierarchy of spectral gap certificates for qubit Hamiltonians",
    "abstract": "We give a convergent hierarchy of SDP certificates for bounding the spectral gap of local qubit Hamiltonians from below. Our approach is based on the NPA hierarchy applied to a polynomially-sized system of constraints defining the universal enveloping algebra of the Lie algebra $\\mathfrak{su}(2^{n})$, as well as additional constraints which put restrictions on the corresponding representations of the algebra. We also use as input an upper bound on the ground state energy, either using a hierarchy introduced by Fawzi, Fawzi, and Scalet, or an analog for qubit Hamiltonians of the Lasserre hierarchy of upper bounds introduced by Klep, Magron, Mass\\'{e}, and Vol\\v{c}i\\v{c}. The convergence of the certificates does not require that the Hamiltonian be frustration-free. We prove that the resulting certificates have polynomial size at fixed degree and converge asymptotically (in fact, at level $n$), by showing that all allowed representations of the algebra correspond to the second exterior power $\\wedge^2(\\mathbb{C}^{2^n})$, which encodes the sum of the two smallest eigenvalues of the original Hamiltonian. We also give an example showing that for a commuting 1-local Hamiltonian, the hierarchy certifies a nontrivial lower bound on the spectral gap.",
    "authors": [
      "Sujit Rao"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T16:42:21.000Z",
    "updatedAt": "2025-10-09T16:42:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08427v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08427v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08667v1",
    "arxivId": "2510.08667v1",
    "title": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data",
    "abstract": "Modern software teams frequently encounter delays in resolving recurring or related issues due to fragmented knowledge scattered across JIRA tickets, developer discussions, and GitHub pull requests (PRs). To address this challenge, we propose a Retrieval-Augmented Generation (RAG) framework that integrates Sentence-Transformers for semantic embeddings with FAISS-based vector search to deliver context-aware ticket resolution recommendations. The approach embeds historical JIRA tickets, user comments, and linked PR metadata to retrieve semantically similar past cases, which are then synthesized by a Large Language Model (LLM) into grounded and explainable resolution suggestions. The framework contributes a unified pipeline linking JIRA and GitHub data, an embedding and FAISS indexing strategy for heterogeneous software artifacts, and a resolution generation module guided by retrieved evidence. Experimental evaluation using precision, recall, resolution time reduction, and developer acceptance metrics shows that the proposed system significantly improves resolution accuracy, fix quality, and knowledge reuse in modern DevOps environments.",
    "authors": [
      "Mohammad Baqar"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T16:33:00.000Z",
    "updatedAt": "2025-10-09T16:33:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08667v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08667v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08408v1",
    "arxivId": "2510.08408v1",
    "title": "Validation of collision-free spheres of Stewart-Gough platforms for constant orientations using the Application Programming Interface of a CAD software",
    "abstract": "This paper presents a method of validation of the size of the largest collision-free sphere (CFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) for a given orientation of its moving platform (MP) using the Application Programming Interface (API) of a CAD software. The position of the MP is updated via the API in an automated manner over a set of samples within a shell enclosing the surface of the CFS. For each pose of the manipulator, each pair of legs is investigated for mutual collisions. The CFS is considered safe or validated iff none of the points falling inside the CFS lead to a collision between any pair of legs. This approach can not only validate the safety of a precomputed CFS, but also estimate the same for any spatial parallel manipulator.",
    "authors": [
      "Bibekananda Patra",
      "Rajeevlochana G. Chittawadigi",
      "Sandipan Bandyopadhyay"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T16:27:40.000Z",
    "updatedAt": "2025-10-09T16:27:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08408v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08408v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08406v1",
    "arxivId": "2510.08406v1",
    "title": "Reliability of Single-Level Equality-Constrained Inverse Optimal Control",
    "abstract": "Inverse optimal control (IOC) allows the retrieval of optimal cost function weights, or behavioral parameters, from human motion. The literature on IOC uses methods that are either based on a slow bilevel process or a fast but noise-sensitive minimization of optimality condition violation. Assuming equality-constrained optimal control models of human motion, this article presents a faster but robust approach to solving IOC using a single-level reformulation of the bilevel method and yields equivalent results. Through numerical experiments in simulation, we analyze the robustness to noise of the proposed single-level reformulation to the bilevel IOC formulation with a human-like planar reaching task that is used across recent studies. The approach shows resilience to very large levels of noise and reduces the computation time of the IOC on this task by a factor of 15 when compared to a classical bilevel implementation.",
    "authors": [
      "Filip Bečanović",
      "Kosta Jovanović",
      "Vincent Bonnet"
    ],
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "I.2.9; G.1.6; I.2.6"
    ],
    "publishedAt": "2025-10-09T16:26:35.000Z",
    "updatedAt": "2025-10-09T16:26:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08406v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08406v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08394v1",
    "arxivId": "2510.08394v1",
    "title": "Spectral Prefiltering of Neural Fields",
    "abstract": "Neural fields excel at representing continuous visual signals but typically operate at a single, fixed resolution. We present a simple yet powerful method to optimize neural fields that can be prefiltered in a single forward pass. Key innovations and features include: (1) We perform convolutional filtering in the input domain by analytically scaling Fourier feature embeddings with the filter's frequency response. (2) This closed-form modulation generalizes beyond Gaussian filtering and supports other parametric filters (Box and Lanczos) that are unseen at training time. (3) We train the neural field using single-sample Monte Carlo estimates of the filtered signal. Our method is fast during both training and inference, and imposes no additional constraints on the network architecture. We show quantitative and qualitative improvements over existing methods for neural-field filtering.",
    "authors": [
      "Mustafa B. Yaldiz",
      "Ishit Mehta",
      "Nithin Raghavan",
      "Andreas Meuleman",
      "Tzu-Mao Li",
      "Ravi Ramamoorthi"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T16:15:46.000Z",
    "updatedAt": "2025-10-09T16:15:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08394v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08394v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08392v1",
    "arxivId": "2510.08392v1",
    "title": "MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean Flows",
    "abstract": "Zero-shot voice conversion (VC) aims to transfer timbre from a source speaker to any unseen target speaker while preserving linguistic content. Growing application scenarios demand models with streaming inference capabilities. This has created a pressing need for models that are simultaneously fast, lightweight, and high-fidelity. However, existing streaming methods typically rely on either autoregressive (AR) or non-autoregressive (NAR) frameworks, which either require large parameter sizes to achieve strong performance or struggle to generalize to unseen speakers. In this study, we propose MeanVC, a lightweight and streaming zero-shot VC approach. MeanVC introduces a diffusion transformer with a chunk-wise autoregressive denoising strategy, combining the strengths of both AR and NAR paradigms for efficient streaming processing. By introducing mean flows, MeanVC regresses the average velocity field during training, enabling zero-shot VC with superior speech quality and speaker similarity in a single sampling step by directly mapping from the start to the endpoint of the flow trajectory. Additionally, we incorporate diffusion adversarial post-training to mitigate over-smoothing and further enhance speech quality. Experimental results demonstrate that MeanVC significantly outperforms existing zero-shot streaming VC systems, achieving superior conversion quality with higher efficiency and significantly fewer parameters. Audio demos and code are publicly available at https://aslp-lab.github.io/MeanVC.",
    "authors": [
      "Guobin Ma",
      "Jixun Yao",
      "Ziqian Ning",
      "Yuepeng Jiang",
      "Lingxin Xiong",
      "Lei Xie",
      "Pengcheng Zhu"
    ],
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "publishedAt": "2025-10-09T16:14:46.000Z",
    "updatedAt": "2025-10-09T16:14:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08392v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08392v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08381v1",
    "arxivId": "2510.08381v1",
    "title": "Airy: Reading Robot Intent through Height and Sky",
    "abstract": "As industrial robots move into shared human spaces, their opaque decision making threatens safety, trust, and public oversight. This artwork, Airy, asks whether complex multi agent AI can become intuitively understandable by staging a competition between two reinforcement trained robot arms that snap a bedsheet skyward. Building on three design principles, competition as a clear metric (who lifts higher), embodied familiarity (audiences recognize fabric snapping), and sensor to sense mapping (robot cooperation or rivalry shown through forest and weather projections), the installation gives viewers a visceral way to read machine intent. Observations from five international exhibitions indicate that audiences consistently read the robots' strategies, conflict, and cooperation in real time, with emotional reactions that mirror the system's internal state. The project shows how sensory metaphors can turn a black box into a public interface.",
    "authors": [
      "Baoyang Chen",
      "Xian Xu",
      "Huamin Qu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T16:07:30.000Z",
    "updatedAt": "2025-10-09T16:07:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08381v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08381v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08378v1",
    "arxivId": "2510.08378v1",
    "title": "A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles II: Vertex and Edge Deletion Numbers",
    "abstract": "We consider the problem of finding a Hamiltonian path or cycle with precedence constraints in the form of a partial order on the vertex set. We study the complexity for graph width parameters for which the ordinary problems $\\mathsf{Hamiltonian\\ Path}$ and $\\mathsf{Hamiltonian\\ Cycle}$ are in $\\mathsf{FPT}$. In particular, we focus on parameters that describe how many vertices and edges have to be deleted to become a member of a certain graph class. We show that the problems are $\\mathsf{W[1]}$-hard for such restricted cases as vertex distance to path and vertex distance to clique. We complement these results by showing that the problems can be solved in $\\mathsf{XP}$ time for vertex distance to outerplanar and vertex distance to block. Furthermore, we present some $\\mathsf{FPT}$ algorithms, e.g., for edge distance to block. Additionally, we prove para-$\\mathsf{NP}$-hardness when considered with the edge clique cover number.",
    "authors": [
      "Jesse Beisegel",
      "Katharina Klost",
      "Kristin Knorr",
      "Fabienne Ratajczak",
      "Robert Scheffler"
    ],
    "categories": [
      "cs.DM",
      "cs.CC",
      "cs.DS",
      "math.CO"
    ],
    "publishedAt": "2025-10-09T16:02:03.000Z",
    "updatedAt": "2025-10-09T16:02:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08378v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08378v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08665v1",
    "arxivId": "2510.08665v1",
    "title": "RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution",
    "abstract": "Code generation models based on large language models (LLMs) have gained wide adoption, but challenges remain in ensuring safety, accuracy, and controllability, especially for complex tasks. Existing methods often lack dynamic integration of external tools, transparent reasoning, and user control over safety. To address these issues, we propose a controllable code generation framework utilizing the ReAct paradigm for multi-agent task execution. This framework is a multi-agent system designed to enable efficient, precise, and interpretable code generation through dynamic interactions between LLMs and external resources. The framework adopts a collaborative architecture comprising four specialized agents: a Planner for task decomposition, a Searcher that leverages the ReAct framework for reasoning and tool integration, a CodeGen agent for accurate code generation, and an Extractor for structured data retrieval. The ReAct-based Searcher alternates between generating reasoning traces and executing actions, facilitating seamless integration of internal knowledge with external tools (such as search engines) to enhance accuracy and user control. Experimental results show the framework's effectiveness across multiple languages, achieving a 94.8% security rate on the SVEN dataset with CodeQL, outperforming existing approaches. Its transparent reasoning process fosters user trust and improves controllability.",
    "authors": [
      "Aofan Liu",
      "Haoxuan Li",
      "Bin Wang",
      "Ao Yang",
      "Hui Li"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T15:59:24.000Z",
    "updatedAt": "2025-10-09T15:59:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08665v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08665v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08368v1",
    "arxivId": "2510.08368v1",
    "title": "Co-design is powerful and not free",
    "abstract": "Robotic performance emerges from the coupling of body and controller, yet it remains unclear when morphology-control co-design is necessary. We present a unified framework that embeds morphology and control parameters within a single neural network, enabling end-to-end joint optimization. Through case studies in static-obstacle-constrained reaching, we evaluate trajectory error, success rate, and collision probability. The results show that co-design provides clear benefits when morphology is poorly matched to the task, such as near obstacles or workspace boundaries, where structural adaptation simplifies control. Conversely, when the baseline morphology already affords sufficient capability, control-only optimization often matches or exceeds co-design. By clarifying when control is enough and when it is not, this work advances the understanding of embodied intelligence and offers practical guidance for embodiment-aware robot design.",
    "authors": [
      "Yi Zhang",
      "Yue Xie",
      "Tao Sun",
      "Fumiya Iida"
    ],
    "categories": [
      "cs.NE",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T15:52:48.000Z",
    "updatedAt": "2025-10-09T15:52:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08368v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08368v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08361v1",
    "arxivId": "2510.08361v1",
    "title": "Isolation of non-triangle cycles in graphs",
    "abstract": "Given a set $\\mathcal{F}$ of graphs, we call a copy of a graph in $\\mathcal{F}$ an $\\mathcal{F}$-graph. The $\\mathcal{F}$-isolation number of a graph $G$, denoted by $\\iota(G, \\mathcal{F})$, is the size of a smallest set $D$ of vertices of $G$ such that the closed neighbourhood of $D$ intersects the vertex sets of the $\\mathcal{F}$-graphs contained by $G$ (equivalently, $G-N[D]$ contains no $\\mathcal{F}$-graph). Let $\\mathcal{C}$ be the set of cycles, and let $\\mathcal{C}'$ be the set of non-triangle cycles (that is, cycles of length at least $4$). Let $G$ be a connected graph having exactly $n$ vertices and $m$ edges. The first author proved that $\\iota(G,\\mathcal{C}) \\leq n/4$ if $G$ is not a triangle. Bartolo and the authors proved that $\\iota(G,\\{C_4\\}) \\leq n/5$ if $G$ is not a copy of one of nine graphs. Various authors proved that $\\iota(G,\\mathcal{C}) \\leq (m+1)/5$ if $G$ is not a triangle. We prove that $\\iota(G,\\mathcal{C}') \\leq (m+1)/6$ if $G$ is not a $4$-cycle. Zhang and Wu established this for the case where $G$ is triangle-free. Our result yields the inequality $\\iota(G,\\{C_4\\}) \\leq (m+1)/6$ of Wei, Zhang and Zhao. These bounds are attained by infinitely many (non-isomorphic) graphs. The proof of our inequality hinges on also determining the graphs attaining the bound.",
    "authors": [
      "Peter Borg",
      "Dayle Scicluna"
    ],
    "categories": [
      "math.CO",
      "cs.DM",
      "05C35, 05C38, 05C69"
    ],
    "publishedAt": "2025-10-09T15:47:43.000Z",
    "updatedAt": "2025-10-09T15:47:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08361v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08361v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08357v1",
    "arxivId": "2510.08357v1",
    "title": "Learning to Mitigate Post-Outage Load Surges: A Data-Driven Framework for Electrifying and Decarbonizing Grids",
    "abstract": "Electrification and decarbonization are transforming power system demand and recovery dynamics, yet their implications for post-outage load surges remain poorly understood. Here we analyze a metropolitan-scale heterogeneous dataset for Indianapolis comprising 30,046 feeder-level outages between 2020 and 2024, linked to smart meters and submetering, to quantify the causal impact of electric vehicles (EVs), heat pumps (HPs) and distributed energy resources (DERs) on restoration surges. Statistical analysis and causal forest inference demonstrate that rising penetrations of all three assets significantly increase surge ratios, with effects strongly modulated by restoration timing, outage duration and weather conditions. We develop a component-aware multi-task Transformer estimator that disaggregates EV, HP and DER contributions, and apply it to project historical outages under counterfactual 2035 adoption pathways. In a policy-aligned pathway, evening restorations emerge as the binding reliability constraint, with exceedance probabilities of 0.057 when 30\\% of system load is restored within the first 15 minutes. Mitigation measures, probabilistic EV restarts, short thermostat offsets and accelerated DER reconnection, reduce exceedance to 0.019 and eliminate it entirely when 20\\% or less of system load is restored. These results demonstrate that transition-era surges are asset-driven and causally linked to electrification and decarbonization, but can be effectively managed through integrated operational strategies.",
    "authors": [
      "Wenlong Shi",
      "Dingwei Wang",
      "Liming Liu",
      "Zhaoyu Wang"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T15:42:47.000Z",
    "updatedAt": "2025-10-09T15:42:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08357v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08357v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08356v1",
    "arxivId": "2510.08356v1",
    "title": "Underground Power Distribution System Restoration Using Inverter Based Resources",
    "abstract": "Underground power distribution systems (PDSs) are increasingly deployed in urban areas. The integration of smart devices including smart switchgears, pad-mounted distribution transformers and inverter-based resources (IBRs) enhance system resilience, however simultaneously introducing unique challenges. The challenges include inrush currents caused by trapped charges in underground cables, ferroresonance in distribution transformers during energization, and three-phase load imbalance resulting from single-phase underground laterals. To address these issues, this paper proposes an underground PDS restoration framework using IBRs. Firstly, an underground cable energization model is developed to quantify inrush current by analyzing voltage differences across both switchgear terminals. Secondly, a distribution transformer energization model is proposed to evaluate ferroresonance using Q-factor constraints based on underground cable capacitance and damping resistance. Thirdly, a phase-swapping model is proposed to improve load balancing by dynamically reassigning lateral-phase connections through smart switchgears. The proposed models are further integrated into a mixed-integer nonlinear programming (MINLP) formulation to maximize the total weighted restored load while constraining inrush currents, ferroresonance, and phase imbalance. To address the nonlinearity induced by impedance matrix reordering during phase swapping, a permutation-based linearization technique is proposed. Finally, case studies on an underground PDS established based on IEEE 123-Node Test Feeder validate the effectiveness of the proposed strategy in improving uderground PDS restoration performance.",
    "authors": [
      "Wenlong Shi",
      "Hongyi Li",
      "Zhaoyu Wang"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T15:42:44.000Z",
    "updatedAt": "2025-10-09T15:42:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08356v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08356v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08664v1",
    "arxivId": "2510.08664v1",
    "title": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware",
    "abstract": "LLM-based RTL generation is an interesting research direction, as it holds the potential to liberate the least automated stage in the current chip design. However, due to the substantial semantic gap between high-level specifications and RTL, coupled with limited training data, existing models struggle with generation accuracy. Drawing on human experience, design with verification helps improving accuracy. However, as the RTL testbench data are even more scarce, it is not friendly for LLMs. Although LLMs excel at higher-level languages like Python/C, they have a huge semantic gap from RTL. When implementing the same functionality, Python/C code and hardware code differ significantly in the spatiotemporal granularity, requiring the LLM not only to consider high-level functional semantics but also to ensure the low-level details align with the circuit code. It is not an easy task. In this paper, we propose a function abstracted verifiable middleware (Faver) that streamlines RTL verification in LLM-based workflows. By mixing LLM-friendly code structures with a rule-based template, Faver decouples the details of circuit verification, allowing the LLM to focus on the functionality itself. In our experiments on the SFT model and open-source models, Faver improved the model's generation accuracy by up to 14%.",
    "authors": [
      "Jianan Mu",
      "Mingyu Shi",
      "Yining Wang",
      "Tianmeng Yang",
      "Bin Sun",
      "Xing Hu",
      "Jing Ye",
      "Huawei Li"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T15:41:43.000Z",
    "updatedAt": "2025-10-09T15:41:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08664v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08664v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08348v1",
    "arxivId": "2510.08348v1",
    "title": "Adaptive Sparsification for Linear Programming",
    "abstract": "We introduce a generic framework for solving linear programs (LPs) with many constraints $(n \\gg d)$ via adaptive sparsification. Our approach provides a principled generalization of the techniques of [Assadi '23] from matching problems to general LPs and robustifies [Clarkson's '95] celebrated algorithm for the exact setting. The framework reduces LP solving to a sequence of calls to a ``low-violation oracle'' on small, adaptively sampled subproblems, which we analyze through the lens of the multiplicative weight update method. Our main results demonstrate the versatility of this paradigm. First, we present a quantum version of Clarkson's algorithm that finds an exact solution to an LP using $\\tilde{O}(\\sqrt{n} d^3)$ row-queries to the constraint matrix. This is achieved by accelerating the classical bottleneck (the search for violated constraints) with a generalization of Grover search, decoupling the quantum component from the classical solver. Second, our framework yields new state-of-the-art algorithms for mixed packing and covering problems when the packing constraints are ``simple''. By retaining all packing constraints while sampling only from the covering constraints, we achieve a significant width reduction, leading to faster solvers in both the classical and quantum query models. Our work provides a modular and powerful approach for accelerating LP solvers.",
    "authors": [
      "Étienne Objois",
      "Adrian Vladu"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T15:36:00.000Z",
    "updatedAt": "2025-10-09T15:36:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08348v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08348v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09697v1",
    "arxivId": "2510.09697v1",
    "title": "Combining Blotto Networks and Voter Models to Simulate Voter Behavior in Response to Competitive Election Spending",
    "abstract": "In the past, the Voter Model has been explicitly used to model the impact of propaganda on a dynamic, interconnected population, and certain factors have been identified that influence the behavior of voters when under outside influence. The Blotto Game has also been explicitly used to study information wars between two opposing parties, whether in regards to a political issue or advertising war. Both the graph theory behind the Voter Model and the game theory aspects of the Blotto Game are relevant to the behavior of voters or consumers when they are under the influence of competing propaganda campaigns, and for this reason both are useful to understand the most effective spending strategy. In this project, we seek to combine the two problems into a Voter-Blotto Game and examine what components of the graph most effect its value in the eyes of the competing players.",
    "authors": [
      "Renee Jerome"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "publishedAt": "2025-10-09T15:30:50.000Z",
    "updatedAt": "2025-10-09T15:30:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09697v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09697v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08342v1",
    "arxivId": "2510.08342v1",
    "title": "Self-replication and Computational Universality",
    "abstract": "Self-replication is central to all life, and yet how it dynamically emerges in physical, non-equilibrium systems remains poorly understood. Von Neumann's pioneering work in the 1940s and subsequent developments suggest a natural hypothesis: that any physical system capable of Turing-universal computation can support self-replicating objects. In this work, we challenge this hypothesis by clarifying what computational universality means for physical systems and constructing a cellular automaton that is Turing-universal but cannot sustain non-trivial self-replication. By analogy with biology, such dynamics manifest transcription and translation but cannot instantiate replication. More broadly, our work emphasizes that the computational complexity of translating between physical dynamics and symbolic computation is inseparable from any claim of universality (exemplified by our analysis of Rule 110) and builds mathematical foundations for identifying self-replicating behavior. Our approach enables the formulation of necessary dynamical and computational conditions for a physical system to constitute a living organism.",
    "authors": [
      "Jordan Cotler",
      "Clément Hongler",
      "Barbora Hudcová"
    ],
    "categories": [
      "nlin.CG",
      "cs.FL",
      "nlin.AO"
    ],
    "publishedAt": "2025-10-09T15:28:07.000Z",
    "updatedAt": "2025-10-09T15:28:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08342v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08342v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08969v1",
    "arxivId": "2510.08969v1",
    "title": "Concept-Based Generic Programming in C++",
    "abstract": "We present programming techniques to illustrate the facilities and principles of C++ generic programming using concepts. Concepts are C++'s way to express constraints on generic code. As an initial example, we provide a simple type system that eliminates narrowing conversions and provides range checking without unnecessary notational or run-time overheads. Concepts are used throughout to provide user-defined extensions to the type system. The aim is to show their utility and the fundamental ideas behind them, rather than to provide a detailed or complete explanation of C++'s language support for generic programming or the extensive support provided by the standard library. Generic programming is an integral part of C++, rather than an isolated sub-language. In particular, key facilities support general programming as well as generic programming (e.g., uniform notation for types, lambdas, variadic templates, and C++26 static reflection). Finally, we give design rationales and origins for key parts of the concept design, including use patterns, the relationship to Object-Oriented Programming, value arguments, notation, concept type-matching, and definition checking.",
    "authors": [
      "Bjarne Stroustrup"
    ],
    "categories": [
      "cs.PL",
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T15:27:30.000Z",
    "updatedAt": "2025-10-09T15:27:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08969v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08969v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08336v1",
    "arxivId": "2510.08336v1",
    "title": "Computing moment polytopes -- with a focus on tensors, entanglement and matrix multiplication",
    "abstract": "Tensors are fundamental in mathematics, computer science, and physics. Their study through algebraic geometry and representation theory has proved very fruitful in the context of algebraic complexity theory and quantum information. In particular, moment polytopes have been understood to play a key role. In quantum information, moment polytopes (also known as entanglement polytopes) provide a framework for the single-particle quantum marginal problem and offer a geometric characterization of entanglement. In algebraic complexity, they underpin quantum functionals that capture asymptotic tensor relations. More recently, moment polytopes have also become foundational to the emerging field of scaling algorithms in computer science and optimization. Despite their fundamental role and interest from many angles, much is still unknown about these polytopes, and in particular for tensors beyond $\\mathbb{C}^2\\otimes\\mathbb{C}^2\\otimes\\mathbb{C}^2$ and $\\mathbb{C}^2\\otimes\\mathbb{C}^2\\otimes\\mathbb{C}^2\\otimes\\mathbb{C}^2$ only sporadically have they been computed. We give a new algorithm for computing moment polytopes of tensors (and in fact moment polytopes for the general class of reductive algebraic groups) based on a mathematical description by Franz (J. Lie Theory 2002). This algorithm enables us to compute moment polytopes of tensors of dimension an order of magnitude larger than previous methods, allowing us to compute with certainty, for the first time, all moment polytopes of tensors in $\\mathbb{C}^3\\otimes\\mathbb{C}^3\\otimes\\mathbb{C}^3$, and with high probability those in $\\mathbb{C}^4\\otimes\\mathbb{C}^4\\otimes\\mathbb{C}^4$ (which includes the $2\\times 2$ matrix multiplication tensor). We discuss how these explicit moment polytopes have led to several new theoretical directions and results.",
    "authors": [
      "Maxim van den Berg",
      "Matthias Christandl",
      "Vladimir Lysikov",
      "Harold Nieuwboer",
      "Michael Walter",
      "Jeroen Zuiddam"
    ],
    "categories": [
      "math.RT",
      "cs.CC",
      "cs.SC",
      "math.AG",
      "quant-ph",
      "20G05, 15A69, 14L24, 68W30"
    ],
    "publishedAt": "2025-10-09T15:23:49.000Z",
    "updatedAt": "2025-10-09T15:23:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08336v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08336v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08332v1",
    "arxivId": "2510.08332v1",
    "title": "What Makes a Visualization Complex?",
    "abstract": "We investigate the perceived visual complexity (VC) in data visualizations using objective image-based metrics. We collected VC scores through a large-scale crowdsourcing experiment involving 349 participants and 1,800 visualization images. We then examined how these scores align with 12 image-based metrics spanning information-theoretic, clutter, color, and our two object-based metrics. Our results show that both low-level image properties and the high-level elements affect perceived VC in visualization images; The number of corners and distinct colors are robust metrics across visualizations. Second, feature congestion, an information-theoretic metric capturing statistical patterns in color and texture, is the strongest predictor of perceived complexity in visualizations rich in the same stimuli; edge density effectively explains VC in node-link diagrams. Additionally, we observe a bell-curve effect for text annotations: increasing text-to-ink ratio (TiR) initially reduces complexity, reaching an optimal point, beyond which further text increases perceived complexity. Our quantification pipeline is also interpretable, enabling metric-based explanations, grounded in the VisComplexity2K dataset, bridging computational metrics with human perceptual responses. osf.io/5xe8a has the preregistration and osf.io/bdet6 has the VisComplexity2K dataset, source code, and all Apdx. and figures.",
    "authors": [
      "Mengdi Chu",
      "Zefeng Qiu",
      "Meng Ling",
      "Shuning Jiang",
      "Robert S. Laramee",
      "Michael Sedlmair",
      "Jian Chen"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T15:22:05.000Z",
    "updatedAt": "2025-10-09T15:22:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08332v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08332v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08328v1",
    "arxivId": "2510.08328v1",
    "title": "Motion Exploration of Articulated Product Concepts in Interactive Sketching Environment",
    "abstract": "In the early stages of engineering design, it is essential to know how a product behaves, especially how it moves. As designers must keep adjusting the motion until it meets the intended requirements, this process is often repetitive and time-consuming. Although the physics behind these motions is usually based on simple equations, manually working through them can be tedious and inefficient. To ease this burden, some tasks are now handled by computers. One common method involves converting hand-drawn sketches into models using CAD or CAE software. However, this approach can be time- and resource-intensive. Additionally, product sketches are usually best understood only by the designers who created them. Others may struggle to interpret them correctly, relying heavily on intuition and prior experience. Since sketches are static, they fail to show how a product moves, limiting their usefulness. This paper presents a new approach that addresses these issues by digitising the natural act of sketching. It allows designers to create, simulate, and test the motion of mechanical concepts in a more interactive way. An application was developed to evaluate this method, focusing on user satisfaction and mental workload during a design task. The results showed a 77% reduction in cognitive effort compared to traditional methods, with users reporting high satisfaction. Future work will focus on expanding this approach from 2D (planar) to full 3D (spatial) design environments, enabling more complex product concept development.",
    "authors": [
      "Kalyan Ramana Gattoz",
      "Prasad S. Onkar"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T15:17:16.000Z",
    "updatedAt": "2025-10-09T15:17:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08328v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08328v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08326v1",
    "arxivId": "2510.08326v1",
    "title": "LacAIDes: Generative AI-Supported Creative Interactive Circuits Crafting to Enliven Traditional Lacquerware",
    "abstract": "Lacquerware, a representative craft of Chinese intangible cultural heritage, is renowned for its layered aesthetics and durability but faces declining engagement. While prior human-computer interaction research has explored embedding interactive circuits to transform lacquerware into responsive artifacts, most studies have focused on fabrication techniques rather than supporting makers in creatively designing such interactions at a low threshold. To address this gap, we present LacAIDes, a Generative AI powered creativity-support tool built on a multi-agent workflow aligned with the double diamond model of design thinking. LacAIDes enables exploration and creation of culturally grounded interactive circuits without requiring prior technical expertise. We evaluated LacAIDes in a longitudinal workshop with 34 participants using a mixed-method approach. Results show that LacAIDes demonstrated high usability, enhanced creative engagement in craft making, and encouraged critical reflection on the role of Generative AI in digital craft practices. This work contributes to human-computer interaction by introducing a novel creativity-support tool and providing empirical insights into revitalizing traditional craft making through Generative AI.",
    "authors": [
      "Yaning Li",
      "Yutong Chen",
      "Yihan Hou",
      "Chenyi Chen",
      "Yihan Han",
      "Jingxuan Han",
      "Wenxi Dai",
      "Youyou Li",
      "Xinke Tang",
      "Meng Li",
      "Qi Dong",
      "Hongwei Li"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T15:15:12.000Z",
    "updatedAt": "2025-10-09T15:15:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08326v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08326v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08314v1",
    "arxivId": "2510.08314v1",
    "title": "To Ask or Not to Ask: Learning to Require Human Feedback",
    "abstract": "Developing decision-support systems that complement human performance in classification tasks remains an open challenge. A popular approach, Learning to Defer (LtD), allows a Machine Learning (ML) model to pass difficult cases to a human expert. However, LtD treats humans and ML models as mutually exclusive decision-makers, restricting the expert contribution to mere predictions. To address this limitation, we propose Learning to Ask (LtA), a new framework that handles both when and how to incorporate expert input in an ML model. LtA is based on a two-part architecture: a standard ML model and an enriched model trained with additional expert human feedback, with a formally optimal strategy for selecting when to query the enriched model. We provide two practical implementations of LtA: a sequential approach, which trains the models in stages, and a joint approach, which optimises them simultaneously. For the latter, we design surrogate losses with realisable-consistency guarantees. Our experiments with synthetic and real expert data demonstrate that LtA provides a more flexible and powerful foundation for effective human-AI collaboration.",
    "authors": [
      "Andrea Pugnana",
      "Giovanni De Toni",
      "Cesare Barbera",
      "Roberto Pellungrini",
      "Bruno Lepri",
      "Andrea Passerini"
    ],
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T15:00:06.000Z",
    "updatedAt": "2025-10-09T15:00:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08314v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08314v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08299v1",
    "arxivId": "2510.08299v1",
    "title": "Quantum memory optimisation using finite-horizon, decoherence time and discounted mean-square performance criteria",
    "abstract": "This paper is concerned with open quantum memory systems for approximately retaining quantum information, such as initial dynamic variables or quantum states to be stored over a bounded time interval. In the Heisenberg picture of quantum dynamics, the deviation of the system variables from their initial values lends itself to closed-form computation in terms of tractable moment dynamics for open quantum harmonic oscillators and finite-level quantum systems governed by linear or quasi-linear Hudson-Parthasarathy quantum stochastic differential equations, respectively. This tractability is used in a recently proposed optimality criterion for varying the system parameters so as to maximise the memory decoherence time when the mean-square deviation achieves a given critical threshold. The memory decoherence time maximisation approach is extended beyond the previously considered low-threshold asymptotic approximation and to Schr\\\"{o}dinger type mean-square deviation functionals for the reduced system state governed by the Lindblad master equation. We link this approach with the minimisation of the mean-square deviation functionals at a finite time horizon and with their discounted version which quantifies the averaged performance of the quantum system as a temporary memory under a Poisson flow of storage requests.",
    "authors": [
      "Igor G. Vladimirov",
      "Ian R. Petersen",
      "Guodong Shi"
    ],
    "categories": [
      "quant-ph",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "81Q93, 81S25, 81S05, 81S22, 81P16, 15A16, 15A24, 49N35, 93B52, 49K15"
    ],
    "publishedAt": "2025-10-09T14:51:08.000Z",
    "updatedAt": "2025-10-09T14:51:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08299v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08299v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08297v1",
    "arxivId": "2510.08297v1",
    "title": "Dynamic Connectivity with Expected Polylogarithmic Worst-Case Update Time",
    "abstract": "Whether a graph $G=(V,E)$ is connected is arguably its most fundamental property. Naturally, connectivity was the first characteristic studied for dynamic graphs, i.e. graphs that undergo edge insertions and deletions. While connectivity algorithms with polylogarithmic amortized update time have been known since the 90s, achieving worst-case guarantees has proven more elusive. Two recent breakthroughs have made important progress on this question: (1) Kapron, King and Mountjoy [SODA'13; Best Paper] gave a Monte-Carlo algorithm with polylogarithmic worst-case update time, and (2) Nanongkai, Saranurak and Wulff-Nilsen [STOC'17, FOCS'17] obtained a Las-Vegas data structure, however, with subpolynomial worst-case update time. Their algorithm was subsequently de-randomized [FOCS'20]. In this article, we present a new dynamic connectivity algorithm based on the popular core graph framework that maintains a hierarchy interleaving vertex and edge sparsification. Previous dynamic implementations of the core graph framework required subpolynomial update time. In contrast, we show how to implement it for dynamic connectivity with polylogarithmic expected worst-case update time. We further show that the algorithm can be de-randomized efficiently: a deterministic static algorithm for computing a connectivity edge-sparsifier of low congestion in time $T(m) \\cdot m$ on an $m$-edge graph yields a deterministic dynamic connectivity algorithm with $\\tilde{O}(T(m))$ worst-case update time. Via current state-of-the-art algorithms [STOC'24], we obtain $T(m) = m^{o(1)}$ and recover deterministic subpolynomial worst-case update time.",
    "authors": [
      "Simon Meierhans",
      "Maximilian Probst Gutenberg"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T14:50:20.000Z",
    "updatedAt": "2025-10-09T14:50:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08297v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08297v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08288v1",
    "arxivId": "2510.08288v1",
    "title": "CPU- and GPU-Based Parallelization of the Robust Reference Governor",
    "abstract": "Constraint management is a central challenge in modern control systems. A solution is the Reference Governor (RG), which is an add-on strategy to pre-stabilized feedback control systems to enforce state and input constraints by shaping the reference command. While robust formulations of RG exist for linear systems, their extension to nonlinear systems is often computationally intractable. This paper develops a scenario-based robust RG formulation for nonlinear systems and investigates its parallel implementation on multi-core CPUs and CUDA-enabled GPUs. We analyze the computational structure of the algorithm, identify parallelization opportunities, and implement the resulting schemes on modern parallel hardware. Benchmarking on a nonlinear hydrogen fuel cell model demonstrates order-of-magnitude speedups (by as much as three orders of magnitude) compared to sequential implementations.",
    "authors": [
      "Hamid R. Ossareh",
      "William Shayne",
      "Samuel Chevalier"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T14:40:32.000Z",
    "updatedAt": "2025-10-09T14:40:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08288v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08288v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08278v2",
    "arxivId": "2510.08278v2",
    "title": "A Multimodal Depth-Aware Method For Embodied Reference Understanding",
    "abstract": "Embodied Reference Understanding requires identifying a target object in a visual scene based on both language instructions and pointing cues. While prior works have shown progress in open-vocabulary object detection, they often fail in ambiguous scenarios where multiple candidate objects exist in the scene. To address these challenges, we propose a novel ERU framework that jointly leverages LLM-based data augmentation, depth-map modality, and a depth-aware decision module. This design enables robust integration of linguistic and embodied cues, improving disambiguation in complex or cluttered environments. Experimental results on two datasets demonstrate that our approach significantly outperforms existing baselines, achieving more accurate and reliable referent detection.",
    "authors": [
      "Fevziye Irem Eyiokur",
      "Dogucan Yaman",
      "Hazım Kemal Ekenel",
      "Alexander Waibel"
    ],
    "categories": [
      "cs.CV",
      "cs.HC",
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T14:32:21.000Z",
    "updatedAt": "2025-10-10T13:05:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08278v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08278v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08275v2",
    "arxivId": "2510.08275v2",
    "title": "A Control Allocation Algorithm for Hypersonic Glide Vehicles with Input Limitations",
    "abstract": "Hypersonic glide vehicles (HGVs) operate in challenging flight regimes characterized by strong nonlinearities in actuation and stringent physical constraints. These include state-dependent actuator limitations, asymmetric control bounds, and thermal loads that vary with maneuvering conditions. This paper introduces an iterative control allocation method to address these challenges in real time. The proposed algorithm searches for control inputs that achieve the desired moment commands while respecting constraints on input magnitude and rate. For slender HGV configurations, thermal loads and drag generation are strongly correlated-lower drag typically results in reduced surface heating. By embedding drag-sensitive soft constraints, the method improves energy efficiency and implicitly reduces surface temperatures, lowering the vehicle's infrared signature. These features are particularly advantageous for long-range military operations that require low observability. The approach is demonstrated using the DLR's Generic Hypersonic Glide Vehicle 2 (GHGV-2) simulation model. The results confirm the method's effectiveness in maintaining control authority under realistic, constrained flight conditions.",
    "authors": [
      "Johannes Autenrieb",
      "Patrick Gruhn"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T14:31:27.000Z",
    "updatedAt": "2025-10-10T12:27:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08275v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08275v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08271v1",
    "arxivId": "2510.08271v1",
    "title": "SViM3D: Stable Video Material Diffusion for Single Image 3D Generation",
    "abstract": "We present Stable Video Materials 3D (SViM3D), a framework to predict multi-view consistent physically based rendering (PBR) materials, given a single image. Recently, video diffusion models have been successfully used to reconstruct 3D objects from a single image efficiently. However, reflectance is still represented by simple material models or needs to be estimated in additional steps to enable relighting and controlled appearance edits. We extend a latent video diffusion model to output spatially varying PBR parameters and surface normals jointly with each generated view based on explicit camera control. This unique setup allows for relighting and generating a 3D asset using our model as neural prior. We introduce various mechanisms to this pipeline that improve quality in this ill-posed setting. We show state-of-the-art relighting and novel view synthesis performance on multiple object-centric datasets. Our method generalizes to diverse inputs, enabling the generation of relightable 3D assets useful in AR/VR, movies, games and other visual media.",
    "authors": [
      "Andreas Engelhardt",
      "Mark Boss",
      "Vikram Voletti",
      "Chun-Han Yao",
      "Hendrik P. A. Lensch",
      "Varun Jampani"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T14:29:47.000Z",
    "updatedAt": "2025-10-09T14:29:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08271v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08271v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08270v1",
    "arxivId": "2510.08270v1",
    "title": "Evaluation of a Robust Control System in Real-World Cable-Driven Parallel Robots",
    "abstract": "This study evaluates the performance of classical and modern control methods for real-world Cable-Driven Parallel Robots (CDPRs), focusing on underconstrained systems with limited time discretization. A comparative analysis is conducted between classical PID controllers and modern reinforcement learning algorithms, including Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimization (PPO), and Trust Region Policy Optimization (TRPO). The results demonstrate that TRPO outperforms other methods, achieving the lowest root mean square (RMS) errors across various trajectories and exhibiting robustness to larger time intervals between control updates. TRPO's ability to balance exploration and exploitation enables stable control in noisy, real-world environments, reducing reliance on high-frequency sensor feedback and computational demands. These findings highlight TRPO's potential as a robust solution for complex robotic control tasks, with implications for dynamic environments and future applications in sensor fusion or hybrid control strategies.",
    "authors": [
      "Damir Nurtdinov",
      "Aliaksei Korshuk",
      "Alexei Kornaev",
      "Alexander Maloletov"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T14:28:58.000Z",
    "updatedAt": "2025-10-09T14:28:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08270v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08270v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08257v1",
    "arxivId": "2510.08257v1",
    "title": "A Distributed Emulation Environment for In-Memory Computing Systems",
    "abstract": "In-memory computing technology is used extensively in artificial intelligence devices due to lower power consumption and fast calculation of matrix-based functions. The development of such a device and its integration in a system takes a significant amount of time and requires the use of a real-time emulation environment, where various system aspects are analyzed, microcode is tested, and applications are deployed, even before the real chip is available. In this work, we present the architecture, the software development tools, and experimental results of a distributed and expandable emulation system for rapid prototyping of integrated circuits based on in-memory computing technologies. Presented experimental results demonstrate the usefulness of the proposed emulator.",
    "authors": [
      "Eleni Bougioukou",
      "Anastasios Petropoulos",
      "Nikolaos Toulgaridis",
      "Theodoros Chatzimichail",
      "Theodore Antonakopoulos"
    ],
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T14:15:35.000Z",
    "updatedAt": "2025-10-09T14:15:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08257v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08257v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08244v1",
    "arxivId": "2510.08244v1",
    "title": "Energy-Efficient Maximal Independent Sets in Radio Networks",
    "abstract": "The maximal independent set (MIS) is one of the most fundamental problems in distributed computing, and it has been studied intensively for over four decades. This paper focuses on the MIS problem in the Radio Network model, a standard model widely used to model wireless networks, particularly ad hoc wireless and sensor networks. Energy is a premium resource in these networks, which are typically battery-powered. Hence, designing distributed algorithms that use as little energy as possible is crucial. We use the well-established energy model where a node can be sleeping or awake in a round, and only the awake rounds (when it can send or listen) determine the energy complexity of the algorithm, which we want to minimize. We present new, more energy-efficient MIS algorithms in radio networks with arbitrary and unknown graph topology. We present algorithms for two popular variants of the radio model -- with collision detection (CD) and without collision detection (no-CD). Specifically, we obtain the following results: 1. CD model: We present a randomized distributed MIS algorithm with energy complexity $O(\\log n)$, round complexity $O(\\log^2 n)$, and failure probability $1 / poly(n)$, where $n$ is the network size. We show that our energy complexity is optimal by showing a matching $\\Omega(\\log n)$ lower bound. 2. no-CD model: In the more challenging no-CD model, we present a randomized distributed MIS algorithm with energy complexity $O(\\log^2n \\log \\log n)$, round complexity $O(\\log^3 n \\log \\Delta)$, and failure probability $1 / poly(n)$. The energy complexity of our algorithm is significantly lower than the round (and energy) complexity of $O(\\log^3 n)$ of the best known distributed MIS algorithm of Davies [PODC 2023] for arbitrary graph topology.",
    "authors": [
      "Dominick Banasik",
      "Varsha Dani",
      "Fabien Dufoulon",
      "Aayush Gupta",
      "Thomas P. Hayes",
      "Gopal Pandurangan"
    ],
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T14:04:48.000Z",
    "updatedAt": "2025-10-09T14:04:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08244v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08244v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08242v1",
    "arxivId": "2510.08242v1",
    "title": "Simulating Teams with LLM Agents: Interactive 2D Environments for Studying Human-AI Dynamics",
    "abstract": "Enabling users to create their own simulations offers a powerful way to study team dynamics and performance. We introduce VirTLab, a system that allows researchers and practitioners to design interactive, customizable simulations of team dynamics with LLM-based agents situated in 2D spatial environments. Unlike prior frameworks that restrict scenarios to predefined or static tasks, our approach enables users to build scenarios, assign roles, and observe how agents coordinate, move, and adapt over time. By bridging team cognition behaviors with scalable agent-based modeling, our system provides a testbed for investigating how environments influence coordination, collaboration, and emergent team behaviors. We demonstrate its utility by aligning simulated outcomes with empirical evaluations and a user study, underscoring the importance of customizable environments for advancing research on multi-agent simulations. This work contributes to making simulations accessible to both technical and non-technical users, supporting the design, execution, and analysis of complex multi-agent experiments.",
    "authors": [
      "Mohammed Almutairi",
      "Charles Chiang",
      "Haoze Guo",
      "Matthew Belcher",
      "Nandini Banerjee",
      "Maria Milkowski",
      "Svitlana Volkova",
      "Daniel Nguyen",
      "Tim Weninger",
      "Michael Yankoski",
      "Trenton W. Ford",
      "Diego Gomez-Zara"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T14:04:11.000Z",
    "updatedAt": "2025-10-09T14:04:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08242v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08242v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08230v1",
    "arxivId": "2510.08230v1",
    "title": "pyGinkgo: A Sparse Linear Algebra Operator Framework for Python",
    "abstract": "Sparse linear algebra is a cornerstone of many scientific computing and machine learning applications. Python has become a popular choice for these applications due to its simplicity and ease of use. Yet high performance sparse kernels in Python remain limited in functionality, especially on modern CPU and GPU architectures. We present pyGinkgo, a lightweight and Pythonic interface to the Ginkgo library, offering high-performance sparse linear algebra support with platform portability across CUDA, HIP, and OpenMP backends. pyGinkgo bridges the gap between high-performance C++ backends and Python usability by exposing Ginkgo's capabilities via Pybind11 and a NumPy and PyTorch compatible interface. We benchmark pyGinkgo's performance against state-of-the-art Python libraries including SciPy, CuPy, PyTorch, and TensorFlow. Results across hardware from different vendors demonstrate that pyGinkgo consistently outperforms existing Python tools in both sparse matrix vector (SpMV) product and iterative solver performance, while maintaining performance parity with native Ginkgo C++ code. Our work positions pyGinkgo as a compelling backend for sparse machine learning models and scientific workflows.",
    "authors": [
      "Keshvi Tuteja",
      "Gregor Olenik",
      "Roman Mishchuk",
      "Yu-Hsiang Tsai",
      "Markus Götz",
      "Achim Streit",
      "Hartwig Anzt",
      "Charlotte Debus"
    ],
    "categories": [
      "cs.MS",
      "cs.DC",
      "cs.PF",
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T13:55:51.000Z",
    "updatedAt": "2025-10-09T13:55:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08230v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08230v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08228v1",
    "arxivId": "2510.08228v1",
    "title": "Distributed Resource Selection for Self-Organising Cloud-Edge Systems",
    "abstract": "This paper presents a distributed resource selection mechanism for diverse cloud-edge environments, enabling dynamic and context-aware allocation of resources to meet the demands of complex distributed applications. By distributing the decision-making process, our approach ensures efficiency, scalability, and resilience in highly dynamic cloud-edge environments where centralised coordination becomes a bottleneck. The proposed mechanism aims to function as a core component of a broader, distributed, and self-organising orchestration system that facilitates the intelligent placement and adaptation of applications in real-time. This work leverages a consensus-based mechanism utilising local knowledge and inter-agent collaboration to achieve efficient results without relying on a central controller, thus paving the way for distributed orchestration. Our results indicate that computation time is the key factor influencing allocation decisions. Our approach consistently delivers rapid allocations without compromising optimality or incurring additional cost, achieving timely results at scale where exhaustive search is infeasible and centralised heuristics run up to 30 times slower.",
    "authors": [
      "Quentin Renau",
      "Amjad Ullah",
      "Emma Hart"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T13:53:08.000Z",
    "updatedAt": "2025-10-09T13:53:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08228v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08228v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08227v1",
    "arxivId": "2510.08227v1",
    "title": "Practicing a Second Language Without Fear: Mixed Reality Agents for Interactive Group Conversation",
    "abstract": "Developing speaking proficiency in a second language can be cognitively demanding and emotionally taxing, often triggering fear of making mistakes or being excluded from larger groups. While current learning tools show promise for speaking practice, most focus on dyadic, scripted scenarios, limiting opportunities for dynamic group interactions. To address this gap, we present ConversAR, a Mixed Reality system that leverages Generative AI and XR to support situated and personalized group conversations. It integrates embodied AI agents, scene recognition, and generative 3D props anchored to real-world surroundings. Based on a formative study with experts in language acquisition, we developed and tested this system with a user study with 21 second-language learners. Results indicate that the system enhanced learner engagement, increased willingness to communicate, and offered a safe space for speaking. We discuss the implications for integrating Generative AI and XR into the design of future language learning applications.",
    "authors": [
      "Mariana Fernandez-Espinosa",
      "Kai Zhang",
      "Jad Bendarkawi",
      "Ashley Ponce",
      "Sean Chidozie Mata",
      "Aminah Aliu",
      "Lei Zhang",
      "Francisco Fernandez Medina",
      "Elena Mangione-Lora",
      "Andres Monroy-Hernandez",
      "Diego Gomez-Zara"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T13:50:42.000Z",
    "updatedAt": "2025-10-09T13:50:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08227v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08227v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08202v1",
    "arxivId": "2510.08202v1",
    "title": "Sentiment Matters: An Analysis of 200 Human-SAV Interactions",
    "abstract": "Shared Autonomous Vehicles (SAVs) are likely to become an important part of the transportation system, making effective human-SAV interactions an important area of research. This paper introduces a dataset of 200 human-SAV interactions to further this area of study. We present an open-source human-SAV conversational dataset, comprising both textual data (e.g., 2,136 human-SAV exchanges) and empirical data (e.g., post-interaction survey results on a range of psychological factors). The dataset's utility is demonstrated through two benchmark case studies: First, using random forest modeling and chord diagrams, we identify key predictors of SAV acceptance and perceived service quality, highlighting the critical influence of response sentiment polarity (i.e., perceived positivity). Second, we benchmark the performance of an LLM-based sentiment analysis tool against the traditional lexicon-based TextBlob method. Results indicate that even simple zero-shot LLM prompts more closely align with user-reported sentiment, though limitations remain. This study provides novel insights for designing conversational SAV interfaces and establishes a foundation for further exploration into advanced sentiment modeling, adaptive user interactions, and multimodal conversational systems.",
    "authors": [
      "Lirui Guo",
      "Michael G. Burke",
      "Wynita M. Griggs"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "publishedAt": "2025-10-09T13:30:23.000Z",
    "updatedAt": "2025-10-09T13:30:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08202v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08202v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08200v1",
    "arxivId": "2510.08200v1",
    "title": "Building Whitespace-Sensitive Languages Using Whitespace-Insensitive Components",
    "abstract": "In Software Language Engineering, there is a trend towards reusability by composing modular language components. However, this reusability is severely inhibited by a gap in integrating whitespace-sensitive and whitespace-insensitive languages. There is currently no consistent procedure for seamlessly reusing such language components in both cases, such that libraries often cannot be reused, and whitespacesensitive languages are developed from scratch. This paper presents a technique for using modular, whitespaceinsensitive language modules to construct whitespace sensitive languages by pre-processing language artifacts before parsing. The approach is evaluated by reconstructing a simplified version of the programming language Python. Our solution aims to increase the reusability of existing language components to reduce development time and increase the overall quality of software languages.",
    "authors": [
      "Alexander Hellwig",
      "Nico Jansen",
      "Bernhard Rumpe"
    ],
    "categories": [
      "cs.SE",
      "68N15",
      "D.2.13"
    ],
    "publishedAt": "2025-10-09T13:26:47.000Z",
    "updatedAt": "2025-10-09T13:26:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08200v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08200v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08190v1",
    "arxivId": "2510.08190v1",
    "title": "Geometric opinion exchange polarizes in every dimension",
    "abstract": "A recent line of work studies models of opinion exchange where agent opinions about $d$ topics are tracked simultaneously. The opinions are represented as vectors on the unit $(d-1)$-sphere, and the update rule is based on the overall correlation between the relevant vectors. The update rule reflects the assumption of biased assimilation, i.e., a pair of opinions is brought closer together if their correlation is positive and further apart if the correlation is negative. This model seems to induce the polarization of opinions into two antipodal groups. This is in contrast to many other known models which tend to achieve consensus. The polarization property has been recently proved for $d=2$, but the general case of $d \\ge 3$ remained open. In this work, we settle the general case, using a more detailed understanding of the model dynamics and tools from the theory of random processes.",
    "authors": [
      "Abdou Majeed Alidou",
      "Júlia Baligács",
      "Jan Hązła"
    ],
    "categories": [
      "cs.SI"
    ],
    "publishedAt": "2025-10-09T13:17:28.000Z",
    "updatedAt": "2025-10-09T13:17:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08190v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08190v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08185v1",
    "arxivId": "2510.08185v1",
    "title": "k-SUM Hardness Implies Treewidth-SETH",
    "abstract": "We show that if k-SUM is hard, in the sense that the standard algorithm is essentially optimal, then a variant of the SETH called the Primal Treewidth SETH is true. Formally: if there is an $\\varepsilon>0$ and an algorithm which solves SAT in time $(2-\\varepsilon)^{tw}|\\phi|^{O(1)}$, where $tw$ is the width of a given tree decomposition of the primal graph of the input, then there exists a randomized algorithm which solves k-SUM in time $n^{(1-\\delta)\\frac{k}{2}}$ for some $\\delta>0$ and all sufficiently large $k$. We also establish an analogous result for the k-XOR problem, where integer addition is replaced by component-wise addition modulo $2$. As an application of our reduction we are able to revisit tight lower bounds on the complexity of several fundamental problems parameterized by treewidth (Independent Set, Max Cut, $k$-Coloring). Our results imply that these bounds, which were initially shown under the SETH, also hold if one assumes the k-SUM or k-XOR Hypotheses, arguably increasing our confidence in their validity.",
    "authors": [
      "Michael Lampis"
    ],
    "categories": [
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T13:13:21.000Z",
    "updatedAt": "2025-10-09T13:13:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08185v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08185v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08184v1",
    "arxivId": "2510.08184v1",
    "title": "Satellite Navigation and Control using Physics-Informed Artificial Potential Field and Sliding Mode Controller",
    "abstract": "Increase in the number of space exploration missions has led to the accumulation of space debris, posing risk of collision with the operational satellites. Addressing this challenge is crucial for the sustainability of space operations. To plan a safe trajectory in the presence of moving space debris, an integrated approach of artificial potential field and sliding mode controller is proposed and implemented in this paper. The relative 6-DOF kinematics and dynamics of the spacecraft is modelled in the framework of geometric mechanics with the relative configuration expressed through exponential coordinates. Various collision avoidance guidance algorithms have been proposed in the literature but the Artificial Potential Field guidance algorithm is computationally efficient and enables real-time path adjustments to avoid collision with obstacles. However, it is prone to issues such as local minima. In literature, local minima issue is typically avoided by either redefining the potential function such as adding vorticity or by employing search techniques which are computationally expensive. To address these challenges, a physics-informed APF is proposed in this paper where Hamiltonian mechanics is used instead of the traditional Newtonian mechanics-based approach. In this approach, instead of relying on attractive and repulsive forces for path planning, the Hamiltonian approach uses the potential field to define a path of minimum potential. Additionally, to track the desired trajectory planned by the guidance algorithm within a fixed-time frame, a non-singular fixed-time sliding mode controller (FTSMC) is used. The proposed fixed-time sliding surface not only ensures fixed-time convergence of system states but also guarantees the global stability of the closed-loop system without singularity. The simulation results presented support the claims made.",
    "authors": [
      "Rakesh Kumar Sahoo",
      "Paridhi Choudhary",
      "Manoranjan Sinha"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T13:09:18.000Z",
    "updatedAt": "2025-10-09T13:09:18.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08184v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08184v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08180v1",
    "arxivId": "2510.08180v1",
    "title": "Towards Energy-Efficient Serverless Computing with Hardware Isolation",
    "abstract": "Serverless computing provides just-in-time infrastructure provisioning with rapid elasticity and a finely-grained pricing model. As full control of resource allocation is in the hands of the cloud provider and applications only consume resources when they actually perform work, we believe that serverless computing is uniquely positioned to maximize energy efficiency. However, the focus of current serverless platforms is to run hundreds or thousands of serverless functions from different tenants on traditional server hardware, requiring expensive software isolation mechanisms and a high degree of overprovisioning, i.e., idle servers, to anticipate load spikes. With shared caches, high clock frequencies, and many-core architectures, servers today are optimized for large, singular workloads but not to run thousands of isolated functions. We propose rethinking the serverless hardware architecture to align it with the requirements of serverless software. Specifically, we propose using hardware isolation with individual processors per function instead of software isolation resulting in a serverless hardware stack that consumes energy only when an application actually performs work. In preliminary evaluation with real hardware and a typical serverless workload we find that this could reduce energy consumption overheads by 90.63% or an average 70.8MW.",
    "authors": [
      "Natalie Carl",
      "Tobias Pfandzelter",
      "David Bermbach"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T13:06:16.000Z",
    "updatedAt": "2025-10-09T13:06:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08180v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08180v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08176v1",
    "arxivId": "2510.08176v1",
    "title": "Leveraging Whisper Embeddings for Audio-based Lyrics Matching",
    "abstract": "Audio-based lyrics matching can be an appealing alternative to other content-based retrieval approaches, but existing methods often suffer from limited reproducibility and inconsistent baselines. In this work, we introduce WEALY, a fully reproducible pipeline that leverages Whisper decoder embeddings for lyrics matching tasks. WEALY establishes robust and transparent baselines, while also exploring multimodal extensions that integrate textual and acoustic features. Through extensive experiments on standard datasets, we demonstrate that WEALY achieves a performance comparable to state-of-the-art methods that lack reproducibility. In addition, we provide ablation studies and analyses on language robustness, loss functions, and embedding strategies. This work contributes a reliable benchmark for future research, and underscores the potential of speech technologies for music information retrieval tasks.",
    "authors": [
      "Eleonora Mancini",
      "Joan Serrà",
      "Paolo Torroni",
      "Yuki Mitsufuji"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "publishedAt": "2025-10-09T13:03:34.000Z",
    "updatedAt": "2025-10-09T13:03:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08176v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08176v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08173v1",
    "arxivId": "2510.08173v1",
    "title": "NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions",
    "abstract": "Instruction-following navigation is a key step toward embodied intelligence. Prior benchmarks mainly focus on semantic understanding but overlook systematically evaluating navigation agents' spatial perception and reasoning capabilities. In this work, we introduce the NavSpace benchmark, which contains six task categories and 1,228 trajectory-instruction pairs designed to probe the spatial intelligence of navigation agents. On this benchmark, we comprehensively evaluate 22 navigation agents, including state-of-the-art navigation models and multimodal large language models. The evaluation results lift the veil on spatial intelligence in embodied navigation. Furthermore, we propose SNav, a new spatially intelligent navigation model. SNav outperforms existing navigation agents on NavSpace and real robot tests, establishing a strong baseline for future work.",
    "authors": [
      "Haolin Yang",
      "Yuxing Long",
      "Zhuoyuan Yu",
      "Zihan Yang",
      "Minghan Wang",
      "Jiapeng Xu",
      "Yihan Wang",
      "Ziyan Yu",
      "Wenzhe Cai",
      "Lei Kang",
      "Hao Dong"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T12:59:19.000Z",
    "updatedAt": "2025-10-09T12:59:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08173v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08173v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08172v1",
    "arxivId": "2510.08172v1",
    "title": "SecuLEx: a Secure Limit Exchange Market for Dynamic Operating Envelopes",
    "abstract": "Distributed energy resources (DERs) are transforming power networks, challenging traditional operational methods, and requiring new coordination mechanisms. To address this challenge, this paper introduces SecuLEx (Secure Limit Exchange), a new market-based paradigm to allocate power injection and withdrawal limits that guarantee network security during time periods, called dynamic operating envelopes (DOEs). Under this paradigm, distribution system operators (DSOs) assign initial DOEs to customers. These limits can be exchanged afterward through a market, allowing customers to reallocate them according to their needs while ensuring network operational constraints. We formalize SecuLEx and illustrate DOE allocation and market exchanges on a small-scale low-voltage (LV) network, demonstrating that both procedures are computationally tractable. In this example, SecuLEx reduces renewable curtailment and improves grid utilization and social welfare compared to traditional approaches.",
    "authors": [
      "Maurizio Vassallo",
      "Adrien Bolland",
      "Alireza Bahmanyar",
      "Louis Wehenkel",
      "Laurine Duchesne",
      "Dong Liu",
      "Sania Khaskheli",
      "Alexis Ha Thuc",
      "Pedro P. Vergara",
      "Amjad Anvari-Moghaddam",
      "Simon Gerard",
      "Damien Ernst"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T12:59:08.000Z",
    "updatedAt": "2025-10-09T12:59:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08172v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08172v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08166v2",
    "arxivId": "2510.08166v2",
    "title": "Variable-Rate Texture Compression: Real-Time Rendering with JPEG",
    "abstract": "Although variable-rate compressed image formats such as JPEG are widely used to efficiently encode images, they have not found their way into real-time rendering due to special requirements such as random access to individual texels. In this paper, we investigate the feasibility of variable-rate texture compression on modern GPUs using the JPEG format, and how it compares to the GPU-friendly fixed-rate compression approaches BC1 and ASTC. Using a deferred rendering pipeline, we are able to identify the subset of blocks that are needed for a given frame, decode these, and colorize the framebuffer's pixels. Despite the additional $\\sim$0.17 bit per pixel that we require for our approach, JPEG maintains significantly better quality and compression rates compared to BC1, and depending on the type of image, outperforms or competes with ASTC. The JPEG rendering pipeline increases rendering duration by less than 0.3 ms on an RTX 4090, demonstrating that sophisticated variable-rate compression schemes are feasible on modern GPUs, even in VR. Source code and data sets are available at: https://github.com/elias1518693/jpeg_textures",
    "authors": [
      "Elias Kristmann",
      "Markus Schütz",
      "Michael Wimmer"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-09T12:51:40.000Z",
    "updatedAt": "2025-10-10T12:05:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08166v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08166v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08164v1",
    "arxivId": "2510.08164v1",
    "title": "A Multi-Simulation Bridge for IoT Digital Twins",
    "abstract": "The increasing capabilities of Digital Twins (DTs) in the context of the Internet of Things (IoT) and Industrial IoT (IIoT) call for seamless integration with simulation platforms to support system design, validation, and real-time operation. This paper introduces the concept, design, and experimental evaluation of the DT Simulation Bridge - a software framework that enables diverse interaction patterns between active DTs and simulation environments. The framework supports both the DT development lifecycle and the incorporation of simulations during active operation. Through bidirectional data exchange, simulations can update DT models dynamically, while DTs provide real-time feedback to adapt simulation parameters. We describe the architectural design and core software components that ensure flexible interoperability and scalable deployment. Experimental results show that the DT Simulation Bridge enhances design agility, facilitates virtual commissioning, and supports live behavioral analysis under realistic conditions, demonstrating its effectiveness across a range of industrial scenarios.",
    "authors": [
      "Marco Picone",
      "Samuele Burattini",
      "Marco Melloni",
      "Prasad Talasila",
      "Davide Ziglioli",
      "Matteo Martinelli",
      "Nicola Bicocchi",
      "Alessandro Ricci",
      "Peter Gorm Larsen"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T12:49:41.000Z",
    "updatedAt": "2025-10-09T12:49:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08164v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08164v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08160v1",
    "arxivId": "2510.08160v1",
    "title": "Beyond Sub-6 GHz: Leveraging mmWave Wi-Fi for Gait-Based Person Identification",
    "abstract": "Person identification plays a vital role in enabling intelligent, personalized, and secure human-computer interaction. Recent research has demonstrated the feasibility of leveraging Wi-Fi signals for passive person identification using a person's unique gait pattern. Although most existing work focuses on sub-6 GHz frequencies, the emergence of mmWave offers new opportunities through its finer spatial resolution, though its comparative advantages for person identification remain unexplored. This work presents the first comparative study between sub-6 GHz and mmWave Wi-Fi signals for person identification with commercial off-the-shelf (COTS) Wi-Fi, using a novel dataset of synchronized measurements from the two frequency bands in an indoor environment. To ensure a fair comparison, we apply identical training pipelines and model configurations across both frequency bands. Leveraging end-to-end deep learning, we show that even at low sampling rates (10 Hz), mmWave Wi-Fi signals can achieve high identification accuracy (91.2% on 20 individuals) when combined with effective background subtraction.",
    "authors": [
      "Nabeel Nisar Bhat",
      "Maksim Karnaukh",
      "Jakob Struye",
      "Rafael Berkvens",
      "Jeroen Famaey"
    ],
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T12:39:11.000Z",
    "updatedAt": "2025-10-09T12:39:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08160v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08160v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08139v1",
    "arxivId": "2510.08139v1",
    "title": "BlockSDN: Towards a High-Performance Blockchain via Software-Defined Cross Networking optimization",
    "abstract": "The scalability of blockchain systems is constrained by inefficient P2P broadcasting, as most existing optimizations focus only on the logical layer without considering physical network conditions. To address this, we propose BlockSDN, the first SDN-based integrated architecture for blockchain. BlockSDN employs a distributed control plane for a global network view, a graph engine for hierarchical clustering, and a hybrid macro-micro neighbor selection with hierarchical broadcasting. A dedicated simulation platform shows that BlockSDN reduces global block synchronization time by 65% and 55% compared to Gossip and Mercury, respectively.These results highlight the potential of SDN-enabled cross-layer coordination to significantly enhance blockchain scalability and performance.",
    "authors": [
      "Wenyang Jia",
      "Jingjing Wang",
      "Ziwei Yan",
      "Xiangli Peng",
      "Guohui Yuan"
    ],
    "categories": [
      "cs.NI",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T12:22:39.000Z",
    "updatedAt": "2025-10-09T12:22:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08139v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08139v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08127v1",
    "arxivId": "2510.08127v1",
    "title": "On the Complexity of Language Membership for Probabilistic Words",
    "abstract": "We study the membership problem to context-free languages L (CFLs) on probabilistic words, that specify for each position a probability distribution on the letters (assuming independence across positions). Our task is to compute, given a probabilistic word, what is the probability that a word drawn according to the distribution belongs to L. This problem generalizes the problem of counting how many words of length n belong to L, or of counting how many completions of a partial word belong to L. We show that this problem is in polynomial time for unambiguous context-free languages (uCFLs), but can be #P-hard already for unions of two linear uCFLs. More generally, we show that the problem is in polynomial time for so-called poly-slicewise-unambiguous languages, where given a length n we can tractably compute an uCFL for the words of length n in the language. This class includes some inherently ambiguous languages, and implies the tractability of bounded CFLs and of languages recognized by unambiguous polynomial-time counter automata; but we show that the problem can be #P-hard for nondeterministic counter automata, even for Parikh automata with a single counter. We then introduce classes of circuits from knowledge compilation which we use for tractable counting, and show that this covers the tractability of poly-slicewise-unambiguous languages and of some CFLs that are not poly-slicewise-unambiguous. Extending these circuits with negation further allows us to show tractability for the language of primitive words, and for the language of concatenations of two palindromes. We finally show the conditional undecidability of the meta-problem that asks, given a CFG, whether the probabilistic membership problem for that CFG is tractable or #P-hard.",
    "authors": [
      "Antoine Amarilli",
      "Mikaël Monet",
      "Paul Raphaël",
      "Sylvain Salvati"
    ],
    "categories": [
      "cs.FL"
    ],
    "publishedAt": "2025-10-09T12:13:34.000Z",
    "updatedAt": "2025-10-09T12:13:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08127v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08127v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08124v1",
    "arxivId": "2510.08124v1",
    "title": "Timeline Problems in Temporal Graphs: Vertex Cover vs. Dominating Set",
    "abstract": "A temporal graph is a finite sequence of graphs, called snapshots, over the same vertex set. Many temporal graph problems turn out to be much more difficult than their static counterparts. One such problem is \\textsc{Timeline Vertex Cover} (also known as \\textsc{MinTimeline$_\\infty$}), a temporal analogue to the classical \\textsc{Vertex Cover} problem. In this problem, one is given a temporal graph $\\mathcal{G}$ and two integers $k$ and $\\ell$, and the goal is to cover each edge of each snapshot by selecting for each vertex at most $k$ activity intervals of length at most $\\ell$ each. Here, an edge $uv$ in the $i$th snapshot is covered, if an activity interval of $u$ or $v$ is active at time $i$. In this work, we continue the algorithmic study of \\textsc{Timeline Vertex Cover} and introduce the \\textsc{Timeline Dominating Set} problem where we want to dominate all vertices in each snapshot by the selected activity intervals. We analyze both problems from a classical and parameterized point of view and also consider partial problem versions, where the goal is to cover (dominate) at least $t$ edges (vertices) of the snapshots. With respect to the parameterized complexity, we consider the temporal graph parameters vertex-interval-membership-width $(vimw)$ and interval-membership-width $(imw)$. We show that all considered problems admit FPT-algorithms when parameterized by $vimw + k+\\ell$. This provides a smaller parameter combination than the ones used for previously known FPT-algorithms for \\textsc{Timeline Vertex Cover}. Surprisingly, for $imw+ k+\\ell$, \\textsc{Timeline Dominating Set} turns out to be easier than \\textsc{Timeline Vertex Cover}, by also admitting an FPT-algorithm, whereas the vertex cover version is NP-hard even if $imw+\\, k+\\ell$ is constant. We also consider parameterization by combinations of $n$, the vertex set size, with $k$ or $\\ell$ and parameterization by $t$.",
    "authors": [
      "Anton Herrmann",
      "Christian Komusiewicz",
      "Nils Morawietz",
      "Frank Sommer"
    ],
    "categories": [
      "cs.DS",
      "cs.CC"
    ],
    "publishedAt": "2025-10-09T12:08:54.000Z",
    "updatedAt": "2025-10-09T12:08:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08124v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08124v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08121v1",
    "arxivId": "2510.08121v1",
    "title": "Closed-loop control of sloshing fuel in a spinning spacecraft",
    "abstract": "New-generation space missions require satellites to carry substantial amounts of liquid propellant, making it essential to analyse the coupled control-structure-propellant dynamics in detail. While Computational Fluid Dynamics (CFD) offers high-fidelity predictions, its computational cost limits its use in iterative design. Equivalent Mechanical Models (EMMs) provide a faster alternative, though their predictive performance, especially in closed-loop scenarios, remains largely unexplored. This work presents a comparative analysis of a spacecraft under feedback control, using both CFD and a reduced-order sloshing model. Results show good agreement, validating the simplified model for the manoeuvrer considered. This validation enables efficient sensitivity and stability studies, offering a practical tool for early-stage spacecraft design.",
    "authors": [
      "Umberto Zucchelli",
      "Miguel Alfonso Mendez",
      "Annafederica Urbano",
      "Sebastien Vincent-Bonnieu",
      "Piotr Wenderski",
      "Francesco Sanfedino"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T12:06:21.000Z",
    "updatedAt": "2025-10-09T12:06:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08121v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08121v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08119v2",
    "arxivId": "2510.08119v2",
    "title": "General formulation of an analytic, Lipschitz continuous control allocation for thrust-vectored controlled rigid-bodies",
    "abstract": "This study introduces a systematic and scalable method for arbitrary rigid-bodies equipped with vectorized thrusters. Two novel solutions are proposed: a closed-form, Lipschitz continuous mapping that ensures smooth actuator orientation references, and a convex optimization formulation capable of handling practical actuator constraints such as thrust saturation and angular rate limits. Both methods leverage the null-space structure of the allocation mapping to perform singularity avoidance while generating sub-optimal yet practical solutions. The effectiveness and generality of the proposed framework are demonstrated through numerical simulations on a 3DOF marine vessel and a 6DOF aerial quadcopter.",
    "authors": [
      "Frank Mukwege",
      "Tam Willy Nguyen",
      "Emanuele Garone"
    ],
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "publishedAt": "2025-10-09T12:05:30.000Z",
    "updatedAt": "2025-10-13T10:48:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08119v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08119v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08118v2",
    "arxivId": "2510.08118v2",
    "title": "Accurate and Noise-Tolerant Extraction of Routine Logs in Robotic Process Automation (Extended Version)",
    "abstract": "Robotic Process Mining focuses on the identification of the routine types performed by human resources through a User Interface. The ultimate goal is to discover routine-type models to enable robotic process automation. The discovery of routine-type models requires the provision of a routine log. Unfortunately, the vast majority of existing works do not directly focus on enabling the model discovery, limiting themselves to extracting the set of actions that are part of the routines. They were also not evaluated in scenarios characterized by inconsistent routine execution, hereafter referred to as noise, which reflects natural variability and occasional errors in human performance. This paper presents a clustering-based technique that aims to extract routine logs. Experiments were conducted on nine UI logs from the literature with different levels of injected noise. Our technique was compared with existing techniques, most of which are not meant to discover routine logs but were adapted for the purpose. The results were evaluated through standard state-of-the-art metrics, showing that we can extract more accurate routine logs than what the state of the art could, especially in the presence of noise.",
    "authors": [
      "Massimiliano de Leoni",
      "Faizan Ahmed Khan",
      "Simone Agostinelli"
    ],
    "categories": [
      "cs.RO",
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T12:02:28.000Z",
    "updatedAt": "2025-10-11T09:53:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08118v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08118v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08106v1",
    "arxivId": "2510.08106v1",
    "title": "Beyond hospital reach: Autonomous lightweight ultrasound robot for liver sonography",
    "abstract": "Liver disease is a major global health burden. While ultrasound is the first-line diagnostic tool, liver sonography requires locating multiple non-continuous planes from positions where target structures are often not visible, for biometric assessment and lesion detection, requiring significant expertise. However, expert sonographers are severely scarce in resource-limited regions. Here, we develop an autonomous lightweight ultrasound robot comprising an AI agent that integrates multi-modal perception with memory attention for localization of unseen target structures, and a 588-gram 6-degrees-of-freedom cable-driven robot. By mounting on the abdomen, the system enhances robustness against motion. Our robot can autonomously acquire expert-level standard liver ultrasound planes and detect pathology in patients, including two from Xining, a 2261-meter-altitude city with limited medical resources. Our system performs effectively on rapid-motion individuals and in wilderness environments. This work represents the first demonstration of autonomous sonography across multiple challenging scenarios, potentially transforming access to expert-level diagnostics in underserved regions.",
    "authors": [
      "Zihan Li",
      "Yixiao Xu",
      "Lei Zhang",
      "Taiyu Han",
      "Xinshan Yang",
      "Yingni Wang",
      "Mingxuan Liu",
      "Shenghai Xin",
      "Linxun Liu",
      "Hongen Liao",
      "Guochen Ning"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T11:43:29.000Z",
    "updatedAt": "2025-10-09T11:43:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08106v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08106v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08104v1",
    "arxivId": "2510.08104v1",
    "title": "Development of Mental Models in Human-AI Collaboration: A Conceptual Framework",
    "abstract": "Artificial intelligence has become integral to organizational decision-making and while research has explored many facets of this human-AI collaboration, the focus has mainly been on designing the AI agent(s) and the way the collaboration is set up - generally assuming a human decision-maker to be \"fixed\". However, it has largely been neglected that decision-makers' mental models evolve through their continuous interaction with AI systems. This paper addresses this gap by conceptualizing how the design of human-AI collaboration influences the development of three complementary and interdependent mental models necessary for this collaboration. We develop an integrated socio-technical framework that identifies the mechanisms driving the mental model evolution: data contextualization, reasoning transparency, and performance feedback. Our work advances human-AI collaboration literature through three key contributions: introducing three distinct mental models (domain, information processing, complementarity-awareness); recognizing the dynamic nature of mental models; and establishing mechanisms that guide the purposeful design of effective human-AI collaboration.",
    "authors": [
      "Joshua Holstein",
      "Gerhard Satzger"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T11:40:41.000Z",
    "updatedAt": "2025-10-09T11:40:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08104v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08104v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09690v1",
    "arxivId": "2510.09690v1",
    "title": "A Semantic Model for Audit of Cloud Engines based on ISO/IEC TR 3445:2022",
    "abstract": "Cloud computing has become the foundation of modern digital infrastructure, yet the absence of a unified architectural and compliance framework impedes interoperability, auditability, and robust security. This paper introduces a formal, machine-readable semantic model for Cloud Engines, integrating the architectural taxonomy of ISO/IEC 22123 (Cloud Reference Architecture) with the security and compliance controls of ISO/IEC 27001:2022 and ISO/IEC TR 3445:2022. The model decomposes cloud systems into four canonical interfaces--Control, Business, Audit, and Data--and extends them with a security ontology that maps mechanisms such as authentication, authorization, and encryption to specific compliance controls. Expressed in RDF/Turtle, the model enables semantic reasoning, automated compliance validation, and vendor-neutral architecture design. We demonstrate its practical utility through OpenStack and AWS case studies, and provide reproducible validation workflows using SPARQL and SHACL. This work advances the state of cloud security modeling by bridging architectural and compliance standards in a unified framework, with a particular emphasis on auditability.",
    "authors": [
      "Morteza Sargolzaei Javan"
    ],
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T11:32:35.000Z",
    "updatedAt": "2025-10-09T11:32:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09690v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09690v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08091v1",
    "arxivId": "2510.08091v1",
    "title": "Everything is Plausible: Investigating the Impact of LLM Rationales on Human Notions of Plausibility",
    "abstract": "We investigate the degree to which human plausibility judgments of multiple-choice commonsense benchmark answers are subject to influence by (im)plausibility arguments for or against an answer, in particular, using rationales generated by LLMs. We collect 3,000 plausibility judgments from humans and another 13,600 judgments from LLMs. Overall, we observe increases and decreases in mean human plausibility ratings in the presence of LLM-generated PRO and CON rationales, respectively, suggesting that, on the whole, human judges find these rationales convincing. Experiments with LLMs reveal similar patterns of influence. Our findings demonstrate a novel use of LLMs for studying aspects of human cognition, while also raising practical concerns that, even in domains where humans are ``experts'' (i.e., common sense), LLMs have the potential to exert considerable influence on people's beliefs.",
    "authors": [
      "Shramay Palta",
      "Peter Rankel",
      "Sarah Wiegreffe",
      "Rachel Rudinger"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T11:22:29.000Z",
    "updatedAt": "2025-10-09T11:22:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08091v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08091v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08082v1",
    "arxivId": "2510.08082v1",
    "title": "Optimizing BCI Rehabilitation Protocols for Stroke: Exploring Task Design and Training Duration",
    "abstract": "Stroke is a leading cause of long-term disability and the second most common cause of death worldwide. Although acute treatments have advanced, recovery remains challenging and limited. Brain-computer interfaces (BCIs) have emerged as a promising tool for post-stroke rehabilitation by promoting neuroplasticity. However, clinical outcomes remain variable, and optimal protocols have yet to be established. This study explores strategies to optimize BCI-based rehabilitation by comparing motor imagery of affected hand movement versus rest, instead of the conventional left-versus-right motor imagery. This alternative aims to simplify the task and address the weak contralateral activation commonly observed in stroke patients. Two datasets, one from healthy individuals and one from stroke patients, were used to evaluate the proposed approach. The results showed improved performance using both FBCSP and EEGNet. Additionally, we investigated the impact of session duration and found that shorter training sessions produced better BCI performance than longer sessions.",
    "authors": [
      "Aniana Cruz",
      "Marko Kuzmanoski",
      "Gabriel Pires"
    ],
    "categories": [
      "q-bio.NC",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "publishedAt": "2025-10-09T11:12:34.000Z",
    "updatedAt": "2025-10-09T11:12:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08082v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08082v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08078v2",
    "arxivId": "2510.08078v2",
    "title": "Detecting and Mitigating Insertion Hallucination in Video-to-Audio Generation",
    "abstract": "Video-to-Audio generation has made remarkable strides in automatically synthesizing sound for video. However, existing evaluation metrics, which focus on semantic and temporal alignment, overlook a critical failure mode: models often generate acoustic events, particularly speech and music, that have no corresponding visual source. We term this phenomenon Insertion Hallucination and identify it as a systemic risk driven by dataset biases, such as the prevalence of off-screen sounds, that remains completely undetected by current metrics. To address this challenge, we first develop a systematic evaluation framework that employs a majority-voting ensemble of multiple audio event detectors. We also introduce two novel metrics to quantify the prevalence and severity of this issue: IH@vid (the fraction of videos with hallucinations) and IH@dur (the fraction of hallucinated duration). Building on this, we propose Posterior Feature Correction, a novel training-free inference-time method that mitigates IH. PFC operates in a two-pass process: it first generates an initial audio output to detect hallucinated segments, and then regenerates the audio after masking the corresponding video features at those timestamps. Experiments on several mainstream V2A benchmarks first reveal that state-of-the-art models suffer from severe IH. In contrast, our PFC method reduces both the prevalence and duration of hallucinations by over 50\\% on average, without degrading, and in some cases even improving, conventional metrics for audio quality and temporal synchronization. Our work is the first to formally define, systematically measure, and effectively mitigate Insertion Hallucination, paving the way for more reliable and faithful V2A models.",
    "authors": [
      "Liyang Chen",
      "Hongkai Chen",
      "Yujun Cai",
      "Sifan Li",
      "Qingwen Ye",
      "Yiwei Wang"
    ],
    "categories": [
      "cs.SD",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T11:08:07.000Z",
    "updatedAt": "2025-10-13T11:22:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08078v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.08078v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08072v1",
    "arxivId": "2510.08072v1",
    "title": "When Light Bends to the Collective Will: A Theory and Vision for Adaptive Photonic Scale-up Domains",
    "abstract": "As chip-to-chip silicon photonics gain traction for their bandwidth and energy efficiency, collective communication has emerged as a critical bottleneck in scale-up systems. Programmable photonic interconnects offer a promising path forward: by dynamically reconfiguring the fabric, they can establish direct, high-bandwidth optical paths between communicating endpoints -- \\emph{synchronously and guided by the structure of collective operations} (e.g., AllReduce). However, realizing this vision -- \\emph{when light bends to the collective will} -- requires navigating a fundamental trade-off between reconfiguration delay and the performance gains of adaptive topologies. In this paper, we present a simple theoretical framework for adaptive photonic scale-up domains that makes this trade-off explicit and clarifies when reconfiguration is worthwhile. Along the way, we highlight a connection -- not surprising but still powerful -- between the Birkhoff--von Neumann (BvN) decomposition, maximum concurrent flow (a classic measure of network throughput), and the well-known $\\alpha$-$\\beta$ cost model for collectives. Finally, we outline a research agenda in algorithm design and systems integration that can build on this foundation.",
    "authors": [
      "Vamsi Addanki"
    ],
    "categories": [
      "cs.NI",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T10:59:27.000Z",
    "updatedAt": "2025-10-09T10:59:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08072v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08072v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08062v1",
    "arxivId": "2510.08062v1",
    "title": "Attribution-by-design: Ensuring Inference-Time Provenance in Generative Music Systems",
    "abstract": "The rise of AI-generated music is diluting royalty pools and revealing structural flaws in existing remuneration frameworks, challenging the well-established artist compensation systems in the music industry. Existing compensation solutions, such as piecemeal licensing agreements, lack scalability and technical rigour, while current data attribution mechanisms provide only uncertain estimates and are rarely implemented in practice. This paper introduces a framework for a generative music infrastructure centred on direct attribution, transparent royalty distribution, and granular control for artists and rights' holders. We distinguish ontologically between the training set and the inference set, which allows us to propose two complementary forms of attribution: training-time attribution and inference-time attribution. We here favour inference-time attribution, as it enables direct, verifiable compensation whenever an artist's catalogue is used to condition a generated output. Besides, users benefit from the ability to condition generations on specific songs and receive transparent information about attribution and permitted usage. Our approach offers an ethical and practical solution to the pressing need for robust compensation mechanisms in the era of AI-generated music, ensuring that provenance and fairness are embedded at the core of generative systems.",
    "authors": [
      "Fabio Morreale",
      "Wiebke Hutiri",
      "Joan Serrà",
      "Alice Xiang",
      "Yuki Mitsufuji"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T10:49:44.000Z",
    "updatedAt": "2025-10-09T10:49:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08062v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08062v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08055v1",
    "arxivId": "2510.08055v1",
    "title": "From Tokens to Layers: Redefining Stall-Free Scheduling for LLM Serving with Layered Prefill",
    "abstract": "Large Language Model (LLM) inference in production must meet stringent service-level objectives for both time-to-first-token (TTFT) and time-between-token (TBT) while maximizing throughput under fixed compute, memory, and interconnect budgets. Modern serving systems adopt stall-free scheduling techniques such as chunked prefill, which splits long prompt processing along the token dimension and interleaves prefill with ongoing decode iterations. While effective at stabilizing TBT, chunked prefill incurs substantial overhead in Mixture-of-Experts (MoE) models: redundant expert weight loads increase memory traffic by up to 39% and inflate energy consumption. We propose layered prefill, a new scheduling paradigm that treats transformer layer groups as the primary scheduling unit. By vertically partitioning the model into contiguous layer groups and interleaving prefill and decode across the groups, layered prefill sustains stall-free decoding while eliminating chunk-induced MoE weight reloads. It reduces off-chip bandwidth demand, lowering TTFT by up to 70%, End-to-End latency by 41% and per-token energy by up to 22%. Evaluations show that layered prefill consistently improves the TTFT--TBT Pareto frontier over chunked prefill, reducing expert-load traffic and energy cost while maintaining stall-free decoding. Overall, shifting the scheduling axis from tokens to layers unlocks a new operating regime for high-efficiency, energy-aware LLM serving in co-located environments.",
    "authors": [
      "Gunjun Lee",
      "Jiwon Kim",
      "Jaiyoung Park",
      "Younjoo Lee",
      "Jung Ho Ahn"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T10:41:35.000Z",
    "updatedAt": "2025-10-09T10:41:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08055v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08055v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08044v1",
    "arxivId": "2510.08044v1",
    "title": "Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation",
    "abstract": "Large language models (LLMs) demonstrate advanced reasoning abilities, enabling robots to understand natural language instructions and generate high-level plans with appropriate grounding. However, LLM hallucinations present a significant challenge, often leading to overconfident yet potentially misaligned or unsafe plans. While researchers have explored uncertainty estimation to improve the reliability of LLM-based planning, existing studies have not sufficiently differentiated between epistemic and intrinsic uncertainty, limiting the effectiveness of uncertainty estimation. In this paper, we present Combined Uncertainty estimation for Reliable Embodied planning (CURE), which decomposes the uncertainty into epistemic and intrinsic uncertainty, each estimated separately. Furthermore, epistemic uncertainty is subdivided into task clarity and task familiarity for more accurate evaluation. The overall uncertainty assessments are obtained using random network distillation and multi-layer perceptron regression heads driven by LLM features. We validated our approach in two distinct experimental settings: kitchen manipulation and tabletop rearrangement experiments. The results show that, compared to existing methods, our approach yields uncertainty estimates that are more closely aligned with the actual execution outcomes.",
    "authors": [
      "Shiyuan Yin",
      "Chenjia Bai",
      "Zihao Zhang",
      "Junwei Jin",
      "Xinxin Zhang",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T10:26:58.000Z",
    "updatedAt": "2025-10-09T10:26:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08044v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08044v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08027v1",
    "arxivId": "2510.08027v1",
    "title": "Integer Factoring with Unoperations",
    "abstract": "This work introduces the notion of unoperation $\\mathfrak{Un}(\\hat{O})$ of some operation $\\hat{O}$. Given a valid output of $\\hat{O}$, the corresponding unoperation produces a set of all valid inputs to $\\hat{O}$ that produce the given output. Further, the working principle of unoperations is illustrated using the example of addition. A device providing that functionality is constructed utilising a quantum circuit performing the unoperation of addition - referred to as unaddition. To highlight the potential of the approach the unaddition quantum circuit is employed to construct a device for factoring integer numbers $N$, which is then called unmultiplier. This approach requires only a number of qubits $\\in \\mathcal{O}((\\log{N})^2)$, rivalling the best known factoring algorithms to date.",
    "authors": [
      "Paul Kohl"
    ],
    "categories": [
      "quant-ph",
      "cs.DS",
      "11A51, 68Q12, 81P65, 81P68"
    ],
    "publishedAt": "2025-10-09T10:04:43.000Z",
    "updatedAt": "2025-10-09T10:04:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08027v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08027v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08022v1",
    "arxivId": "2510.08022v1",
    "title": "FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset",
    "abstract": "Data-driven robotic manipulation learning depends on large-scale, high-quality expert demonstration datasets. However, existing datasets, which primarily rely on human teleoperated robot collection, are limited in terms of scalability, trajectory smoothness, and applicability across different robotic embodiments in real-world environments. In this paper, we present FastUMI-100K, a large-scale UMI-style multimodal demonstration dataset, designed to overcome these limitations and meet the growing complexity of real-world manipulation tasks. Collected by FastUMI, a novel robotic system featuring a modular, hardware-decoupled mechanical design and an integrated lightweight tracking system, FastUMI-100K offers a more scalable, flexible, and adaptable solution to fulfill the diverse requirements of real-world robot demonstration data. Specifically, FastUMI-100K contains over 100K+ demonstration trajectories collected across representative household environments, covering 54 tasks and hundreds of object types. Our dataset integrates multimodal streams, including end-effector states, multi-view wrist-mounted fisheye images and textual annotations. Each trajectory has a length ranging from 120 to 500 frames. Experimental results demonstrate that FastUMI-100K enables high policy success rates across various baseline algorithms, confirming its robustness, adaptability, and real-world applicability for solving complex, dynamic manipulation challenges. The source code and dataset will be released in this link https://github.com/MrKeee/FastUMI-100K.",
    "authors": [
      "Kehui Liu",
      "Zhongjie Jia",
      "Yang Li",
      "Zhaxizhuoma",
      "Pengan Chen",
      "Song Liu",
      "Xin Liu",
      "Pingrui Zhang",
      "Haoming Song",
      "Xinyi Ye",
      "Nieqing Cao",
      "Zhigang Wang",
      "Jia Zeng",
      "Dong Wang",
      "Yan Ding",
      "Bin Zhao",
      "Xuelong Li"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T09:57:25.000Z",
    "updatedAt": "2025-10-09T09:57:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08022v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08022v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08012v1",
    "arxivId": "2510.08012v1",
    "title": "Do We Really Need SFT? Prompt-as-Policy over Knowledge Graphs for Cold-start Next POI Recommendation",
    "abstract": "Next point-of-interest (POI) recommendation is crucial for smart urban services such as tourism, dining, and transportation, yet most approaches struggle under cold-start conditions where user-POI interactions are sparse. Recent efforts leveraging large language models (LLMs) address this challenge through either supervised fine-tuning (SFT) or in-context learning (ICL). However, SFT demands costly annotations and fails to generalize to inactive users, while static prompts in ICL cannot adapt to diverse user contexts. To overcome these limitations, we propose Prompt-as-Policy over knowledge graphs, a reinforcement-guided prompting framework that learns to construct prompts dynamically through contextual bandit optimization. Our method treats prompt construction as a learnable policy that adaptively determines (i) which relational evidences to include, (ii) the number of evidence per candidate, and (iii) their organization and ordering within prompts. More specifically, we construct a knowledge graph (KG) to discover candidates and mine relational paths, which are transformed into evidence cards that summarize rationales for each candidate POI. The frozen LLM then acts as a reasoning engine, generating recommendations from the KG-discovered candidate set based on the policy-optimized prompts. Experiments on three real-world datasets demonstrate that Prompt-as-Policy consistently outperforms state-of-the-art baselines, achieving average 7.7\\% relative improvements in Acc@1 for inactive users, while maintaining competitive performance on active users, without requiring model fine-tuning.",
    "authors": [
      "Jinze Wang",
      "Lu Zhang",
      "Yiyang Cui",
      "Zhishu Shen",
      "Xingjun Ma",
      "Jiong Jin",
      "Tiehua Zhang"
    ],
    "categories": [
      "cs.SI"
    ],
    "publishedAt": "2025-10-09T09:50:05.000Z",
    "updatedAt": "2025-10-09T09:50:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08012v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08012v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08005v1",
    "arxivId": "2510.08005v1",
    "title": "Past, Present, and Future of Bug Tracking in the Generative AI Era",
    "abstract": "Traditional bug tracking systems rely heavily on manual reporting, reproduction, triaging, and resolution, each carried out by different stakeholders such as end users, customer support, developers, and testers. This division of responsibilities requires significant coordination and widens the communication gap between non-technical users and technical teams, slowing the process from bug discovery to resolution. Moreover, current systems are highly asynchronous; users often wait hours or days for a first response, delaying fixes and contributing to frustration. This paper examines the evolution of bug tracking, from early paper-based reporting to today's web-based and SaaS platforms. Building on this trajectory, we propose an AI-powered bug tracking framework that augments existing tools with intelligent, large language model (LLM)-driven automation. Our framework addresses two main challenges: reducing time-to-fix and minimizing human overhead. Users report issues in natural language, while AI agents refine reports, attempt reproduction, and request missing details. Reports are then classified, invalid ones resolved through no-code fixes, and valid ones localized and assigned to developers. LLMs also generate candidate patches, with human oversight ensuring correctness. By integrating automation into each phase, our framework accelerates response times, improves collaboration, and strengthens software maintenance practices for a more efficient, user-centric future.",
    "authors": [
      "Utku Boran Torun",
      "Mehmet Taha Demircan",
      "Mahmut Furkan Gön",
      "Eray Tüzün"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T09:42:30.000Z",
    "updatedAt": "2025-10-09T09:42:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08005v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08005v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08004v1",
    "arxivId": "2510.08004v1",
    "title": "Personality-Enhanced Multimodal Depression Detection in the Elderly",
    "abstract": "This paper presents our solution to the Multimodal Personality-aware Depression Detection (MPDD) challenge at ACM MM 2025. We propose a multimodal depression detection model in the Elderly that incorporates personality characteristics. We introduce a multi-feature fusion approach based on a co-attention mechanism to effectively integrate LLDs, MFCCs, and Wav2Vec features in the audio modality. For the video modality, we combine representations extracted from OpenFace, ResNet, and DenseNet to construct a comprehensive visual feature set. Recognizing the critical role of personality in depression detection, we design an interaction module that captures the relationships between personality traits and multimodal features. Experimental results from the MPDD Elderly Depression Detection track demonstrate that our method significantly enhances performance, providing valuable insights for future research in multimodal depression detection among elderly populations.",
    "authors": [
      "Honghong Wang",
      "Jing Deng",
      "Rong Zheng"
    ],
    "categories": [
      "cs.SD",
      "cs.MM",
      "eess.AS"
    ],
    "publishedAt": "2025-10-09T09:41:51.000Z",
    "updatedAt": "2025-10-09T09:41:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08004v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08004v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07989v1",
    "arxivId": "2510.07989v1",
    "title": "A Stable, Accurate and Well-Conditioned Time-Domain PMCHWT Formulation",
    "abstract": "This paper introduces a new boundary element formulation for transient electromagnetic scattering by homogeneous dielectric objects based on the time-domain PMCHWT equation. To address dense-mesh breakdown, a multiplicative Calderon preconditioner utilizing a modified static electric field integral operator is employed. Large-timestep breakdown and late-time instability are simultaneously resolved by rescaling the Helmholtz components leveraging the quasi-Helmholtz projectors and using temporal differentiation and integration as rescaling operators. This rescaling also balances the loop and star components at large timesteps, improving solution accuracy. The resulting discrete system is solved using a marching-on-in-time scheme and iterative solvers. Numerical experiments for simply- and multiply-connected dielectric scatterers, including highly non-smooth geometries, corroborate the accuracy, stability, and efficiency of the proposed approach.",
    "authors": [
      "Van Chien Le",
      "Cedric Munger",
      "Francesco P. Andriulli",
      "Kristof Cools"
    ],
    "categories": [
      "eess.SY",
      "cs.NA",
      "cs.SY",
      "math.NA"
    ],
    "publishedAt": "2025-10-09T09:22:51.000Z",
    "updatedAt": "2025-10-09T09:22:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07989v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07989v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07987v1",
    "arxivId": "2510.07987v1",
    "title": "Quantifying Locomotion Differences Between Virtual Reality Users With and Without Motor Impairments",
    "abstract": "Today's virtual reality (VR) systems and environments assume that users have typical abilities, which can make VR inaccessible to people with physical impairments. However, there is not yet an understanding of how inaccessible locomotion techniques are, and which interactions make them inaccessible. To this end, we conducted a study in which people with and without upper-body impairments navigated a virtual environment with six locomotion techniques to quantify performance differences among groups. We found that groups performed similarly with Sliding Looking on all performance measures, suggesting that this might be a good default locomotion technique for VR apps. To understand the nature of performance differences with the other techniques, we collected low-level interaction data from the controllers and headset and analyzed interaction differences with a set of movement-, button-, and target-related metrics. We found that movement-related metrics from headset data reveal differences among groups with all techniques, suggesting these are good metrics for identifying whether a user has an upper-body impairment. We also identify movement-, button, and target-related metrics that can explain performance differences between groups for particular locomotion techniques.",
    "authors": [
      "Rachel L. Franz",
      "Jacob O. Wobbrock"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T09:21:55.000Z",
    "updatedAt": "2025-10-09T09:21:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07987v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07987v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07986v1",
    "arxivId": "2510.07986v1",
    "title": "Orientation Learning and Adaptation towards Simultaneous Incorporation of Multiple Local Constraints",
    "abstract": "Orientation learning plays a pivotal role in many tasks. However, the rotation group SO(3) is a Riemannian manifold. As a result, the distortion caused by non-Euclidean geometric nature introduces difficulties to the incorporation of local constraints, especially for the simultaneous incorporation of multiple local constraints. To address this issue, we propose the Angle-Axis Space-based orientation representation method to solve several orientation learning problems, including orientation adaptation and minimization of angular acceleration. Specifically, we propose a weighted average mechanism in SO(3) based on the angle-axis representation method. Our main idea is to generate multiple trajectories by considering different local constraints at different basepoints. Then these multiple trajectories are fused to generate a smooth trajectory by our proposed weighted average mechanism, achieving the goal to incorporate multiple local constraints simultaneously. Compared with existing solution, ours can address the distortion issue and make the off-theshelf Euclidean learning algorithm be re-applicable in non-Euclidean space. Simulation and Experimental evaluations validate that our solution can not only adapt orientations towards arbitrary desired via-points and cope with angular acceleration constraints, but also incorporate multiple local constraints simultaneously to achieve extra benefits, e.g., achieving smaller acceleration costs.",
    "authors": [
      "Gaofeng Li",
      "Peisen Xu",
      "Ruize Wang",
      "Qi Ye",
      "Jiming Chen",
      "Dezhen Song",
      "Yanlong Huang"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T09:18:59.000Z",
    "updatedAt": "2025-10-09T09:18:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07986v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07986v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08656v1",
    "arxivId": "2510.08656v1",
    "title": "A 3D Generation Framework from Cross Modality to Parameterized Primitive",
    "abstract": "Recent advancements in AI-driven 3D model generation have leveraged cross modality, yet generating models with smooth surfaces and minimizing storage overhead remain challenges. This paper introduces a novel multi-stage framework for generating 3D models composed of parameterized primitives, guided by textual and image inputs. In the framework, A model generation algorithm based on parameterized primitives, is proposed, which can identifies the shape features of the model constituent elements, and replace the elements with parameterized primitives with high quality surface. In addition, a corresponding model storage method is proposed, it can ensure the original surface quality of the model, while retaining only the parameters of parameterized primitives. Experiments on virtual scene dataset and real scene dataset demonstrate the effectiveness of our method, achieving a Chamfer Distance of 0.003092, a VIoU of 0.545, a F1-Score of 0.9139 and a NC of 0.8369, with primitive parameter files approximately 6KB in size. Our approach is particularly suitable for rapid prototyping of simple models.",
    "authors": [
      "Yiming Liang",
      "Huan Yu",
      "Zili Wang",
      "Shuyou Zhang",
      "Guodong Yi",
      "Jin Wang",
      "Jianrong Tan"
    ],
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T09:15:33.000Z",
    "updatedAt": "2025-10-09T09:15:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08656v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08656v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07979v1",
    "arxivId": "2510.07979v1",
    "title": "IntMeanFlow: Few-step Speech Generation with Integral Velocity Distillation",
    "abstract": "Flow-based generative models have greatly improved text-to-speech (TTS) synthesis quality, but inference speed remains limited by the iterative sampling process and multiple function evaluations (NFE). The recent MeanFlow model accelerates generation by modeling average velocity instead of instantaneous velocity. However, its direct application to TTS encounters challenges, including GPU memory overhead from Jacobian-vector products (JVP) and training instability due to self-bootstrap processes. To address these issues, we introduce IntMeanFlow, a framework for few-step speech generation with integral velocity distillation. By approximating average velocity with the teacher's instantaneous velocity over a temporal interval, IntMeanFlow eliminates the need for JVPs and self-bootstrap, improving stability and reducing GPU memory usage. We also propose the Optimal Step Sampling Search (O3S) algorithm, which identifies the model-specific optimal sampling steps, improving speech synthesis without additional inference overhead. Experiments show that IntMeanFlow achieves 1-NFE inference for token-to-spectrogram and 3-NFE for text-to-spectrogram tasks while maintaining high-quality synthesis. Demo samples are available at https://vvwangvv.github.io/intmeanflow.",
    "authors": [
      "Wei Wang",
      "Rong Cao",
      "Yi Guo",
      "Zhengyang Chen",
      "Kuan Chen",
      "Yuanyuan Huo"
    ],
    "categories": [
      "cs.SD"
    ],
    "publishedAt": "2025-10-09T09:13:11.000Z",
    "updatedAt": "2025-10-09T09:13:11.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07979v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07979v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07975v1",
    "arxivId": "2510.07975v1",
    "title": "Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation",
    "abstract": "Enabling robots to perform precise and generalized manipulation in unstructured environments remains a fundamental challenge in embodied AI. While Vision-Language Models (VLMs) have demonstrated remarkable capabilities in semantic reasoning and task planning, a significant gap persists between their high-level understanding and the precise physical execution required for real-world manipulation. To bridge this \"semantic-to-physical\" gap, we introduce GRACE, a novel framework that grounds VLM-based reasoning through executable analytic concepts (EAC)-mathematically defined blueprints that encode object affordances, geometric constraints, and semantics of manipulation. Our approach integrates a structured policy scaffolding pipeline that turn natural language instructions and visual information into an instantiated EAC, from which we derive grasp poses, force directions and plan physically feasible motion trajectory for robot execution. GRACE thus provides a unified and interpretable interface between high-level instruction understanding and low-level robot control, effectively enabling precise and generalizable manipulation through semantic-physical grounding. Extensive experiments demonstrate that GRACE achieves strong zero-shot generalization across a variety of articulated objects in both simulated and real-world environments, without requiring task-specific training.",
    "authors": [
      "Mingyang Sun",
      "Jiude Wei",
      "Qichen He",
      "Donglin Wang",
      "Cewu Lu",
      "Jianhua Sun"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T09:08:33.000Z",
    "updatedAt": "2025-10-09T09:08:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07975v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07975v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07967v1",
    "arxivId": "2510.07967v1",
    "title": "Pre/Absence: Prompting Cultural Awareness and Understanding for Lost Architectural Heritage in Virtual Reality",
    "abstract": "Lost architectural heritage presents interpretive challenges due to vanished structures and fragmented historical records. Using Hanyuan Hall of the Tang dynasty's Daming Palace as a case study, we conducted a formative investigation with archaeologists, heritage administrators, and visitors to identify key issues in current interpretation practices. We found that these practices often compress complex cultural layers into factual summaries and rely on linear narratives that overlook the continuing reinterpretations following a site's disappearance. In response, we designed Pre/Absence, a virtual reality experience grounded in the presence-absence dialectic to interweave tangible and vanished aspects of heritage within a spatiotemporal narrative. A mixed-method study with 28 participants compared Pre/Absence to a paper-based experience. Both improved users' factual understanding, but the VR experience more strongly enhanced cultural awareness, evoked emotional engagement with loss, and encouraged critical reflection on the evolving social and political meanings of heritage. The findings suggest that VR can move beyond static reconstruction to engage users as co-constructors of cultural meaning, providing a nuanced framework for critical heritage narrative design in human-computer interaction.",
    "authors": [
      "Yaning Li",
      "Ke Zhao",
      "Shucheng Zheng",
      "Xingyu Chen",
      "Chenyi Chen",
      "Wenxi Dai",
      "Weile Jiang",
      "Qi Dong",
      "Yiqing Zhao",
      "Meng Li",
      "Lin-Ping Yuan"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T08:59:19.000Z",
    "updatedAt": "2025-10-09T08:59:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07967v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07967v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07960v1",
    "arxivId": "2510.07960v1",
    "title": "A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG",
    "abstract": "Wearable EEG devices have emerged as a promising alternative to polysomnography (PSG). As affordable and scalable solutions, their widespread adoption results in the collection of massive volumes of unlabeled data that cannot be analyzed by clinicians at scale. Meanwhile, the recent success of deep learning for sleep scoring has relied on large annotated datasets. Self-supervised learning (SSL) offers an opportunity to bridge this gap, leveraging unlabeled signals to address label scarcity and reduce annotation effort. In this paper, we present the first systematic evaluation of SSL for sleep staging using wearable EEG. We investigate a range of well-established SSL methods and evaluate them on two sleep databases acquired with the Ikon Sleep wearable EEG headband: BOAS, a high-quality benchmark containing PSG and wearable EEG recordings with consensus labels, and HOGAR, a large collection of home-based, self-recorded, and unlabeled recordings. Three evaluation scenarios are defined to study label efficiency, representation quality, and cross-dataset generalization. Results show that SSL consistently improves classification performance by up to 10% over supervised baselines, with gains particularly evident when labeled data is scarce. SSL achieves clinical-grade accuracy above 80% leveraging only 5% to 10% of labeled data, while the supervised approach requires twice the labels. Additionally, SSL representations prove robust to variations in population characteristics, recording environments, and signal quality. Our findings demonstrate the potential of SSL to enable label-efficient sleep staging with wearable EEG, reducing reliance on manual annotations and advancing the development of affordable sleep monitoring systems.",
    "authors": [
      "Emilio Estevan",
      "María Sierra-Torralba",
      "Eduardo López-Larraz",
      "Luis Montesano"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T08:54:10.000Z",
    "updatedAt": "2025-10-09T08:54:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07960v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07960v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07941v1",
    "arxivId": "2510.07941v1",
    "title": "An AUTOSAR-Aligned Architectural Study of Vulnerabilities in Automotive SoC Software",
    "abstract": "Cooperative, Connected and Automated Mobility (CCAM) are complex cyber-physical systems (CPS) that integrate computation, communication, and control in safety-critical environments. At their core, System-on-Chip (SoC) platforms consolidate processing units, communication interfaces, AI accelerators, and security modules into a single chip. AUTOSAR (AUTomotive Open System ARchitecture) standard was developed in the automotive domain to better manage this complexity, defining layered software structures and interfaces to facilitate reuse of HW/SW components. However, in practice, this integrated SoC software architecture still poses security challenges, particularly in real-time, safety-critical environments. Recent reports highlight a surge in SoC-related vulnerabilities, yet systematic analysis of their root causes and impact within AUTOSAR-aligned architectures is lacking. This study fills that gap by analyzing 180 publicly reported automotive SoC vulnerabilities, mapped to a representative SoC software architecture model that is aligned with AUTOSAR principles for layered abstraction and service orientation. We identify 16 root causes and 56 affected software modules, and examine mitigation delays across Common Weakness Enumeration (CWE) categories and architectural layers. We uncover dominant vulnerability patterns and critical modules with prolonged patch delays, and provide actionable insights for securing automotive CPS platforms, including guides for improved detection, prioritization, and localization strategies for SoC software architectures in SoC-based vehicle platforms.",
    "authors": [
      "Srijita Basu",
      "Haraldsson Bengt",
      "Miroslaw Staron",
      "Christian Berger",
      "Jennifer Horkoff",
      "Magnus Almgren"
    ],
    "categories": [
      "cs.SE"
    ],
    "publishedAt": "2025-10-09T08:38:06.000Z",
    "updatedAt": "2025-10-09T08:38:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07941v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07941v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07925v1",
    "arxivId": "2510.07925v1",
    "title": "Enabling Personalized Long-term Interactions in LLM-based Agents through Persistent Memory and User Profiles",
    "abstract": "Large language models (LLMs) increasingly serve as the central control unit of AI agents, yet current approaches remain limited in their ability to deliver personalized interactions. While Retrieval Augmented Generation enhances LLM capabilities by improving context-awareness, it lacks mechanisms to combine contextual information with user-specific data. Although personalization has been studied in fields such as human-computer interaction or cognitive science, existing perspectives largely remain conceptual, with limited focus on technical implementation. To address these gaps, we build on a unified definition of personalization as a conceptual foundation to derive technical requirements for adaptive, user-centered LLM-based agents. Combined with established agentic AI patterns such as multi-agent collaboration or multi-source retrieval, we present a framework that integrates persistent memory, dynamic coordination, self-validation, and evolving user profiles to enable personalized long-term interactions. We evaluate our approach on three public datasets using metrics such as retrieval accuracy, response correctness, or BertScore. We complement these results with a five-day pilot user study providing initial insights into user feedback on perceived personalization. The study provides early indications that guide future work and highlights the potential of integrating persistent memory and user profiles to improve the adaptivity and perceived personalization of LLM-based agents.",
    "authors": [
      "Rebecca Westhäußer",
      "Wolfgang Minker",
      "Sebatian Zepf"
    ],
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T08:22:16.000Z",
    "updatedAt": "2025-10-09T08:22:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07925v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07925v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07922v2",
    "arxivId": "2510.07922v2",
    "title": "SketchGuard: Scaling Byzantine-Robust Decentralized Federated Learning via Sketch-Based Screening",
    "abstract": "Decentralized Federated Learning (DFL) enables privacy-preserving collaborative training without centralized servers, but remains vulnerable to Byzantine attacks where malicious clients submit corrupted model updates. Existing Byzantine-robust DFL defenses rely on similarity-based neighbor screening that requires every client to exchange and compare complete high-dimensional model vectors with all neighbors in each training round, creating prohibitive communication and computational costs that prevent deployment at web scale. We propose SketchGuard, a general framework that decouples Byzantine filtering from model aggregation through sketch-based neighbor screening. SketchGuard compresses $d$-dimensional models to $k$-dimensional sketches ($k \\ll d$) using Count Sketch for similarity comparisons, then selectively fetches full models only from accepted neighbors, reducing per-round communication complexity from $O(d|N_i|)$ to $O(k|N_i| + d|S_i|)$, where $|N_i|$ is the neighbor count and $|S_i| \\le |N_i|$ is the accepted neighbor count. We establish rigorous convergence guarantees in both strongly convex and non-convex settings, proving that Count Sketch compression preserves Byzantine resilience with controlled degradation bounds where approximation errors introduce only a $(1+O(\\epsilon))$ factor in the effective threshold parameter. Comprehensive experiments across multiple datasets, network topologies, and attack scenarios demonstrate that SketchGuard maintains identical robustness to state-of-the-art methods while reducing computation time by up to 82% and communication overhead by 50-70% depending on filtering effectiveness, with benefits scaling multiplicatively with model dimensionality and network connectivity. These results establish the viability of sketch-based compression as a fundamental enabler of robust DFL at web scale.",
    "authors": [
      "Murtaza Rangwala",
      "Farag Azzedin",
      "Richard O. Sinnott",
      "Rajkumar Buyya"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T08:16:32.000Z",
    "updatedAt": "2025-10-10T02:39:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07922v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.07922v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07904v1",
    "arxivId": "2510.07904v1",
    "title": "Multi-level informed optimization via decomposed Kriging for large design problems under uncertainty",
    "abstract": "Engineering design involves demanding models encompassing many decision variables and uncontrollable parameters. In addition, unavoidable aleatoric and epistemic uncertainties can be very impactful and add further complexity. The state-of-the-art adopts two steps, uncertainty quantification and design optimization, to optimize systems under uncertainty by means of robust or stochastic metrics. However, conventional scenario-based, surrogate-assisted, and mathematical programming methods are not sufficiently scalable to be affordable and precise in large and complex cases. Here, a multi-level approach is proposed to accurately optimize resource-intensive, high-dimensional, and complex engineering problems under uncertainty with minimal resources. A non-intrusive, fast-scaling, Kriging-based surrogate is developed to map the combined design/parameter domain efficiently. Multiple surrogates are adaptively updated by hierarchical and orthogonal decomposition to leverage the fewer and most uncertainty-informed data. The proposed method is statistically compared to the state-of-the-art via an analytical testbed and is shown to be concurrently faster and more accurate by orders of magnitude.",
    "authors": [
      "Enrico Ampellio",
      "Blazhe Gjorgiev",
      "Giovanni Sansavini"
    ],
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY",
      "stat.ML",
      "60G15 (Primary) 68T37, 90C26 (Secondary)",
      "C.4; G.1.6; G.3; G.4; I.2.3; I.5.1; J.2"
    ],
    "publishedAt": "2025-10-09T07:59:16.000Z",
    "updatedAt": "2025-10-09T07:59:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07904v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07904v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07901v1",
    "arxivId": "2510.07901v1",
    "title": "Decentralised Blockchain Management Through Digital Twins",
    "abstract": "The necessity of blockchain systems to remain decentralised limits current solutions to blockchain governance and dynamic management, forcing a trade-off between control and decentralisation. In light of the above, this work proposes a dynamic and decentralised blockchain management mechanism based on digital twins. To ensure decentralisation, the proposed mechanism utilises multiple digital twins that the system's stakeholders control. To facilitate decentralised decision-making, the twins are organised in a secondary blockchain system that orchestrates agreement on, and propagation of decisions to the managed blockchain. This enables the management of blockchain systems without centralised control. A preliminary evaluation of the performance and impact of the overheads introduced by the proposed mechanism is conducted through simulation. The results demonstrate the proposed mechanism's ability to reach consensus on decisions quickly and reconfigure the primary blockchain with minimal overhead.",
    "authors": [
      "Georgios Diamantopoulos",
      "Nikos Tziritas",
      "Rami Bahsoon",
      "Georgios Theodoropoulos"
    ],
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T07:54:26.000Z",
    "updatedAt": "2025-10-09T07:54:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07901v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07901v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07900v1",
    "arxivId": "2510.07900v1",
    "title": "Topology optimization of nonlinear forced response curves via reduction on spectral submanifolds",
    "abstract": "Forced response curves (FRCs) of nonlinear systems can exhibit complex behaviors, including hardening/softening behavior and bifurcations. Although topology optimization holds great potential for tuning these nonlinear dynamic responses, its use in high-dimensional systems is limited by the high cost of repeated response and sensitivity analyses. To address this challenge, we employ the spectral submanifolds (SSMs) reduction theory, which reformulates the periodic response as the equilibria of an associated reduced-order model (ROM). This enables efficient and analytic evaluation of both response amplitudes and their sensitivities. Based on the SSM-based ROM, we formulate optimization problems that optimize the peak amplitude, the hardening/softening behavior, and the distance between two saddle-node bifurcations for an FRC. The proposed method is applied to the design of nonlinear MEMS devices, achieving targeted performance optimization. This framework provides a practical and efficient strategy for incorporating nonlinear dynamic effects into the topology optimization of structures.",
    "authors": [
      "Hongming Liang",
      "Matteo Pozzi",
      "Jacopo Marconi",
      "Shobhit Jain",
      "Mingwu Li"
    ],
    "categories": [
      "eess.SY",
      "cs.SY",
      "physics.comp-ph"
    ],
    "publishedAt": "2025-10-09T07:54:24.000Z",
    "updatedAt": "2025-10-09T07:54:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07900v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07900v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07889v1",
    "arxivId": "2510.07889v1",
    "title": "Towards Meaningful Transparency in Civic AI Systems",
    "abstract": "Artificial intelligence has become a part of the provision of governmental services, from making decisions about benefits to issuing fines for parking violations. However, AI systems rarely live up to the promise of neutral optimisation, creating biased or incorrect outputs and reducing the agency of both citizens and civic workers to shape the way decisions are made. Transparency is a principle that can both help subjects understand decisions made about them and shape the processes behind those decisions. However, transparency as practiced around AI systems tends to focus on the production of technical objects that represent algorithmic aspects of decision making. These are often difficult for publics to understand, do not connect to potential for action, and do not give insight into the wider socio-material context of decision making. In this paper, we build on existing approaches that take a human-centric view on AI transparency, combined with a socio-technical systems view, to develop the concept of meaningful transparency for civic AI systems: transparencies that allow publics to engage with AI systems that affect their lives, connecting understanding with potential for action.",
    "authors": [
      "Dave Murray-Rust",
      "Kars Alfrink",
      "Cristina Zaga"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T07:43:01.000Z",
    "updatedAt": "2025-10-09T07:43:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07889v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07889v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07882v1",
    "arxivId": "2510.07882v1",
    "title": "Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots",
    "abstract": "In recent years, Multimodal Large Language Models (MLLMs) have demonstrated the ability to serve as high-level planners, enabling robots to follow complex human instructions. However, their effectiveness, especially in long-horizon tasks involving dual-arm humanoid robots, remains limited. This limitation arises from two main challenges: (i) the absence of simulation platforms that systematically support task evaluation and data collection for humanoid robots, and (ii) the insufficient embodiment awareness of current MLLMs, which hinders reasoning about dual-arm selection logic and body positions during planning. To address these issues, we present DualTHOR, a new dual-arm humanoid simulator, with continuous transition and a contingency mechanism. Building on this platform, we propose Proprio-MLLM, a model that enhances embodiment awareness by incorporating proprioceptive information with motion-based position embedding and a cross-spatial encoder. Experiments show that, while existing MLLMs struggle in this environment, Proprio-MLLM achieves an average improvement of 19.75% in planning performance. Our work provides both an essential simulation platform and an effective model to advance embodied intelligence in humanoid robotics. The code is available at https://anonymous.4open.science/r/DualTHOR-5F3B.",
    "authors": [
      "Boyu Li",
      "Siyuan He",
      "Hang Xu",
      "Haoqi Yuan",
      "Yu Zang",
      "Liwei Hu",
      "Junpeng Yue",
      "Zhenxiong Jiang",
      "Pengbo Hu",
      "Börje F. Karlsson",
      "Yehui Tang",
      "Zongqing Lu"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T07:35:12.000Z",
    "updatedAt": "2025-10-09T07:35:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07882v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07882v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07871v1",
    "arxivId": "2510.07871v1",
    "title": "Team Xiaomi EV-AD VLA: Learning to Navigate Socially Through Proactive Risk Perception -- Technical Report for IROS 2025 RoboSense Challenge Social Navigation Track",
    "abstract": "In this report, we describe the technical details of our submission to the IROS 2025 RoboSense Challenge Social Navigation Track. This track focuses on developing RGBD-based perception and navigation systems that enable autonomous agents to navigate safely, efficiently, and socially compliantly in dynamic human-populated indoor environments. The challenge requires agents to operate from an egocentric perspective using only onboard sensors including RGB-D observations and odometry, without access to global maps or privileged information, while maintaining social norm compliance such as safe distances and collision avoidance. Building upon the Falcon model, we introduce a Proactive Risk Perception Module to enhance social navigation performance. Our approach augments Falcon with collision risk understanding that learns to predict distance-based collision risk scores for surrounding humans, which enables the agent to develop more robust spatial awareness and proactive collision avoidance behaviors. The evaluation on the Social-HM3D benchmark demonstrates that our method improves the agent's ability to maintain personal space compliance while navigating toward goals in crowded indoor scenes with dynamic human agents, achieving 2nd place among 16 participating teams in the challenge.",
    "authors": [
      "Erjia Xiao",
      "Lingfeng Zhang",
      "Yingbo Tang",
      "Hao Cheng",
      "Renjing Xu",
      "Wenbo Ding",
      "Lei Zhou",
      "Long Chen",
      "Hangjun Ye",
      "Xiaoshuai Hao"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T07:22:12.000Z",
    "updatedAt": "2025-10-09T07:22:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07871v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07871v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07870v1",
    "arxivId": "2510.07870v1",
    "title": "Symmetric Rule-Based Achlioptas Processes for Random $k$-SAT",
    "abstract": "Inspired by the \"power-of-two-choices\" model from random graphs, we investigate the possibility of limited choices of online clause choices that could shift the satisfiability threshold in random $k$-SAT.Here, we introduce an assignment symmetric, non-adaptive, topology-oblivious online rule called \\emph{MIDDLE-HEAVY}, that prioritizes balanced sign profile clauses.Upon applying a biased $2$-SAT projection and a two-type branching process certificate, we derive closed-form expressions for the shifted thresholds $\\alpha_{\\textbf{SYM}}(k,\\ell)$ for this algorithm.We show that minimal choices $\\ell=5$ for $k=4$, $\\ell=4$ for $k=5$, and $\\ell=3$ for $k\\ge 6$ suffice to exceed the asymptotic first-moment upper bound $\\sim 2^k \\ln 2$ for random $k$-SAT.Moreover, to bridge the gap with biased assignment rules used in maximum of the previous works in this context, we propose a hybrid symmetric biased rule that achieves thresholds comparable to prior work while maintaining symmetry.Our results advance the understanding of Achlioptas processes in random CSPs beyond classical graph-theoretic settings.",
    "authors": [
      "Arnab Chatterjee"
    ],
    "categories": [
      "cs.DM",
      "math.CO",
      "math.PR",
      "05C80, 68W20"
    ],
    "publishedAt": "2025-10-09T07:19:59.000Z",
    "updatedAt": "2025-10-09T07:19:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07870v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07870v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07869v2",
    "arxivId": "2510.07869v2",
    "title": "USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots",
    "abstract": "Underwater environments present unique challenges for robotic operation, including complex hydrodynamics, limited visibility, and constrained communication. Although data-driven approaches have advanced embodied intelligence in terrestrial robots and enabled task-specific autonomous underwater robots, developing underwater intelligence capable of autonomously performing multiple tasks remains highly challenging, as large-scale, high-quality underwater datasets are still scarce. To address these limitations, we introduce USIM, a simulation-based multi-task Vision-Language-Action (VLA) dataset for underwater robots. USIM comprises over 561K frames from 1,852 trajectories, totaling approximately 15.6 hours of BlueROV2 interactions across 20 tasks in 9 diverse scenarios, ranging from visual navigation to mobile manipulation. Building upon this dataset, we propose U0, a VLA model for general underwater robots, which integrates binocular vision and other sensor modalities through multimodal fusion, and further incorporates a convolution-attention-based perception focus enhancement module (CAP) to improve spatial understanding and mobile manipulation. Across tasks such as inspection, obstacle avoidance, scanning, and dynamic tracking, the framework achieves a success rate of 80%, while in challenging mobile manipulation tasks, it reduces the distance to the target by 21.2% compared with baseline methods, demonstrating its effectiveness. USIM and U0 show that VLA models can be effectively applied to underwater robotic applications, providing a foundation for scalable dataset construction, improved task autonomy, and the practical realization of intelligent general underwater robots.",
    "authors": [
      "Junwen Gu",
      "Zhiheng wu",
      "Pengxuan Si",
      "Shuang Qiu",
      "Yukai Feng",
      "Luoyang Sun",
      "Laien Luo",
      "Lianyi Yu",
      "Jian Wang",
      "Zhengxing Wu"
    ],
    "categories": [
      "cs.RO"
    ],
    "publishedAt": "2025-10-09T07:19:29.000Z",
    "updatedAt": "2025-10-10T04:24:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07869v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.07869v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07868v1",
    "arxivId": "2510.07868v1",
    "title": "NRRS: Neural Russian Roulette and Splitting",
    "abstract": "We propose a novel framework for Russian Roulette and Splitting (RRS) tailored to wavefront path tracing, a highly parallel rendering architecture that processes path states in batched, stage-wise execution for efficient GPU utilization. Traditional RRS methods, with unpredictable path counts, are fundamentally incompatible with wavefront's preallocated memory and scheduling requirements. To resolve this, we introduce a normalized RRS formulation with a bounded path count, enabling stable and memory-efficient execution. Furthermore, we pioneer the use of neural networks to learn RRS factors, presenting two models: NRRS and AID-NRRS. At a high level, both feature a carefully designed RRSNet that explicitly incorporates RRS normalization, with only subtle differences in their implementation. To balance computational cost and inference accuracy, we introduce Mix-Depth, a path-depth-aware mechanism that adaptively regulates neural evaluation, further improving efficiency. Extensive experiments demonstrate that our method outperforms traditional heuristics and recent RRS techniques in both rendering quality and performance across a variety of complex scenes.",
    "authors": [
      "Haojie Jin",
      "Jierui Ren",
      "Yisong Chen",
      "Guoping Wang",
      "Sheng Li"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-09T07:19:26.000Z",
    "updatedAt": "2025-10-09T07:19:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07868v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07868v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07860v1",
    "arxivId": "2510.07860v1",
    "title": "Clustering in Varying Metrics",
    "abstract": "We introduce the aggregated clustering problem, where one is given $T$ instances of a center-based clustering task over the same $n$ points, but under different metrics. The goal is to open $k$ centers to minimize an aggregate of the clustering costs -- e.g., the average or maximum -- where the cost is measured via $k$-center/median/means objectives. More generally, we minimize a norm $\\Psi$ over the $T$ cost values. We show that for $T \\geq 3$, the problem is inapproximable to any finite factor in polynomial time. For $T = 2$, we give constant-factor approximations. We also show W[2]-hardness when parameterized by $k$, but obtain $f(k,T)\\mathrm{poly}(n)$-time 3-approximations when parameterized by both $k$ and $T$. When the metrics have structure, we obtain efficient parameterized approximation schemes (EPAS). If all $T$ metrics have bounded $\\varepsilon$-scatter dimension, we achieve a $(1+\\varepsilon)$-approximation in $f(k,T,\\varepsilon)\\mathrm{poly}(n)$ time. If the metrics are induced by edge weights on a common graph $G$ of bounded treewidth $\\mathsf{tw}$, and $\\Psi$ is the sum function, we get an EPAS in $f(T,\\varepsilon,\\mathsf{tw})\\mathrm{poly}(n,k)$ time. Conversely, unless (randomized) ETH is false, any finite factor approximation is impossible if parametrized by only $T$, even when the treewidth is $\\mathsf{tw} = \\Omega(\\mathrm{poly}\\log n)$.",
    "authors": [
      "Deeparnab Chakrabarty",
      "Jonathan Conroy",
      "Ankita Sarkar"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T07:03:15.000Z",
    "updatedAt": "2025-10-09T07:03:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07860v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07860v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07829v1",
    "arxivId": "2510.07829v1",
    "title": "The Rise of the Knowledge Sculptor: A New Archetype for Knowledge Work in the Age of Generative AI",
    "abstract": "In the Generative Age, the nature of knowledge work is transforming. Traditional models that emphasise the organisation and retrieval of pre-existing information are increasingly inadequate in the face of generative AI (GenAI) systems capable of autonomous content creation. This paper introduces the Knowledge Sculptor (KS), a new professional archetype for Human-GenAI collaboration that transforms raw AI output into trustworthy, actionable knowledge. Grounded in a socio-technical perspective, the KS is conceptualised through a framework of competencies, including architecting a vision, iterative dialogue, information sculpting, and curiosity-driven synthesis. A practice-based vignette illustrates the KS role in action, and in a self-referential approach, the paper itself serves as an artefact of the sculpting process it describes.",
    "authors": [
      "Cathal Doyle"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "publishedAt": "2025-10-09T06:19:17.000Z",
    "updatedAt": "2025-10-09T06:19:17.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07829v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07829v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07811v1",
    "arxivId": "2510.07811v1",
    "title": "Adaptive Execution Scheduler for DataDios SmartDiff",
    "abstract": "We present an adaptive scheduler for a single differencing engine (SmartDiff) with two execution modes: (i) in-memory threads and (ii) Dask based parallelism. The scheduler continuously tunes batch size and worker/thread count within fixed CPU and memory budgets to minimize p95 latency. A lightweight preflight profiler estimates bytes/row and I/O rate; an online cost/memory model prunes unsafe actions; and a guarded hill-climb policy favors lower latency with backpressure and straggler mitigation. Backend selection is gated by a conservative working-set estimate so that in-memory execution is chosen when safe, otherwise Dask is used. Across synthetic and public tabular benchmarks, the scheduler reduces p95 latency by 23 to 28 percent versus a tuned warm-up heuristic (and by 35 to 40 percent versus fixed grid baselines), while lowering peak memory by 16 to 22 percent (25 to 32 percent vs. fixed) with zero OOMs and comparable throughput.",
    "authors": [
      "Aryan Poduri"
    ],
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-09T05:40:16.000Z",
    "updatedAt": "2025-10-09T05:40:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07811v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07811v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08645v1",
    "arxivId": "2510.08645v1",
    "title": "Generating Sizing Fields for Mesh Generation via GCN-based Simplification of Adaptive Background Grids",
    "abstract": "The sizing field defined on a triangular background grid is pivotal for controlling the quality and efficiency of unstructured mesh generation. However, creating an optimal background grid that is geometrically conforming, computationally lightweight, and free from artifacts like banding is a significant challenge. This paper introduces a novel, adaptive background grid simplification (ABGS) framework based on a Graph Convolutional Network (GCN). We reformulate the grid simplification task as an edge score regression problem and train a GCN model to efficiently predict optimal edge collapse candidates. The model is guided by a custom loss function that holistically considers both geometric fidelity and sizing field accuracy. This data-driven approach replaces a costly procedural evaluation, accelerating the simplification process. Experimental results demonstrate the effectiveness of our framework across diverse and complex engineering models. Compared to the initial dense grids, our simplified background grids achieve an element reduction of 74%-94%, leading to a 35%-88% decrease in sizing field query times.",
    "authors": [
      "Xunyang Zhu",
      "Hongfei Ye",
      "Yifei Wang",
      "Taoran Liu",
      "Jianjun Chen"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-09T03:57:25.000Z",
    "updatedAt": "2025-10-09T03:57:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08645v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08645v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07754v1",
    "arxivId": "2510.07754v1",
    "title": "Human-in-the-Loop Optimization with Model-Informed Priors",
    "abstract": "Human-in-the-loop optimization identifies optimal interface designs by iteratively observing user performance. However, it often requires numerous iterations due to the lack of prior information. While recent approaches have accelerated this process by leveraging previous optimization data, collecting user data remains costly and often impractical. We present a conceptual framework, Human-in-the-Loop Optimization with Model-Informed Priors (HOMI), which augments human-in-the-loop optimization with a training phase where the optimizer learns adaptation strategies from diverse, synthetic user data generated with predictive models before deployment. To realize HOMI, we introduce Neural Acquisition Function+ (NAF+), a Bayesian optimization method featuring a neural acquisition function trained with reinforcement learning. NAF+ learns optimization strategies from large-scale synthetic data, improving efficiency in real-time optimization with users. We evaluate HOMI and NAF+ with mid-air keyboard optimization, a representative VR input task. Our work presents a new approach for more efficient interface adaptation by bridging in situ and in silico optimization processes.",
    "authors": [
      "Yi-Chi Liao",
      "João Belo",
      "Hee-Seung Moon",
      "Jürgen Steimle",
      "Anna Maria Feit"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-09T03:46:51.000Z",
    "updatedAt": "2025-10-09T03:46:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07754v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07754v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07699v1",
    "arxivId": "2510.07699v1",
    "title": "Optimal lower bounds for quantum state tomography",
    "abstract": "We show that $n = \\Omega(rd/\\varepsilon^2)$ copies are necessary to learn a rank $r$ mixed state $\\rho \\in \\mathbb{C}^{d \\times d}$ up to error $\\varepsilon$ in trace distance. This matches the upper bound of $n = O(rd/\\varepsilon^2)$ from prior work, and therefore settles the sample complexity of mixed state tomography. We prove this lower bound by studying a special case of full state tomography that we refer to as projector tomography, in which $\\rho$ is promised to be of the form $\\rho = P/r$, where $P \\in \\mathbb{C}^{d \\times d}$ is a rank $r$ projector. A key technical ingredient in our proof, which may be of independent interest, is a reduction which converts any algorithm for projector tomography which learns to error $\\varepsilon$ in trace distance to an algorithm which learns to error $O(\\varepsilon)$ in the more stringent Bures distance.",
    "authors": [
      "Thilo Scharnhorst",
      "Jack Spilecki",
      "John Wright"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-09T02:36:48.000Z",
    "updatedAt": "2025-10-09T02:36:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07699v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07699v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07696v1",
    "arxivId": "2510.07696v1",
    "title": "Languages of Words of Low Automatic Complexity Are Hard to Compute",
    "abstract": "The automatic complexity of a finite word (string) is an analogue for finite automata of Sipser's distinguishing complexity (1983) and was introduced by Shallit and Wang (2001). For a finite alphabet $\\Sigma$ of at least two elements, we consider the non-deterministic automatic complexity given by exactly - yet not necessarily uniquely - accepting automata: a word $x \\in \\Sigma^*$ has exact non-deterministic automatic complexity $k \\in \\mathbb{N}$ if there exists a non-deterministic automaton of $k$ states which accepts $x$ while rejecting every other word of the same length as $x$, and no automaton of fewer states has this property. Importantly, and in contrast to the classical notion, the witnessing automaton may have multiple paths of computation accepting $x$. We denote this measure of complexity by $A_{Ne}$, and study a class of languages of low $A_{Ne}$-complexity defined as $L_q = \\{ \\, x \\in \\Sigma^* : A_{Ne}(x) < q|x| \\, \\}$, which is parameterised by rationals $q \\in (0,1/2)$ (generalising a class of sets first studied by Kjos-Hanssen). We show that for every $q \\in (0,1/2)$, this class is neither context-free nor recognisable by certain Boolean circuits. In the process, we answer an open question of Kjos-Hanssen quantifying the complexity of $L_{1/3}$ in terms of Boolean circuits, and also prove the Shannon effect for $A_{Ne}$.",
    "authors": [
      "Joey Chen",
      "Bjørn Kjos-Hanssen",
      "Ivan Koswara",
      "Linus Richter",
      "Frank Stephan"
    ],
    "categories": [
      "cs.FL",
      "math.LO",
      "68Q45 (Primary) 03D05, 68Q30, 68Q06 (Secondary)",
      "F.4.2; F.4.3"
    ],
    "publishedAt": "2025-10-09T02:34:45.000Z",
    "updatedAt": "2025-10-09T02:34:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07696v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07696v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07664v1",
    "arxivId": "2510.07664v1",
    "title": "FedQS: Optimizing Gradient and Model Aggregation for Semi-Asynchronous Federated Learning",
    "abstract": "Federated learning (FL) enables collaborative model training across multiple parties without sharing raw data, with semi-asynchronous FL (SAFL) emerging as a balanced approach between synchronous and asynchronous FL. However, SAFL faces significant challenges in optimizing both gradient-based (e.g., FedSGD) and model-based (e.g., FedAvg) aggregation strategies, which exhibit distinct trade-offs in accuracy, convergence speed, and stability. While gradient aggregation achieves faster convergence and higher accuracy, it suffers from pronounced fluctuations, whereas model aggregation offers greater stability but slower convergence and suboptimal accuracy. This paper presents FedQS, the first framework to theoretically analyze and address these disparities in SAFL. FedQS introduces a divide-and-conquer strategy to handle client heterogeneity by classifying clients into four distinct types and adaptively optimizing their local training based on data distribution characteristics and available computational resources. Extensive experiments on computer vision, natural language processing, and real-world tasks demonstrate that FedQS achieves the highest accuracy, attains the lowest loss, and ranks among the fastest in convergence speed, outperforming state-of-the-art baselines. Our work bridges the gap between aggregation strategies in SAFL, offering a unified solution for stable, accurate, and efficient federated learning. The code and datasets are available at https://anonymous.4open.science/r/FedQS-EDD6.",
    "authors": [
      "Yunbo Li",
      "Jiaping Gui",
      "Zhihang Deng",
      "Fanchao Meng",
      "Yue Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "publishedAt": "2025-10-09T01:32:19.000Z",
    "updatedAt": "2025-10-09T01:32:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07664v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07664v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07638v1",
    "arxivId": "2510.07638v1",
    "title": "Differentiable Variable Fonts",
    "abstract": "Editing and animating text appearance for graphic designs, commercials, etc. remain highly skilled tasks requiring detailed, hands on efforts from artists. Automating these manual workflows requires balancing the competing goals of maintaining legibility and aesthetics of text, while enabling creative expression. Variable fonts, recent parametric extensions to traditional fonts, offer the promise of new ways to ease and automate typographic design and animation. Variable fonts provide custom constructed parameters along which fonts can be smoothly varied. These parameterizations could then potentially serve as high value continuous design spaces, opening the door to automated design optimization tools. However, currently variable fonts are underutilized in creative applications, because artists so far still need to manually tune font parameters. Our work opens the door to intuitive and automated font design and animation workflows with differentiable variable fonts. To do so we distill the current variable font specification to a compact mathematical formulation that differentiably connects the highly non linear, non invertible mapping of variable font parameters to the underlying vector graphics representing the text. This enables us to construct a differentiable framework, with respect to variable font parameters, allowing us to perform gradient based optimization of energies defined on vector graphics control points, and on target rasterized images. We demonstrate the utility of this framework with four applications: direct shape manipulation, overlap aware modeling, physics based text animation, and automated font design optimization. Our work now enables leveraging the carefully designed affordances of variable fonts with differentiability to use modern design optimization technologies, opening new possibilities for easy and intuitive typographic design workflows.",
    "authors": [
      "Kinjal Parikh",
      "Danny M. Kaufman",
      "David I. W. Levin",
      "Alec Jacobson"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-09T00:22:27.000Z",
    "updatedAt": "2025-10-09T00:22:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07638v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07638v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07622v1",
    "arxivId": "2510.07622v1",
    "title": "Conjugate queries can help",
    "abstract": "We give a natural problem over input quantum oracles $U$ which cannot be solved with exponentially many black-box queries to $U$ and $U^\\dagger$, but which can be solved with constant many queries to $U$ and $U^*$, or $U$ and $U^{\\mathrm{T}}$. We also demonstrate a quantum commitment scheme that is secure against adversaries that query only $U$ and $U^\\dagger$, but is insecure if the adversary can query $U^*$. These results show that conjugate and transpose queries do give more power to quantum algorithms, lending credence to the idea put forth by Zhandry that cryptographic primitives should prove security against these forms of queries. Our key lemma is that any circuit using $q$ forward and inverse queries to a state preparation unitary for a state $\\sigma$ can be simulated to $\\varepsilon$ error with $n = \\mathcal{O}(q^2/\\varepsilon)$ copies of $\\sigma$. Consequently, for decision tasks, algorithms using (forward and inverse) state preparation queries only ever perform quadratically better than sample access. These results follow from straightforward combinations of existing techniques; our contribution is to state their consequences in their strongest, most counter-intuitive form. In doing so, we identify a motif where generically strengthening a quantum resource can be possible if the output is allowed to be random, bypassing no-go theorems for deterministic algorithms. We call this the acorn trick.",
    "authors": [
      "Ewin Tang",
      "John Wright",
      "Mark Zhandry"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T23:44:30.000Z",
    "updatedAt": "2025-10-08T23:44:30.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07622v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07622v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07621v1",
    "arxivId": "2510.07621v1",
    "title": "Retentive Relevance: Capturing Long-Term User Value in Recommendation Systems",
    "abstract": "Recommendation systems have traditionally relied on short-term engagement signals, such as clicks and likes, to personalize content. However, these signals are often noisy, sparse, and insufficient for capturing long-term user satisfaction and retention. We introduce Retentive Relevance, a novel content-level survey-based feedback measure that directly assesses users' intent to return to the platform for similar content. Unlike other survey measures that focus on immediate satisfaction, Retentive Relevance targets forward-looking behavioral intentions, capturing longer term user intentions and providing a stronger predictor of retention. We validate Retentive Relevance using psychometric methods, establishing its convergent, discriminant, and behavioral validity. Through large-scale offline modeling, we show that Retentive Relevance significantly outperforms both engagement signals and other survey measures in predicting next-day retention, especially for users with limited historical engagement. We develop a production-ready proxy model that integrates Retentive Relevance into the final stage of a multi-stage ranking system on a social media platform. Calibrated score adjustments based on this model yield substantial improvements in engagement, and retention, while reducing exposure to low-quality content, as demonstrated by large-scale A/B experiments. This work provides the first empirically validated framework linking content-level user perceptions to retention outcomes in production systems. We offer a scalable, user-centered solution that advances both platform growth and user experience. Our work has broad implications for responsible AI development.",
    "authors": [
      "Saeideh Bakhshi",
      "Phuong Mai Nguyen",
      "Robert Schiller",
      "Tiantian Xu",
      "Pawan Kodandapani",
      "Andrew Levine",
      "Cayman Simpson",
      "Qifan Wang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-08T23:38:57.000Z",
    "updatedAt": "2025-10-08T23:38:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07621v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07621v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07610v1",
    "arxivId": "2510.07610v1",
    "title": "The Slow Space Editor : Broadening Access to Restorative XR",
    "abstract": "The Slow Space Editor is a 2D tool for creating 3D spaces. It was built as part of a research-through-design project that investigates how Virtual and Mixed Reality (XR) environments might be used for reflection and attention restoration. In this phase, we seek to radically simplify the creation of virtual environments, thereby broadening the potential group of users who could benefit from them. The research described in this paper has three aspects. First, we define the concept of \"slow space,\" situating it alongside existing research in HCI and environmental psychology. Second, we report on a series of interviews with professional designers about how slow spaces are created in the physical world. Third, we share the design of the tool itself, focussing on the benefits of providing a simple method for users to control their environments. We conclude with our findings from a 19-person qualitative study of the tool.",
    "authors": [
      "Nate Laffan",
      "Ashley Hom",
      "Andrea Nadine Castillo",
      "Elizabeth Gitelman",
      "Rebecca Zhao",
      "Nikita Shenoy",
      "Kaia Rae Schweig",
      "Katherine Isbister"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T23:13:19.000Z",
    "updatedAt": "2025-10-08T23:13:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07610v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07610v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07609v1",
    "arxivId": "2510.07609v1",
    "title": "IGUANA: Immersive Guidance, Navigation, and Control for Consumer UAV",
    "abstract": "As the markets for unmanned aerial vehicles (UAVs) and mixed reality (MR) headsets continue to grow, recent research has increasingly explored their integration, which enables more intuitive, immersive, and situationally aware control systems. We present IGUANA, an MR-based immersive guidance, navigation, and control system for consumer UAVs. IGUANA introduces three key elements beyond conventional control interfaces: (1) a 3D terrain map interface with draggable waypoint markers and live camera preview for high-level control, (2) a novel spatial control metaphor that uses a virtual ball as a physical analogy for low-level control, and (3) a spatial overlay that helps track the UAV when it is not visible with the naked eye or visual line of sight is interrupted. We conducted a user study to evaluate our design, both quantitatively and qualitatively, and found that (1) the 3D map interface is intuitive and easy to use, relieving users from manual control and suggesting improved accuracy and consistency with lower perceived workload relative to conventional dual-stick controller, (2) the virtual ball interface is intuitive but limited by the lack of physical feedback, and (3) the spatial overlay is very useful in enhancing the users' situational awareness.",
    "authors": [
      "Victor Victor",
      "Tania Krisanty",
      "Matthew McGinity",
      "Stefan Gumhold",
      "Uwe Aßmann"
    ],
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "publishedAt": "2025-10-08T23:07:03.000Z",
    "updatedAt": "2025-10-08T23:07:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07609v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07609v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07572v1",
    "arxivId": "2510.07572v1",
    "title": "Deterministic algorithms for inhomogeneous Bernoulli trials: Shapley value of network devices",
    "abstract": "Suppose that $n$ computer devices are to be connected to a network via inhomogeneous Bernoulli trials. The Shapley value of a device quantifies how much the network's value increases due to the participation of that device. Characteristic functions of such games are naturally taken as the belief function (containment function) and Choquet capacity (hitting probability) of a random set (random network of devices). Traditionally, the Shapley value is either calculated as the expected marginal contribution over all possible coalitions (subnetworks), which results in exponential computational complexity, or approximated by the Monte Carlo sampling technique, where the performance is highly dependent on the stochastic sampling process. The purpose of this study is to design deterministic algorithms for games formulated via inhomogeneous Bernoulli trials that approximate the Shapley value in linear or quadratic time, with rigorous error analysis (Sections 3 and 4). Additionally, we provide a review of relevant literature on existing calculation methods in Remark 3.1 and Appendix I. A further goal is to supplement Shapley's original proof by deriving the Shapley value formula using a rigorous approach based on definite integrals and combinatorial analysis. This method explicitly highlights the roles of the Binomial Theorem and the Beta function in the proof, addressing a gap in Shapley's work (Appendix II).",
    "authors": [
      "Jesse D Wei",
      "Guo Wei"
    ],
    "categories": [
      "cs.GT",
      "cs.IT",
      "math.IT",
      "math.PR",
      "60D05, 68Q87",
      "G.3; I.2.4"
    ],
    "publishedAt": "2025-10-08T21:33:59.000Z",
    "updatedAt": "2025-10-08T21:33:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07572v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07572v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07557v1",
    "arxivId": "2510.07557v1",
    "title": "Investigating Thematic Patterns and User Preferences in LLM Interactions using BERTopic",
    "abstract": "This study applies BERTopic, a transformer-based topic modeling technique, to the lmsys-chat-1m dataset, a multilingual conversational corpus built from head-to-head evaluations of large language models (LLMs). Each user prompt is paired with two anonymized LLM responses and a human preference label, used to assess user evaluation of competing model outputs. The main objective is uncovering thematic patterns in these conversations and examining their relation to user preferences, particularly if certain LLMs are consistently preferred within specific topics. A robust preprocessing pipeline was designed for multilingual variation, balancing dialogue turns, and cleaning noisy or redacted data. BERTopic extracted over 29 coherent topics including artificial intelligence, programming, ethics, and cloud infrastructure. We analysed relationships between topics and model preferences to identify trends in model-topic alignment. Visualization techniques included inter-topic distance maps, topic probability distributions, and model-versus-topic matrices. Our findings inform domain-specific fine-tuning and optimization strategies for improving real-world LLM performance and user satisfaction.",
    "authors": [
      "Abhay Bhandarkar",
      "Gaurav Mishra",
      "Khushi Juchani",
      "Harsh Singhal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T21:13:44.000Z",
    "updatedAt": "2025-10-08T21:13:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07557v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07557v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07515v1",
    "arxivId": "2510.07515v1",
    "title": "No exponential quantum speedup for $\\mathrm{SIS}^\\infty$ anymore",
    "abstract": "In 2021, Chen, Liu, and Zhandry presented an efficient quantum algorithm for the average-case $\\ell_\\infty$-Short Integer Solution ($\\mathrm{SIS}^\\infty$) problem, in a parameter range outside the normal range of cryptographic interest, but still with no known efficient classical algorithm. This was particularly exciting since $\\mathrm{SIS}^\\infty$ is a simple problem without structure, and their algorithmic techniques were different from those used in prior exponential quantum speedups. We present efficient classical algorithms for all of the $\\mathrm{SIS}^\\infty$ and (more general) Constrained Integer Solution problems studied in their paper, showing there is no exponential quantum speedup anymore.",
    "authors": [
      "Robin Kothari",
      "Ryan O'Donnell",
      "Kewen Wu"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.CR",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T20:28:47.000Z",
    "updatedAt": "2025-10-08T20:28:47.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07515v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07515v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07495v1",
    "arxivId": "2510.07495v1",
    "title": "3-Local Hamiltonian Problem and Constant Relative Error Quantum Partition Function Approximation: $O(2^{\\frac{n}{2}})$ Algorithm Is Nearly Optimal under QSETH",
    "abstract": "We investigate the computational complexity of the Local Hamiltonian (LH) problem and the approximation of the Quantum Partition Function (QPF), two central problems in quantum many-body physics and quantum complexity theory. Both problems are known to be QMA-hard, and under the widely believed assumption that $\\mathsf{BQP} \\neq \\mathsf{QMA}$, no efficient quantum algorithm exits. The best known quantum algorithm for LH runs in $O\\bigl(2^{\\frac{n}{2}(1 - o(1))}\\bigr)$ time, while for QPF, the state-of-the-art algorithm achieves relative error $\\delta$ in $O^\\ast\\bigl(\\frac{1}{\\delta}\\sqrt{\\frac{2^n}{Z}}\\bigr)$ time, where $Z$ denotes the value of the partition function. A nature open question is whether more efficient algorithms exist for both problems. In this work, we establish tight conditional lower bounds showing that these algorithms are nearly optimal. Under the plausible Quantum Strong Exponential Time Hypothesis (QSETH), we prove that no quantum algorithm can solve either LH or approximate QPF significantly faster than $O(2^{n/2})$, even for 3-local Hamiltonians. In particular, we show: 1) 3-local LH cannot be solved in time $O(2^{\\frac{n}{2}(1-\\varepsilon)})$ for any $\\varepsilon > 0$ under QSETH; 2) 3-local QPF cannot be approximated up to any constant relative error in $O(2^{\\frac{n}{2}(1-\\varepsilon)})$ time for any $\\varepsilon > 0$ under QSETH; and 3) we present a quantum algorithm that approximates QPF up to relative error $1/2 + 1/\\mathrm{poly}(n)$ in $O^\\ast(2^{n/2})$ time, matching our conditional lower bound. Notably, our results provide the first fine-grained lower bounds for both LH and QPF with fixed locality. This stands in sharp contrast to QSETH and the trivial fine-grained lower bounds for LH, where the locality of the SAT instance and the Hamiltonian depends on the parameter $\\varepsilon$ in the $O(2^{\\frac{n}{2}(1-\\varepsilon)})$ running time.",
    "authors": [
      "Nai-Hui Chia",
      "Yu-Ching Shen"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T19:45:24.000Z",
    "updatedAt": "2025-10-08T19:45:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07495v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07495v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07478v1",
    "arxivId": "2510.07478v1",
    "title": "Fixed Points and Stochastic Meritocracies: A Long-Term Perspective",
    "abstract": "We study group fairness in the context of feedback loops induced by meritocratic selection into programs that themselves confer additional advantage, like college admissions. We introduce a novel stylized inter-generational model for the setting and analyze it in situations where there are no underlying differences between two populations. We show that, when the benefit of the program (or the harm of not getting into it) is completely symmetric, disparities between the two populations will eventually dissipate. However, the time an accumulated advantage takes to dissipate could be significant, and increases substantially as a function of the relative importance of the program in conveying benefits. We also find that significant disparities can arise due to chance even from completely symmetric initial conditions, especially when populations are small. The introduction of even a slight asymmetry, where the group that has accumulated an advantage becomes slightly preferred, leads to a completely different outcome. In these instances, starting from completely symmetric initial conditions, disparities between groups arise stochastically and then persist over time, yielding a permanent advantage for one group. Our analysis precisely characterizes conditions under which disparities persist or diminish, with a particular focus on the role of the scarcity of available spots in the program and its effectiveness. We also present extensive simulations in a richer model that further support our theoretical results in the simpler, stylized model. Our findings are relevant for the design and implementation of algorithmic fairness interventions in similar selection processes.",
    "authors": [
      "Gaurab Pokharel",
      "Diptangshu Sen",
      "Sanmay Das",
      "Juba Ziani"
    ],
    "categories": [
      "cs.CY",
      "cs.GT",
      "physics.soc-ph"
    ],
    "publishedAt": "2025-10-08T19:23:57.000Z",
    "updatedAt": "2025-10-08T19:23:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07478v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07478v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07464v1",
    "arxivId": "2510.07464v1",
    "title": "DRACO: Data Replication and Collection Framework for Enhanced Data Availability and Robustness in IoT Networks",
    "abstract": "The Internet of Things (IoT) bridges the gap between the physical and digital worlds, enabling seamless interaction with real-world objects via the Internet. However, IoT systems face significant challenges in ensuring efficient data generation, collection, and management, particularly due to the resource-constrained and unreliable nature of connected devices, which can lead to data loss. This paper presents DRACO (Data Replication and Collection), a framework that integrates a distributed hop-by-hop data replication approach with an overhead-free mobile sink-based data collection strategy. DRACO enhances data availability, optimizes replica placement, and ensures efficient data retrieval even under node failures and varying network densities. Extensive ns-3 simulations demonstrate that DRACO outperforms state-of-the-art techniques, improving data availability by up to 15% and 34%, and replica creation by up to 18% and 40%, compared to greedy and random replication techniques, respectively. DRACO also ensures efficient data dissemination through optimized replica distribution and achieves superior data collection efficiency under varying node densities and failure scenarios as compared to commonly used uncontrolled sink mobility approaches namely random walk and self-avoiding random walk. By addressing key IoT data management challenges, DRACO offers a scalable and resilient solution well-suited for emerging use cases.",
    "authors": [
      "Waleed Bin Qaim",
      "Oznur Ozkasap",
      "Rabia Qadar",
      "Moncef Gabbouj"
    ],
    "categories": [
      "cs.NI",
      "cs.ET"
    ],
    "publishedAt": "2025-10-08T19:13:50.000Z",
    "updatedAt": "2025-10-08T19:13:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07464v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07464v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07439v1",
    "arxivId": "2510.07439v1",
    "title": "Quantum Filtering and Analysis of Multiplicities in Eigenvalue Spectra",
    "abstract": "Fine-grained spectral properties of quantum Hamiltonians, including both eigenvalues and their multiplicities, provide useful information for characterizing many-body quantum systems as well as for understanding phenomena such as topological order. Extracting such information with small additive error is $\\#\\textsf{BQP}$-complete in the worst case. In this work, we introduce QFAMES (Quantum Filtering and Analysis of Multiplicities in Eigenvalue Spectra), a quantum algorithm that efficiently identifies clusters of closely spaced dominant eigenvalues and determines their multiplicities under physically motivated assumptions, which allows us to bypass worst-case complexity barriers. QFAMES also enables the estimation of observable expectation values within targeted energy clusters, providing a powerful tool for studying quantum phase transitions and other physical properties. We validate the effectiveness of QFAMES through numerical demonstrations, including its applications to characterizing quantum phases in the transverse-field Ising model and estimating the ground-state degeneracy of a topologically ordered phase in the two-dimensional toric code model. Our approach offers rigorous theoretical guarantees and significant advantages over existing subspace-based quantum spectral analysis methods, particularly in terms of the sample complexity and the ability to resolve degeneracies.",
    "authors": [
      "Zhiyan Ding",
      "Lin Lin",
      "Yilun Yang",
      "Ruizhe Zhang"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T18:37:36.000Z",
    "updatedAt": "2025-10-08T18:37:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07439v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07439v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07435v1",
    "arxivId": "2510.07435v1",
    "title": "Modeling Developer Burnout with GenAI Adoption",
    "abstract": "Generative AI (GenAI) is rapidly reshaping software development workflows. While prior studies emphasize productivity gains, the adoption of GenAI also introduces new pressures that may harm developers' well-being. In this paper, we investigate the relationship between the adoption of GenAI and developers' burnout. We utilized the Job Demands--Resources (JD--R) model as the analytic lens in our empirical study. We employed a concurrent embedded mixed-methods research design, integrating quantitative and qualitative evidence. We first surveyed 442 developers across diverse organizations, roles, and levels of experience. We then employed Partial Least Squares--Structural Equation Modeling (PLS-SEM) and regression to model the relationships among job demands, job resources, and burnout, complemented by a qualitative analysis of open-ended responses to contextualize the quantitative findings. Our results show that GenAI adoption heightens burnout by increasing job demands, while job resources and positive perceptions of GenAI mitigate these effects, reframing adoption as an opportunity.",
    "authors": [
      "Zixuan Feng",
      "Sadia Afroz",
      "Anita Sarma"
    ],
    "categories": [
      "cs.SE",
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T18:35:38.000Z",
    "updatedAt": "2025-10-08T18:35:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07435v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07435v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07430v1",
    "arxivId": "2510.07430v1",
    "title": "BG-FlipIn: A Bayesian game framework for FlipIt-insider models in advanced persistent threats",
    "abstract": "In this paper, we study advanced persistent threats (APT) with an insider who has different preferences. To address the uncertainty of the insider's preference, we propose the BG-FlipIn: a Bayesian game framework for FlipIt-insider models with an investigation on malicious, inadvertent, or corrupt insiders. We calculate the closed-form Bayesian Nash Equilibrium expression and further obtain three edge cases with deterministic insiders corresponding to their Nash Equilibrium expressions. On this basis, we further discover several phenomena in APT related to the defender's move rate and cost, as well as the insider's preferences. We then provide decision-making guidance for the defender, given different parametric conditions. Two applications validate that our BG-FlipIn framework enables the defender to make decisions consistently, avoiding detecting the insider's concrete preference or adjusting its strategy frequently.",
    "authors": [
      "Yang Jiao",
      "Guanpu Chen",
      "Yiguang Hong"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-08T18:26:40.000Z",
    "updatedAt": "2025-10-08T18:26:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07430v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07430v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07427v1",
    "arxivId": "2510.07427v1",
    "title": "SEPhIA: <1 laser/neuron Spiking Electro-Photonic Integrated Multi-Tiled Architecture for Scalable Optical Neuromorphic Computing",
    "abstract": "Research into optical spiking neural networks (SNNs) has primarily focused on spiking devices, networks of excitable lasers or numerical modelling of large architectures, often overlooking key constraints such as limited optical power, crosstalk and footprint. We introduce SEPhIA, a photonic-electronic, multi-tiled SNN architecture emphasizing implementation feasibility and realistic scaling. SEPhIA leverages microring resonator modulators (MRMs) and multi-wavelength sources to achieve effective sub-one-laser-per-spiking neuron efficiency. We validate SEPhIA at both device and architecture levels by time-domain co-simulating excitable CMOS-MRR coupled circuits and by devising a physics-aware, trainable optoelectronic SNN model, with both approaches utilizing experimentally derived device parameters. The multi-layer optoelectronic SNN achieves classification accuracies over 90% on a four-class spike-encoded dataset, closely comparable to software models. A design space study further quantifies how photonic device parameters impact SNN performance under constrained signal-to-noise conditions. SEPhIA offers a scalable, expressive, physically grounded solution for neuromorphic photonic computing, capable of addressing spike-encoded tasks.",
    "authors": [
      "Matěj Hejda",
      "Aishwarya Natarajan",
      "Chaerin Hong",
      "Mehmet Berkay On",
      "Sébastien d'Herbais de Thun",
      "Raymond G. Beausoleil",
      "Thomas Van Vaerenbergh"
    ],
    "categories": [
      "cs.ET",
      "cs.NE",
      "physics.optics"
    ],
    "publishedAt": "2025-10-08T18:24:29.000Z",
    "updatedAt": "2025-10-08T18:24:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07427v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07427v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07422v1",
    "arxivId": "2510.07422v1",
    "title": "Homomorphism Problems in Graph Databases and Automatic Structures",
    "abstract": "This thesis investigates the central role of homomorphism problems (structure-preserving maps) in two complementary domains: database querying over finite, graph-shaped data, and constraint solving over (potentially infinite) structures. Building on the well-known equivalence between conjunctive query evaluation and homomorphism existence, the first part focuses on conjunctive regular path queries, a standard extension of conjunctive queries that incorporates regular-path predicates. We study the fundamental problem of query minimization under two measures: the number of atoms (constraints) and the tree-width of the query graph. In both cases, we prove the problem to be decidable, and provide efficient algorithms for a large fragment of queries used in practice. The second part of the thesis lifts homomorphism problems to automatic structures, which are infinite structures describable by finite automata. We highlight a dichotomy, between homomorphism problems over automatic structures that are decidable in non-deterministic logarithmic space, and those that are undecidable (proving to be the more common case). In contrast to this prevalence of undecidability, we then focus on the language-theoretic properties of these structures, and show, relying on a novel algebraic language theory, that for any well-behaved logic (a pseudovariety), whether an automatic structure can be described in this logic is decidable.",
    "authors": [
      "Rémi Morvan"
    ],
    "categories": [
      "cs.LO",
      "cs.DB",
      "cs.FL"
    ],
    "publishedAt": "2025-10-08T18:23:00.000Z",
    "updatedAt": "2025-10-08T18:23:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07422v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07422v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07275v1",
    "arxivId": "2510.07275v1",
    "title": "Geometric Queries on Closed Implicit Surfaces for Walk on Stars",
    "abstract": "Walk on stars (WoSt) is currently one of the most advanced Monte Carlo solvers for PDEs. Unfortunately, the lack of reliable geometric query approaches has hindered its applicability to boundaries defined by implicit surfaces. This work proposes a geometric query framework over closed implicit surfaces for WoSt, under the scope of walkin' Robin. Our key observation is that all WoSt queries can be formulated as constrained global optimization or constraint satisfaction problems. Based on our formulations, to solve the highly non-convex problems, we adopt a branch-and-bound approach based on interval analysis. To the best of our knowledge, our method is the first to study closest silhouette point queries and Robin radius bound queries on closed implicit surfaces. Our formulations and methods first enable mesh-free PDE solving via WoSt when boundaries are defined by closed implicit surfaces.",
    "authors": [
      "Tianyu Huang"
    ],
    "categories": [
      "cs.GR"
    ],
    "publishedAt": "2025-10-08T17:40:05.000Z",
    "updatedAt": "2025-10-08T17:40:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07275v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07275v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07267v1",
    "arxivId": "2510.07267v1",
    "title": "On quantum to classical comparison for Davies generators",
    "abstract": "Despite extensive study, our understanding of quantum Markov chains remains far less complete than that of their classical counterparts. [Temme'13] observed that the Davies Lindbladian, a well-studied model of quantum Markov dynamics, contains an embedded classical Markov generator, raising the natural question of how the convergence properties of the quantum and classical dynamics are related. While [Temme'13] showed that the spectral gap of the Davies Lindbladian can be much smaller than that of the embedded classical generator for certain highly structured Hamiltonians, we show that if the spectrum of the Hamiltonian does not contain long arithmetic progressions, then the two spectral gaps must be comparable. As a consequence, we prove that for a large class of Hamiltonians, including those obtained by perturbing a fixed Hamiltonian with a generic external field, the quantum spectral gap remains within a constant factor of the classical spectral gap. Our result aligns with physical intuition and enables the application of classical Markov chain techniques to the quantum setting. The proof is based on showing that any ``off-diagonal'' eigenvector of the Davies generator can be used to construct an observable which commutes with the Hamiltonian and has a Lindbladian Rayleigh quotient which can be upper bounded in terms of that of the original eigenvector's Lindbladian Rayleigh quotient. Thus, a spectral gap for such observables implies a spectral gap for the full Davies generator.",
    "authors": [
      "Joao Basso",
      "Shirshendu Ganguly",
      "Alistair Sinclair",
      "Nikhil Srivastava",
      "Zachary Stier",
      "Thuy-Duong Vuong"
    ],
    "categories": [
      "quant-ph",
      "cs.DS",
      "math-ph",
      "math.MP",
      "math.PR"
    ],
    "publishedAt": "2025-10-08T17:33:23.000Z",
    "updatedAt": "2025-10-08T17:33:23.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07267v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07267v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07266v1",
    "arxivId": "2510.07266v1",
    "title": "Dynamic Regret Bounds for Online Omniprediction with Long Term Constraints",
    "abstract": "We present an algorithm guaranteeing dynamic regret bounds for online omniprediction with long term constraints. The goal in this recently introduced problem is for a learner to generate a sequence of predictions which are broadcast to a collection of downstream decision makers. Each decision maker has their own utility function, as well as a vector of constraint functions, each mapping their actions and an adversarially selected state to reward or constraint violation terms. The downstream decision makers select actions \"as if\" the state predictions are correct, and the goal of the learner is to produce predictions such that all downstream decision makers choose actions that give them worst-case utility guarantees while minimizing worst-case constraint violation. Within this framework, we give the first algorithm that obtains simultaneous \\emph{dynamic regret} guarantees for all of the agents -- where regret for each agent is measured against a potentially changing sequence of actions across rounds of interaction, while also ensuring vanishing constraint violation for each agent. Our results do not require the agents themselves to maintain any state -- they only solve one-round constrained optimization problems defined by the prediction made at that round.",
    "authors": [
      "Yahav Bechavod",
      "Jiuyao Lu",
      "Aaron Roth"
    ],
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "publishedAt": "2025-10-08T17:28:05.000Z",
    "updatedAt": "2025-10-08T17:28:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07266v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07266v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07200v1",
    "arxivId": "2510.07200v1",
    "title": "Regulating Social Media: Surveying the Impact of Nepali Government's TikTok Ban",
    "abstract": "Social media platforms have transformed global communication and interaction, with TikTok emerging as a critical tool for education, connection, and social impact, including in contexts where infrastructural resources are limited. Amid growing political discussions about banning platforms like TikTok, such actions can create significant ripple effects, particularly impacting marginalized communities. We present a study on Nepal, where a TikTok ban was recently imposed and lifted. As a low-resource country in transition where digital communication is rapidly evolving, TikTok enables a space for community engagement and cultural expression. In this context, we conducted an online survey (N=108) to explore user values, experiences, and strategies for navigating online spaces post-ban. By examining these transitions, we aim to improve our understanding of how digital technologies, policy responses, and cultural dynamics interact globally and their implications for governance and societal norms. Our results indicate that users express skepticism toward platform bans but often passively accept them without active opposition. Findings suggest the importance of institutionalizing collective governance models that encourage public deliberation, nuanced control, and socially resonant policy decisions.",
    "authors": [
      "Prerana Khatiwada",
      "Alejandro Ciuba",
      "Aditya Nayak",
      "Aakash Gautam",
      "Matthew Louis Mauriello"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T16:33:14.000Z",
    "updatedAt": "2025-10-08T16:33:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07200v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07200v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.09672v1",
    "arxivId": "2510.09672v1",
    "title": "Pingmark: A Textual Protocol for Universal Spatial Mentions",
    "abstract": "Pingmark defines a universal textual protocol for expressing spatial context through a minimal symbol: !@. Rather than embedding coordinates or using proprietary map links, Pingmark introduces a semantic trigger that compliant client applications interpret to generate a standardized resolver link of the form https://pingmark.me/lat/lon/[timestamp]. This allows location expression to function like existing textual conventions - @ for identity or # for topics - but for physical space. The protocol requires no user registration, relies on open mapping technologies, and protects privacy by generating location data ephemerally and locally. This paper presents the motivation, syntax, and design of the Pingmark Protocol Specification (PPS v0.1), its reference resolver implementation, and the long-term goal of establishing Pingmark as an open Internet standard for spatial mentions.",
    "authors": [
      "Kalin Dimitrov"
    ],
    "categories": [
      "cs.CR",
      "cs.HC",
      "cs.NI"
    ],
    "publishedAt": "2025-10-08T16:25:38.000Z",
    "updatedAt": "2025-10-08T16:25:38.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.09672v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.09672v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07184v1",
    "arxivId": "2510.07184v1",
    "title": "Exploring the Feasibility of Gaze-Based Navigation Across Path Types",
    "abstract": "Gaze input, as a modality inherently conveying user intent, offers intuitive and immersive experiences in extended reality (XR). With eye-tracking now being a standard feature in modern XR headsets, gaze has been extensively applied to tasks such as selection, text entry, and object manipulation. However, gaze based navigation despite being a fundamental interaction task remains largely underexplored. In particular, little is known about which path types are well suited for gaze navigation and under what conditions it performs effectively. To bridge this gap, we conducted a controlled user study evaluating gaze-based navigation across three representative path types: linear, narrowing, and circular. Our findings reveal distinct performance characteristics and parameter ranges for each path type, offering design insights and practical guidelines for future gaze-driven navigation systems in XR.",
    "authors": [
      "Yichuan Zhang",
      "Liangyuting Zhang",
      "Xuning Hu",
      "Yong Yue",
      "Hai-Ning Liang"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T16:21:55.000Z",
    "updatedAt": "2025-10-08T16:21:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07184v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07184v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07164v1",
    "arxivId": "2510.07164v1",
    "title": "Clifford testing: algorithms and lower bounds",
    "abstract": "We consider the problem of Clifford testing, which asks whether a black-box $n$-qubit unitary is a Clifford unitary or at least $\\varepsilon$-far from every Clifford unitary. We give the first 4-query Clifford tester, which decides this problem with probability $\\mathrm{poly}(\\varepsilon)$. This contrasts with the minimum of 6 copies required for the closely-related task of stabilizer testing. We show that our tester is tolerant, by adapting techniques from tolerant stabilizer testing to our setting. In doing so, we settle in the positive a conjecture of Bu, Gu and Jaffe, by proving a polynomial inverse theorem for a non-commutative Gowers 3-uniformity norm. We also consider the restricted setting of single-copy access, where we give an $O(n)$-query Clifford tester that requires no auxiliary memory qubits or adaptivity. We complement this with a lower bound, proving that any such, potentially adaptive, single-copy algorithm needs at least $\\Omega(n^{1/4})$ queries. To obtain our results, we leverage the structure of the commutant of the Clifford group, obtaining several technical statements that may be of independent interest.",
    "authors": [
      "Marcel Hinsche",
      "Zongbo Bao",
      "Philippe van Dordrecht",
      "Jens Eisert",
      "Jop Briët",
      "Jonas Helsen"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T16:02:07.000Z",
    "updatedAt": "2025-10-08T16:02:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07164v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07164v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07159v1",
    "arxivId": "2510.07159v1",
    "title": "On some 2-binomial coefficients of binary words: geometrical interpretation, partitions of integers, and fair words",
    "abstract": "The binomial notation (w u) represents the number of occurrences of the word u as a (scattered) subword in w. We first introduce and study possible uses of a geometrical interpretation of (w ab) and (w ba) when a and b are distinct letters. We then study the structure of the 2-binomial equivalence class of a binary word w (two words are 2-binomially equivalent if they have the same binomial coefficients, that is, the same numbers of occurrences, for each word of length at most 2). Especially we prove the existence of an isomorphism between the graph of the 2-binomial equivalence class of w with respect to a particular rewriting rule and the lattice of partitions of the integer (w ab) with (w a) parts and greatest part bounded by (w b). Finally we study binary fair words, the words over {a, b} having the same numbers of occurrences of ab and ba as subwords ((w ab) = (w ba)). In particular, we prove a recent conjecture related to a special case of the least square approximation.",
    "authors": [
      "Gwenaël Richomme"
    ],
    "categories": [
      "cs.DM",
      "math.CO"
    ],
    "publishedAt": "2025-10-08T15:57:36.000Z",
    "updatedAt": "2025-10-08T15:57:36.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07159v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07159v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07156v1",
    "arxivId": "2510.07156v1",
    "title": "AI for Abolition? A Participatory Design Approach",
    "abstract": "The abolitionist community faces challenges from both the carceral state and oppressive technologies which, by empowering the ruling class who have the resources to develop artificial intelligence (AI), serve to entrench societal inequities even more deeply. This paper presents a case study in participatory design with transformative and restorative justice practitioners with the goal of designing an AI system to support their work. By co-designing an evaluation framework for large language models with the practitioners, we hope to push back against the exclusionary status quo of AI and extent AI's potentiality to a historically marginalized community.",
    "authors": [
      "Carolyn Wang",
      "Avriel Epps",
      "Taylor Ferrari",
      "Ra Ames"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T15:53:25.000Z",
    "updatedAt": "2025-10-08T15:53:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07156v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07156v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07132v1",
    "arxivId": "2510.07132v1",
    "title": "DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture Model Nonparametric Clustering",
    "abstract": "Clustered Federated Learning (CFL) improves performance under non-IID client heterogeneity by clustering clients and training one model per cluster, thereby balancing between a global model and fully personalized models. However, most CFL methods require the number of clusters K to be fixed a priori, which is impractical when the latent structure is unknown. We propose DPMM-CFL, a CFL algorithm that places a Dirichlet Process (DP) prior over the distribution of cluster parameters. This enables nonparametric Bayesian inference to jointly infer both the number of clusters and client assignments, while optimizing per-cluster federated objectives. This results in a method where, at each round, federated updates and cluster inferences are coupled, as presented in this paper. The algorithm is validated on benchmark datasets under Dirichlet and class-split non-IID partitions.",
    "authors": [
      "Mariona Jaramillo-Civill",
      "Peng Wu",
      "Pau Closas"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "stat.ML"
    ],
    "publishedAt": "2025-10-08T15:27:08.000Z",
    "updatedAt": "2025-10-08T15:27:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07132v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07132v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07126v1",
    "arxivId": "2510.07126v1",
    "title": "Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?",
    "abstract": "Deep learning (DL) has been increasingly applied in medical imaging, however, it requires large amounts of data, which raises many challenges related to data privacy, storage, and transfer. Federated learning (FL) is a training paradigm that overcomes these issues, though its effectiveness may be reduced when dealing with non-independent and identically distributed (non-IID) data. This study simulates non-IID conditions by applying different MRI intensity normalization techniques to separate data subsets, reflecting a common cause of heterogeneity. These subsets are then used for training and testing models for brain tumor segmentation. The findings provide insights into the influence of the MRI intensity normalization methods on segmentation models, both training and inference. Notably, the FL methods demonstrated resilience to inconsistently normalized data across clients, achieving the 3D Dice score of 92%, which is comparable to a centralized model (trained using all data). These results indicate that FL is a solution to effectively train high-performing models without violating data privacy, a crucial concern in medical applications. The code is available at: https://github.com/SanoScience/fl-varying-normalization.",
    "authors": [
      "Jan Fiszer",
      "Dominika Ciupek",
      "Maciej Malawski"
    ],
    "categories": [
      "cs.CV",
      "cs.DC"
    ],
    "publishedAt": "2025-10-08T15:21:53.000Z",
    "updatedAt": "2025-10-08T15:21:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07126v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07126v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07116v1",
    "arxivId": "2510.07116v1",
    "title": "From Neural Sensing to Stimulation: An Interdisciplinary Roadmap for Neurotechnology",
    "abstract": "Neurotechnologies are transforming how we measure, interpret, and modulate brain-body interactions, integrating real-time sensing, computation, and stimulation to enable precise physiological control. They hold transformative potential across clinical and non-clinical domains, from treating disorders to enhancing cognition and performance. Realizing this potential requires navigating complex, interdisciplinary challenges spanning neuroscience, materials science, device engineering, signal processing, computational modelling, and regulatory and ethical frameworks. This Perspective presents a strategic roadmap for neurotechnology development, created by early-career researchers, highlighting their role at the intersection of disciplines and their capacity to bridge traditional silos. We identify five cross-cutting trade-offs that constrain progress across functionality, scalability, adaptability, and translatability, and illustrate how technical domains influence their resolution. Rather than a domain-specific review, we focus on shared challenges and strategic opportunities that transcend disciplines. We propose a unified framework for collaborative innovation and education, highlight ethical and regulatory priorities, and outline a timeline for overcoming key bottlenecks. By aligning technical development with translational and societal needs, this roadmap aims to accelerate equitable, effective, and future-ready adaptive neurotechnologies, guiding coordinated efforts across the global research and innovation community.",
    "authors": [
      "Ruben Ruiz-Mateos Serrano",
      "Joe G Troughton",
      "Nima Mirkhani",
      "Natalia Martinez",
      "Massimo Mariello",
      "Jordan Tsigarides",
      "Simon Williamson",
      "Juan Sapriza",
      "Ioana Susnoschi Luca",
      "Antonio Dominguez-Alfaro",
      "Estelle Cuttaz",
      "Nicole Thompson",
      "Sydney Swedick",
      "Latifah Almulla",
      "Amparo Guemes"
    ],
    "categories": [
      "cs.ET",
      "cs.AR",
      "cs.HC",
      "cs.SE",
      "cs.SY",
      "eess.SY"
    ],
    "publishedAt": "2025-10-08T15:09:54.000Z",
    "updatedAt": "2025-10-08T15:09:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07116v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07116v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07101v1",
    "arxivId": "2510.07101v1",
    "title": "Data as Commodity: a Game-Theoretic Principle for Information Pricing",
    "abstract": "Data is the central commodity of the digital economy. Unlike physical goods, it is non-rival, replicable at near-zero cost, and traded under heterogeneous licensing rules. These properties defy standard supply--demand theory and call for new pricing principles. We propose a game-theoretic approach in which the value of a data string emerges from strategic competition among N players betting on an underlying stochastic process, each holding partial information about past outcomes. A better-informed player faces a choice: exploit their informational advantage, or sell part of their dataset to less-informed competitors. By analytically computing the Nash equilibrium of the game, we determine the price range where the trade is beneficial to both buyer and seller. We uncover a rich landscape of market effects that diverge from textbook economics: first, prospective sellers and buyers can compete or jointly exploit the less informed competitors depending on the quality of data they hold. In a symbiotic regime, the seller can even share data for free while still improving her payoffs, showing that losing exclusivity does not necessarily reduce profit. Moreover, rivalry between well-informed players can paradoxically benefit uninformed ones, demonstrating that information abundance does not always translate to higher payoffs. We also show that the number of players influences the competition between informed parties: trades impossible in small markets become feasible in larger ones. These findings establish a theoretical foundation for the pricing of intangible goods in dynamically interacting digital markets, which are in need of robust valuation principles.",
    "authors": [
      "Pasquale Casaburi",
      "Giovanni Piccioli",
      "Pierpaolo Vivo"
    ],
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech",
      "cs.GT"
    ],
    "publishedAt": "2025-10-08T14:58:14.000Z",
    "updatedAt": "2025-10-08T14:58:14.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07101v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07101v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07079v1",
    "arxivId": "2510.07079v1",
    "title": "An HPC-Inspired Blueprint for a Technology-Agnostic Quantum Middle Layer",
    "abstract": "We present a blueprint for a quantum middle layer that supports applications across various quantum technologies. Inspired by concepts and abstractions from HPC libraries and middleware, our design is backend-neutral and context-aware. A program only needs to specify its intent once as typed data and operator descriptors. It declares what the quantum registers mean and which logical transformations are required, without committing to gates, pulses, continuous-variable routines, or anneal backend. Such execution details are carried separately in a context descriptor and can change per backend without modifying the intent artifacts. We develop a proof of concept implementation that uses JSON files for the descriptors and two backends: a gate-model path realized with IBM Qiskit Aer simulator and an annealing path realized with D-Wave Ocean's simulated annealer. On a Max-Cut problem instance, the same typed problem runs on both backends by varying only the operator formulation (Quantum Approximated Optimization Algorithm formulation vs. Ising Hamiltonian formulation) and the context. The proposed middle layer concepts are characterized by portability, composability, and its minimal core can evolve with hardware capabilities.",
    "authors": [
      "Stefano Markidis",
      "Gilbert Netzer",
      "Luca Pennati",
      "Ivy Peng"
    ],
    "categories": [
      "cs.ET"
    ],
    "publishedAt": "2025-10-08T14:39:19.000Z",
    "updatedAt": "2025-10-08T14:39:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07079v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07079v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07065v1",
    "arxivId": "2510.07065v1",
    "title": "Parameterized Complexity of s-Club Cluster Edge Deletion",
    "abstract": "We study the parameterized and classical complexity of the s-Club Cluster Edge Deletion problem: given a graph G = (V, E) and integers k and s, determine whether it is possible to delete at most k edges so that every connected component of the resulting graph has diameter at most s. This problem generalizes Cluster Edge Deletion (the case s = 1) and captures a variety of distance-bounded graph modification tasks. Montecchiani, Ortali, Piselli, and Tappini (Information and Computation, 2023) showed that the problem is fixed-parameter tractable when parameterized by s plus the treewidth of G, and asked whether the dependence on s is necessary; that is, whether the problem is FPT when parameterized by treewidth alone. We resolve this by proving that the problem is W[1]-hard when parameterized by pathwidth, and hence by treewidth. On the algorithmic side, we show that the problem is FPT when parameterized by neighborhood diversity, twin cover, or cluster vertex deletion number, thereby extending to all s >= 1 the results of Italiano, Konstantinidis, and Papadopoulos (Algorithmica, 2023), who established FPT algorithms for the case s = 1 under the neighborhood diversity and twin cover parameters. From a classical perspective, we prove that the problem is NP-hard on split graphs already for s = 2, complementing the polynomial-time solvability for s = 1 due to Bonomo, Duran, and Valencia-Pabon (Theoretical Computer Science, 2015) and the trivial case s = 3. Finally, while the problem is FPT when parameterized by s + k, its complexity for the solution size k alone remains open. We make progress on this front by designing an FPT bicriteria approximation algorithm, which runs in time f(k, 1/epsilon) * n^{O(1)} and, for graphs excluding long induced cycles, outputs a solution of size at most k whose connected components have diameter at most (1 + epsilon) * s.",
    "authors": [
      "Ajinkya Gaikwad"
    ],
    "categories": [
      "cs.DM",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T14:30:42.000Z",
    "updatedAt": "2025-10-08T14:30:42.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07065v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07065v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07063v2",
    "arxivId": "2510.07063v2",
    "title": "Artists' Views on Robotics Involvement in Painting Productions",
    "abstract": "As robotic technologies evolve, their potential in artistic creation becomes an increasingly relevant topic of inquiry. This study explores how professional abstract artists perceive and experience co-creative interactions with an autonomous painting robotic arm. Eight artists engaged in six painting sessions -- three with a human partner, followed by three with the robot -- and subsequently participated in semi-structured interviews analyzed through reflexive thematic analysis. Human-human interactions were described as intuitive, dialogic, and emotionally engaging, whereas human-robot sessions felt more playful and reflective, offering greater autonomy and prompting for novel strategies to overcome the system's limitations. This work offers one of the first empirical investigations into artists' lived experiences with a robot, highlighting the value of long-term engagement and a multidisciplinary approach to human-robot co-creation.",
    "authors": [
      "Francesca Cocchella",
      "Nilay Roy Choudhury",
      "Eric Chen",
      "Patrícia Alves-Oliveira"
    ],
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "publishedAt": "2025-10-08T14:28:30.000Z",
    "updatedAt": "2025-10-09T18:14:34.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07063v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.07063v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07050v2",
    "arxivId": "2510.07050v2",
    "title": "The Feature Understandability Scale for Human-Centred Explainable AI: Assessing Tabular Feature Importance",
    "abstract": "As artificial intelligence becomes increasingly pervasive and powerful, the ability to audit AI-based systems is growing in importance. However, explainability for artificial intelligence systems is not a one-size-fits-all solution; different target audiences have varying requirements and expectations for explanations. While various approaches to explainability have been proposed, most explainable artificial intelligence methods for tabular data focus on explaining the outputs of supervised machine learning models using the input features. However, a user's ability to understand an explanation depends on their understanding of such features. Therefore, it is in the best interest of the system designer to try to pre-select understandable features for producing a global explanation of an ML model. Unfortunately, no measure currently exists to assess the degree to which a user understands a given input feature. This work introduces two psychometrically validated scales that quantitatively seek to assess users' understanding of tabular input features for supervised classification problems. Specifically, these scales, one for numerical and one for categorical data, each with two factors and comprising 8 and 9 items, aim to assign a score to each input feature, effectively producing a rank, and allowing for the quantification of feature prioritisation. A confirmatory factor analysis demonstrates a strong relationship between such items and a good fit of the two-factor structure for each scale. This research presents a novel method for assessing understanding and outlines potential applications in the domain of explainable artificial intelligence.",
    "authors": [
      "Nicola Rossberg",
      "Bennett Kleinberg",
      "Barry O'Sullivan",
      "Luca Longo",
      "Andrea Visentin"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T14:17:30.000Z",
    "updatedAt": "2025-10-10T11:08:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07050v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.07050v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07009v1",
    "arxivId": "2510.07009v1",
    "title": "The Stage Comes to You: A Real-Time Tele-Immersive System with 3D Point Clouds and Vibrotactile Feedback",
    "abstract": "We present a low-latency tele-immersive entertainment system that streams 3D point clouds and performers' footstep vibrations, creating the sense that the stage is present. Moving performers and their surroundings are captured as dynamic point clouds under rapidly changing lighting, then processed, transmitted, and rendered within a total latency of less than 100 ms. Under high ambient noise, footstep vibrations are sensed by wearable accelerometers. Real-time visual and haptic streams are delivered to a remote venue, where a large 3D LED wall and a vibration-efficient haptic floor envelop dozens of spectators. A public trial at Expo 2025 linked sites 20 km apart: visitors watched a live dance show and conversed with performers without noticeable delay.",
    "authors": [
      "Takahiro Matsumoto",
      "Takahiro Kusabuka",
      "Hiroshi Chigira",
      "Kazuhiko Murasaki",
      "Kakagu Komazaki",
      "Masafumi Suzuki",
      "Masakatsu Aoki"
    ],
    "categories": [
      "cs.ET",
      "cs.HC",
      "I.3.7"
    ],
    "publishedAt": "2025-10-08T13:33:55.000Z",
    "updatedAt": "2025-10-08T13:33:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07009v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07009v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06998v1",
    "arxivId": "2510.06998v1",
    "title": "Evaluating Rapid Makespan Predictions for Heterogeneous Systems with Programmable Logic",
    "abstract": "Heterogeneous computing systems, which combine general-purpose processors with specialized accelerators, are increasingly important for optimizing the performance of modern applications. A central challenge is to decide which parts of an application should be executed on which accelerator or, more generally, how to map the tasks of an application to available devices. Predicting the impact of a change in a task mapping on the overall makespan is non-trivial. While there are very capable simulators, these generally require a full implementation of the tasks in question, which is particularly time-intensive for programmable logic. A promising alternative is to use a purely analytical function, which allows for very fast predictions, but abstracts significantly from reality. Bridging the gap between theory and practice poses a significant challenge to algorithm developers. This paper aims to aid in the development of rapid makespan prediction algorithms by providing a highly flexible evaluation framework for heterogeneous systems consisting of CPUs, GPUs and FPGAs, which is capable of collecting real-world makespan results based on abstract task graph descriptions. We analyze to what extent actual makespans can be predicted by existing analytical approaches. Furthermore, we present common challenges that arise from high-level characteristics such as data transfer overhead and device congestion in heterogeneous systems.",
    "authors": [
      "Martin Wilhelm",
      "Franz Freitag",
      "Max Tzschoppe",
      "Thilo Pionteck"
    ],
    "categories": [
      "cs.DC",
      "cs.AR"
    ],
    "publishedAt": "2025-10-08T13:20:51.000Z",
    "updatedAt": "2025-10-08T13:20:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06998v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06998v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06933v1",
    "arxivId": "2510.06933v1",
    "title": "On the distribution of $A_α$-eigenvalues in terms of graph invariants",
    "abstract": "Let $G$ be a connected graph of order $n$, and $A(G)$ and $D(G)$ its adjacency and degree diagonal matrices, respectively. For a parameter $\\alpha \\in [0,1]$, Nikiforov~(2017) introduced the convex combination $A_{\\alpha}(G) = \\alpha D(G) + (1 - \\alpha)A(G)$. In this paper, we investigate the spectral distribution of $A_\\alpha(G)$-eigenvalues, over subintervals of the real line. We establish lower and upper bounds on the number of such eigenvalues in terms of structural parameters of $G$, including the number of pendant and quasi-pendant vertices, the domination number, the matching number, and the edge covering number. Additionally, we exhibit families of graphs for which these bounds are attained. Several of our results extend known spectral bounds on the eigenvalue distributions of both the adjacency and the signless Laplacian matrices.",
    "authors": [
      "Uilton Cesar Peres Junior",
      "Carla Silva Oliveira",
      "André Ebling Brondan"
    ],
    "categories": [
      "cs.DM",
      "05C50, 05C35"
    ],
    "publishedAt": "2025-10-08T12:17:40.000Z",
    "updatedAt": "2025-10-08T12:17:40.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06933v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06933v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06925v1",
    "arxivId": "2510.06925v1",
    "title": "Quantum Sparse Recovery and Quantum Orthogonal Matching Pursuit",
    "abstract": "We study quantum sparse recovery in non-orthogonal, overcomplete dictionaries: given coherent quantum access to a state and a dictionary of vectors, the goal is to reconstruct the state up to $\\ell_2$ error using as few vectors as possible. We first show that the general recovery problem is NP-hard, ruling out efficient exact algorithms in full generality. To overcome this, we introduce Quantum Orthogonal Matching Pursuit (QOMP), the first quantum analogue of the classical OMP greedy algorithm. QOMP combines quantum subroutines for inner product estimation, maximum finding, and block-encoded projections with an error-resetting design that avoids iteration-to-iteration error accumulation. Under standard mutual incoherence and well-conditioned sparsity assumptions, QOMP provably recovers the exact support of a $K$-sparse state in polynomial time. As an application, we give the first framework for sparse quantum tomography with non-orthogonal dictionaries in $\\ell_2$ norm, achieving query complexity $\\widetilde{O}(\\sqrt{N}/\\epsilon)$ in favorable regimes and reducing tomography to estimating only $K$ coefficients instead of $N$ amplitudes. In particular, for pure-state tomography with $m=O(N)$ dictionary vectors and sparsity $K=\\widetilde{O}(1)$ on a well-conditioned subdictionary, this circumvents the $\\widetilde{\\Omega}(N/\\epsilon)$ lower bound that holds in the dense, orthonormal-dictionary setting, without contradiction, by leveraging sparsity together with non-orthogonality. Beyond tomography, we analyze QOMP in the QRAM model, where it yields polynomial speedups over classical OMP implementations, and provide a quantum algorithm to estimate the mutual incoherence of a dictionary of $m$ vectors in $O(m/\\epsilon)$ queries, improving over both deterministic and quantum-inspired classical methods.",
    "authors": [
      "Armando Bellante",
      "Stefano Vanerio",
      "Stefano Zanero"
    ],
    "categories": [
      "quant-ph",
      "cs.DS",
      "cs.LG"
    ],
    "publishedAt": "2025-10-08T12:05:07.000Z",
    "updatedAt": "2025-10-08T12:05:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06925v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06925v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06908v2",
    "arxivId": "2510.06908v2",
    "title": "Emotionally Vulnerable Subtype of Internet Gaming Disorder: Measuring and Exploring the Pathology of Problematic Generative AI Use",
    "abstract": "Concerns over the potential over-pathologization of generative AI (GenAI) use and the lack of conceptual clarity surrounding GenAI addiction call for empirical tools and theoretical refinement. This study developed and validated the PUGenAIS-9 (Problematic Use of Generative Artificial Intelligence Scale-9 items) and examined whether PUGenAIS reflects addiction-like patterns under the Internet Gaming Disorder (IGD) framework. Using samples from China and the United States (N = 1,508), we conducted confirmatory factor analysis and identified a robust 31-item structure across nine IGD-based dimensions. We then derived the PUGenAIS-9 by selecting the highest-loading items from each dimension and validated its structure in an independent sample (N = 1,426). Measurement invariance tests confirmed its stability across nationality and gender. Person-centered (latent profile analysis) and variable-centered (network analysis) approaches revealed a 5-10% prevalence rate, a symptom network structure similar to IGD, and predictive factors related to psychological distress and functional impairment. These findings indicate that PUGenAI shares features of the emotionally vulnerable subtype of IGD rather than the competence-based type. These results support using PUGenAIS-9 to identify problematic GenAI use and show the need to rethink digital addiction with an ICD (infrastructures, content, and device) model. This keeps addiction research responsive to new media while avoiding over-pathologizing.",
    "authors": [
      "Haocan Sun",
      "Di Wu",
      "Weizi Liu",
      "Guoming Yu",
      "Mike Yao"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "publishedAt": "2025-10-08T11:43:39.000Z",
    "updatedAt": "2025-10-09T01:37:06.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06908v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.06908v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08627v1",
    "arxivId": "2510.08627v1",
    "title": "A Denoising Diffusion-Based Evolutionary Algorithm Framework: Application to the Maximum Independent Set Problem",
    "abstract": "Denoising diffusion models (DDMs) offer a promising generative approach for combinatorial optimization, yet they often lack the robust exploration capabilities of traditional metaheuristics like evolutionary algorithms (EAs). We propose a Denoising Diffusion-based Evolutionary Algorithm (DDEA) framework that synergistically integrates these paradigms. It utilizes pre-trained DDMs for both high-quality and diverse population initialization and a novel diffusion-based recombination operator, trained via imitation learning against an optimal demonstrator. Evaluating DDEA on the Maximum Independent Set problem on Erd\\H{o}s-R\\'enyi graphs, we demonstrate notable improvements over DIFUSCO, a leading DDM solver. DDEA consistently outperforms it given the same time budget, and surpasses Gurobi on larger graphs under the same time limit, with DDEA's solution sizes being 3.9% and 7.5% larger on the ER-300-400 and ER-700-800 datasets, respectively. In out-of-distribution experiments, DDEA provides solutions of 11.6% higher quality than DIFUSCO under the same time limit. Ablation studies confirm that both diffusion initialization and recombination are crucial. Our work highlights the potential of hybridizing DDMs and EAs, offering a promising direction for the development of powerful machine learning solvers for complex combinatorial optimization problems.",
    "authors": [
      "Joan Salvà Soler",
      "Günther R. Raidl"
    ],
    "categories": [
      "cs.NE",
      "cs.DM"
    ],
    "publishedAt": "2025-10-08T11:41:52.000Z",
    "updatedAt": "2025-10-08T11:41:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08627v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08627v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06902v1",
    "arxivId": "2510.06902v1",
    "title": "GROMACS Unplugged: How Power Capping and Frequency Shapes Performance on GPUs",
    "abstract": "Molecular dynamics simulations are essential tools in computational biophysics, but their performance depend heavily on hardware choices and configuration. In this work, we presents a comprehensive performance analysis of four NVIDIA GPU accelerators -- A40, A100, L4, and L40 -- using six representative GROMACS biomolecular workloads alongside two synthetic benchmarks: Pi Solver (compute bound) and STREAM Triad (memory bound). We investigate how performance scales with GPU graphics clock frequency and how workloads respond to power capping. The two synthetic benchmarks define the extremes of frequency scaling: Pi Solver shows ideal compute scalability, while STREAM Triad reveals memory bandwidth limits -- framing GROMACS's performance in context. Our results reveal distinct frequency scaling behaviors: Smaller GROMACS systems exhibit strong frequency sensitivity, while larger systems saturate quickly, becoming increasingly memory bound. Under power capping, performance remains stable until architecture- and workload-specific thresholds are reached, with high-end GPUs like the A100 maintaining near-maximum performance even under reduced power budgets. Our findings provide practical guidance for selecting GPU hardware and optimizing GROMACS performance for large-scale MD workflows under power constraints.",
    "authors": [
      "Ayesha Afzal",
      "Anna Kahler",
      "Georg Hager",
      "Gerhard Wellein"
    ],
    "categories": [
      "cs.DC",
      "cs.PF"
    ],
    "publishedAt": "2025-10-08T11:36:09.000Z",
    "updatedAt": "2025-10-08T11:36:09.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06902v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06902v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06882v1",
    "arxivId": "2510.06882v1",
    "title": "Multi-Dimensional Autoscaling of Stream Processing Services on Edge Devices",
    "abstract": "Edge devices have limited resources, which inevitably leads to situations where stream processing services cannot satisfy their needs. While existing autoscaling mechanisms focus entirely on resource scaling, Edge devices require alternative ways to sustain the Service Level Objectives (SLOs) of competing services. To address these issues, we introduce a Multi-dimensional Autoscaling Platform (MUDAP) that supports fine-grained vertical scaling across both service- and resource-level dimensions. MUDAP supports service-specific scaling tailored to available parameters, e.g., scale data quality or model size for a particular service. To optimize the execution across services, we present a scaling agent based on Regression Analysis of Structural Knowledge (RASK). The RASK agent efficiently explores the solution space and learns a continuous regression model of the processing environment for inferring optimal scaling actions. We compared our approach with two autoscalers, the Kubernetes VPA and a reinforcement learning agent, for scaling up to 9 services on a single Edge device. Our results showed that RASK can infer an accurate regression model in merely 20 iterations (i.e., observe 200s of processing). By increasingly adding elasticity dimensions, RASK sustained the highest request load with 28% less SLO violations, compared to baselines.",
    "authors": [
      "Boris Sedlak",
      "Philipp Raith",
      "Andrea Morichetta",
      "Víctor Casamayor Pujol",
      "Schahram Dustdar"
    ],
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "publishedAt": "2025-10-08T10:51:50.000Z",
    "updatedAt": "2025-10-08T10:51:50.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06882v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06882v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06872v1",
    "arxivId": "2510.06872v1",
    "title": "Prototyping Multimodal GenAI Real-Time Agents with Counterfactual Replays and Hybrid Wizard-of-Oz",
    "abstract": "Recent advancements in multimodal generative AI (GenAI) enable the creation of personal context-aware real-time agents that, for example, can augment user workflows by following their on-screen activities and providing contextual assistance. However, prototyping such experiences is challenging, especially when supporting people with domain-specific tasks using real-time inputs such as speech and screen recordings. While prototyping an LLM-based proactive support agent system, we found that existing prototyping and evaluation methods were insufficient to anticipate the nuanced situational complexity and contextual immediacy required. To overcome these challenges, we explored a novel user-centered prototyping approach that combines counterfactual video replay prompting and hybrid Wizard-of-Oz methods to iteratively design and refine agent behaviors. This paper discusses our prototyping experiences, highlighting successes and limitations, and offers a practical guide and an open-source toolkit for UX designers, HCI researchers, and AI toolmakers to build more user-centered and context-aware multimodal agents.",
    "authors": [
      "Frederic Gmeiner",
      "Kenneth Holstein",
      "Nikolas Martelaro"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T10:39:27.000Z",
    "updatedAt": "2025-10-08T10:39:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06872v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06872v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06851v1",
    "arxivId": "2510.06851v1",
    "title": "Randomized Quantum Singular Value Transformation",
    "abstract": "We introduce the first randomized algorithms for Quantum Singular Value Transformation (QSVT), a unifying framework for many quantum algorithms. Standard implementations of QSVT rely on block encodings of the Hamiltonian, which are costly to construct, requiring a logarithmic number of ancilla qubits, intricate multi-qubit control, and circuit depth scaling linearly with the number of Hamiltonian terms. In contrast, our algorithms use only a single ancilla qubit and entirely avoid block encodings. We develop two methods: (i) a direct randomization of QSVT, where block encodings are replaced by importance sampling, and (ii) an approach that integrates qDRIFT into the generalized quantum signal processing framework, with the dependence on precision exponentially improved through classical extrapolation. Both algorithms achieve gate complexity independent of the number of Hamiltonian terms, a hallmark of randomized methods, while incurring only quadratic dependence on the degree of the target polynomial. We identify natural parameter regimes where our methods outperform even standard QSVT, making them promising for early fault-tolerant quantum devices. We also establish a fundamental lower bound showing that the quadratic dependence on the polynomial degree is optimal within this framework. We apply our framework to two fundamental tasks: solving quantum linear systems and estimating ground-state properties of Hamiltonians, obtaining polynomial advantages over prior randomized algorithms. Finally, we benchmark our ground-state property estimation algorithm on electronic structure Hamiltonians and the transverse-field Ising model with long-range interactions. In both cases, our approach outperforms prior work by several orders of magnitude in circuit depth, establishing randomized QSVT as a practical and resource-efficient alternative for early fault-tolerant quantum devices.",
    "authors": [
      "Xinzhao Wang",
      "Yuxin Zhang",
      "Soumyabrata Hazra",
      "Tongyang Li",
      "Changpeng Shao",
      "Shantanav Chakraborty"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T10:14:15.000Z",
    "updatedAt": "2025-10-08T10:14:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06851v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06851v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06849v1",
    "arxivId": "2510.06849v1",
    "title": "Extending Ghouila-Houri's Characterization of Comparability Graphs to Temporal Graphs",
    "abstract": "An orientation of a given static graph is called transitive if for any three vertices $a,b,c$, the presence of arcs $(a,b)$ and $(b,c)$ forces the presence of the arc $(a,c)$. If only the presence of an arc between $a$ and $c$ is required, but its orientation is unconstrained, the orientation is called quasi-transitive. A fundamental result presented by Ghouila-Houri guarantees that any static graph admitting a quasi-transitive orientation also admits a transitive orientation. In a seminal work, Mertzios et al. introduced the notion of temporal transitivity in order to model information flows in simple temporal networks. We revisit the model introduced by Mertzios et al. and propose an analogous to Ghouila-Houri's characterization for the temporal scenario. We present a structure theorem that will allow us to express by a 2-SAT formula all the constraints imposed by temporal transitive orientations. The latter produces an efficient recognition algorithm for graphs admitting such orientations. Additionally, we extend the temporal transitivity model to temporal graphs having multiple time-labels associated to their edges and claim that the previous results hold in the multilabel setting. Finally, we propose a characterization of temporal comparability graphs via forbidden temporal ordered patterns.",
    "authors": [
      "Pierre Charbit",
      "Michel Habib",
      "Amalia Sorondo"
    ],
    "categories": [
      "math.CO",
      "cs.DM",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T10:14:02.000Z",
    "updatedAt": "2025-10-08T10:14:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06849v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06849v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06848v1",
    "arxivId": "2510.06848v1",
    "title": "Reconquering Bell sampling on qudits: stabilizer learning and testing, quantum pseudorandomness bounds, and more",
    "abstract": "Bell sampling is a simple yet powerful tool based on measuring two copies of a quantum state in the Bell basis, and has found applications in a plethora of problems related to stabiliser states and measures of magic. However, it was not known how to generalise the procedure from qubits to $d$-level systems -- qudits -- for all dimensions $d > 2$ in a useful way. Indeed, a prior work of the authors (arXiv'24) showed that the natural extension of Bell sampling to arbitrary dimensions fails to provide meaningful information about the quantum states being measured. In this paper, we overcome the difficulties encountered in previous works and develop a useful generalisation of Bell sampling to qudits of all $d\\geq 2$. At the heart of our primitive is a new unitary, based on Lagrange's four-square theorem, that maps four copies of any stabiliser state $|\\mathcal{S}\\rangle$ to four copies of its complex conjugate $|\\mathcal{S}^\\ast\\rangle$ (up to some Pauli operator), which may be of independent interest. We then demonstrate the utility of our new Bell sampling technique by lifting several known results from qubits to qudits for any $d\\geq 2$: 1. Learning stabiliser states in $O(n^3)$ time with $O(n)$ samples; 2. Solving the Hidden Stabiliser Group Problem in $\\tilde{O}(n^3/\\varepsilon)$ time with $\\tilde{O}(n/\\varepsilon)$ samples; 3. Testing whether $|\\psi\\rangle$ has stabiliser size at least $d^t$ or is $\\varepsilon$-far from all such states in $\\tilde{O}(n^3/\\varepsilon)$ time with $\\tilde{O}(n/\\varepsilon)$ samples; 4. Clifford circuits with at most $n/2$ single-qudit non-Clifford gates cannot prepare pseudorandom states; 5. Testing whether $|\\psi\\rangle$ has stabiliser fidelity at least $1-\\varepsilon_1$ or at most $1-\\varepsilon_2$ with $O(d^2/\\varepsilon_2)$ samples if $\\varepsilon_1 = 0$ or $O(d^2/\\varepsilon_2^2)$ samples if $\\varepsilon_1 = O(d^{-2})$.",
    "authors": [
      "Jonathan Allcock",
      "Joao F. Doriguello",
      "Gábor Ivanyos",
      "Miklos Santha"
    ],
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS",
      "cs.LG"
    ],
    "publishedAt": "2025-10-08T10:13:16.000Z",
    "updatedAt": "2025-10-08T10:13:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06848v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06848v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06834v1",
    "arxivId": "2510.06834v1",
    "title": "Vectorized FlashAttention with Low-cost Exponential Computation in RISC-V Vector Processors",
    "abstract": "Attention is a core operation in numerous machine learning and artificial intelligence models. This work focuses on the acceleration of attention kernel using FlashAttention algorithm, in vector processors, particularly those based on the RISC-V instruction set architecture (ISA). This work represents the first effort to vectorize FlashAttention, minimizing scalar code and simplifying the computational complexity of evaluating exponentials needed by softmax used in attention. By utilizing a low-cost approximation for exponentials in floating-point arithmetic, we reduce the cost of computing the exponential function without the need to extend baseline vector ISA with new custom instructions. Also, appropriate tiling strategies are explored with the goal to improve memory locality. Experimental results highlight the scalability of our approach, demonstrating significant performance gains with the vectorized implementations when processing attention layers in practical applications.",
    "authors": [
      "Vasileios Titopoulos",
      "Kosmas Alexandridis",
      "Giorgos Dimitrakopoulos"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.PF"
    ],
    "publishedAt": "2025-10-08T09:55:32.000Z",
    "updatedAt": "2025-10-08T09:55:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06834v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06834v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06816v1",
    "arxivId": "2510.06816v1",
    "title": "Am I Productive? Exploring the Experience of Remote Workers with Task Management Tools",
    "abstract": "As the world continues to change, more and more knowledge workers are embracing remote work. Yet this comes with its challenges for their productivity, and while many Task Management applications promise to improve the productivity of remote workers, it remains unclear how effective they are. Based on existing frameworks, this study investigated the productivity needs and challenges of remote knowledge workers and how they use Task Management tools. The research was conducted through a 2-week long, mixed-methods diary study and semi-structured interview. Perceptions of productivity, task management tool use and productivity challenges were observed. The findings show that using a digital Task Management application made no significant difference to using pen and paper for improving perceived productivity of remote workers and discuss the need for better personalization of Task Management applications.",
    "authors": [
      "Russell Beale"
    ],
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "publishedAt": "2025-10-08T09:41:46.000Z",
    "updatedAt": "2025-10-08T09:41:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06816v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06816v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06802v1",
    "arxivId": "2510.06802v1",
    "title": "Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity",
    "abstract": "Capturing and rendering three-dimensional (3D) objects in real time remain a significant challenge, yet hold substantial potential for applications in augmented reality, digital twin systems, remote collaboration and prototyping. We present an end-to-end pipeline that leverages 3D Gaussian Splatting (3D GS) to enable rapid acquisition and interactive rendering of real-world objects using a mobile device, cloud processing and a local computer. Users scan an object with a smartphone video, upload it for automated 3D reconstruction, and visualize it interactively in Unity at an average of 150 frames per second (fps) on a laptop. The system integrates mobile capture, cloud-based 3D GS and Unity rendering to support real-time telepresence. Our experiments show that the pipeline processes scans in approximately 10 minutes on a graphics processing unit (GPU) achieving real-time rendering on the laptop.",
    "authors": [
      "Islomjon Shukhratov",
      "Sergey Gorinsky"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "publishedAt": "2025-10-08T09:31:29.000Z",
    "updatedAt": "2025-10-08T09:31:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06802v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06802v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06800v2",
    "arxivId": "2510.06800v2",
    "title": "FURINA: A Fully Customizable Role-Playing Benchmark via Scalable Multi-Agent Collaboration Pipeline",
    "abstract": "As large language models (LLMs) advance in role-playing (RP) tasks, existing benchmarks quickly become obsolete due to their narrow scope, outdated interaction paradigms, and limited adaptability across diverse application scenarios. To address this gap, we introduce FURINA-Builder, a novel multi-agent collaboration pipeline that automatically constructs fully customizable RP benchmarks at any scale. It enables evaluation of arbitrary characters across diverse scenarios and prompt formats, as the first benchmark builder in RP area for adaptable assessment. FURINA-Builder simulates dialogues between a test character and other characters drawn from a well-constructed character-scene pool, while an LLM judge selects fine-grained evaluation dimensions and adjusts the test character's responses into final test utterances. Using this pipeline, we build FURINA-Bench, a new comprehensive role-playing benchmark featuring both established and synthesized test characters, each assessed with dimension-specific evaluation criteria. Human evaluation and preliminary separability analysis justify our pipeline and benchmark design. We conduct extensive evaluations of cutting-edge LLMs and find that o3 and DeepSeek-R1 achieve the best performance on English and Chinese RP tasks, respectively. Across all models, established characters consistently outperform synthesized ones, with reasoning capabilities further amplifying this disparity. Interestingly, we observe that model scale does not monotonically reduce hallucinations. More critically, for reasoning LLMs, we uncover a novel trade-off: reasoning improves RP performance but simultaneously increases RP hallucinations. This trade-off extends to a broader Pareto frontier between RP performance and reliability for all LLMs. These findings demonstrate the effectiveness of FURINA-Builder and the challenge posed by FURINA-Bench.",
    "authors": [
      "Haotian Wu",
      "Shufan Jiang",
      "Mingyu Chen",
      "Yiyang Feng",
      "Hehai Lin",
      "Heqing Zou",
      "Yao Shu",
      "Chengwei Qin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "publishedAt": "2025-10-08T09:30:36.000Z",
    "updatedAt": "2025-10-12T15:48:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06800v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.06800v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06782v1",
    "arxivId": "2510.06782v1",
    "title": "GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting",
    "abstract": "We present a quantitative evaluation to understand the effect of zero-shot large-language model (LLMs) and prompting uses on chart reading tasks. We asked LLMs to answer 107 visualization questions to compare inference accuracies between the agentic GPT-5 and multimodal GPT-4V, for difficult image instances, where GPT-4V failed to produce correct answers. Our results show that model architecture dominates the inference accuracy: GPT5 largely improved accuracy, while prompt variants yielded only small effects. Pre-registration of this work is available here: https://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3; the Google Drive materials are here:https://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/view.",
    "authors": [
      "Kaichun Yang",
      "Jian Chen"
    ],
    "categories": [
      "cs.HC",
      "cs.CL",
      "cs.CV"
    ],
    "publishedAt": "2025-10-08T09:09:29.000Z",
    "updatedAt": "2025-10-08T09:09:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06782v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06782v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06775v1",
    "arxivId": "2510.06775v1",
    "title": "Breaking the Treewidth Barrier in Quantum Circuit Simulation with Decision Diagrams",
    "abstract": "Classical simulation of quantum circuits is a critical tool for validating quantum hardware and probing the boundary between classical and quantum computational power. Existing state-of-the-art methods, notably tensor network approaches, have computational costs governed by the treewidth of the underlying circuit graph, making circuits with large treewidth intractable. This work rigorously analyzes FeynmanDD, a decision diagram-based simulation method proposed in CAV 2025 by a subset of the authors, and shows that the size of the multi-terminal decision diagram used in FeynmanDD is exponential in the linear rank-width of the circuit graph. As linear rank-width can be substantially smaller than treewidth and is at most larger than the treewidth by a logarithmic factor, our analysis demonstrates that FeynmanDD outperforms all tensor network-based methods for certain circuit families. We also show that the method remains efficient if we use the Solovay-Kitaev algorithm to expand arbitrary single-qubit gates to sequences of Hadamard and T gates, essentially removing the gate-set restriction posed by the method.",
    "authors": [
      "Bin Cheng",
      "Ziyuan Wang",
      "Ruixuan Deng",
      "Jianxin Chen",
      "Zhengfeng Ji"
    ],
    "categories": [
      "quant-ph",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T08:58:58.000Z",
    "updatedAt": "2025-10-08T08:58:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06775v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06775v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06733v1",
    "arxivId": "2510.06733v1",
    "title": "Lonely Individuals Show Distinct Patterns of Social Media Engagement",
    "abstract": "Loneliness has reached epidemic proportions globally, posing serious risks to mental and physical health. As social media platforms increasingly mediate social interaction, understanding their relationship with loneliness has become urgent. While survey-based research has examined social media use and loneliness, findings remain mixed, and little is known about when and how often people engage with social media, or about whether different types of platforms are differently associated with loneliness. Web trace data now enable objective examination of these behavioral dimensions. We asked whether objectively measured patterns of social media engagement differ between lonely and non-lonely individuals across devices and platform types. Analyzing six months of web trace data combined with repeated surveys ($N=589$ mobile users; $N=851$ desktop users), we found that greater social media use was associated with higher loneliness across both devices, with this relationship specific to social media rather than other online activities. On desktop, lonely individuals exhibited shorter sessions but more frequent daily engagement. Lonely individuals spent more time on visual-sharing ($g = -0.47$), messaging ($g = -0.36$), and networking-oriented platforms on mobile. These findings demonstrate how longitudinal web trace data can reveal behavioral patterns associated with loneliness, and more broadly illustrate the potential of digital traces for studying other psychological states. Beyond research, the results inform the responsible design of digital interventions and platform features that better support psychological well-being across different technological contexts.",
    "authors": [
      "Yajing Wang",
      "Talayeh Aledavood",
      "Juhi Kulshrestha"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T07:43:29.000Z",
    "updatedAt": "2025-10-08T07:43:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06733v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06733v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06721v1",
    "arxivId": "2510.06721v1",
    "title": "Neuromorphic Computing -- An Overview",
    "abstract": "With traditional computing technologies reaching their limit, a new field has emerged seeking to follow the example of the human brain into a new era: neuromorphic computing. This paper provides an introduction to neuromorphic computing, why this and other new computing systems are needed, and what technologies currently exist in the neuromorphic field. It begins with a general introduction into the history of traditional computing and its present problems, and then proceeds to a general overview of neuromorphic systems. It subsequently discusses the main technologies currently in development. For completeness, the paper first discusses neuromorphic-style computing on traditional hardware, and then discusses the two top branches of specialized hardware in this field; neuromorphic chips and photonic systems. Both branches are explained as well as their relative benefits and drawbacks. The paper concludes with a summary and an outlook on the future.",
    "authors": [
      "Benedikt Jung",
      "Maximilian Kalcher",
      "Merlin Marinova",
      "Piper Powell",
      "Esma Sakalli"
    ],
    "categories": [
      "cs.NE",
      "cs.ET"
    ],
    "publishedAt": "2025-10-08T07:21:07.000Z",
    "updatedAt": "2025-10-08T07:21:07.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06721v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06721v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06697v1",
    "arxivId": "2510.06697v1",
    "title": "\"Sometimes You Need Facts, and Sometimes a Hug\": Understanding Older Adults' Preferences for Explanations in LLM-Based Conversational AI Systems",
    "abstract": "Designing Conversational AI systems to support older adults requires these systems to explain their behavior in ways that align with older adults' preferences and context. While prior work has emphasized the importance of AI explainability in building user trust, relatively little is known about older adults' requirements and perceptions of AI-generated explanations. To address this gap, we conducted an exploratory Speed Dating study with 23 older adults to understand their responses to contextually grounded AI explanations. Our findings reveal the highly context-dependent nature of explanations, shaped by conversational cues such as the content, tone, and framing of explanation. We also found that explanations are often interpreted as interactive, multi-turn conversational exchanges with the AI, and can be helpful in calibrating urgency, guiding actionability, and providing insights into older adults' daily lives for their family members. We conclude by discussing implications for designing context-sensitive and personalized explanations in Conversational AI systems.",
    "authors": [
      "Niharika Mathur",
      "Tamara Zubatiy",
      "Agata Rozga",
      "Jodi Forlizzi",
      "Elizabeth Mynatt"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T06:44:10.000Z",
    "updatedAt": "2025-10-08T06:44:10.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06697v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06697v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06690v1",
    "arxivId": "2510.06690v1",
    "title": "\"It feels like hard work trying to talk to it\": Understanding Older Adults' Experiences of Encountering and Repairing Conversational Breakdowns with AI Systems",
    "abstract": "Designing Conversational AI systems to support older adults requires more than usability and reliability, it also necessitates robustness in handling conversational breakdowns. In this study, we investigate how older adults navigate and repair such breakdowns while interacting with a voice-based AI system deployed in their homes for medication management. Through a 20-week in-home deployment with 7 older adult participant dyads, we analyzed 844 recoded interactions to identify conversational breakdowns and user-initiated repair strategies. Through findings gleaned from post-deployment interviews, we reflect on the nature of these breakdowns and older adults' experiences of mitigating them. We identify four types of conversational breakdowns and demonstrate how older adults draw on their situated knowledge and environment to make sense of and recover from these disruptions, highlighting the cognitive effort required in doing so. Our findings emphasize the collaborative nature of interactions in human-AI contexts, and point to the need for AI systems to better align with users' expectations for memory, their routines, and external resources in their environment. We conclude by discussing opportunities for AI systems to integrate contextual knowledge from older adults' sociotechnical environment and to facilitate more meaningful and user-centered interactions.",
    "authors": [
      "Niharika Mathur",
      "Tamara Zubatiy",
      "Agata Rozga",
      "Elizabeth Mynatt"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T06:26:12.000Z",
    "updatedAt": "2025-10-08T06:26:12.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06690v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06690v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06675v1",
    "arxivId": "2510.06675v1",
    "title": "REACH: Reinforcement Learning for Adaptive Microservice Rescheduling in the Cloud-Edge Continuum",
    "abstract": "Cloud computing, despite its advantages in scalability, may not always fully satisfy the low-latency demands of emerging latency-sensitive pervasive applications. The cloud-edge continuum addresses this by integrating the responsiveness of edge resources with cloud scalability. Microservice Architecture (MSA) characterized by modular, loosely coupled services, aligns effectively with this continuum. However, the heterogeneous and dynamic computing resource poses significant challenges to the optimal placement of microservices. We propose REACH, a novel rescheduling algorithm that dynamically adapts microservice placement in real time using reinforcement learning to react to fluctuating resource availability, and performance variations across distributed infrastructures. Extensive experiments on a real-world testbed demonstrate that REACH reduces average end-to-end latency by 7.9%, 10%, and 8% across three benchmark MSA applications, while effectively mitigating latency fluctuations and spikes.",
    "authors": [
      "Xu Bai",
      "Muhammed Tawfiqul Islam",
      "Rajkumar Buyya",
      "Adel N. Toosi"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-08T05:57:39.000Z",
    "updatedAt": "2025-10-08T05:57:39.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06675v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06675v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06617v1",
    "arxivId": "2510.06617v1",
    "title": "Investigating Students' Preferences for AI Roles in Mathematical Modelling: Evidence from a Randomized Controlled Trial",
    "abstract": "Mathematical modelling (MM) is a key competency for solving complex real-world problems, yet many students struggle with abstraction, representation, and iterative reasoning. Artificial intelligence (AI) has been proposed as a support for higher-order thinking, but its role in MM education is still underexplored. This study examines the relationships among students' design thinking (DT), computational thinking (CT), and mathematical modelling self-efficacy (MMSE), and investigates their preferences for different AI roles during the modelling process. Using a randomized controlled trial, we identify significant connections among DT, CT, and MMSE, and reveal distinct patterns in students' preferred AI roles, including AI as a tutor (providing explanations and feedback), AI as a tool (assisting with calculations and representations), AI as a collaborator (suggesting strategies and co-creating models), and AI as a peer (offering encouragement and fostering reflection). Differences across learner profiles highlight how students' dispositions shape their expectations for AI. These findings advance understanding of AI-supported MM and provide design implications for adaptive, learner-centered systems.",
    "authors": [
      "Wangda Zhu",
      "Guang Chen",
      "Yumeng Zhu",
      "Lei Cai",
      "Xiangen Hu"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T03:50:59.000Z",
    "updatedAt": "2025-10-08T03:50:59.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06617v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06617v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06608v1",
    "arxivId": "2510.06608v1",
    "title": "A Review of 10 Years of ProtoSpace: Spacecraft CAD Visualization in Collaborative Augmented Reality",
    "abstract": "ProtoSpace is a custom JPL-built platform to help scientists and engineers visualize their CAD models collaboratively in augmented reality (AR) and on the web in 3D. In addition to this main use case, ProtoSpace has been used throughout the entire spacecraft mission lifecycle and beyond: ventilator design and assembly; providing AR-based instructions to astronauts in-training; educating the next generation on the process of spacecraft design; etc. ProtoSpace has been used for a decade by NASA missions-including Mars Perseverance, Europa Clipper, NISAR, SPHEREx, CAL, and Mars Sample Return-to reduce cost and risk by helping engineers and scientists fix problems earlier through reducing miscommunication and helping people understand the spatial context of their spacecraft in the appropriate physical context more quickly. This paper will explore how ProtoSpace came to be, define the system architecture and overview-including HoloLens and 3D web clients, the ProtoSpace server, and the CAD model optimizer-and dive into the use cases, spin-offs, and lessons learned that led to 10 years of success at NASA's Jet Propulsion Laboratory.",
    "authors": [
      "Benjamin Nuernberger",
      "Samuel-Hunter Berndt",
      "Robert Tapella",
      "Laura Mann",
      "Aaron Plave",
      "Sasha Samochina",
      "Victor X. Luo"
    ],
    "categories": [
      "cs.ET",
      "astro-ph.IM",
      "cs.GR",
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T03:35:56.000Z",
    "updatedAt": "2025-10-08T03:35:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06608v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06608v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06581v1",
    "arxivId": "2510.06581v1",
    "title": "Constant Weighted Maximin Share Approximations for Chores",
    "abstract": "We study the fair allocation of indivisible chores among agents with asymmetric weights. Among the various fairness notions, weighted maximin share (WMMS) stands out as particularly compelling. However, whether WMMS admits a constant-factor approximation has remained unknown and is one of the important open problems in weighted fair division [ALMW22, Suk25]. So far, the best known approximation ratio is O(log n), where n is the number of agents. In this paper, we advance the state of the art and present the first constant-factor approximate WMMS algorithm. To this end, we introduce canonical instance reductions and different bounds of agents' valuations. We also prove that guaranteeing better than 2-approximation is not possible, which improves the best-known lower bound of 1.366.",
    "authors": [
      "Bo Li",
      "Fangxiao Wang",
      "Shiji Xing"
    ],
    "categories": [
      "cs.GT"
    ],
    "publishedAt": "2025-10-08T02:24:32.000Z",
    "updatedAt": "2025-10-08T02:24:32.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06581v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06581v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06573v1",
    "arxivId": "2510.06573v1",
    "title": "RAVEN: Realtime Accessibility in Virtual ENvironments for Blind and Low-Vision People",
    "abstract": "As virtual 3D environments become prevalent, equitable access is crucial for blind and low-vision (BLV) users who face challenges with spatial awareness, navigation, and interactions. To address this gap, previous work explored supplementing visual information with auditory and haptic modalities. However, these methods are static and offer limited support for dynamic, in-context adaptation. Recent work in generative AI enables users to query and modify 3D scenes via natural language, introducing a paradigm with increased flexibility and control for accessibility improvements. We present RAVEN, a system that responds to query or modification prompts from BLV users to improve the runtime accessibility of 3D virtual scenes. We evaluated the system with eight BLV people, uncovering key insights into the strengths and shortcomings of generative AI-driven accessibility in virtual 3D environments, pointing to promising results as well as challenges related to system reliability and user trust.",
    "authors": [
      "Xinyun Cao",
      "Kexin Phyllis Ju",
      "Chenglin Li",
      "Venkatesh Potluri",
      "Dhruv Jain"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T02:07:05.000Z",
    "updatedAt": "2025-10-08T02:07:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06573v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06573v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06550v1",
    "arxivId": "2510.06550v1",
    "title": "PriorWeaver: Prior Elicitation via Iterative Dataset Construction",
    "abstract": "In Bayesian analysis, prior elicitation, or the process of explicating one's beliefs to inform statistical modeling, is an essential yet challenging step. Analysts often have beliefs about real-world variables and their relationships. However, existing tools require analysts to translate these beliefs and express them indirectly as probability distributions over model parameters. We present PriorWeaver, an interactive visualization system that facilitates prior elicitation through iterative dataset construction and refinement. Analysts visually express their assumptions about individual variables and their relationships. Under the hood, these assumptions create a dataset used to derive statistical priors. Prior predictive checks then help analysts compare the priors to their assumptions. In a lab study with 17 participants new to Bayesian analysis, we compare PriorWeaver to a baseline incorporating existing techniques. Compared to the baseline, PriorWeaver gave participants greater control, clarity, and confidence, leading to priors that were better aligned with their expectations.",
    "authors": [
      "Yuwei Xiao",
      "Shuai Ma",
      "Antti Oulasvirta",
      "Eunice Jun"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T01:01:46.000Z",
    "updatedAt": "2025-10-08T01:01:46.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06550v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06550v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06549v1",
    "arxivId": "2510.06549v1",
    "title": "Trickle-down Theorems via C-Lorentzian Polynomials II: Pairwise Spectral Influence and Improved Dobrushin's Condition",
    "abstract": "Let $\\mu$ be a probability distribution on a multi-state spin system on a set $V$ of sites. Equivalently, we can think of this as a $d$-partite simplical complex with distribution $\\mu$ on maximal faces. For any pair of vertices $u,v\\in V$, define the pairwise spectral influence $\\mathcal{I}_{u,v}$ as follows. Let $\\sigma$ be a choice of spins $s_w\\in S_w$ for every $w\\in V \\setminus \\{u,v\\}$, and construct a matrix in $\\mathbb{R}^{(S_u\\cup S_v)\\times (S_u\\cup S_v)}$ where for any $s_u\\in S_u, s_v\\in S_v$, the $(us_u,vs_v)$-entry is the probability that $s_v$ is the spin of $v$ conditioned on $s_u$ being the spin of $u$ and on $\\sigma$. Then $\\mathcal{I}_{u,v}$ is the maximal second eigenvalue of this matrix, over all choices of spins for all $w \\in V \\setminus \\{u,v\\}$. Equivalently, $\\mathcal{I}_{u,v}$ is the maximum local spectral expansion of links of codimension $2$ that include a spin for every $w \\in V \\setminus \\{u,v\\}$. We show that if the largest eigenvalue of the pairwise spectral influence matrix with entries $\\mathcal{I}_{u,v}$ is bounded away from 1, i.e. $\\lambda_{\\max}(\\mathcal{I})\\leq 1-\\epsilon$ (and $X$ is connected), then the Glauber dynamics mixes rapidly and generate samples from $\\mu$. This improves/generalizes the classical Dobrushin's influence matrix as the $\\mathcal{I}_{u,v}$ lower-bounds the classical influence of $u\\to v$. As a by-product, we also prove improved/almost optimal trickle-down theorems for partite simplicial complexes. The proof builds on the trickle-down theorems via $\\mathcal{C}$-Lorentzian polynomials machinery recently developed by the authors and Lindberg.",
    "authors": [
      "Jonathan Leake",
      "Shayan Oveis Gharan"
    ],
    "categories": [
      "math.CO",
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-08T01:00:48.000Z",
    "updatedAt": "2025-10-08T01:00:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06549v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06549v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06537v1",
    "arxivId": "2510.06537v1",
    "title": "Examining Solidarity Against AI-Enabled Surveillance at the Intersection of Workplace and Carceral Realities",
    "abstract": "As panoptical, AI-driven surveillance becomes a norm, everyone is impacted. In a reality where all people fall victim to these technologies, establishing links and solidarity is essential to fighting back. Two groups facing rising and targeted surveillance are workers and individuals impacted by the carceral system. Through preliminary data collection from a worker-surveillance lens, our findings reveal several cases of these surveillance infrastructures intersecting. Continuation of our work will involve collecting cases from a carceral-centered lens. Driven by a community-facing analysis of the overlap in the AI-driven surveillance experienced by workers and individuals impacted by the carceral system, we will facilitate discussions with restorative justice activists around cultivating solidarity and empowerment focused on the interconnected nature of workplace and carceral surveillance technologies.",
    "authors": [
      "Morgan McErlean",
      "Cella M. Sum",
      "Sukrit Venkatagiri",
      "Sarah Fox"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-08T00:25:45.000Z",
    "updatedAt": "2025-10-08T00:25:45.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06537v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06537v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06533v1",
    "arxivId": "2510.06533v1",
    "title": "A Computer-Assisted Proof of the Optimal Density Bound for Pinwheel Covering",
    "abstract": "In the covering version of the pinwheel scheduling problem, a daily task must be assigned to agents under the constraint that agent $i$ can perform the task at most once in any $a_i$-day interval. In this paper, we determine the optimal constant $\\alpha^* = 1.264\\ldots {}$ such that every instance with $\\sum_{i} \\frac{1}{a_i} \\ge \\alpha^*$ is schedulable. This resolves an open problem posed by Soejima and Kawamura (2020). Our proof combines Kawamura's (2024) techniques for the packing version with new mathematical insights, along with an exhaustive computer-aided search that draws on some ideas from G\\k{a}sieniec, Smith, and Wild (2022).",
    "authors": [
      "Akitoshi Kawamura",
      "Yusuke Kobayashi"
    ],
    "categories": [
      "cs.DM"
    ],
    "publishedAt": "2025-10-08T00:20:29.000Z",
    "updatedAt": "2025-10-08T00:20:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06533v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06533v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06530v1",
    "arxivId": "2510.06530v1",
    "title": "From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond",
    "abstract": "The quality and experience of mobile communication have significantly improved with the introduction of 5G, and these improvements are expected to continue beyond the 5G era. However, vulnerabilities in control-plane protocols, such as Radio Resource Control (RRC) and Non-Access Stratum (NAS), pose significant security threats, such as Blind Denial of Service (DoS) attacks. Despite the availability of existing anomaly detection methods that leverage rule-based systems or traditional machine learning methods, these methods have several limitations, including the need for extensive training data, predefined rules, and limited explainability. Addressing these challenges, we propose a novel anomaly detection framework that leverages the capabilities of Large Language Models (LLMs) in zero-shot mode with unordered data and short natural language attack descriptions within the Open Radio Access Network (O-RAN) architecture. We analyse robustness to prompt variation, demonstrate the practicality of automating the attack descriptions and show that detection quality relies on the semantic completeness of the description rather than its phrasing or length. We utilise an RRC/NAS dataset to evaluate the solution and provide an extensive comparison of open-source and proprietary LLM implementations to demonstrate superior performance in attack detection. We further validate the practicality of our framework within O-RAN's real-time constraints, illustrating its potential for detecting other Layer-3 attacks.",
    "authors": [
      "Thusitha Dayaratne",
      "Ngoc Duy Pham",
      "Viet Vo",
      "Shangqi Lai",
      "Sharif Abuadbba",
      "Hajime Suzuki",
      "Xingliang Yuan",
      "Carsten Rudolph"
    ],
    "categories": [
      "cs.CR",
      "cs.ET",
      "cs.LG",
      "cs.NI"
    ],
    "publishedAt": "2025-10-08T00:13:02.000Z",
    "updatedAt": "2025-10-08T00:13:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06530v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06530v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06517v1",
    "arxivId": "2510.06517v1",
    "title": "Visualizing Multimodality in Combinatorial Search Landscapes",
    "abstract": "This work walks through different visualization techniques for combinatorial search landscapes, focusing on multimodality. We discuss different techniques from the landscape analysis literature, and how they can be combined to provide a more comprehensive view of the search landscape. We also include examples and discuss relevant work to show how others have used these techniques in practice, based on the geometric and aesthetic elements of the Grammar of Graphics. We conclude that there is no free lunch in visualization, and provide recommendations for future work as there are several paths to continue the work in this field.",
    "authors": [
      "Xavier F. C. Sánchez-Díaz",
      "Ole Jakob Mengshoel"
    ],
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.NE"
    ],
    "publishedAt": "2025-10-07T23:29:19.000Z",
    "updatedAt": "2025-10-07T23:29:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06517v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06517v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06513v1",
    "arxivId": "2510.06513v1",
    "title": "On-Package Memory with Universal Chiplet Interconnect Express (UCIe): A Low Power, High Bandwidth, Low Latency and Low Cost Approach",
    "abstract": "Emerging computing applications such as Artificial Intelligence (AI) are facing a memory wall with existing on-package memory solutions that are unable to meet the power-efficient bandwidth demands. We propose to enhance UCIe with memory semantics to deliver power-efficient bandwidth and cost-effective on-package memory solutions applicable across the entire computing continuum. We propose approaches by reusing existing LPDDR6 and HBM memory through a logic die that connects to the SoC using UCIe. We also propose an approach where the DRAM die natively supports UCIe instead of the LPDDR6 bus interface. Our approaches result in significantly higher bandwidth density (up to 10x), lower latency (up to 3x), lower power (up to 3x), and lower cost compared to existing HBM4 and LPDDR on-package memory solutions.",
    "authors": [
      "Debendra Das Sharma",
      "Swadesh Choudhary",
      "Peter Onufryk",
      "Rob Pelt"
    ],
    "categories": [
      "cs.AR",
      "cs.DC"
    ],
    "publishedAt": "2025-10-07T23:10:13.000Z",
    "updatedAt": "2025-10-07T23:10:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06513v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06513v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06507v1",
    "arxivId": "2510.06507v1",
    "title": "A Meat-Summer Night's Dream: A Tangible Design Fiction Exploration of Eating Biohybrid Flying Robots",
    "abstract": "What if future dining involved eating robots? We explore this question through a playful and poetic experiential dinner theater: a tangible design fiction staged as a 2052 Paris restaurant where diners consume a biohybrid flying robot in place of the banned delicacy of ortolan bunting. Moving beyond textual or visual speculation, our ``dinner-in-the-drama'' combined performance, ritual, and multisensory immersion to provoke reflection on sustainability, ethics, and cultural identity. Six participants from creative industries engaged as diners and role-players, responding with curiosity, discomfort, and philosophical debate. They imagined biohybrids as both plausible and unsettling -- raising questions of sentience, symbolism, and technology adoption that exceed conventional sustainability framings of synthetic meat. Our contributions to HCI are threefold: (i) a speculative artifact that stages robots as food, (ii) empirical insights into how publics negotiate cultural and ethical boundaries in post-natural eating, and (iii) a methodological advance in embodied, multisensory design fiction.",
    "authors": [
      "Ziming Wang",
      "Yiqian Wu",
      "Qingxiao Zheng",
      "Shihan Zhang",
      "Ned Barker",
      "Morten Fjeld"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T22:49:15.000Z",
    "updatedAt": "2025-10-07T22:49:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06507v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06507v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06480v1",
    "arxivId": "2510.06480v1",
    "title": "AI Eyes on the Road: Cross-Cultural Perspectives on Traffic Surveillance",
    "abstract": "AI-powered road surveillance systems are increasingly proposed to monitor infractions such as speeding, phone use, and jaywalking. While these systems promise to enhance safety by discouraging dangerous behaviors, they also raise concerns about privacy, fairness, and potential misuse of personal data. Yet empirical research on how people perceive AI-enhanced monitoring of public spaces remains limited. We conducted an online survey ($N=720$) using a 3$\\times$3 factorial design to examine perceptions of three road surveillance modes -- conventional, AI-enhanced, and AI-enhanced with public shaming -- across China, Europe, and the United States. We measured perceived capability, risk, transparency, and acceptance. Results show that conventional surveillance was most preferred, while public shaming was least preferred across all regions. Chinese respondents, however, expressed significantly higher acceptance of AI-enhanced modes than Europeans or Americans. Our findings highlight the need to account for context, culture, and social norms when considering AI-enhanced monitoring, as these shape trust, comfort, and overall acceptance.",
    "authors": [
      "Ziming Wang",
      "Shiwei Yang",
      "Rebecca Currano",
      "Morten Fjeld",
      "David Sirkin"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T21:32:00.000Z",
    "updatedAt": "2025-10-07T21:32:00.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06480v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06480v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06472v1",
    "arxivId": "2510.06472v1",
    "title": "Back to the Future Museum -- Speculative Design for Virtual Citizen-Curated Museums",
    "abstract": "This forward-looking paper uses speculative design fiction to explore future museum scenarios where citizen curators design and share immersive virtual reality museums populated with tangible heritage artefacts, intangible virtual elements and interactive experiences. The work also explores takeaway 'asset packs' containing 3D artefact models, curation assets, and interactive experiences, and we envisage a visit to the future museum, where the physical and virtual experiences interplay. Finally, the paper considers the implications of this future museum in terms of resources and the potential impacts on traditional museums.",
    "authors": [
      "Richard Rhodes",
      "Sandra Woolley"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T21:19:24.000Z",
    "updatedAt": "2025-10-07T21:19:24.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06472v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06472v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06457v1",
    "arxivId": "2510.06457v1",
    "title": "Evaluating Node-tree Interfaces for AI Explainability",
    "abstract": "As large language models (LLMs) become ubiquitous in workplace tools and decision-making processes, ensuring explainability and fostering user trust are critical. Although advancements in LLM engineering continue, human-centered design is still catching up, particularly when it comes to embedding transparency and trust into AI interfaces. This study evaluates user experiences with two distinct AI interfaces - node-tree interfaces and chatbot interfaces - to assess their performance in exploratory, follow-up inquiry, decision-making, and problem-solving tasks. Our design-driven approach introduces a node-tree interface that visually structures AI-generated responses into hierarchically organized, interactive nodes, allowing users to navigate, refine, and follow up on complex information. In a comparative study with n=20 business users, we observed that while the chatbot interface effectively supports linear, step-by-step queries, it is the node-tree interface that enhances brainstorming. Quantitative and qualitative findings indicate that node-tree interfaces not only improve task performance and decision-making support but also promote higher levels of user trust by preserving context. Our findings suggest that adaptive AI interfaces capable of switching between structured visualizations and conversational formats based on task requirements can significantly enhance transparency and user confidence in AI-powered systems. This work contributes actionable insights to the fields of human-robot interaction and AI design, particularly for enterprise applications where trust-building is critical for teams.",
    "authors": [
      "Lifei Wang",
      "Natalie Friedman",
      "Chengchao Zhu",
      "Zeshu Zhu",
      "S. Joy Mountford"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2; I.2.7"
    ],
    "publishedAt": "2025-10-07T20:48:08.000Z",
    "updatedAt": "2025-10-07T20:48:08.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06457v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06457v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06452v1",
    "arxivId": "2510.06452v1",
    "title": "Code Semantic Zooming",
    "abstract": "Recent advances in Large Language Models (LLMs) have introduced a new paradigm for software development, where source code is generated directly from natural language prompts. While this paradigm significantly boosts development productivity, building complex, real-world software systems remains challenging because natural language offers limited control over the generated code. Inspired by the historical evolution of programming languages toward higher levels of abstraction, we advocate for a high-level abstraction language that gives developers greater control over LLM-assisted code writing. To this end, we propose Code Semantic Zooming, a novel approach based on pseudocode that allows developers to iteratively explore, understand, and refine code across multiple layers of semantic abstraction. We implemented Code Semantic Zooming as a VS Code extension and demonstrated its effectiveness through two real-world case studies.",
    "authors": [
      "Jinsheng Ba",
      "Sverrir Thorgeirsson",
      "Zhendong Su"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T20:43:35.000Z",
    "updatedAt": "2025-10-07T20:43:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06452v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06452v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06444v1",
    "arxivId": "2510.06444v1",
    "title": "Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks",
    "abstract": "In decentralized learning networks, predictions from many participants are combined to generate a network inference. While many studies have demonstrated performance benefits of combining multiple model predictions, existing strategies using linear pooling methods (ranging from simple averaging to dynamic weight updates) face a key limitation. Dynamic prediction combinations that rely on historical performance to update weights are necessarily reactive. Due to the need to average over a reasonable number of epochs (with moving averages or exponential weighting), they tend to be slow to adjust to changing circumstances (phase or regime changes). In this work, we develop a model that uses machine learning to forecast the performance of predictions by models at each epoch in a time series. This enables `context-awareness' by assigning higher weight to models that are likely to be more accurate at a given time. We show that adding a performance forecasting worker in a decentralized learning network, following a design similar to the Allora network, can improve the accuracy of network inferences. Specifically, we find forecasting models that predict regret (performance relative to the network inference) or regret z-score (performance relative to other workers) show greater improvement than models predicting losses, which often do not outperform the naive network inference (historically weighted average of all inferences). Through a series of optimization tests, we show that the performance of the forecasting model can be sensitive to choices in the feature set and number of training epochs. These properties may depend on the exact problem and should be tailored to each domain. Although initially designed for a decentralized learning network, using performance forecasting for prediction combination may be useful in any situation where predictive rather than reactive model weighting is needed.",
    "authors": [
      "Joel Pfeffer",
      "J. M. Diederik Kruijssen",
      "Clément Gossart",
      "Mélanie Chevance",
      "Diego Campo Millan",
      "Florian Stecker",
      "Steven N. Longmore"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "publishedAt": "2025-10-07T20:30:21.000Z",
    "updatedAt": "2025-10-07T20:30:21.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06444v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06444v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06413v1",
    "arxivId": "2510.06413v1",
    "title": "A Hybrid Quantum-AI Framework for Protein Structure Prediction on NISQ Devices",
    "abstract": "Variational quantum algorithms provide a direct, physics-based approach to protein structure prediction, but their accuracy is limited by the coarse resolution of the energy landscapes generated on current noisy devices. We propose a hybrid framework that combines quantum computation with deep learning, formulating structure prediction as a problem of energy fusion. Candidate conformations are obtained through the Variational Quantum Eigensolver (VQE) executed on IBM's 127-qubit superconducting processor, which defines a global yet low-resolution quantum energy surface. To refine these basins, secondary structure probabilities and dihedral angle distributions predicted by the NSP3 neural network are incorporated as statistical potentials. These additional terms sharpen the valleys of the quantum landscape, resulting in a fused energy function that enhances effective resolution and better distinguishes native-like structures. Evaluation on 375 conformations from 75 protein fragments shows consistent improvements over AlphaFold3, ColabFold, and quantum-only predictions, achieving a mean RMSD of 4.9 {\\AA} with statistical significance (p < 0.001). The findings demonstrate that energy fusion offers a systematic method for combining data-driven models with quantum algorithms, improving the practical applicability of near-term quantum computing to molecular and structural biology.",
    "authors": [
      "Yuqi Zhang",
      "Yuxin Yang",
      "Feixiong Chen",
      "Cheng-Chang Lu",
      "Nima Saeidi",
      "Samuel L. Volchenboum",
      "Junhan Zhao",
      "Siwei Chen",
      "Weiwen Jiang",
      "Qiang Guan"
    ],
    "categories": [
      "cs.ET"
    ],
    "publishedAt": "2025-10-07T19:45:25.000Z",
    "updatedAt": "2025-10-07T19:45:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06413v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06413v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06404v1",
    "arxivId": "2510.06404v1",
    "title": "MuFASA -- Asynchronous Checkpoint for Weakly Consistent Fully Replicated Databases",
    "abstract": "We focus on the problem of checkpointing in fully replicated weakly consistent distributed databases, which we refer to as Distributed Transaction Consistent Snapshot (DTCS). A typical example of such a system is a main-memory database that provides strong eventual consistency. This problem is important and challenging for several reasons: (1) eventual consistency often creates anomalies that the users do not anticipate. Hence, frequent checkpoints to ascertain desired invariants is highly beneficial in their use, and (2) traditional checkpoints lead to significant overhead and/or inconsistencies. By showing that the traditional checkpoint leads to inconsistencies or excessive overhead, we define the notion of size-minimal checkpointing for fully replicated databases. We present an algorithm for checkpointing with minimal checkpointing overhead (only O(n) new messages and addition of a single counter for existing messages). It also provides a significant benefit over existing checkpointing algorithms for distributed systems and main-memory databases. A key benefit of DTCS is that it summarizes the computation by a sequence of snapshots that are strongly consistent even though the underlying computation is weakly consistent. In essence, when anomalies arise in an eventually consistent system, DTCS enables one to concentrate solely on the snapshots surrounding the time point of the anomaly.",
    "authors": [
      "Raaghav Ravishankar",
      "Sandeep Kulkarni",
      "Nitin H Vaidya"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-07T19:29:41.000Z",
    "updatedAt": "2025-10-07T19:29:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06404v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06404v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06396v1",
    "arxivId": "2510.06396v1",
    "title": "Adaptive Protein Design Protocols and Middleware",
    "abstract": "Computational protein design is experiencing a transformation driven by AI/ML. However, the range of potential protein sequences and structures is astronomically vast, even for moderately sized proteins. Hence, achieving convergence between generated and predicted structures demands substantial computational resources for sampling. The Integrated Machine-learning for Protein Structures at Scale (IMPRESS) offers methods and advanced computing systems for coupling AI to high-performance computing tasks, enabling the ability to evaluate the effectiveness of protein designs as they are developed, as well as the models and simulations used to generate data and train models. This paper introduces IMPRESS and demonstrates the development and implementation of an adaptive protein design protocol and its supporting computing infrastructure. This leads to increased consistency in the quality of protein design and enhanced throughput of protein design due to dynamic resource allocation and asynchronous workload execution.",
    "authors": [
      "Aymen Alsaadi",
      "Jonathan Ash",
      "Mikhail Titov",
      "Matteo Turilli",
      "Andre Merzky",
      "Shantenu Jha",
      "Sagar Khare"
    ],
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF",
      "cs.SE"
    ],
    "publishedAt": "2025-10-07T19:23:53.000Z",
    "updatedAt": "2025-10-07T19:23:53.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06396v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06396v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06388v1",
    "arxivId": "2510.06388v1",
    "title": "Making and Evaluating Calibrated Forecasts",
    "abstract": "Calibrated predictions can be reliably interpreted as probabilities. An important step towards achieving better calibration is to design an appropriate calibration measure to meaningfully assess the miscalibration level of a predictor. A recent line of work initiated by Haghtalab et al. [2024] studies the design of truthful calibration measures: a truthful measure is minimized when a predictor outputs the true probabilities, whereas a non-truthful measure incentivizes the predictor to lie so as to appear more calibrated. All previous calibration measures were non-truthful until Hartline et al. [2025] introduced the first perfectly truthful calibration measures for binary prediction tasks in the batch setting. We introduce a perfectly truthful calibration measure for multi-class prediction tasks, generalizing the work of Hartline et al. [2025] beyond binary prediction. We study common methods of extending calibration measures from binary to multi-class prediction and identify ones that do or do not preserve truthfulness. In addition to truthfulness, we mathematically prove and empirically verify that our calibration measure exhibits superior robustness: it robustly preserves the ordering between dominant and dominated predictors, regardless of the choice of hyperparameters (bin sizes). This result addresses the non-robustness issue of binned ECE, which has been observed repeatedly in prior work.",
    "authors": [
      "Yuxuan Lu",
      "Yifan Wu",
      "Jason Hartline",
      "Lunjia Hu"
    ],
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "publishedAt": "2025-10-07T19:11:03.000Z",
    "updatedAt": "2025-10-07T19:11:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06388v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06388v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06387v1",
    "arxivId": "2510.06387v1",
    "title": "DiLi: A Lock-Free Asynchronously Distributable Linked List",
    "abstract": "Modern databases use dynamic search structures that store a huge amount of data, and often serve them using multi-threaded algorithms to support the ever-increasing throughput needs. When this throughput need exceeds the capacity of the machine hosting the structure, one either needs to replace the underlying hardware (an option that is typically not viable and introduces a long down time) or make the data structure distributed. Static partitioning of the data structure for distribution is not desirable, as it is prone to uneven load distribution over time, and having to change the partitioning scheme later will require downtime. Since a distributed data structure, inherently, relies on communication support from the network stack and operating systems, we introduce the notion of conditional lock-freedom that extends the notion of lock-free computation with reasonable assumptions about communication between processes. We present DiLi, a conditional lock-free, linearizable, and distributable linked list that can be asynchronously and dynamically (1) partitioned into multiple sublists and (2) load balanced by distributing sublists across multiple machines. DiLi contains primitives for these that also maintain the lock-free property of the underlying search structure that supports find, remove, and insert of a key as the client operations. Searching for an item in DiLi is by a novel traversal that involves a binary search on the partitioning scheme, and then a linear traversal on a limitable number of linked nodes. As a result, we are able to empirically show that DiLi performs as well as the state-of-the-art lock-free concurrent search structures that are based off of a linked list when executed on a single-machine. We also show that the throughput of DiLi scales linearly with the number of machines that host it.",
    "authors": [
      "Raaghav Ravishankar",
      "Sandeep Kulkarni",
      "Sathya Peri",
      "Gokarna Sharma"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-07T19:09:25.000Z",
    "updatedAt": "2025-10-07T19:09:25.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06387v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06387v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07343v2",
    "arxivId": "2510.07343v2",
    "title": "Local MAP Sampling for Diffusion Models",
    "abstract": "Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to inverse problems by sampling from $p(x_0 \\mid y)$. However, in practice, the goal of inverse problem solving is not to cover the posterior but to recover the most accurate reconstruction, where optimization-based diffusion solvers often excel despite lacking a clear probabilistic foundation. We introduce Local MAP Sampling (LMAPS), a new inference framework that iteratively solving local MAP subproblems along the diffusion trajectory. This perspective clarifies their connection to global MAP estimation and DPS, offering a unified probabilistic interpretation for optimization-based methods. Building on this foundation, we develop practical algorithms with a probabilistically interpretable covariance approximation, a reformulated objective for stability and interpretability, and a gradient approximation for non-differentiable operators. Across a broad set of image restoration and scientific tasks, LMAPS achieves state-of-the-art performance, including $\\geq 2$ dB gains on motion deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on inverse scattering benchmarks.",
    "authors": [
      "Shaorong Zhang",
      "Rob Brekelmans",
      "Greg Ver Steeg"
    ],
    "categories": [
      "cs.GR",
      "cs.AI",
      "eess.IV"
    ],
    "publishedAt": "2025-10-07T19:02:32.000Z",
    "updatedAt": "2025-10-12T18:18:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07343v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.07343v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06350v1",
    "arxivId": "2510.06350v1",
    "title": "Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation",
    "abstract": "Online communities rely on a mix of platform policies and community-authored rules to define acceptable behavior and maintain order. However, these rules vary widely across communities, evolve over time, and are enforced inconsistently, posing challenges for transparency, governance, and automation. In this paper, we model the relationship between rules and their enforcement at scale, introducing ModQ, a novel question-answering framework for rule-sensitive content moderation. Unlike prior classification or generation-based approaches, ModQ conditions on the full set of community rules at inference time and identifies which rule best applies to a given comment. We implement two model variants - extractive and multiple-choice QA - and train them on large-scale datasets from Reddit and Lemmy, the latter of which we construct from publicly available moderation logs and rule descriptions. Both models outperform state-of-the-art baselines in identifying moderation-relevant rule violations, while remaining lightweight and interpretable. Notably, ModQ models generalize effectively to unseen communities and rules, supporting low-resource moderation settings and dynamic governance environments.",
    "authors": [
      "Mattia Samory",
      "Diana Pamfile",
      "Andrew To",
      "Shruti Phadke"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-07T18:11:27.000Z",
    "updatedAt": "2025-10-07T18:11:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06350v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06350v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.07340v1",
    "arxivId": "2510.07340v1",
    "title": "SpotDiff: Spotting and Disentangling Interference in Feature Space for Subject-Preserving Image Generation",
    "abstract": "Personalized image generation aims to faithfully preserve a reference subject's identity while adapting to diverse text prompts. Existing optimization-based methods ensure high fidelity but are computationally expensive, while learning-based approaches offer efficiency at the cost of entangled representations influenced by nuisance factors. We introduce SpotDiff, a novel learning-based method that extracts subject-specific features by spotting and disentangling interference. Leveraging a pre-trained CLIP image encoder and specialized expert networks for pose and background, SpotDiff isolates subject identity through orthogonality constraints in the feature space. To enable principled training, we introduce SpotDiff10k, a curated dataset with consistent pose and background variations. Experiments demonstrate that SpotDiff achieves more robust subject preservation and controllable editing than prior methods, while attaining competitive performance with only 10k training samples.",
    "authors": [
      "Yongzhi Li",
      "Saining Zhang",
      "Yibing Chen",
      "Boying Li",
      "Yanxin Zhang",
      "Xiaoyu Du"
    ],
    "categories": [
      "cs.GR",
      "cs.LG"
    ],
    "publishedAt": "2025-10-07T18:01:55.000Z",
    "updatedAt": "2025-10-07T18:01:55.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.07340v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.07340v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06316v1",
    "arxivId": "2510.06316v1",
    "title": "Quantum matrix arithmetics with Hamiltonian evolution",
    "abstract": "The efficient implementation of matrix arithmetic operations underpins the speedups of many quantum algorithms. We develop a suite of methods to perform matrix arithmetics -- with the result encoded in the off-diagonal blocks of a Hamiltonian -- using Hamiltonian evolutions of input operators. We show how to maintain this $\\textit{Hamiltonian block encoding}$, so that matrix operations can be composed one after another, and the entire quantum computation takes $\\leq 2$ ancilla qubits. We achieve this for matrix multiplication, matrix addition, matrix inversion, Hermitian conjugation, fractional scaling, integer scaling, complex phase scaling, as well as singular value transformation for both odd and even polynomials. We also present an overlap estimation algorithm to extract classical properties of Hamiltonian block encoded operators, analogous to the well known Hadmard test, at no extra cost of qubit. Our Hamiltonian matrix multiplication uses the Lie group commutator product formula and its higher-order generalizations due to Childs and Wiebe. Our Hamiltonian singular value transformation employs a dominated polynomial approximation, where the approximation holds within the domain of interest, while the constructed polynomial is upper bounded by the target function over the entire unit interval. We describe a circuit for simulating a class of sum-of-squares Hamiltonians, attaining a commutator scaling in step count, while leveraging the power of matrix arithmetics to reduce the cost of each simulation step. In particular, we apply this to the doubly factorized tensor hypercontracted Hamiltonians from recent studies of quantum chemistry, obtaining further improvements for initial states with a fixed number of particles. We achieve this with $1$ ancilla qubit.",
    "authors": [
      "Christopher Kang",
      "Yuan Su"
    ],
    "categories": [
      "quant-ph",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "physics.chem-ph"
    ],
    "publishedAt": "2025-10-07T18:00:01.000Z",
    "updatedAt": "2025-10-07T18:00:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06316v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06316v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06306v1",
    "arxivId": "2510.06306v1",
    "title": "\"Grillz on a hijabi\": Intersectional Identities in Fostering Critical AI Literacy",
    "abstract": "As AI increasingly saturates our daily lives, it is crucial that youth develop skills to critically use and assess AI systems and envision better alternatives. We apply theories from culturally responsive computing to design and study a learning experience meant to support Black Muslim teen girls in developing critical literacy with generative AI (GenAI). We investigate fashion design as a culturally-rich, creative domain for youth to apply GenAI and then reflect on GenAI's socio-ethical aspects in relation to their own intersectional identities. Through a case study of a three-day, voluntary informal education program, we show how fashion design with GenAI exposed affordances and limitations of current GenAI tools. As the girls used GenAI to create realistic depictions of their dream fashion collections, they encountered socio-ethical limitations of AI, such as biased models and malfunctioning safety systems that prohibited their generation of outputs that reflected their creative ideas, bodies, and cultures. Discussions anchored in the phenomenology of impossible creative realization supported participants' development of critical AI literacy and descriptions of how preferable, identity-affirming technologies would behave. Our findings contribute to the field's growing understanding of how computing education experience designs linking creativity and identity can support critical AI literacy development.",
    "authors": [
      "Jaemarie Solyst",
      "Chloe Fong",
      "Faisal Nurdin",
      "Rotem Landesman",
      "R. Benjamin Shapiro"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T17:52:33.000Z",
    "updatedAt": "2025-10-07T17:52:33.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06306v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06306v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06156v1",
    "arxivId": "2510.06156v1",
    "title": "Observing Interaction Rather Than Interfaces",
    "abstract": "The science of Human-Computer Interaction (HCI) is populated by isolated empirical findings, often tied to specific technologies, designs, and tasks. This situation probably lies in observing the wrong object of study, that is to say, observing interfaces rather than interaction. This paper proposes an experimental methodology, powered by a research methodology, that enables tackling the ambition of observing interaction (rather than interfaces). These observations are done during the treatment of applicative cases, allowing to generate and replicate results covering various experimental conditions, expressed from the need of end users and the evolution of technologies. Performing these observations when developing applicative prototypes illustrating novel technologies' utility allows, in the same time, to benefit from an optimization of these prototypes to better accomplish end users tasks. This paper depicts a long term research direction, from generating the initial observations of interaction properties and their replication, to their integration, that would then lead to exploring the possible relations existing between those properties, to end toward the description of human-computer interaction's physics.",
    "authors": [
      "Guillaume Rivière"
    ],
    "categories": [
      "cs.HC",
      "H.5.2"
    ],
    "publishedAt": "2025-10-07T17:23:35.000Z",
    "updatedAt": "2025-10-07T17:23:35.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06156v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06156v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06151v1",
    "arxivId": "2510.06151v1",
    "title": "LLMs as Policy-Agnostic Teammates: A Case Study in Human Proxy Design for Heterogeneous Agent Teams",
    "abstract": "A critical challenge in modelling Heterogeneous-Agent Teams is training agents to collaborate with teammates whose policies are inaccessible or non-stationary, such as humans. Traditional approaches rely on expensive human-in-the-loop data, which limits scalability. We propose using Large Language Models (LLMs) as policy-agnostic human proxies to generate synthetic data that mimics human decision-making. To evaluate this, we conduct three experiments in a grid-world capture game inspired by Stag Hunt, a game theory paradigm that balances risk and reward. In Experiment 1, we compare decisions from 30 human participants and 2 expert judges with outputs from LLaMA 3.1 and Mixtral 8x22B models. LLMs, prompted with game-state observations and reward structures, align more closely with experts than participants, demonstrating consistency in applying underlying decision criteria. Experiment 2 modifies prompts to induce risk-sensitive strategies (e.g. \"be risk averse\"). LLM outputs mirror human participants' variability, shifting between risk-averse and risk-seeking behaviours. Finally, Experiment 3 tests LLMs in a dynamic grid-world where the LLM agents generate movement actions. LLMs produce trajectories resembling human participants' paths. While LLMs cannot yet fully replicate human adaptability, their prompt-guided diversity offers a scalable foundation for simulating policy-agnostic teammates.",
    "authors": [
      "Aju Ani Justus",
      "Chris Baber"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T17:21:20.000Z",
    "updatedAt": "2025-10-07T17:21:20.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06151v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06151v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06147v1",
    "arxivId": "2510.06147v1",
    "title": "Non-iid hypothesis testing: from classical to quantum",
    "abstract": "We study hypothesis testing (aka state certification) in the non-identically distributed setting. A recent work (Garg et al. 2023) considered the classical case, in which one is given (independent) samples from $T$ unknown probability distributions $p_1, \\dots, p_T$ on $[d] = \\{1, 2, \\dots, d\\}$, and one wishes to accept/reject the hypothesis that their average $p_{\\mathrm{avg}}$ equals a known hypothesis distribution $q$. Garg et al. showed that if one has just $c = 2$ samples from each $p_i$, and provided $T \\gg \\frac{\\sqrt{d}}{\\epsilon^2} + \\frac{1}{\\epsilon^4}$, one can (whp) distinguish $p_{\\mathrm{avg}} = q$ from $d_{\\mathrm{TV}}(p_{\\mathrm{avg}},q) > \\epsilon$. This nearly matches the optimal result for the classical iid setting (namely, $T \\gg \\frac{\\sqrt{d}}{\\epsilon^2}$). Besides optimally improving this result (and generalizing to tolerant testing with more stringent distance measures), we study the analogous problem of hypothesis testing for non-identical quantum states. Here we uncover an unexpected phenomenon: for any $d$-dimensional hypothesis state $\\sigma$, and given just a single copy ($c = 1$) of each state $\\rho_1, \\dots, \\rho_T$, one can distinguish $\\rho_{\\mathrm{avg}} = \\sigma$ from $D_{\\mathrm{tr}}(\\rho_{\\mathrm{avg}},\\sigma) > \\epsilon$ provided $T \\gg d/\\epsilon^2$. (Again, we generalize to tolerant testing with more stringent distance measures.) This matches the optimal result for the iid case, which is surprising because doing this with $c = 1$ is provably impossible in the classical case. We also show that the analogous phenomenon happens for the non-iid extension of identity testing between unknown states. A technical tool we introduce may be of independent interest: an Efron-Stein inequality, and more generally an Efron-Stein decomposition, in the quantum setting.",
    "authors": [
      "Giacomo De Palma",
      "Marco Fanizza",
      "Connor Mowry",
      "Ryan O'Donnell"
    ],
    "categories": [
      "quant-ph",
      "cs.DS",
      "cs.LG"
    ],
    "publishedAt": "2025-10-07T17:19:26.000Z",
    "updatedAt": "2025-10-07T17:19:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06147v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06147v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06130v1",
    "arxivId": "2510.06130v1",
    "title": "Local Search-based Individually Fair Clustering with Outliers",
    "abstract": "In this paper, we present a local search-based algorithm for individually fair clustering in the presence of outliers. We consider the individual fairness definition proposed in Jung et al., which requires that each of the $n$ points in the dataset must have one of the $k$ centers within its $n/k$ nearest neighbors. However, if the dataset is known to contain outliers, the set of fair centers obtained under this definition might be suboptimal for non-outlier points. In order to address this issue, we propose a method that discards a set of points marked as outliers and computes the set of fair centers for the remaining non-outlier points. Our method utilizes a randomized variant of local search, which makes it scalable to large datasets. We also provide an approximation guarantee of our method as well as a bound on the number of outliers discarded. Additionally, we demonstrate our claims experimentally on a set of real-world datasets.",
    "authors": [
      "Binita Maity",
      "Shrutimoy Das",
      "Anirban Dasgupta"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-07T17:06:52.000Z",
    "updatedAt": "2025-10-07T17:06:52.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06130v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06130v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06124v2",
    "arxivId": "2510.06124v2",
    "title": "Taxonomy of User Needs and Actions",
    "abstract": "The growing ubiquity of conversational AI highlights the need for frameworks that capture not only users' instrumental goals but also the situated, adaptive, and social practices through which they achieve them. Existing taxonomies of conversational behavior either overgeneralize, remain domain-specific, or reduce interactions to narrow dialogue functions. To address this gap, we introduce the Taxonomy of User Needs and Actions (TUNA), an empirically grounded framework developed through iterative qualitative analysis of 1193 human-AI conversations, supplemented by theoretical review and validation across diverse contexts. TUNA organizes user actions into a three-level hierarchy encompassing behaviors associated with information seeking, synthesis, procedural guidance, content creation, social interaction, and meta-conversation. By centering user agency and appropriation practices, TUNA enables multi-scale evaluation, supports policy harmonization across products, and provides a backbone for layering domain-specific taxonomies. This work contributes a systematic vocabulary for describing AI use, advancing both scholarly understanding and practical design of safer, more responsive, and more accountable conversational systems.",
    "authors": [
      "Renee Shelby",
      "Fernando Diaz",
      "Vinodkumar Prabhakaran"
    ],
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "publishedAt": "2025-10-07T17:04:42.000Z",
    "updatedAt": "2025-10-10T16:13:43.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06124v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.06124v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06105v1",
    "arxivId": "2510.06105v1",
    "title": "Moloch's Bargain: Emergent Misalignment When LLMs Compete for Audiences",
    "abstract": "Large language models (LLMs) are increasingly shaping how information is created and disseminated, from companies using them to craft persuasive advertisements, to election campaigns optimizing messaging to gain votes, to social media influencers boosting engagement. These settings are inherently competitive, with sellers, candidates, and influencers vying for audience approval, yet it remains poorly understood how competitive feedback loops influence LLM behavior. We show that optimizing LLMs for competitive success can inadvertently drive misalignment. Using simulated environments across these scenarios, we find that, 6.3% increase in sales is accompanied by a 14.0% rise in deceptive marketing; in elections, a 4.9% gain in vote share coincides with 22.3% more disinformation and 12.5% more populist rhetoric; and on social media, a 7.5% engagement boost comes with 188.6% more disinformation and a 16.3% increase in promotion of harmful behaviors. We call this phenomenon Moloch's Bargain for AI--competitive success achieved at the cost of alignment. These misaligned behaviors emerge even when models are explicitly instructed to remain truthful and grounded, revealing the fragility of current alignment safeguards. Our findings highlight how market-driven optimization pressures can systematically erode alignment, creating a race to the bottom, and suggest that safe deployment of AI systems will require stronger governance and carefully designed incentives to prevent competitive dynamics from undermining societal trust.",
    "authors": [
      "Batu El",
      "James Zou"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-07T16:37:15.000Z",
    "updatedAt": "2025-10-07T16:37:15.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06105v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06105v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06102v1",
    "arxivId": "2510.06102v1",
    "title": "A Finer View of the Parameterized Landscape of Labeled Graph Contractions",
    "abstract": "We study the \\textsc{Labeled Contractibility} problem, where the input consists of two vertex-labeled graphs $G$ and $H$, and the goal is to determine whether $H$ can be obtained from $G$ via a sequence of edge contractions. Lafond and Marchand~[WADS 2025] initiated the parameterized complexity study of this problem, showing it to be \\(\\W[1]\\)-hard when parameterized by the number \\(k\\) of allowed contractions. They also proved that the problem is fixed-parameter tractable when parameterized by the tree-width \\(\\tw\\) of \\(G\\), via an application of Courcelle's theorem resulting in a non-constructive algorithm. In this work, we present a constructive fixed-parameter algorithm for \\textsc{Labeled Contractibility} with running time \\(2^{\\mathcal{O}(\\tw^2)} \\cdot |V(G)|^{\\mathcal{O}(1)}\\). We also prove that unless the Exponential Time Hypothesis (\\ETH) fails, it does not admit an algorithm running in time \\(2^{o(\\tw^2)} \\cdot |V(G)|^{\\mathcal{O}(1)}\\). This result adds \\textsc{Labeled Contractibility} to a small list of problems that admit such a lower bound and matching algorithm. We further strengthen existing hardness results by showing that the problem remains \\NP-complete even when both input graphs have bounded maximum degree. We also investigate parameterizations by \\((k + \\delta(G))\\) where \\(\\delta(G)\\) denotes the degeneracy of \\(G\\), and rule out the existence of subexponential-time algorithms. This answers question raised in Lafond and Marchand~[WADS 2025]. We additionally provide an improved \\FPT\\ algorithm with better dependence on \\((k + \\delta(G))\\) than previously known. Finally, we analyze a brute-force algorithm for \\textsc{Labeled Contractibility} with running time \\(|V(H)|^{\\mathcal{O}(|V(G)|)}\\), and show that this running time is optimal under \\ETH.",
    "authors": [
      "Yashaswini Mathur",
      "Prafullkumar Tale"
    ],
    "categories": [
      "cs.DS",
      "cs.DM"
    ],
    "publishedAt": "2025-10-07T16:33:44.000Z",
    "updatedAt": "2025-10-07T16:33:44.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06102v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06102v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06071v1",
    "arxivId": "2510.06071v1",
    "title": "Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks",
    "abstract": "AI models are increasingly used for data analysis and visualization, yet benchmarks rarely address scatterplot-specific tasks, limiting insight into performance. To address this gap for one of the most common chart types, we introduce a synthetic, annotated dataset of over 18,000 scatterplots from six data generators and 17 chart designs, and a benchmark based on it. We evaluate proprietary models from OpenAI and Google using N-shot prompting on five distinct tasks derived from annotations of cluster bounding boxes, their center coordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash, especially when prompted with examples, are viable options for counting clusters and, in Flash's case, outliers (90%+ Accuracy). However, the results for localization-related tasks are unsatisfactory: Precision and Recall are near or below 50%, except for Flash in outlier identification (65.01%). Furthermore, the impact of chart design on performance appears to be a secondary factor, but it is advisable to avoid scatterplots with wide aspect ratios (16:9 and 21:9) or those colored randomly. Supplementary materials are available at https://github.com/feedzai/biy-paper.",
    "authors": [
      "João Palmeiro",
      "Diogo Duarte",
      "Rita Costa",
      "Pedro Bizarro"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T15:59:19.000Z",
    "updatedAt": "2025-10-07T15:59:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06071v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06071v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06023v1",
    "arxivId": "2510.06023v1",
    "title": "Optimal Good-Case Latency for Sleepy Consensus",
    "abstract": "In the context of Byzantine consensus problems such as Byzantine broadcast (BB) and Byzantine agreement (BA), the good-case setting aims to study the minimal possible latency of a BB or BA protocol under certain favorable conditions, namely the designated leader being correct (for BB), or all parties having the same input value (for BA). We provide a full characterization of the feasibility and impossibility of good-case latency, for both BA and BB, in the synchronous sleepy model. Surprisingly to us, we find irrational resilience thresholds emerging: 2-round good-case BB is possible if and only if at all times, at least $\\frac{1}{\\varphi} \\approx 0.618$ fraction of the active parties are correct, where $\\varphi = \\frac{1+\\sqrt{5}}{2} \\approx 1.618$ is the golden ratio; 1-round good-case BA is possible if and only if at least $\\frac{1}{\\sqrt{2}} \\approx 0.707$ fraction of the active parties are correct.",
    "authors": [
      "Yuval Efron",
      "Joachim Neu",
      "Ling Ren",
      "Ertem Nusret Tas"
    ],
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "publishedAt": "2025-10-07T15:22:29.000Z",
    "updatedAt": "2025-10-07T15:22:29.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06023v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06023v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06019v2",
    "arxivId": "2510.06019v2",
    "title": "Iterating Non-Aggregative Structure Compositions",
    "abstract": "An aggregative composition is a binary operation obeying the principle that the whole is determined by the sum of its parts. The development of graph algebras, on which the theory of formal graph languages is built, relies on aggregative compositions that behave like disjoint union, except for a set of well-marked interface vertices from both sides, that are joined. The same style of composition has been considered in the context of relational structures, that generalize graphs and use constant symbols to label the interface. In this paper, we study a non-aggregative composition operation, called \\emph{fusion}, that joins non-deterministically chosen elements from disjoint structures. The sets of structures obtained by iteratively applying fusion do not always have bounded tree-width, even when starting from a tree-width bounded set. First, we prove that the problem of the existence of a bound on the tree-width of the closure of a given set under fusion is decidable, when the input set is described inductively by a finite \\emph{hyperedge-replacement} (HR) grammar, written using the operations of aggregative composition, forgetting and renaming of constants. Such sets are usually called \\emph{context-free}. Second, assuming that the closure under fusion of a context-free set has bounded tree-width, we show that it is the language of an effectively constructible HR grammar. A possible application of the latter result is the possiblity of checking whether all structures from a non-aggregatively closed set having bounded tree-width satisfy a given monadic second order logic formula.",
    "authors": [
      "Marius Bozga",
      "Radu Iosif",
      "Florian Zuleger"
    ],
    "categories": [
      "cs.FL"
    ],
    "publishedAt": "2025-10-07T15:17:20.000Z",
    "updatedAt": "2025-10-10T07:57:54.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06019v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.06019v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06015v1",
    "arxivId": "2510.06015v1",
    "title": "\"Your Doctor is Spying on You\": An Analysis of Data Practices in Mobile Healthcare Applications",
    "abstract": "Mobile healthcare (mHealth) applications promise convenient, continuous patient-provider interaction but also introduce severe and often underexamined security and privacy risks. We present an end-to-end audit of 272 Android mHealth apps from Google Play, combining permission forensics, static vulnerability analysis, and user review mining. Our multi-tool assessment with MobSF, RiskInDroid, and OWASP Mobile Audit revealed systemic weaknesses: 26.1% request fine-grained location without disclosure, 18.3% initiate calls silently, and 73 send SMS without notice. Nearly half (49.3%) still use deprecated SHA-1 encryption, 42 transmit unencrypted data, and 6 remain vulnerable to StrandHogg 2.0. Analysis of 2.56 million user reviews found 28.5% negative or neutral sentiment, with over 553,000 explicitly citing privacy intrusions, data misuse, or operational instability. These findings demonstrate the urgent need for enforceable permission transparency, automated pre-market security vetting, and systematic adoption of secure-by-design practices to protect Protected Health Information (PHI).",
    "authors": [
      "Luke Stevenson",
      "Sanchari Das"
    ],
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T15:12:48.000Z",
    "updatedAt": "2025-10-07T15:12:48.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06015v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06015v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.06011v1",
    "arxivId": "2510.06011v1",
    "title": "How many more is different?",
    "abstract": "From the formation of ice in small clusters of water molecules to the mass raids of army ant colonies, the emergent behavior of collectives depends critically on their size. At the same time, common wisdom holds that such behaviors are robust to the loss of individuals. This tension points to the need for a more systematic study of how number influences collective behavior. We initiate this study by focusing on collective behaviors that change abruptly at certain critical numbers of individuals. We show that a subtle modification of standard bifurcation analysis identifies such critical numbers, including those associated with discreteness- and noise-induced transitions. By treating them as instances of the same phenomenon, we show that critical numbers across physical scales and scientific domains commonly arise from competing feedbacks that scale differently with number. We then use this idea to find overlooked critical numbers in past studies of collective behavior and explore the implications for their conclusions. In particular, we highlight how deterministic approximations of stochastic models can fail near critical numbers. We close by distinguishing these qualitative changes from density-dependent phase transitions and by discussing how our approach could generalize to broader classes of collective behaviors.",
    "authors": [
      "Jacob Calvert",
      "Andréa W. Richa",
      "Dana Randall"
    ],
    "categories": [
      "q-bio.PE",
      "cond-mat.stat-mech",
      "cs.DC",
      "nlin.AO"
    ],
    "publishedAt": "2025-10-07T15:10:13.000Z",
    "updatedAt": "2025-10-07T15:10:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.06011v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.06011v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05986v1",
    "arxivId": "2510.05986v1",
    "title": "A Small Collusion is All You Need",
    "abstract": "Transaction Fee Mechanisms (TFMs) study auction design in the Blockchain context, and emphasize robustness against miner and user collusion, moreso than traditional auction theory. \\cite{chung2023foundations} introduce the notion of a mechanism being $c$-Side-Contract-Proof ($c$-SCP), i.e., robust to a collusion of the miner and $c$ users. Later work \\cite{chung2024collusion,welfareIncreasingCollusion} shows a gap between the $1$-SCP and $2$-SCP classes. We show that the class of $2$-SCP mechanisms equals that of any $c$-SCP with $c\\geq 2$, under a relatively minor assumption of consistent tie-breaking. In essence, this implies that any mechanism vulnerable to collusion, is also vulnerable to a small collusion.",
    "authors": [
      "Yotam Gafni"
    ],
    "categories": [
      "cs.GT",
      "econ.TH"
    ],
    "publishedAt": "2025-10-07T14:46:04.000Z",
    "updatedAt": "2025-10-07T14:46:04.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05986v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05986v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05975v2",
    "arxivId": "2510.05975v2",
    "title": "Fast-Convergent Proximity Graphs for Approximate Nearest Neighbor Search",
    "abstract": "Approximate nearest neighbor (ANN) search in high-dimensional metric spaces is a fundamental problem with many applications. Over the past decade, proximity graph (PG)-based indexes have demonstrated superior empirical performance over alternatives. However, these methods often lack theoretical guarantees regarding the quality of query results, especially in the worst-case scenarios. In this paper, we introduce the {\\alpha}-convergent graph ({\\alpha}-CG), a new PG structure that employs a carefully designed edge pruning rule. This rule eliminates candidate neighbors for each data point p by applying the shifted-scaled triangle inequalities among p, its existing out-neighbors, and new candidates. If the distance between the query point q and its exact nearest neighbor v* is at most {\\tau} for some constant {\\tau} > 0, our {\\alpha}-CG finds the exact nearest neighbor in poly-logarithmic time, assuming bounded intrinsic dimensionality for the dataset; otherwise, it can find an ANN in the same time. To enhance scalability, we develop the {\\alpha}-convergent neighborhood graph ({\\alpha}-CNG), a practical variant that applies the pruning rule locally within each point's neighbors. We also introduce optimizations to reduce the index construction time. Experimental results show that our {\\alpha}-CNG outperforms existing PGs on real-world datasets. For most datasets, {\\alpha}-CNG can reduce the number of distance computations and search steps by over 15% and 45%, respectively, when compared with the best-performing baseline.",
    "authors": [
      "Binhong Li",
      "Xiao Yan",
      "Shangqi Lu"
    ],
    "categories": [
      "cs.DS"
    ],
    "publishedAt": "2025-10-07T14:29:54.000Z",
    "updatedAt": "2025-10-13T14:31:19.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05975v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.05975v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05955v1",
    "arxivId": "2510.05955v1",
    "title": "Efficient Heuristics and Exact Methods for Pairwise Interaction Sampling",
    "abstract": "We consider a class of optimization problems that are fundamental to testing in modern configurable software systems, e.g., in automotive industries. In pairwise interaction sampling, we are given a (potentially very large) configuration space, in which each dimension corresponds to a possible Boolean feature of a software system; valid configurations are the satisfying assignments of a given propositional formula $\\varphi$. The objective is to find a minimum-sized family of configurations, such that each pair of features is jointly tested at least once. Due to its relevance in Software Engineering, this problem has been studied extensively for over 20 years. In addition to new theoretical insights (we prove BH-hardness), we provide a broad spectrum of key contributions on the practical side that allow substantial progress for the practical performance. Remarkably, we are able to solve the largest instances we found in published benchmark sets (with about 500000000 feasible interactions) to provable optimality. Previous approaches were not even able to compute feasible solutions.",
    "authors": [
      "Sándor P. Fekete",
      "Phillip Keldenich",
      "Dominik Krupke",
      "Michael Perk"
    ],
    "categories": [
      "cs.DS",
      "cs.CC",
      "cs.SE"
    ],
    "publishedAt": "2025-10-07T14:11:28.000Z",
    "updatedAt": "2025-10-07T14:11:28.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05955v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05955v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05943v1",
    "arxivId": "2510.05943v1",
    "title": "EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models",
    "abstract": "Reinforcement learning (RL) has become a pivotal component of large language model (LLM) post-training, and agentic RL extends this paradigm to operate as agents through multi-turn interaction and tool use. Scaling such systems exposes two practical bottlenecks: (1) context length grows rapidly during training, inflating memory usage and latency, and triggering out-of-memory (OOM) failures; and (2) intermediate tensors accumulate with context length, making cross-device data movement a major system bottleneck. We present EARL, a scalable system for efficient agentic RL. EARL designs a parallelism selector that dynamically adapts model and training parallelism across RL stages based on sequence length and system load, and a data dispatcher that performs layout-aware, decentralized exchange of intermediate data batches. Together, these components increase throughput, reduce long-context failures, and enable stable large-scale training of agentic LLMs without relying on hard limits or penalties of context length.",
    "authors": [
      "Zheyue Tan",
      "Mustapha Abdullahi",
      "Tuo Shi",
      "Huining Yuan",
      "Zelai Xu",
      "Chao Yu",
      "Boxun Li",
      "Bo Zhao"
    ],
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "publishedAt": "2025-10-07T13:52:51.000Z",
    "updatedAt": "2025-10-07T13:52:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05943v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05943v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05937v1",
    "arxivId": "2510.05937v1",
    "title": "Improved Streaming Algorithm for Fair $k$-Center Clustering",
    "abstract": "Many real-world applications pose challenges in incorporating fairness constraints into the $k$-center clustering problem, where the dataset consists of $m$ demographic groups, each with a specified upper bound on the number of centers to ensure fairness. Focusing on big data scenarios, this paper addresses the problem in a streaming setting, where data points arrive one by one sequentially in a continuous stream. Leveraging a structure called the $\\lambda$-independent center set, we propose a one-pass streaming algorithm that first computes a reserved set of points during the streaming process. Then, for the post-streaming process, we propose an approach for selecting centers from the reserved point set by analyzing all three possible cases, transforming the most complicated one into a specially constrained vertex cover problem in an auxiliary graph. Our algorithm achieves a tight approximation ratio of 5 while consuming $O(k\\log n)$ memory. It can also be readily adapted to solve the offline fair $k$-center problem, achieving a 3-approximation ratio that matches the current state of the art. Furthermore, we extend our approach to a semi-structured data stream, where data points from each group arrive in batches. In this setting, we present a 3-approximation algorithm for $m = 2$ and a 4-approximation algorithm for general $m$. Lastly, we conduct extensive experiments to evaluate the performance of our approaches, demonstrating that they outperform existing baselines in both clustering cost and runtime efficiency.",
    "authors": [
      "Longkun Guo",
      "Zeyu Lin",
      "Chaoqi Jia",
      "Chao Chen"
    ],
    "categories": [
      "cs.DS",
      "cs.DM"
    ],
    "publishedAt": "2025-10-07T13:49:56.000Z",
    "updatedAt": "2025-10-07T13:49:56.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05937v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05937v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05927v1",
    "arxivId": "2510.05927v1",
    "title": "Computational Complexity in Property Testing",
    "abstract": "We initiate a systematic study of the computational complexity of property testing, focusing on the relationship between query and time complexity. While traditional work in property testing has emphasized query complexity, relatively little is known about the computational hardness of property testers. Our goal is to chart the landscape of time-query interplay and develop tools for proving time complexity lower bounds. Our first contribution is a pair of time-query hierarchy theorems for property testing. For all suitable nondecreasing functions $q(n)$ and $t(n)$ with $t(n)\\geq q(n)$, we construct properties with query complexity $\\tilde{\\Theta}(q(n))$ and time complexity $\\tilde\\Omega(t(n))$. Our weak hierarchy holds unconditionally, whereas the strong version-assuming the Strong Exponential Time Hypothesis-provides better control over the time complexity of the constructed properties. We then turn to halfspaces in $\\mathbb{R}^d$, a fundamental class in property testing and learning theory. We study the problem of approximating the distance from the input function to the nearest halfspace within additive error $\\epsilon$. For the distribution-free distance approximation problem, known algorithms achieve query complexity $O(d/\\epsilon^2)$, but take time $\\tilde{\\Theta}(1/\\epsilon^d)$. We provide a fine-grained justification for this gap: assuming the $k$-SUM conjecture, any algorithm must have running time ${\\Omega}(1/\\epsilon^{d/2})$. This fine-grained lower bound yields a provable separation between query and time complexity for a natural and well-studied (tolerant) testing problem. We also prove that any Statistical Query (SQ) algorithm under the standard Gaussian distribution requires $(1/\\epsilon)^{\\Omega(d)}$ queries if the queries are answered with additive error up to $\\epsilon^{\\Omega(d)}$, revealing a fundamental barrier even in the distribution-specific setting.",
    "authors": [
      "Renato Ferreira Pinto Jr.",
      "Diptaksho Palit",
      "Sofya Raskhodnikova"
    ],
    "categories": [
      "cs.CC",
      "cs.DS"
    ],
    "publishedAt": "2025-10-07T13:40:01.000Z",
    "updatedAt": "2025-10-07T13:40:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05927v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05927v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05911v1",
    "arxivId": "2510.05911v1",
    "title": "Weighted Food Webs Make Computing Phylogenetic Diversity So Much Harder",
    "abstract": "Phylogenetic trees represent certain species and their likely ancestors. In such a tree, present-day species are leaves and an edge from u to v indicates that u is an ancestor of v. Weights on these edges indicate the phylogenetic distance. The phylogenetic diversity (PD) of a set of species A is the total weight of edges that are on any path between the root of the phylogenetic tree and a species in A. Selecting a small set of species that maximizes phylogenetic diversity for a given phylogenetic tree is an essential task in preservation planning, where limited resources naturally prevent saving all species. An optimal solution can be found with a greedy algorithm [Steel, Systematic Biology, 2005; Pardi and Goldman, PLoS Genetics, 2005]. However, when a food web representing predator-prey relationships is given, finding a set of species that optimizes phylogenetic diversity subject to the condition that each saved species should be able to find food among the preserved species is NP-hard [Spillner et al., IEEE/ACM, 2008]. We present a generalization of this problem, where, inspired by biological considerations, the food web has weighted edges to represent the importance of predator-prey relationships. We show that this version is NP-hard even when both structures, the food web and the phylogenetic tree, are stars. To cope with this intractability, we proceed in two directions. Firstly, we study special cases where a species can only survive if a given fraction of its prey is preserved. Secondly, we analyze these problems through the lens of parameterized complexity. Our results include that finding a solution is fixed-parameter tractable with respect to the vertex cover number of the food web, assuming the phylogenetic tree is a star.",
    "authors": [
      "Jannik Schestag"
    ],
    "categories": [
      "q-bio.PE",
      "cs.DM"
    ],
    "publishedAt": "2025-10-07T13:22:27.000Z",
    "updatedAt": "2025-10-07T13:22:27.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05911v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05911v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.08607v1",
    "arxivId": "2510.08607v1",
    "title": "GRPO-GCC: Enhancing Cooperation in Spatial Public Goods Games via Group Relative Policy Optimization with Global Cooperation Constraint",
    "abstract": "Inspired by the principle of self-regulating cooperation in collective institutions, we propose the Group Relative Policy Optimization with Global Cooperation Constraint (GRPO-GCC) framework. This work is the first to introduce GRPO into spatial public goods games, establishing a new deep reinforcement learning baseline for structured populations. GRPO-GCC integrates group relative policy optimization with a global cooperation constraint that strengthens incentives at intermediate cooperation levels while weakening them at extremes. This mechanism aligns local decision making with sustainable collective outcomes and prevents collapse into either universal defection or unconditional cooperation. The framework advances beyond existing approaches by combining group-normalized advantage estimation, a reference-anchored KL penalty, and a global incentive term that dynamically adjusts cooperative payoffs. As a result, it achieves accelerated cooperation onset, stabilized policy adaptation, and long-term sustainability. GRPO-GCC demonstrates how a simple yet global signal can reshape incentives toward resilient cooperation, and provides a new paradigm for multi-agent reinforcement learning in socio-technical systems.",
    "authors": [
      "Zhaoqilin Yang",
      "Chanchan Li",
      "Tianqi Liu",
      "Hongxin Zhao",
      "Youliang Tian"
    ],
    "categories": [
      "cs.MA",
      "cs.GT"
    ],
    "publishedAt": "2025-10-07T13:10:05.000Z",
    "updatedAt": "2025-10-07T13:10:05.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.08607v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.08607v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05844v1",
    "arxivId": "2510.05844v1",
    "title": "From \"Arbitrary Timberland\" To \"Skyline Charts\": Is Visualization At Risk From The Pollution of Scientific Literature?",
    "abstract": "In this essay, I argue that, while visualization research does not seem to be directly at risk of being corrupted by the current massive wave of polluted research, certain visualization concepts are being used in fraudulent fashions and fields close to ours are being targeted. Worse, the society publishing our work is overwhelmed by thousands of questionable papers that are being, unfortunately, published. As a community, and if we want our research to remain as good as it currently is, I argue that we should all get involved with our variety of skills to help identify and correct the current scientific record. I thus aim to present a few questionable practices that are worth knowing about when reviewing for fields using visualization research, and hopefully will never be useful when reviewing for our main venues. I also argue that our skill set could become particularly relevant in the future and invite scholars of the fields to try to get involved.",
    "authors": [
      "Lonni Besançon"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T12:07:51.000Z",
    "updatedAt": "2025-10-07T12:07:51.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05844v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05844v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05833v1",
    "arxivId": "2510.05833v1",
    "title": "The Interplay of Attention and Memory in Visual Enumeration",
    "abstract": "Humans navigate and understand complex visual environments by subconsciously quantifying what they see, a process known as visual enumeration. However, traditional studies using flat screens fail to capture the cognitive dynamics of this process over the large visual fields of real-world scenes. To address this gap, we developed an immersive virtual reality system with integrated eye-tracking to investigate the interplay between attention and memory during complex enumeration. We conducted a two-phase experiment where participants enumerated scenes of either simple abstract shapes or complex real-world objects, systematically varying the task intent (e.g., selective vs. exhaustive counting) and the spatial layout of items. Our results reveal that task intent is the dominant factor driving performance, with selective counting imposing a significant cognitive cost that was dramatically amplified by stimulus complexity. The semantic processing required for real-world objects reduced accuracy and suppressed memory recall, while the influence of spatial layout was secondary and statistically non-significant when a higher-order cognitive task intent was driving the human behaviour. We conclude that real-world enumeration is fundamentally constrained by the cognitive load of semantic processing, not just the mechanics of visual search. Our findings demonstrate that under high cognitive demand, the effort to understand what we are seeing directly limits our capacity to remember it.",
    "authors": [
      "B. Sankar",
      "Devottama Sen",
      "Dibakar Sen"
    ],
    "categories": [
      "cs.HC",
      "91E30, 62P25, 68T05",
      "H.5.2; H.1.2; H.5.0; J.4"
    ],
    "publishedAt": "2025-10-07T11:56:26.000Z",
    "updatedAt": "2025-10-07T11:56:26.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05833v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05833v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05806v1",
    "arxivId": "2510.05806v1",
    "title": "Parameterized Complexity of Temporal Connected Components: Treewidth and k-Path Graphs",
    "abstract": "We study the parameterized complexity of maximum temporal connected components (tccs) in temporal graphs, i.e., graphs that deterministically change over time. In a tcc, any pair of vertices must be able to reach each other via a time-respecting path. We consider both problems of maximum open tccs (openTCC), which allow temporal paths through vertices outside the component, and closed tccs (closedTCC) which require at least one temporal path entirely within the component for every pair. We focus on the structural parameter of treewidth, tw, and the recently introduced temporal parameter of temporal path number, tpn, which is the minimum number of paths needed to fully describe a temporal graph. We prove that these parameters on their own are not sufficient for fixed parameter tractability: both openTCC and closedTCC are NP-hard even when tw=9, and closedTCC is NP-hard when tpn=6. In contrast, we prove that openTCC is in XP when parameterized by tpn. On the positive side, we show that both problem become fixed parameter tractable under various combinations of structural and temporal parameters that include, tw plus tpn, tw plus the lifetime of the graph, and tw plus the maximum temporal degree.",
    "authors": [
      "Argyrios Deligkas",
      "Michelle Döring",
      "Eduard Eiben",
      "Tiger-Lily Goldsmith",
      "George Skretas",
      "Georg Tennigkeit"
    ],
    "categories": [
      "cs.DS",
      "cs.DM",
      "math.CO"
    ],
    "publishedAt": "2025-10-07T11:23:58.000Z",
    "updatedAt": "2025-10-07T11:23:58.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05806v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05806v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05786v2",
    "arxivId": "2510.05786v2",
    "title": "Möbius transforms and Shapley values for vector-valued functions on weighted directed acyclic multigraphs",
    "abstract": "We generalize the concept of M\\\"obius inversion and Shapley values to directed acyclic multigraphs and weighted versions thereof. We further allow value functions (games) and thus their M\\\"obius transforms (synergy function) and Shapley values to have values in any abelian group that is a module over a ring that contains the graph weights, e.g. vector-valued functions. To achieve this and overcome the obstruction that the classical axioms (linearity, efficiency, null player, symmetry) are not strong enough to uniquely determine Shapley values in this more general setting, we analyze Shapley values from two novel points of view: 1) We introduce projection operators that allow us to interpret Shapley values as the recursive projection and re-attribution of higher-order synergies to lower-order ones; 2) we propose a strengthening of the null player axiom and a localized symmetry axiom, namely the weak elements and flat hierarchy axioms. The former allows us to remove coalitions with vanishing synergy while preserving the rest of the hierarchical structure. The latter treats player-coalition bonds uniformly in the corner case of hierarchically flat graphs. Together with linearity these axioms already imply a unique explicit formula for the Shapley values, as well as classical properties like efficiency, null player, symmetry, and novel ones like the projection property. This whole framework then specializes to finite inclusion algebras, lattices, partial orders and mereologies, and also recovers certain previously known cases as corner cases, and presents others from a new perspective. The admission of general weighted directed acyclic multigraph structured hierarchies and vector-valued functions and Shapley values opens up the possibility for new analytic tools and application areas, like machine learning, language processing, explainable artificial intelligence, and many more.",
    "authors": [
      "Patrick Forré",
      "Abel Jansma"
    ],
    "categories": [
      "cs.GT",
      "cs.DM",
      "cs.LG",
      "math.CO",
      "91A12 (Primary) 06A07, 05E99 (Secondary)",
      "F.2.2; G.2.1; G.2.2; I.2.0"
    ],
    "publishedAt": "2025-10-07T11:05:25.000Z",
    "updatedAt": "2025-10-08T12:55:31.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05786v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.05786v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05771v1",
    "arxivId": "2510.05771v1",
    "title": "Evidence of Cognitive Biases in Capture-the-Flag Cybersecurity Competitions",
    "abstract": "Understanding how cognitive biases influence adversarial decision-making is essential for developing effective cyber defenses. Capture-the-Flag (CTF) competitions provide an ecologically valid testbed to study attacker behavior at scale, simulating real-world intrusion scenarios under pressure. We analyze over 500,000 submission logs from picoCTF, a large educational CTF platform, to identify behavioral signatures of cognitive biases with defensive implications. Focusing on availability bias and the sunk cost fallacy, we employ a mixed-methods approach combining qualitative coding, descriptive statistics, and generalized linear modeling. Our findings show that participants often submitted flags with correct content but incorrect formatting (availability bias), and persisted in attempting challenges despite repeated failures and declining success probabilities (sunk cost fallacy). These patterns reveal that biases naturally shape attacker behavior in adversarial contexts. Building on these insights, we outline a framework for bias-informed adaptive defenses that anticipate, rather than simply react to, adversarial actions.",
    "authors": [
      "Carolina Carreira",
      "Anu Aggarwal",
      "Alejandro Cuevas",
      "Maria José Ferreira",
      "Hanan Hibshi",
      "Cleotilde Gonzalez"
    ],
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T10:41:03.000Z",
    "updatedAt": "2025-10-07T10:41:03.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05771v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05771v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05742v1",
    "arxivId": "2510.05742v1",
    "title": "Vipera: Blending Visual and LLM-Driven Guidance for Systematic Auditing of Text-to-Image Generative AI",
    "abstract": "Despite their increasing capabilities, text-to-image generative AI systems are known to produce biased, offensive, and otherwise problematic outputs. While recent advancements have supported testing and auditing of generative AI, existing auditing methods still face challenges in supporting effectively explore the vast space of AI-generated outputs in a structured way. To address this gap, we conducted formative studies with five AI auditors and synthesized five design goals for supporting systematic AI audits. Based on these insights, we developed Vipera, an interactive auditing interface that employs multiple visual cues including a scene graph to facilitate image sensemaking and inspire auditors to explore and hierarchically organize the auditing criteria. Additionally, Vipera leverages LLM-powered suggestions to facilitate exploration of unexplored auditing directions. Through a controlled experiment with 24 participants experienced in AI auditing, we demonstrate Vipera's effectiveness in helping auditors navigate large AI output spaces and organize their analyses while engaging with diverse criteria.",
    "authors": [
      "Yanwei Huang",
      "Wesley Hanwen Deng",
      "Sijia Xiao",
      "Motahhare Eslami",
      "Jason I. Hong",
      "Arpit Narechania",
      "Adam Perer"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T10:01:57.000Z",
    "updatedAt": "2025-10-07T10:01:57.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05742v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05742v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05738v1",
    "arxivId": "2510.05738v1",
    "title": "A Review of Ontology-Driven Big Data Analytics in Healthcare: Challenges, Tools, and Applications",
    "abstract": "Exponential growth in heterogeneous healthcare data arising from electronic health records (EHRs), medical imaging, wearable sensors, and biomedical research has accelerated the adoption of data lakes and centralized architectures capable of handling the Volume, Variety, and Velocity of Big Data for advanced analytics. However, without effective governance, these repositories risk devolving into disorganized data swamps. Ontology-driven semantic data management offers a robust solution by linking metadata to healthcare knowledge graphs, thereby enhancing semantic interoperability, improving data discoverability, and enabling expressive, domain-aware access. This review adopts a systematic research strategy, formulating key research questions and conducting a structured literature search across major academic databases, with selected studies analyzed and classified into six categories of ontology-driven healthcare analytics: (i) ontology-driven integration frameworks, (ii) semantic modeling for metadata enrichment, (iii) ontology-based data access (OBDA), (iv) basic semantic data management, (v) ontology-based reasoning for decision support, and (vi) semantic annotation for unstructured data. We further examine the integration of ontology technologies with Big Data frameworks such as Hadoop, Spark, Kafka, and so on, highlighting their combined potential to deliver scalable and intelligent healthcare analytics. For each category, recent techniques, representative case studies, technical and organizational challenges, and emerging trends such as artificial intelligence, machine learning, the Internet of Things (IoT), and real-time analytics are reviewed to guide the development of sustainable, interoperable, and high-performance healthcare data ecosystems.",
    "authors": [
      "Ritesh Chandra",
      "Sonali Agarwal",
      "Navjot Singh",
      "Sadhana Tiwari"
    ],
    "categories": [
      "cs.DC"
    ],
    "publishedAt": "2025-10-07T09:59:16.000Z",
    "updatedAt": "2025-10-07T09:59:16.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05738v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05738v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05711v1",
    "arxivId": "2510.05711v1",
    "title": "Intertemporal Pricing of Time-Bound Stablecoins: Measuring and Controlling the Liquidity-of-Time Premium",
    "abstract": "Time-bound stablecoins are DeFi assets that temporarily tokenize traditional securities during market off-hours, enabling continuous cross-market liquidity. We introduce the Liquidity-of-Time Premium (TLP): the extra return or cost of providing liquidity when the primary market is closed. We build a no-arbitrage pricing model that yields a band for fair values over different expiries, and a dynamic risk-control mechanism that adjusts loan-to-value (LTV) ratios in real time to keep TLP within a target range. Our analysis blends financial engineering (no-arbitrage conditions, option-style pricing) with empirical finance (event studies on cross-listed stocks and futures) to measure TLP under time-zone frictions. We define TLP formally, derive closed-form expressions for its term structure under idealized assumptions, and simulate scenarios that vary volatility and collateralization. We then propose an LTV policy that raises or lowers collateral to expand or curtail time-bound stablecoin supply, analogous to a central bank adjusting rates to defend a peg. We outline empirical proxies for TLP, including ADR premiums, overseas index futures versus cash index divergence, and pre-market versus official close gaps. Results show that TLP grows with closure length and volatility, yet can be contained by adaptive LTV. We provide backtests and figures (term-structure curves, capital-efficiency versus tail-risk trade-offs, time-liquidity heatmaps) and discuss protocol design (vault structure, closing-price oracles, on-chain auction liquidations). The findings position time-bound stablecoins as a tool to reduce temporal market inefficiencies and inform future research and deployment.",
    "authors": [
      "Ailiya Borjigin",
      "Cong He"
    ],
    "categories": [
      "cs.DC",
      "cs.CE"
    ],
    "publishedAt": "2025-10-07T09:23:37.000Z",
    "updatedAt": "2025-10-07T09:23:37.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05711v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05711v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05705v1",
    "arxivId": "2510.05705v1",
    "title": "The Software Observatory: aggregating and analysing software metadata for trend computation and FAIR assessment",
    "abstract": "In the ever-changing realm of research software development, it is crucial for the scientific community to grasp current trends to identify gaps that can potentially hinder scientific progress. The adherence to the FAIR (Findable, Accessible, Interoperable, Reusable) principles can serve as a proxy to understand those trends and provide a mechanism to propose specific actions. The Software Observatory at OpenEBench (https://openebench.bsc.es/observatory) is a novel web portal that consolidates software metadata from various sources, offering comprehensive insights into critical research software aspects. Our platform enables users to analyse trends, identify patterns and advancements within the Life Sciences research software ecosystem, and understand its evolution over time. It also evaluates research software according to FAIR principles for research software, providing scores for different indicators. Users have the ability to visualise this metadata at different levels of granularity, ranging from the entire software landscape to specific communities to individual software entries through the FAIRsoft Evaluator. Indeed, the FAIRsoft Evaluator component streamlines the assessment process, helping developers efficiently evaluate and obtain guidance to improve their software's FAIRness. The Software Observatory represents a valuable resource for researchers and software developers, as well as stakeholders, promoting better software development practices and adherence to FAIR principles for research software.",
    "authors": [
      "Eva Martín del Pico",
      "Josep Lluís Gelpí",
      "Salvador Capella-Gutiérrez"
    ],
    "categories": [
      "cs.SE",
      "cs.DL",
      "q-bio.OT"
    ],
    "publishedAt": "2025-10-07T09:15:02.000Z",
    "updatedAt": "2025-10-07T09:15:02.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05705v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05705v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05679v1",
    "arxivId": "2510.05679v1",
    "title": "Locability: An Ability-Based Ranking Model for Virtual Reality Locomotion Techniques",
    "abstract": "There are over a hundred virtual reality (VR) locomotion techniques that exist today, with new ones being designed as VR technology evolves. The different ways of controlling locomotion techniques (e.g., gestures, button inputs, body movements), along with the diversity of upper-body motor impairments, can make it difficult for a user to know which locomotion technique is best suited to their particular abilities. Moreover, trial-and-error can be difficult, time-consuming, and costly. Using machine learning techniques and data from 20 people with and without upper-body motor impairments, we developed a modeling approach to predict a ranked list of a user's fastest techniques based on questionnaire and interaction data. We found that a user's fastest technique could be predicted based on interaction data with 92% accuracy and that predicted locomotion times were within 12% of observed times. The model we trained could also rank six locomotion techniques based on speed with 61% accuracy and that predictions were within 8% of observed times. Our findings contribute to growing research in VR accessibility by taking an ability-based design approach to adapt systems to users' abilities.",
    "authors": [
      "Rachel L. Franz",
      "Jacob O. Wobbrock"
    ],
    "categories": [
      "cs.HC"
    ],
    "publishedAt": "2025-10-07T08:36:01.000Z",
    "updatedAt": "2025-10-07T08:36:01.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05679v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05679v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.05621v1",
    "arxivId": "2510.05621v1",
    "title": "Decoupling Correctness from Policy: A Deterministic Causal Structure for Multi-Agent Systems",
    "abstract": "In distributed multi-agent systems, correctness is often entangled with operational policies such as scheduling, batching, or routing, which makes systems brittle since performance-driven policy evolution may break integrity guarantees. This paper introduces the Deterministic Causal Structure (DCS), a formal foundation that decouples correctness from policy. We develop a minimal axiomatic theory and prove four results: existence and uniqueness, policy-agnostic invariance, observational equivalence, and axiom minimality. These results show that DCS resolves causal ambiguities that value-centric convergence models such as CRDTs cannot address, and that removing any axiom collapses determinism into ambiguity. DCS thus emerges as a boundary principle of asynchronous computation, analogous to CAP and FLP: correctness is preserved only within the expressive power of a join-semilattice. All guarantees are established by axioms and proofs, with only minimal illustrative constructions included to aid intuition. This work establishes correctness as a fixed, policy-agnostic substrate, a Correctness-as-a-Chassis paradigm, on which distributed intelligent systems can be built modularly, safely, and evolvably.",
    "authors": [
      "Zhiyuan Ren",
      "Tao Zhang",
      "Wenchi Chen"
    ],
    "categories": [
      "cs.DC",
      "cs.MA"
    ],
    "publishedAt": "2025-10-07T07:10:49.000Z",
    "updatedAt": "2025-10-07T07:10:49.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.05621v1",
    "pdfUrl": "https://arxiv.org/pdf/2510.05621v1.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.04952v2",
    "arxivId": "2510.04952v2",
    "title": "Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits",
    "abstract": "We present a cross-market algorithmic trading system that balances execution quality with rigorous compliance enforcement. The architecture comprises a high-level planner, a reinforcement learning execution agent, and an independent compliance agent. We formulate trade execution as a constrained Markov decision process with hard constraints on participation limits, price bands, and self-trading avoidance. The execution agent is trained with proximal policy optimization, while a runtime action-shield projects any unsafe action into a feasible set. To support auditability without exposing proprietary signals, we add a zero-knowledge compliance audit layer that produces cryptographic proofs that all actions satisfied the constraints. We evaluate in a multi-venue, ABIDES-based simulator and compare against standard baselines (e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and variance while exhibiting no observed constraint violations across stress scenarios including elevated latency, partial fills, compliance module toggling, and varying constraint limits. We report effects at the 95% confidence level using paired t-tests and examine tail risk via CVaR. We situate the work at the intersection of optimal execution, safe reinforcement learning, regulatory technology, and verifiable AI, and discuss ethical considerations, limitations (e.g., modeling assumptions and computational overhead), and paths to real-world deployment.",
    "authors": [
      "Ailiya Borjigin",
      "Cong He"
    ],
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "publishedAt": "2025-10-06T15:52:12.000Z",
    "updatedAt": "2025-10-07T07:12:41.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.04952v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.04952v2.pdf",
    "source": "arxiv"
  },
  {
    "id": "arxiv-2510.04748v2",
    "arxivId": "2510.04748v2",
    "title": "Social bias is prevalent in user reports of hate and abuse online",
    "abstract": "The prevalence of online hate and abuse is a pressing global concern. While tackling such societal harms is a priority for research across the social sciences, it is a difficult task, in part because of the magnitude of the problem. User engagement with reporting mechanisms (flagging) online is an increasingly important part of monitoring and addressing harmful content at scale. However, users may not flag content routinely enough, and when they do engage, they may be biased by group identity and political beliefs. Across five well-powered and pre-registered online experiments, we examine the extent of social bias in the flagging of hate and abuse in four different intergroup contexts: political affiliation, vaccination opinions, beliefs about climate change, and stance on abortion rights. Overall, participants reported abuse reliably, with approximately half of the abusive comments in each study reported. However, a pervasive social bias was present whereby ingroup-directed abuse was consistently flagged to a greater extent than outgroup-directed abuse. Our findings offer new insights into the nature of user flagging online, an understanding of which is crucial for enhancing user intervention against online hate speech and thus ensuring a safer online environment.",
    "authors": [
      "Florence E. Enock",
      "Helen Z. Margetts",
      "Jonathan Bright"
    ],
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "publishedAt": "2025-10-06T12:27:19.000Z",
    "updatedAt": "2025-10-07T15:07:13.000Z",
    "sourceUrl": "https://arxiv.org/abs/2510.04748v2",
    "pdfUrl": "https://arxiv.org/pdf/2510.04748v2.pdf",
    "source": "arxiv"
  }
]